{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d20fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficient_det\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficient_net (EfficientNet) multiple                  6771296   \n",
      "_________________________________________________________________\n",
      "bi_fpn (BiFPN)               multiple                  129126    \n",
      "_________________________________________________________________\n",
      "box_class_predict (BoxClassP multiple                  249069    \n",
      "=================================================================\n",
      "Total params: 7,149,491\n",
      "Trainable params: 7,106,515\n",
      "Non-trainable params: 42,976\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2428c044400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from configuration import Config\n",
    "from core.efficientdet import EfficientDet, PostProcessing\n",
    "\n",
    "\n",
    "def print_model_summary(network):\n",
    "    sample_inputs = tf.random.normal(shape=(Config.batch_size, Config.get_image_size()[0], Config.get_image_size()[1], Config.image_channels))\n",
    "    sample_outputs = network(sample_inputs, training=True)\n",
    "    network.summary()\n",
    "\n",
    "model = EfficientDet()\n",
    "print_model_summary(model)\n",
    "load_weights_from_epoch = Config.load_weights_from_epoch\n",
    "model.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b793d01",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: ./data/datasets/JPEGImages\\\\*'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19932/1571036838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/datasets/JPEGImages'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrepresentative_data_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mdataset_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/datasets/JPEGImages'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[1;34m(file_pattern, shuffle, seed)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m       assert_not_empty = control_flow_ops.Assert(\n\u001b[1;32m-> 1230\u001b[1;33m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[0m\u001b[0;32m   1231\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[0mmatching_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;34m\"\"\"Decorates the input function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m       return _add_should_use_warning(fn(*args, **kwargs),\n\u001b[0m\u001b[0;32m    248\u001b[0m                                      \u001b[0mwarn_in_eager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_in_eager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                                      error_in_function=error_in_function)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mAssert\u001b[1;34m(condition, data, summarize, name)\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m           \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Expected '%s' to be true. Summarized data: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m           (condition, \"\\n\".join(data_str)))\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: ./data/datasets/JPEGImages\\\\*'"
     ]
    }
   ],
   "source": [
    "dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "\n",
    "def representative_data_gen():\n",
    "  dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "  for i in range(100):\n",
    "    image = next(iter(dataset_list))\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (512,512))\n",
    "    # image = tf.cast(image / 255., tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "# Model has only one input so each data point has one element\n",
    "    yield [image]\n",
    "    \n",
    "\n",
    "    #### 수정좀 해보기\n",
    "def representative_data_gen():\n",
    "  dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "  for i in range(100):\n",
    "    image = next(iter(dataset_list))\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (512,512))\n",
    "    # image = tf.cast(image / 255., tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "# Model has only one input so each data point has one element\n",
    "    yield [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6dd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "converter.experimental_new_quantizer = True\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479105eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "for item in interpreter.get_tensor_details():\n",
    "    for key in item.keys():\n",
    "        print(\"%s : %s\" % (key, item[key]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tflite_model_quant.tflite', 'wb') as f:\n",
    "  f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1029241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/yutan/Desktop/EfficientDet_TensorFlow2/tflite_model_quant.tflite\"\n",
    "\n",
    "def load_model(path):  \n",
    "    interpreter = tf.lite.Interpreter(model_path = path)\n",
    "    return interpreter\n",
    "\n",
    "def data_pre(data):\n",
    "    \n",
    "    return\n",
    "\n",
    "def prediction(model, data):\n",
    "    interpreter = model\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_data = np.array(data, dtype = np.uint8)\n",
    "\n",
    "    interpreter.set_tensor(input_details['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data_class= interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data_bb= interpreter.get_tensor(output_details[1]['index'])\n",
    "\n",
    "    return output_data_class, output_data_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "image = next(iter(dataset_list))\n",
    "image = tf.io.read_file(image)\n",
    "image = tf.io.decode_jpeg(image, channels=3)\n",
    "image = tf.image.resize(image, (512,512))\n",
    "# image = tf.cast(image / 255., tf.float32)\n",
    "image = tf.expand_dims(image, 0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "classification, regression = prediction(model, image)\n",
    "\n",
    "print(classification.shape)\n",
    "print(regression[0][1])\n",
    "\n",
    "classification =  np.array(classification, dtype=np.float32)\n",
    "regression =  np.array(regression, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44345e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab4e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
