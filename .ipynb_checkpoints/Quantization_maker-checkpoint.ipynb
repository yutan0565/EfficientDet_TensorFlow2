{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d20fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Model: \"efficient_det\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficient_net (EfficientNet) multiple                  6771296   \n",
      "_________________________________________________________________\n",
      "bi_fpn (BiFPN)               multiple                  129126    \n",
      "_________________________________________________________________\n",
      "box_class_predict (BoxClassP multiple                  347736    \n",
      "=================================================================\n",
      "Total params: 7,248,158\n",
      "Trainable params: 7,205,182\n",
      "Non-trainable params: 42,976\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e132b9aef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from configuration import Config\n",
    "from core.efficientdet import EfficientDet, PostProcessing\n",
    "\n",
    "\n",
    "def print_model_summary(network):\n",
    "    sample_inputs = tf.random.normal(shape=(Config.batch_size, Config.get_image_size()[0], Config.get_image_size()[1], Config.image_channels))\n",
    "    sample_outputs = network(sample_inputs, training=True)\n",
    "    network.summary()\n",
    "\n",
    "model = EfficientDet()\n",
    "print_model_summary(model)\n",
    "load_weights_from_epoch = Config.load_weights_from_epoch\n",
    "model.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b793d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "\n",
    "def representative_data_gen():\n",
    "  dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "  for i in range(100):\n",
    "    image = next(iter(dataset_list))\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (512,512))\n",
    "    # image = tf.cast(image / 255., tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "# Model has only one input so each data point has one element\n",
    "    yield [image]\n",
    "    \n",
    "\n",
    "    #### 수정좀 해보기\n",
    "def representative_data_gen():\n",
    "  dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "  for i in range(100):\n",
    "    image = next(iter(dataset_list))\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (512,512))\n",
    "    # image = tf.cast(image / 255., tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "# Model has only one input so each data point has one element\n",
    "    yield [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6dd0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512, 512, 3)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(1, 512, 512, 3)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "converter.experimental_new_quantizer = True\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2140223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479105eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : input_1\n",
      "index : 0\n",
      "shape : [  1 512 512   3]\n",
      "shape_signature : [  1 512 512   3]\n",
      "dtype : <class 'numpy.uint8'>\n",
      "quantization : (1.0, 0)\n",
      "quantization_parameters : {'scales': array([1.], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices\n",
      "index : 1\n",
      "shape : [2]\n",
      "shape_signature : [2]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d/mul\n",
      "index : 2\n",
      "shape : [2]\n",
      "shape_signature : [2]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/Sum/reduction_indices\n",
      "index : 3\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d_1/mul\n",
      "index : 4\n",
      "shape : [2]\n",
      "shape_signature : [2]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d_2/mul\n",
      "index : 5\n",
      "shape : [2]\n",
      "shape_signature : [2]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d_3/mul\n",
      "index : 6\n",
      "shape : [2]\n",
      "shape_signature : [2]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape/shape\n",
      "index : 7\n",
      "shape : [3]\n",
      "shape_signature : [3]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_1/shape\n",
      "index : 8\n",
      "shape : [3]\n",
      "shape_signature : [3]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/conv2d/Conv2D\n",
      "index : 9\n",
      "shape : [32  3  3  3]\n",
      "shape_signature : [32  3  3  3]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00110028, 0.00116148, 0.00110143, 0.00115063, 0.0011666 ,\n",
      "       0.00114771, 0.00117466, 0.00111183, 0.00117161, 0.0010798 ,\n",
      "       0.00117127, 0.001134  , 0.00117169, 0.00117791, 0.00103485,\n",
      "       0.00113682, 0.00115056, 0.0011427 , 0.00103324, 0.00113701,\n",
      "       0.00111431, 0.00117153, 0.00116293, 0.00116762, 0.00112427,\n",
      "       0.00111516, 0.00103893, 0.00115343, 0.00115731, 0.00108991,\n",
      "       0.00101124, 0.00111048], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/batch_normalization/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D;efficient_det/efficient_net/conv2d/Conv2D\n",
      "index : 10\n",
      "shape : [32]\n",
      "shape_signature : [32]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00110028, 0.00116148, 0.00110143, 0.00115063, 0.0011666 ,\n",
      "       0.00114771, 0.00117466, 0.00111183, 0.00117161, 0.0010798 ,\n",
      "       0.00117127, 0.001134  , 0.00117169, 0.00117791, 0.00103485,\n",
      "       0.00113682, 0.00115056, 0.0011427 , 0.00103324, 0.00113701,\n",
      "       0.00111431, 0.00117153, 0.00116293, 0.00116762, 0.00112427,\n",
      "       0.00111516, 0.00103893, 0.00115343, 0.00115731, 0.00108991,\n",
      "       0.00101124, 0.00111048], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/conv2d_1/Conv2D\n",
      "index : 11\n",
      "shape : [32  1  1 32]\n",
      "shape_signature : [32  1  1 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00255586, 0.00252388, 0.0025148 , 0.00260632, 0.00250484,\n",
      "       0.00260936, 0.0025649 , 0.00251449, 0.00228026, 0.00239569,\n",
      "       0.00243815, 0.00254534, 0.00258216, 0.00243608, 0.00256504,\n",
      "       0.00256162, 0.00241933, 0.00254916, 0.00247273, 0.00252353,\n",
      "       0.0024869 , 0.00257571, 0.00247784, 0.00254042, 0.00252474,\n",
      "       0.00246566, 0.00247896, 0.00258339, 0.00250446, 0.00254209,\n",
      "       0.00256006, 0.00246447], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_1/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D;efficient_det/efficient_net/sequential/mb_conv/conv2d_1/Conv2D\n",
      "index : 12\n",
      "shape : [32]\n",
      "shape_signature : [32]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00326533, 0.00322447, 0.00321287, 0.00332979, 0.00320015,\n",
      "       0.00333368, 0.00327688, 0.00321248, 0.00291323, 0.0030607 ,\n",
      "       0.00311495, 0.00325189, 0.00329893, 0.0031123 , 0.00327706,\n",
      "       0.00327269, 0.0030909 , 0.00325677, 0.00315913, 0.00322402,\n",
      "       0.00317723, 0.0032907 , 0.00316565, 0.0032456 , 0.00322558,\n",
      "       0.0031501 , 0.00316709, 0.0033005 , 0.00319967, 0.00324774,\n",
      "       0.00327069, 0.00314857], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_2/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/depthwise_conv2d/depthwise;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D\n",
      "index : 13\n",
      "shape : [ 1  3  3 32]\n",
      "shape_signature : [ 1  3  3 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00120188, 0.00105883, 0.00121449, 0.00116219, 0.00117231,\n",
      "       0.00118846, 0.00113424, 0.00101639, 0.0008567 , 0.00092585,\n",
      "       0.00081509, 0.0011709 , 0.00114182, 0.00109019, 0.00099739,\n",
      "       0.00113689, 0.00107563, 0.00113   , 0.00115095, 0.00119922,\n",
      "       0.00101709, 0.00080256, 0.00110804, 0.00119738, 0.00115784,\n",
      "       0.00118122, 0.00115338, 0.00102326, 0.00111624, 0.00100491,\n",
      "       0.00092051, 0.00101314], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_2/FusedBatchNormV3\n",
      "index : 14\n",
      "shape : [32]\n",
      "shape_signature : [32]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.000714  , 0.00062902, 0.0007215 , 0.00069043, 0.00069644,\n",
      "       0.00070604, 0.00067382, 0.00060381, 0.00050894, 0.00055002,\n",
      "       0.00048423, 0.0006956 , 0.00067833, 0.00064765, 0.00059253,\n",
      "       0.0006754 , 0.00063901, 0.0006713 , 0.00068375, 0.00071243,\n",
      "       0.00060422, 0.00047678, 0.00065826, 0.00071133, 0.00068784,\n",
      "       0.00070173, 0.00068519, 0.0006079 , 0.00066313, 0.00059699,\n",
      "       0.00054685, 0.00060188], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/Conv2D\n",
      "index : 15\n",
      "shape : [ 8  1  1 32]\n",
      "shape_signature : [ 8  1  1 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00300347, 0.0029614 , 0.00267272, 0.00302858, 0.00275908,\n",
      "       0.00281396, 0.00303583, 0.00300241], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/BiasAdd;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/Conv2D;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/BiasAdd/ReadVariableOp/resource\n",
      "index : 16\n",
      "shape : [8]\n",
      "shape_signature : [8]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00061183, 0.00060326, 0.00054445, 0.00061694, 0.00056204,\n",
      "       0.00057322, 0.00061842, 0.00061161], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D\n",
      "index : 17\n",
      "shape : [32  1  1  8]\n",
      "shape_signature : [32  1  1  8]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00285381, 0.00300679, 0.00276414, 0.00290368, 0.00286378,\n",
      "       0.00289348, 0.00266868, 0.00294581, 0.00247339, 0.00289376,\n",
      "       0.00254778, 0.00271803, 0.00287761, 0.00279165, 0.00290123,\n",
      "       0.00293312, 0.00250047, 0.00214339, 0.00287124, 0.00284669,\n",
      "       0.00305049, 0.00244183, 0.00279155, 0.00296601, 0.00268798,\n",
      "       0.0029437 , 0.00298859, 0.00214924, 0.00288049, 0.00253722,\n",
      "       0.00297557, 0.00266419], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/BiasAdd;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/BiasAdd/ReadVariableOp/resource\n",
      "index : 18\n",
      "shape : [32]\n",
      "shape_signature : [32]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00017212, 0.00018135, 0.00016671, 0.00017513, 0.00017272,\n",
      "       0.00017451, 0.00016096, 0.00017767, 0.00014918, 0.00017453,\n",
      "       0.00015366, 0.00016393, 0.00017356, 0.00016837, 0.00017498,\n",
      "       0.0001769 , 0.00015081, 0.00012927, 0.00017317, 0.00017169,\n",
      "       0.00018398, 0.00014727, 0.00016837, 0.00017889, 0.00016212,\n",
      "       0.00017754, 0.00018025, 0.00012963, 0.00017373, 0.00015303,\n",
      "       0.00017947, 0.00016069], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/conv2d_4/Conv2D\n",
      "index : 19\n",
      "shape : [16  1  1 32]\n",
      "shape_signature : [16  1  1 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0029354 , 0.00298537, 0.00290762, 0.00300703, 0.00299803,\n",
      "       0.00257516, 0.00298005, 0.00298368, 0.0028748 , 0.00288035,\n",
      "       0.00267554, 0.0029513 , 0.00290765, 0.00298285, 0.00296952,\n",
      "       0.00292443], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_3/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/conv2d_4/Conv2D\n",
      "index : 20\n",
      "shape : [16]\n",
      "shape_signature : [16]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00022703, 0.0002309 , 0.00022488, 0.00023257, 0.00023188,\n",
      "       0.00019917, 0.00023049, 0.00023077, 0.00022235, 0.00022277,\n",
      "       0.00020693, 0.00022826, 0.00022489, 0.0002307 , 0.00022967,\n",
      "       0.00022618], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/conv2d_5/Conv2D\n",
      "index : 21\n",
      "shape : [96  1  1 16]\n",
      "shape_signature : [96  1  1 16]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00176892, 0.00172726, 0.00187393, 0.00193275, 0.00189305,\n",
      "       0.00188033, 0.00182939, 0.00191257, 0.00183691, 0.0017823 ,\n",
      "       0.0018105 , 0.00184997, 0.00173882, 0.00182083, 0.00186252,\n",
      "       0.00190171, 0.00179553, 0.00179123, 0.00181629, 0.00176235,\n",
      "       0.00183646, 0.0019485 , 0.00182392, 0.00186781, 0.00177614,\n",
      "       0.00187238, 0.0017981 , 0.00188199, 0.00152034, 0.00174572,\n",
      "       0.0019089 , 0.00189833, 0.00174827, 0.00192838, 0.00185423,\n",
      "       0.0019122 , 0.00178259, 0.00191515, 0.00189396, 0.00184463,\n",
      "       0.00193   , 0.00183025, 0.00188618, 0.00182742, 0.00185411,\n",
      "       0.00181423, 0.00183961, 0.00178918, 0.00171226, 0.0019108 ,\n",
      "       0.00191983, 0.00189148, 0.00192865, 0.0018691 , 0.0017855 ,\n",
      "       0.00187889, 0.00189149, 0.00186644, 0.00181271, 0.0018833 ,\n",
      "       0.00183201, 0.00190309, 0.0015848 , 0.00189943, 0.00193127,\n",
      "       0.00174752, 0.00182369, 0.00175815, 0.00184894, 0.00184035,\n",
      "       0.00185039, 0.00185482, 0.00172428, 0.00184925, 0.00187687,\n",
      "       0.00193921, 0.00194265, 0.00175011, 0.00194731, 0.00176485,\n",
      "       0.00191967, 0.00185278, 0.00163269, 0.00183701, 0.00181383,\n",
      "       0.00188017, 0.00190447, 0.00173784, 0.00191674, 0.00184165,\n",
      "       0.00188135, 0.00190588, 0.00174705, 0.00176441, 0.00185426,\n",
      "       0.00189238], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_4/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/conv2d_5/Conv2D\n",
      "index : 22\n",
      "shape : [96]\n",
      "shape_signature : [96]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.03379207e-04, 1.00944584e-04, 1.09515720e-04, 1.12953487e-04,\n",
      "       1.10633380e-04, 1.09889996e-04, 1.06913052e-04, 1.11774090e-04,\n",
      "       1.07352440e-04, 1.04160739e-04, 1.05808707e-04, 1.08115855e-04,\n",
      "       1.01619815e-04, 1.06412903e-04, 1.08849243e-04, 1.11139496e-04,\n",
      "       1.04933926e-04, 1.04682607e-04, 1.06147105e-04, 1.02995014e-04,\n",
      "       1.07326014e-04, 1.13873946e-04, 1.06593179e-04, 1.09158464e-04,\n",
      "       1.03800900e-04, 1.09425222e-04, 1.05084051e-04, 1.09987152e-04,\n",
      "       8.88512732e-05, 1.02023281e-04, 1.11559646e-04, 1.10941925e-04,\n",
      "       1.02172140e-04, 1.12698122e-04, 1.08364940e-04, 1.11752539e-04,\n",
      "       1.04177860e-04, 1.11925154e-04, 1.10686677e-04, 1.07803899e-04,\n",
      "       1.12792804e-04, 1.06963416e-04, 1.10231755e-04, 1.06797917e-04,\n",
      "       1.08357919e-04, 1.06026768e-04, 1.07510430e-04, 1.04563209e-04,\n",
      "       1.00067722e-04, 1.11670481e-04, 1.12198381e-04, 1.10541689e-04,\n",
      "       1.12713627e-04, 1.09233602e-04, 1.04347993e-04, 1.09806082e-04,\n",
      "       1.10541958e-04, 1.09078414e-04, 1.05938132e-04, 1.10063767e-04,\n",
      "       1.07065971e-04, 1.11220055e-04, 9.26184730e-05, 1.11006077e-04,\n",
      "       1.12866808e-04, 1.02128062e-04, 1.06579631e-04, 1.02749385e-04,\n",
      "       1.08055428e-04, 1.07553773e-04, 1.08140215e-04, 1.08399341e-04,\n",
      "       1.00770012e-04, 1.08073458e-04, 1.09687709e-04, 1.13331284e-04,\n",
      "       1.13532289e-04, 1.02279424e-04, 1.13804163e-04, 1.03141319e-04,\n",
      "       1.12189031e-04, 1.08280030e-04, 9.54174538e-05, 1.07358355e-04,\n",
      "       1.06003848e-04, 1.09880450e-04, 1.11300578e-04, 1.01562495e-04,\n",
      "       1.12017646e-04, 1.07629552e-04, 1.09949629e-04, 1.11383299e-04,\n",
      "       1.02100676e-04, 1.03115672e-04, 1.08366272e-04, 1.10594468e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_5/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_1/depthwise_conv2d_1/depthwise;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D\n",
      "index : 23\n",
      "shape : [ 1  3  3 96]\n",
      "shape_signature : [ 1  3  3 96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00061604, 0.00049939, 0.00063967, 0.00070969, 0.00070255,\n",
      "       0.00067531, 0.00060781, 0.00071335, 0.00060269, 0.00060667,\n",
      "       0.00063241, 0.00066563, 0.00067433, 0.0006789 , 0.00055426,\n",
      "       0.00061333, 0.00070054, 0.00070188, 0.0006887 , 0.00061457,\n",
      "       0.00063031, 0.00062727, 0.00064738, 0.0005987 , 0.00069215,\n",
      "       0.00054422, 0.00061147, 0.00069554, 0.00067969, 0.00063515,\n",
      "       0.00065332, 0.00068786, 0.00059588, 0.00049554, 0.00061462,\n",
      "       0.00067512, 0.00067352, 0.0006999 , 0.00053701, 0.00062316,\n",
      "       0.00063817, 0.00062084, 0.00068803, 0.00069741, 0.00066485,\n",
      "       0.00066311, 0.00066441, 0.00065929, 0.00054424, 0.00070483,\n",
      "       0.00070204, 0.00066253, 0.00062362, 0.00057481, 0.00066412,\n",
      "       0.00065668, 0.00058532, 0.00070277, 0.0006089 , 0.00070276,\n",
      "       0.00067848, 0.00069503, 0.00051501, 0.00066377, 0.00068175,\n",
      "       0.00060278, 0.00067634, 0.0006938 , 0.00067785, 0.00063082,\n",
      "       0.0006327 , 0.00071126, 0.00068729, 0.00068254, 0.00068284,\n",
      "       0.00063495, 0.00070208, 0.00065893, 0.00064876, 0.00069777,\n",
      "       0.00065725, 0.0006744 , 0.00041751, 0.00070656, 0.00069308,\n",
      "       0.00057939, 0.00067765, 0.00061579, 0.00056203, 0.00034091,\n",
      "       0.00059709, 0.00064617, 0.00059606, 0.00068554, 0.00065689,\n",
      "       0.00065098], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_5/FusedBatchNormV3\n",
      "index : 24\n",
      "shape : [96]\n",
      "shape_signature : [96]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.45056210e-05, 1.17589307e-05, 1.50622545e-05, 1.67108974e-05,\n",
      "       1.65426463e-05, 1.59012798e-05, 1.43118841e-05, 1.67971630e-05,\n",
      "       1.41914907e-05, 1.42849940e-05, 1.48911022e-05, 1.56733477e-05,\n",
      "       1.58781932e-05, 1.59858755e-05, 1.30510043e-05, 1.44419992e-05,\n",
      "       1.64953490e-05, 1.65270285e-05, 1.62166998e-05, 1.44710048e-05,\n",
      "       1.48418485e-05, 1.47702676e-05, 1.52436414e-05, 1.40974162e-05,\n",
      "       1.62979177e-05, 1.28145448e-05, 1.43982115e-05, 1.63777604e-05,\n",
      "       1.60045984e-05, 1.49556345e-05, 1.53834499e-05, 1.61969620e-05,\n",
      "       1.40309521e-05, 1.16684023e-05, 1.44723426e-05, 1.58969724e-05,\n",
      "       1.58591902e-05, 1.64802714e-05, 1.26447731e-05, 1.46733400e-05,\n",
      "       1.50267188e-05, 1.46186958e-05, 1.62009437e-05, 1.64217672e-05,\n",
      "       1.56550323e-05, 1.56141195e-05, 1.56446240e-05, 1.55241160e-05,\n",
      "       1.28151123e-05, 1.65965193e-05, 1.65307702e-05, 1.56003971e-05,\n",
      "       1.46841594e-05, 1.35349146e-05, 1.56378519e-05, 1.54626159e-05,\n",
      "       1.37822799e-05, 1.65478650e-05, 1.43377001e-05, 1.65478141e-05,\n",
      "       1.59760402e-05, 1.63658060e-05, 1.21268631e-05, 1.56295828e-05,\n",
      "       1.60529871e-05, 1.41933888e-05, 1.59255251e-05, 1.63368022e-05,\n",
      "       1.59611063e-05, 1.48536428e-05, 1.48979125e-05, 1.67479229e-05,\n",
      "       1.61834087e-05, 1.60716427e-05, 1.60786149e-05, 1.49509988e-05,\n",
      "       1.65316051e-05, 1.55156631e-05, 1.52762386e-05, 1.64302564e-05,\n",
      "       1.54761219e-05, 1.58799612e-05, 9.83097925e-06, 1.66372483e-05,\n",
      "       1.63197146e-05, 1.36427452e-05, 1.59564297e-05, 1.44998230e-05,\n",
      "       1.32340792e-05, 8.02723389e-06, 1.40596358e-05, 1.52152425e-05,\n",
      "       1.40352759e-05, 1.61421194e-05, 1.54676436e-05, 1.53284946e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/Conv2D\n",
      "index : 25\n",
      "shape : [24  1  1 96]\n",
      "shape_signature : [24  1  1 96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00175863, 0.00175694, 0.00176632, 0.00175717, 0.00176125,\n",
      "       0.00175955, 0.00175195, 0.0017066 , 0.00175235, 0.00175638,\n",
      "       0.00174337, 0.00173787, 0.00172547, 0.00174291, 0.00175784,\n",
      "       0.0017511 , 0.00175225, 0.00172364, 0.00173075, 0.00175073,\n",
      "       0.0017562 , 0.00175161, 0.00173992, 0.00173403], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/BiasAdd;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/BiasAdd/ReadVariableOp/resource\n",
      "index : 26\n",
      "shape : [24]\n",
      "shape_signature : [24]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.5011985e-06, 7.4939908e-06, 7.5339890e-06, 7.4949799e-06,\n",
      "       7.5123967e-06, 7.5051421e-06, 7.4727031e-06, 7.2792600e-06,\n",
      "       7.4744030e-06, 7.4916179e-06, 7.4361333e-06, 7.4126424e-06,\n",
      "       7.3597780e-06, 7.4341424e-06, 7.4978248e-06, 7.4691011e-06,\n",
      "       7.4739737e-06, 7.3519705e-06, 7.3822853e-06, 7.4675095e-06,\n",
      "       7.4908417e-06, 7.4712457e-06, 7.4214154e-06, 7.3962756e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D\n",
      "index : 27\n",
      "shape : [96  1  1 24]\n",
      "shape_signature : [96  1  1 24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00159893, 0.00159649, 0.00168439, 0.00174469, 0.00172057,\n",
      "       0.001746  , 0.00157593, 0.0017248 , 0.00174851, 0.0017256 ,\n",
      "       0.00156949, 0.00172392, 0.00165492, 0.00173179, 0.00175306,\n",
      "       0.00165102, 0.00172486, 0.00167707, 0.00163565, 0.00171767,\n",
      "       0.00171348, 0.00175828, 0.0017454 , 0.00173491, 0.00173673,\n",
      "       0.00161346, 0.00171816, 0.00169708, 0.00174432, 0.00162894,\n",
      "       0.00169077, 0.00162745, 0.00168147, 0.00173631, 0.00168673,\n",
      "       0.00162911, 0.00174612, 0.00162587, 0.00173521, 0.0017255 ,\n",
      "       0.00170744, 0.00164226, 0.00170716, 0.00171222, 0.00174965,\n",
      "       0.00172746, 0.00171835, 0.00176664, 0.00175967, 0.0014328 ,\n",
      "       0.0016991 , 0.00171443, 0.00171287, 0.00169781, 0.0016564 ,\n",
      "       0.00167406, 0.00175634, 0.00158613, 0.00155571, 0.00176192,\n",
      "       0.00171961, 0.00173886, 0.00166184, 0.00172153, 0.0017332 ,\n",
      "       0.00163661, 0.0016268 , 0.00174306, 0.00172241, 0.00171343,\n",
      "       0.00155557, 0.00169457, 0.00170568, 0.00173797, 0.0017226 ,\n",
      "       0.00153545, 0.00175813, 0.00173011, 0.00155538, 0.00175814,\n",
      "       0.0017209 , 0.0016464 , 0.00158475, 0.00154902, 0.00175932,\n",
      "       0.00171681, 0.00174093, 0.00175674, 0.00176414, 0.00149037,\n",
      "       0.00171269, 0.0016437 , 0.00173564, 0.00175358, 0.00174324,\n",
      "       0.00176223], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/BiasAdd;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/BiasAdd/ReadVariableOp/resource\n",
      "index : 28\n",
      "shape : [96]\n",
      "shape_signature : [96]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.2416473e-06, 2.2382153e-06, 2.3614525e-06, 2.4459860e-06,\n",
      "       2.4121800e-06, 2.4478231e-06, 2.2094002e-06, 2.4181090e-06,\n",
      "       2.4513463e-06, 2.4192345e-06, 2.2003685e-06, 2.4168703e-06,\n",
      "       2.3201305e-06, 2.4279109e-06, 2.4577305e-06, 2.3146722e-06,\n",
      "       2.4181895e-06, 2.3511936e-06, 2.2931154e-06, 2.4081116e-06,\n",
      "       2.4022411e-06, 2.4650446e-06, 2.4469914e-06, 2.4322819e-06,\n",
      "       2.4348371e-06, 2.2620156e-06, 2.4087974e-06, 2.3792386e-06,\n",
      "       2.4454798e-06, 2.2837075e-06, 2.3704008e-06, 2.2816287e-06,\n",
      "       2.3573662e-06, 2.4342401e-06, 2.3647299e-06, 2.2839542e-06,\n",
      "       2.4480023e-06, 2.2794134e-06, 2.4327062e-06, 2.4190817e-06,\n",
      "       2.3937678e-06, 2.3023877e-06, 2.3933828e-06, 2.4004721e-06,\n",
      "       2.4529427e-06, 2.4218416e-06, 2.4090650e-06, 2.4767603e-06,\n",
      "       2.4669971e-06, 2.0087343e-06, 2.3820801e-06, 2.4035683e-06,\n",
      "       2.4013850e-06, 2.3802697e-06, 2.3222187e-06, 2.3469718e-06,\n",
      "       2.4623309e-06, 2.2237014e-06, 2.1810433e-06, 2.4701405e-06,\n",
      "       2.4108349e-06, 2.4378203e-06, 2.3298403e-06, 2.4135197e-06,\n",
      "       2.4298847e-06, 2.2944630e-06, 2.2807085e-06, 2.4437068e-06,\n",
      "       2.4147532e-06, 2.4021658e-06, 2.1808464e-06, 2.3757284e-06,\n",
      "       2.3912969e-06, 2.4365731e-06, 2.4150190e-06, 2.1526459e-06,\n",
      "       2.4648323e-06, 2.4255557e-06, 2.1805854e-06, 2.4648502e-06,\n",
      "       2.4126434e-06, 2.3081989e-06, 2.2217623e-06, 2.1716687e-06,\n",
      "       2.4665053e-06, 2.4069084e-06, 2.4407245e-06, 2.4628816e-06,\n",
      "       2.4732569e-06, 2.0894383e-06, 2.4011247e-06, 2.3044006e-06,\n",
      "       2.4333017e-06, 2.4584506e-06, 2.4439594e-06, 2.4705816e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/conv2d_8/Conv2D\n",
      "index : 29\n",
      "shape : [24  1  1 96]\n",
      "shape_signature : [24  1  1 96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00189842, 0.00189019, 0.00188442, 0.00184336, 0.00188784,\n",
      "       0.00188002, 0.00187071, 0.00188095, 0.00187682, 0.00189912,\n",
      "       0.0018866 , 0.00190133, 0.00188194, 0.0018768 , 0.00189617,\n",
      "       0.00188164, 0.00189677, 0.00184854, 0.00188138, 0.001866  ,\n",
      "       0.00186716, 0.0018595 , 0.00188041, 0.00185619], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_6/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/conv2d_8/Conv2D\n",
      "index : 30\n",
      "shape : [24]\n",
      "shape_signature : [24]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.1577664e-06, 4.1397448e-06, 4.1271228e-06, 4.0371788e-06,\n",
      "       4.1346102e-06, 4.1174844e-06, 4.0970840e-06, 4.1195162e-06,\n",
      "       4.1104599e-06, 4.1593057e-06, 4.1318908e-06, 4.1641520e-06,\n",
      "       4.1216745e-06, 4.1104313e-06, 4.1528497e-06, 4.1210192e-06,\n",
      "       4.1541721e-06, 4.0485247e-06, 4.1204617e-06, 4.0867781e-06,\n",
      "       4.0893060e-06, 4.0725276e-06, 4.1183221e-06, 4.0652808e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_9/Conv2D\n",
      "index : 31\n",
      "shape : [144   1   1  24]\n",
      "shape_signature : [144   1   1  24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00153257, 0.00153675, 0.00154954, 0.00147324, 0.00156292,\n",
      "       0.00156203, 0.00158501, 0.00154971, 0.0015882 , 0.00153627,\n",
      "       0.00154454, 0.0015779 , 0.00150719, 0.00158248, 0.00152727,\n",
      "       0.00157777, 0.00155456, 0.00133251, 0.00153558, 0.00156607,\n",
      "       0.00151983, 0.00151794, 0.00156051, 0.00150151, 0.00144793,\n",
      "       0.00154345, 0.00152628, 0.00155321, 0.00149229, 0.00154455,\n",
      "       0.00147325, 0.00144798, 0.0015728 , 0.00151505, 0.00155978,\n",
      "       0.00155816, 0.00158071, 0.00149651, 0.00152976, 0.00152478,\n",
      "       0.00158506, 0.00148608, 0.00157806, 0.00149426, 0.00147603,\n",
      "       0.00146448, 0.00156609, 0.00157197, 0.00148727, 0.00138929,\n",
      "       0.00140458, 0.00157249, 0.00156349, 0.00150147, 0.00152788,\n",
      "       0.00154376, 0.00154582, 0.00154744, 0.0015069 , 0.00150651,\n",
      "       0.00154303, 0.00155413, 0.0015462 , 0.00154861, 0.00147943,\n",
      "       0.00144745, 0.00146685, 0.00156072, 0.00156681, 0.00154011,\n",
      "       0.00154951, 0.00148785, 0.00139662, 0.00153435, 0.00159653,\n",
      "       0.00155309, 0.00158558, 0.00150119, 0.00146967, 0.0015125 ,\n",
      "       0.00147086, 0.00152142, 0.00156595, 0.00151332, 0.00146871,\n",
      "       0.00131492, 0.00154728, 0.00151942, 0.00156964, 0.00156243,\n",
      "       0.001406  , 0.00156299, 0.00155065, 0.00136647, 0.00155401,\n",
      "       0.00149636, 0.00154841, 0.00144749, 0.00142099, 0.00147154,\n",
      "       0.00149634, 0.00156133, 0.00148979, 0.00149315, 0.00147283,\n",
      "       0.0014275 , 0.00136711, 0.00149546, 0.00156741, 0.00150736,\n",
      "       0.00153052, 0.00156638, 0.0015315 , 0.00148813, 0.00150596,\n",
      "       0.00158658, 0.00151848, 0.00151404, 0.00157078, 0.00152623,\n",
      "       0.00147634, 0.00149063, 0.00148867, 0.0015519 , 0.00150596,\n",
      "       0.00150365, 0.00156522, 0.00151304, 0.00153245, 0.001505  ,\n",
      "       0.00153261, 0.00144872, 0.00151748, 0.00155159, 0.00157942,\n",
      "       0.00150312, 0.00156834, 0.00147581, 0.00157224, 0.00156737,\n",
      "       0.00155565, 0.00154436, 0.00156313, 0.00151651], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_7/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_9/Conv2D\n",
      "index : 32\n",
      "shape : [144]\n",
      "shape_signature : [144]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.1028534e-06, 2.1085821e-06, 2.1261335e-06, 2.0214452e-06,\n",
      "       2.1444898e-06, 2.1432772e-06, 2.1748015e-06, 2.1263704e-06,\n",
      "       2.1791825e-06, 2.1079297e-06, 2.1192714e-06, 2.1650430e-06,\n",
      "       2.0680200e-06, 2.1713270e-06, 2.0955752e-06, 2.1648691e-06,\n",
      "       2.1330218e-06, 1.8283444e-06, 2.1069820e-06, 2.1488120e-06,\n",
      "       2.0853743e-06, 2.0827806e-06, 2.1411904e-06, 2.0602336e-06,\n",
      "       1.9867166e-06, 2.1177755e-06, 2.0942207e-06, 2.1311762e-06,\n",
      "       2.0475859e-06, 2.1192916e-06, 2.0214557e-06, 1.9867882e-06,\n",
      "       2.1580508e-06, 2.0788118e-06, 2.1401836e-06, 2.1379606e-06,\n",
      "       2.1689073e-06, 2.0533662e-06, 2.0989953e-06, 2.0921652e-06,\n",
      "       2.1748656e-06, 2.0390610e-06, 2.1652636e-06, 2.0502891e-06,\n",
      "       2.0252664e-06, 2.0094262e-06, 2.1488452e-06, 2.1569083e-06,\n",
      "       2.0406983e-06, 1.9062594e-06, 1.9272318e-06, 2.1576277e-06,\n",
      "       2.1452736e-06, 2.0601769e-06, 2.0964078e-06, 2.1182086e-06,\n",
      "       2.1210321e-06, 2.1232502e-06, 2.0676327e-06, 2.0670943e-06,\n",
      "       2.1172057e-06, 2.1324386e-06, 2.1215465e-06, 2.1248559e-06,\n",
      "       2.0299296e-06, 1.9860590e-06, 2.0126688e-06, 2.1414749e-06,\n",
      "       2.1498245e-06, 2.1131971e-06, 2.1260937e-06, 2.0414843e-06,\n",
      "       1.9163072e-06, 2.1052940e-06, 2.1906160e-06, 2.1310025e-06,\n",
      "       2.1755898e-06, 2.0597922e-06, 2.0165430e-06, 2.0753173e-06,\n",
      "       2.0181790e-06, 2.0875448e-06, 2.1486487e-06, 2.0764414e-06,\n",
      "       2.0152258e-06, 1.8042117e-06, 2.1230348e-06, 2.0848040e-06,\n",
      "       2.1537153e-06, 2.1438238e-06, 1.9291842e-06, 2.1445940e-06,\n",
      "       2.1276633e-06, 1.8749421e-06, 2.1322721e-06, 2.0531650e-06,\n",
      "       2.1245862e-06, 1.9861156e-06, 1.9497506e-06, 2.0191146e-06,\n",
      "       2.0531370e-06, 2.1423120e-06, 2.0441528e-06, 2.0487644e-06,\n",
      "       2.0208870e-06, 1.9586878e-06, 1.8758201e-06, 2.0519276e-06,\n",
      "       2.1506607e-06, 2.0682530e-06, 2.1000401e-06, 2.1492419e-06,\n",
      "       2.1013839e-06, 2.0418727e-06, 2.0663317e-06, 2.1769597e-06,\n",
      "       2.0835216e-06, 2.0774205e-06, 2.1552714e-06, 2.0941452e-06,\n",
      "       2.0256928e-06, 2.0453047e-06, 2.0426148e-06, 2.1293743e-06,\n",
      "       2.0663326e-06, 2.0631649e-06, 2.1476544e-06, 2.0760529e-06,\n",
      "       2.1026804e-06, 2.0650239e-06, 2.1029011e-06, 1.9878014e-06,\n",
      "       2.0821406e-06, 2.1289418e-06, 2.1671335e-06, 2.0624402e-06,\n",
      "       2.1519327e-06, 2.0249659e-06, 2.1572782e-06, 2.1506037e-06,\n",
      "       2.1345170e-06, 2.1190258e-06, 2.1447768e-06, 2.0808111e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_8/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_2/depthwise_conv2d_2/depthwise;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D\n",
      "index : 33\n",
      "shape : [  1   3   3 144]\n",
      "shape_signature : [  1   3   3 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00056073, 0.00056144, 0.00055887, 0.00049807, 0.00039277,\n",
      "       0.00056998, 0.00056293, 0.00051478, 0.00042198, 0.00055703,\n",
      "       0.00054304, 0.00057108, 0.00048777, 0.00054779, 0.00053404,\n",
      "       0.00057295, 0.00052041, 0.00046968, 0.00047643, 0.00055432,\n",
      "       0.00049028, 0.00053257, 0.00055646, 0.00056425, 0.00054885,\n",
      "       0.00053171, 0.0005254 , 0.00054016, 0.00057611, 0.00057302,\n",
      "       0.00054479, 0.0005771 , 0.00050954, 0.00054251, 0.00056904,\n",
      "       0.00055892, 0.00052421, 0.00058277, 0.00052958, 0.00035947,\n",
      "       0.00043353, 0.00056876, 0.00051903, 0.0005699 , 0.0004532 ,\n",
      "       0.00051101, 0.00045468, 0.00044354, 0.00043284, 0.00051175,\n",
      "       0.00058226, 0.00056199, 0.00051044, 0.00054942, 0.00056843,\n",
      "       0.00049349, 0.00051669, 0.00053118, 0.00055379, 0.00057963,\n",
      "       0.0005409 , 0.00050348, 0.0004838 , 0.00051724, 0.00042147,\n",
      "       0.00050967, 0.00049499, 0.0005428 , 0.00053613, 0.00026359,\n",
      "       0.00044781, 0.00054385, 0.00057153, 0.00057618, 0.00050469,\n",
      "       0.00054642, 0.00042437, 0.00052767, 0.000542  , 0.00053825,\n",
      "       0.00057425, 0.00052421, 0.00026102, 0.00050667, 0.00057208,\n",
      "       0.00050311, 0.00049692, 0.00057768, 0.00047978, 0.0002964 ,\n",
      "       0.0002948 , 0.00038661, 0.00048937, 0.00042537, 0.00053865,\n",
      "       0.00056812, 0.00054902, 0.00054643, 0.00052725, 0.00055006,\n",
      "       0.00057801, 0.00054278, 0.00044877, 0.00055559, 0.0005596 ,\n",
      "       0.00044108, 0.00051936, 0.00043882, 0.00056347, 0.00052787,\n",
      "       0.0005814 , 0.00054018, 0.00046024, 0.00049121, 0.0005235 ,\n",
      "       0.00056973, 0.00053737, 0.00054055, 0.00055958, 0.00054533,\n",
      "       0.00045325, 0.00055477, 0.00053503, 0.00049793, 0.00056886,\n",
      "       0.0004884 , 0.00044798, 0.00057884, 0.00053832, 0.00036109,\n",
      "       0.00057517, 0.00053739, 0.00051419, 0.00043263, 0.00050911,\n",
      "       0.00054088, 0.00043419, 0.00052989, 0.00052311, 0.00055803,\n",
      "       0.00040441, 0.00057863, 0.00050039, 0.00053854], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_8/FusedBatchNormV3\n",
      "index : 34\n",
      "shape : [144]\n",
      "shape_signature : [144]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.0828309e-07, 3.0867395e-07, 3.0726332e-07, 2.7383342e-07,\n",
      "       2.1593989e-07, 3.1337012e-07, 3.0949536e-07, 2.8302009e-07,\n",
      "       2.3200337e-07, 3.0625301e-07, 2.9855983e-07, 3.1397482e-07,\n",
      "       2.6817429e-07, 3.0117107e-07, 2.9361379e-07, 3.1500201e-07,\n",
      "       2.8611527e-07, 2.5822769e-07, 2.6194030e-07, 3.0475860e-07,\n",
      "       2.6955152e-07, 2.9280235e-07, 3.0593995e-07, 3.1022316e-07,\n",
      "       3.0175227e-07, 2.9233021e-07, 2.8886174e-07, 2.9697816e-07,\n",
      "       3.1674301e-07, 3.1503998e-07, 2.9951943e-07, 3.1728450e-07,\n",
      "       2.8014054e-07, 2.9826685e-07, 3.1285421e-07, 3.0728881e-07,\n",
      "       2.8820509e-07, 3.2040393e-07, 2.9116217e-07, 1.9763212e-07,\n",
      "       2.3835349e-07, 3.1270213e-07, 2.8536019e-07, 3.1332578e-07,\n",
      "       2.4916812e-07, 2.8095110e-07, 2.4997721e-07, 2.4385602e-07,\n",
      "       2.3797475e-07, 2.8135526e-07, 3.2012068e-07, 3.0897604e-07,\n",
      "       2.8063801e-07, 3.0206908e-07, 3.1252088e-07, 2.7131946e-07,\n",
      "       2.8407220e-07, 2.9203704e-07, 3.0446904e-07, 3.1867870e-07,\n",
      "       2.9738226e-07, 2.7681236e-07, 2.6598957e-07, 2.8437699e-07,\n",
      "       2.3171940e-07, 2.8021353e-07, 2.7214105e-07, 2.9842818e-07,\n",
      "       2.9476061e-07, 1.4491822e-07, 2.4620095e-07, 2.9900744e-07,\n",
      "       3.1422459e-07, 3.1677916e-07, 2.7747677e-07, 3.0041659e-07,\n",
      "       2.3331380e-07, 2.9011161e-07, 2.9798866e-07, 2.9592732e-07,\n",
      "       3.1571935e-07, 2.8820750e-07, 1.4350688e-07, 2.7856470e-07,\n",
      "       3.1452365e-07, 2.7660576e-07, 2.7320078e-07, 3.1760268e-07,\n",
      "       2.6377785e-07, 1.6296067e-07, 1.6207707e-07, 2.1255396e-07,\n",
      "       2.6905292e-07, 2.3386278e-07, 2.9614674e-07, 3.1234953e-07,\n",
      "       3.0184609e-07, 3.0042204e-07, 2.8988080e-07, 3.0242015e-07,\n",
      "       3.1778774e-07, 2.9841431e-07, 2.4673045e-07, 3.0545718e-07,\n",
      "       3.0766319e-07, 2.4250494e-07, 2.8553990e-07, 2.4126192e-07,\n",
      "       3.0979413e-07, 2.9022107e-07, 3.1965070e-07, 2.9698484e-07,\n",
      "       2.5303902e-07, 2.7006317e-07, 2.8781517e-07, 3.1323310e-07,\n",
      "       2.9544157e-07, 2.9719197e-07, 3.0765111e-07, 2.9981715e-07,\n",
      "       2.4919365e-07, 3.0500811e-07, 2.9415418e-07, 2.7376015e-07,\n",
      "       3.1275428e-07, 2.6852055e-07, 2.4629819e-07, 3.1824405e-07,\n",
      "       2.9596649e-07, 1.9852540e-07, 3.1622719e-07, 2.9545512e-07,\n",
      "       2.8269622e-07, 2.3785567e-07, 2.7990393e-07, 2.9737441e-07,\n",
      "       2.3871394e-07, 2.9132758e-07, 2.8760081e-07, 3.0680150e-07,\n",
      "       2.2234012e-07, 3.1812911e-07, 2.7511089e-07, 2.9608390e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/Conv2D\n",
      "index : 35\n",
      "shape : [ 36   1   1 144]\n",
      "shape_signature : [ 36   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00139508, 0.00141577, 0.00142585, 0.00143719, 0.00143909,\n",
      "       0.00142942, 0.00143136, 0.00143454, 0.00143716, 0.00144215,\n",
      "       0.0014345 , 0.00143627, 0.00143832, 0.00141706, 0.00143974,\n",
      "       0.00143249, 0.00141949, 0.00142156, 0.00143466, 0.00143102,\n",
      "       0.00143937, 0.00139119, 0.00143379, 0.00142487, 0.0014329 ,\n",
      "       0.00143733, 0.00143133, 0.00142051, 0.0014136 , 0.00142791,\n",
      "       0.00142355, 0.00142637, 0.00143232, 0.00140012, 0.00142332,\n",
      "       0.00143325], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/BiasAdd;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/BiasAdd/ReadVariableOp/resource\n",
      "index : 36\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.2184265e-07, 1.2364991e-07, 1.2453059e-07, 1.2552081e-07,\n",
      "       1.2568643e-07, 1.2484243e-07, 1.2501174e-07, 1.2528895e-07,\n",
      "       1.2551830e-07, 1.2595433e-07, 1.2528629e-07, 1.2544066e-07,\n",
      "       1.2561935e-07, 1.2376309e-07, 1.2574378e-07, 1.2511003e-07,\n",
      "       1.2397474e-07, 1.2415569e-07, 1.2530023e-07, 1.2498197e-07,\n",
      "       1.2571094e-07, 1.2150339e-07, 1.2522419e-07, 1.2444525e-07,\n",
      "       1.2514593e-07, 1.2553262e-07, 1.2500927e-07, 1.2406407e-07,\n",
      "       1.2346018e-07, 1.2471007e-07, 1.2432949e-07, 1.2457558e-07,\n",
      "       1.2509577e-07, 1.2228300e-07, 1.2430941e-07, 1.2517650e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/Conv2D\n",
      "index : 37\n",
      "shape : [144   1   1  36]\n",
      "shape_signature : [144   1   1  36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00140547, 0.00142101, 0.00143041, 0.00133092, 0.00142914,\n",
      "       0.00138735, 0.00131283, 0.0014429 , 0.00143562, 0.0014042 ,\n",
      "       0.00137948, 0.00142954, 0.00140863, 0.00139185, 0.00140363,\n",
      "       0.00140915, 0.00139374, 0.00139049, 0.00141354, 0.00142838,\n",
      "       0.00135642, 0.00140112, 0.00137912, 0.00143274, 0.00143386,\n",
      "       0.00138212, 0.00133095, 0.00142893, 0.00140478, 0.00142077,\n",
      "       0.00139435, 0.00143493, 0.00144177, 0.00143386, 0.00142736,\n",
      "       0.00142144, 0.00136213, 0.00142229, 0.00143547, 0.00143128,\n",
      "       0.00139617, 0.0013641 , 0.00142847, 0.00143154, 0.00143501,\n",
      "       0.00135855, 0.00138705, 0.00138685, 0.00141768, 0.00139542,\n",
      "       0.00140716, 0.00140919, 0.00140389, 0.00137209, 0.00138189,\n",
      "       0.00134659, 0.00142546, 0.00140401, 0.0014172 , 0.00143742,\n",
      "       0.00142315, 0.00133074, 0.00141625, 0.00140178, 0.00140825,\n",
      "       0.00139643, 0.00143418, 0.00143172, 0.00142657, 0.0013284 ,\n",
      "       0.00143157, 0.00141184, 0.0014236 , 0.00143243, 0.00143962,\n",
      "       0.00143572, 0.00142671, 0.00142853, 0.00143039, 0.00143056,\n",
      "       0.00142661, 0.00144027, 0.00142892, 0.00137439, 0.00142906,\n",
      "       0.00141365, 0.00141415, 0.00141113, 0.00140312, 0.00137389,\n",
      "       0.00142621, 0.00138133, 0.00143082, 0.00141739, 0.00138463,\n",
      "       0.0014207 , 0.00142434, 0.00133067, 0.00137913, 0.00141409,\n",
      "       0.00142884, 0.00143239, 0.00142669, 0.00140089, 0.00143309,\n",
      "       0.00142789, 0.00143427, 0.00142989, 0.00136541, 0.00142574,\n",
      "       0.00142434, 0.00136374, 0.00137179, 0.00133765, 0.00138352,\n",
      "       0.00135197, 0.00143566, 0.00141793, 0.00142609, 0.0013747 ,\n",
      "       0.00135778, 0.00141008, 0.00140632, 0.00142711, 0.00139819,\n",
      "       0.00136165, 0.00133094, 0.00142599, 0.00143073, 0.00135245,\n",
      "       0.00136756, 0.00143602, 0.00143211, 0.00140234, 0.00139261,\n",
      "       0.00139322, 0.00140699, 0.00141922, 0.00135783, 0.0014169 ,\n",
      "       0.0014311 , 0.00141687, 0.00142672, 0.00142909], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/BiasAdd;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/BiasAdd/ReadVariableOp/resource\n",
      "index : 38\n",
      "shape : [144]\n",
      "shape_signature : [144]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.1824762e-08, 4.2287365e-08, 4.2567123e-08, 3.9606242e-08,\n",
      "       4.2529358e-08, 4.1285752e-08, 3.9068130e-08, 4.2938638e-08,\n",
      "       4.2722082e-08, 4.1787096e-08, 4.1051504e-08, 4.2541192e-08,\n",
      "       4.1918994e-08, 4.1419586e-08, 4.1770186e-08, 4.1934204e-08,\n",
      "       4.1475648e-08, 4.1378907e-08, 4.2065061e-08, 4.2506709e-08,\n",
      "       4.0365236e-08, 4.1695255e-08, 4.1040771e-08, 4.2636433e-08,\n",
      "       4.2669612e-08, 4.1130079e-08, 3.9607301e-08, 4.2523041e-08,\n",
      "       4.1804313e-08, 4.2280060e-08, 4.1494012e-08, 4.2701416e-08,\n",
      "       4.2905192e-08, 4.2669619e-08, 4.2476167e-08, 4.2300158e-08,\n",
      "       4.0534985e-08, 4.2325393e-08, 4.2717684e-08, 4.2593051e-08,\n",
      "       4.1548109e-08, 4.0593786e-08, 4.2509377e-08, 4.2600654e-08,\n",
      "       4.2703761e-08, 4.0428617e-08, 4.1276628e-08, 4.1270738e-08,\n",
      "       4.2188265e-08, 4.1525798e-08, 4.1875211e-08, 4.1935554e-08,\n",
      "       4.1777923e-08, 4.0831477e-08, 4.1123037e-08, 4.0072688e-08,\n",
      "       4.2419710e-08, 4.1781533e-08, 4.2173891e-08, 4.2775628e-08,\n",
      "       4.2350866e-08, 3.9600973e-08, 4.2145604e-08, 4.1714902e-08,\n",
      "       4.1907473e-08, 4.1555818e-08, 4.2679122e-08, 4.2605979e-08,\n",
      "       4.2452665e-08, 3.9531407e-08, 4.2601645e-08, 4.2014335e-08,\n",
      "       4.2364480e-08, 4.2627057e-08, 4.2841148e-08, 4.2725077e-08,\n",
      "       4.2456769e-08, 4.2510933e-08, 4.2566441e-08, 4.2571553e-08,\n",
      "       4.2453806e-08, 4.2860481e-08, 4.2522533e-08, 4.0899817e-08,\n",
      "       4.2526736e-08, 4.2068308e-08, 4.2083055e-08, 4.1993150e-08,\n",
      "       4.1754870e-08, 4.0884927e-08, 4.2442014e-08, 4.1106563e-08,\n",
      "       4.2579213e-08, 4.2179472e-08, 4.1204633e-08, 4.2277929e-08,\n",
      "       4.2386475e-08, 3.9598881e-08, 4.1040970e-08, 4.2081457e-08,\n",
      "       4.2520163e-08, 4.2625885e-08, 4.2456321e-08, 4.1688615e-08,\n",
      "       4.2646743e-08, 4.2491941e-08, 4.2681918e-08, 4.2551690e-08,\n",
      "       4.0632589e-08, 4.2428173e-08, 4.2386453e-08, 4.0582979e-08,\n",
      "       4.0822716e-08, 3.9806693e-08, 4.1171678e-08, 4.0232692e-08,\n",
      "       4.2723272e-08, 4.2195598e-08, 4.2438312e-08, 4.0909278e-08,\n",
      "       4.0405634e-08, 4.1962121e-08, 4.1850221e-08, 4.2468869e-08,\n",
      "       4.1608185e-08, 4.0520721e-08, 3.9607059e-08, 4.2435602e-08,\n",
      "       4.2576552e-08, 4.0246928e-08, 4.0696623e-08, 4.2733937e-08,\n",
      "       4.2617685e-08, 4.1731745e-08, 4.1442242e-08, 4.1460282e-08,\n",
      "       4.1869974e-08, 4.2233875e-08, 4.0407038e-08, 4.2165087e-08,\n",
      "       4.2587413e-08, 4.2164032e-08, 4.2457319e-08, 4.2527763e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D\n",
      "index : 39\n",
      "shape : [ 24   1   1 144]\n",
      "shape_signature : [ 24   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00159091, 0.00160269, 0.00159717, 0.00160798, 0.00158741,\n",
      "       0.00157981, 0.00160652, 0.00158451, 0.00156866, 0.00156929,\n",
      "       0.00159631, 0.00158636, 0.00159444, 0.00160121, 0.00160825,\n",
      "       0.00159642, 0.00153416, 0.00156493, 0.00159914, 0.0016042 ,\n",
      "       0.00158911, 0.0015981 , 0.00158669, 0.00160054], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_9/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D\n",
      "index : 40\n",
      "shape : [24]\n",
      "shape_signature : [24]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.7451131e-08, 4.7802644e-08, 4.7637965e-08, 4.7960469e-08,\n",
      "       4.7346870e-08, 4.7120036e-08, 4.7916831e-08, 4.7260290e-08,\n",
      "       4.6787481e-08, 4.6806324e-08, 4.7612350e-08, 4.7315371e-08,\n",
      "       4.7556608e-08, 4.7758352e-08, 4.7968491e-08, 4.7615600e-08,\n",
      "       4.5758469e-08, 4.6676394e-08, 4.7696773e-08, 4.7847504e-08,\n",
      "       4.7397627e-08, 4.7665516e-08, 4.7325344e-08, 4.7738489e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/conv2d_13/Conv2D\n",
      "index : 41\n",
      "shape : [144   1   1  24]\n",
      "shape_signature : [144   1   1  24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00130311, 0.0015403 , 0.00139536, 0.00152971, 0.00146864,\n",
      "       0.00144763, 0.00133933, 0.00152844, 0.00144845, 0.00142009,\n",
      "       0.00147265, 0.00151181, 0.00150945, 0.00152258, 0.00152258,\n",
      "       0.00144326, 0.00151847, 0.00147245, 0.00148173, 0.00144071,\n",
      "       0.00127621, 0.00149266, 0.00152171, 0.00152714, 0.00150728,\n",
      "       0.00148646, 0.00148342, 0.00152659, 0.00150587, 0.0014742 ,\n",
      "       0.00153356, 0.00148711, 0.00155467, 0.0015535 , 0.00152545,\n",
      "       0.00145124, 0.00154102, 0.00153568, 0.00143735, 0.00129039,\n",
      "       0.00148718, 0.00151679, 0.00150555, 0.00140131, 0.00146189,\n",
      "       0.00127734, 0.00154764, 0.00152005, 0.00148225, 0.0015403 ,\n",
      "       0.0015445 , 0.00149023, 0.00148921, 0.00152084, 0.00150753,\n",
      "       0.0014284 , 0.00127408, 0.00148349, 0.00151284, 0.00153921,\n",
      "       0.00144492, 0.00149675, 0.00146096, 0.00127796, 0.00152023,\n",
      "       0.00142894, 0.00151371, 0.00149145, 0.00147589, 0.00134945,\n",
      "       0.00144729, 0.00137595, 0.00151002, 0.001526  , 0.00145581,\n",
      "       0.0014181 , 0.00149047, 0.00153236, 0.00149177, 0.00131476,\n",
      "       0.00142773, 0.0015251 , 0.00148445, 0.00151706, 0.00150879,\n",
      "       0.00149867, 0.00146004, 0.00143862, 0.00146074, 0.00145882,\n",
      "       0.00145308, 0.00149322, 0.00150998, 0.00146473, 0.00147178,\n",
      "       0.00147079, 0.00126519, 0.00138243, 0.00148939, 0.00148818,\n",
      "       0.00138114, 0.00150324, 0.00148702, 0.00150562, 0.00148555,\n",
      "       0.0015382 , 0.00143658, 0.00148293, 0.0015073 , 0.00153443,\n",
      "       0.00150978, 0.00144157, 0.00154023, 0.00153438, 0.00149502,\n",
      "       0.00147823, 0.00150738, 0.00151464, 0.00143709, 0.00153904,\n",
      "       0.0014652 , 0.00149668, 0.00142123, 0.00151991, 0.00148086,\n",
      "       0.00150016, 0.00139231, 0.00140439, 0.00152775, 0.00148619,\n",
      "       0.00149988, 0.00146291, 0.00148779, 0.00151663, 0.00150582,\n",
      "       0.00153226, 0.00150484, 0.00153113, 0.00149558, 0.00149251,\n",
      "       0.00148625, 0.00145013, 0.00151066, 0.00148748], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_10/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/conv2d_13/Conv2D\n",
      "index : 42\n",
      "shape : [144]\n",
      "shape_signature : [144]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8820066e-06, 2.2245674e-06, 2.0152427e-06, 2.2092695e-06,\n",
      "       2.1210747e-06, 2.0907246e-06, 1.9343113e-06, 2.2074314e-06,\n",
      "       2.0919069e-06, 2.0509538e-06, 2.1268586e-06, 2.1834212e-06,\n",
      "       2.1800126e-06, 2.1989720e-06, 2.1989676e-06, 2.0844134e-06,\n",
      "       2.1930341e-06, 2.1265801e-06, 2.1399783e-06, 2.0807281e-06,\n",
      "       1.8431595e-06, 2.1557669e-06, 2.1977210e-06, 2.2055613e-06,\n",
      "       2.1768783e-06, 2.1468086e-06, 2.1424219e-06, 2.2047584e-06,\n",
      "       2.1748392e-06, 2.1291048e-06, 2.2148363e-06, 2.1477390e-06,\n",
      "       2.2453125e-06, 2.2436341e-06, 2.2031222e-06, 2.0959426e-06,\n",
      "       2.2255990e-06, 2.2178908e-06, 2.0758803e-06, 1.8636382e-06,\n",
      "       2.1478513e-06, 2.1906046e-06, 2.1743733e-06, 2.0238363e-06,\n",
      "       2.1113262e-06, 1.8447878e-06, 2.2351689e-06, 2.1953242e-06,\n",
      "       2.1407204e-06, 2.2245638e-06, 2.2306340e-06, 2.1522524e-06,\n",
      "       2.1507758e-06, 2.1964593e-06, 2.1772437e-06, 2.0629550e-06,\n",
      "       1.8400766e-06, 2.1425162e-06, 2.1849007e-06, 2.2229967e-06,\n",
      "       2.0868165e-06, 2.1616745e-06, 2.1099809e-06, 1.8456794e-06,\n",
      "       2.1955764e-06, 2.0637292e-06, 2.1861592e-06, 2.1540129e-06,\n",
      "       2.1315388e-06, 1.9489371e-06, 2.0902428e-06, 1.9871998e-06,\n",
      "       2.1808380e-06, 2.2039089e-06, 2.1025483e-06, 2.0480832e-06,\n",
      "       2.1526046e-06, 2.2131021e-06, 2.1544827e-06, 1.8988248e-06,\n",
      "       2.0619821e-06, 2.2026147e-06, 2.1438991e-06, 2.1910041e-06,\n",
      "       2.1790615e-06, 2.1644357e-06, 2.1086510e-06, 2.0777209e-06,\n",
      "       2.1096564e-06, 2.1068909e-06, 2.0985983e-06, 2.1565636e-06,\n",
      "       2.1807812e-06, 2.1154194e-06, 2.1256037e-06, 2.1241801e-06,\n",
      "       1.8272467e-06, 1.9965571e-06, 2.1510348e-06, 2.1492860e-06,\n",
      "       1.9946972e-06, 2.1710371e-06, 2.1476146e-06, 2.1744845e-06,\n",
      "       2.1454944e-06, 2.2215361e-06, 2.0747700e-06, 2.1417027e-06,\n",
      "       2.1769113e-06, 2.2160837e-06, 2.1804915e-06, 2.0819734e-06,\n",
      "       2.2244651e-06, 2.2160134e-06, 2.1591713e-06, 2.1349199e-06,\n",
      "       2.1770222e-06, 2.1875128e-06, 2.0755101e-06, 2.2227482e-06,\n",
      "       2.1160988e-06, 2.1615706e-06, 2.0526013e-06, 2.1951116e-06,\n",
      "       2.1387257e-06, 2.1665894e-06, 2.0108382e-06, 2.0282723e-06,\n",
      "       2.2064430e-06, 2.1464177e-06, 2.1661829e-06, 2.1127983e-06,\n",
      "       2.1487240e-06, 2.1903777e-06, 2.1747637e-06, 2.2129536e-06,\n",
      "       2.1733476e-06, 2.2113179e-06, 2.1599851e-06, 2.1555493e-06,\n",
      "       2.1465046e-06, 2.0943439e-06, 2.1817600e-06, 2.1482842e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_11/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/depthwise_conv2d_3/depthwise;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D\n",
      "index : 43\n",
      "shape : [  1   5   5 144]\n",
      "shape_signature : [  1   5   5 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00034565, 0.00032753, 0.00034588, 0.00034859, 0.00032144,\n",
      "       0.00033936, 0.00032844, 0.0003388 , 0.00033827, 0.00033121,\n",
      "       0.00034383, 0.00033552, 0.00034773, 0.00030471, 0.00032816,\n",
      "       0.00031677, 0.00031223, 0.00034893, 0.00032163, 0.00033669,\n",
      "       0.00031896, 0.0003296 , 0.00034264, 0.00031781, 0.00034416,\n",
      "       0.00032833, 0.00034543, 0.00032962, 0.00033675, 0.0003411 ,\n",
      "       0.00034804, 0.00033011, 0.00034636, 0.00031055, 0.00033619,\n",
      "       0.00032792, 0.00034656, 0.00031839, 0.00033215, 0.00034529,\n",
      "       0.00032328, 0.00033657, 0.00032473, 0.00035655, 0.00032278,\n",
      "       0.00035117, 0.00033022, 0.00034437, 0.00034101, 0.0003457 ,\n",
      "       0.00033846, 0.00034024, 0.0003363 , 0.00034069, 0.00030162,\n",
      "       0.00033039, 0.00034617, 0.00033528, 0.00034238, 0.0003432 ,\n",
      "       0.00033927, 0.00034808, 0.00034485, 0.00034511, 0.00033652,\n",
      "       0.00034975, 0.00034098, 0.00034688, 0.00033323, 0.00032382,\n",
      "       0.00032506, 0.00031438, 0.00035085, 0.00033952, 0.00034192,\n",
      "       0.00034103, 0.00034611, 0.00033387, 0.00032984, 0.00031984,\n",
      "       0.00033394, 0.00034961, 0.00033432, 0.00035247, 0.00034343,\n",
      "       0.00034467, 0.00032103, 0.00033666, 0.00034367, 0.00034163,\n",
      "       0.0003479 , 0.00034229, 0.00032744, 0.00032998, 0.00033909,\n",
      "       0.00034082, 0.00033536, 0.0003382 , 0.0003292 , 0.00034631,\n",
      "       0.00033923, 0.00028701, 0.00034121, 0.00035074, 0.00032927,\n",
      "       0.00034357, 0.00034331, 0.00033275, 0.00034686, 0.00034732,\n",
      "       0.0003343 , 0.00034617, 0.00032972, 0.00035085, 0.00034554,\n",
      "       0.00034792, 0.00034438, 0.00033068, 0.00034451, 0.00033911,\n",
      "       0.0003435 , 0.00033797, 0.00035199, 0.00033778, 0.00033891,\n",
      "       0.00031468, 0.00033796, 0.00031029, 0.00034187, 0.00033191,\n",
      "       0.00033778, 0.00034482, 0.00032729, 0.00032693, 0.00031833,\n",
      "       0.00034576, 0.00032511, 0.00033891, 0.00034016, 0.00034084,\n",
      "       0.00033181, 0.00033301, 0.00033478, 0.0003471 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_11/FusedBatchNormV3\n",
      "index : 44\n",
      "shape : [144]\n",
      "shape_signature : [144]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8222910e-07, 1.7267710e-07, 1.8235004e-07, 1.8377791e-07,\n",
      "       1.6946807e-07, 1.7891067e-07, 1.7315449e-07, 1.7861844e-07,\n",
      "       1.7834081e-07, 1.7461552e-07, 1.8126919e-07, 1.7689031e-07,\n",
      "       1.8332547e-07, 1.6064611e-07, 1.7301001e-07, 1.6700243e-07,\n",
      "       1.6461021e-07, 1.8396095e-07, 1.6956812e-07, 1.7750605e-07,\n",
      "       1.6815571e-07, 1.7376861e-07, 1.8064429e-07, 1.6755043e-07,\n",
      "       1.8144483e-07, 1.7310008e-07, 1.8211455e-07, 1.7378001e-07,\n",
      "       1.7753483e-07, 1.7983164e-07, 1.8349003e-07, 1.7403580e-07,\n",
      "       1.8260494e-07, 1.6372597e-07, 1.7724378e-07, 1.7287938e-07,\n",
      "       1.8270670e-07, 1.6785738e-07, 1.7511061e-07, 1.8203733e-07,\n",
      "       1.7043422e-07, 1.7744073e-07, 1.7119935e-07, 1.8797668e-07,\n",
      "       1.7017359e-07, 1.8513992e-07, 1.7409214e-07, 1.8155606e-07,\n",
      "       1.7978563e-07, 1.8225343e-07, 1.7843715e-07, 1.7937747e-07,\n",
      "       1.7729931e-07, 1.7961683e-07, 1.5901482e-07, 1.7418530e-07,\n",
      "       1.8250471e-07, 1.7676480e-07, 1.8050658e-07, 1.8093658e-07,\n",
      "       1.7886467e-07, 1.8351018e-07, 1.8180754e-07, 1.8194245e-07,\n",
      "       1.7741421e-07, 1.8439142e-07, 1.7976473e-07, 1.8287997e-07,\n",
      "       1.7568131e-07, 1.7071858e-07, 1.7137565e-07, 1.6574330e-07,\n",
      "       1.8497151e-07, 1.7899954e-07, 1.8026257e-07, 1.7979113e-07,\n",
      "       1.8247223e-07, 1.7601816e-07, 1.7389679e-07, 1.6862381e-07,\n",
      "       1.7605720e-07, 1.8431808e-07, 1.7625689e-07, 1.8582257e-07,\n",
      "       1.8105986e-07, 1.8171161e-07, 1.6925020e-07, 1.7748974e-07,\n",
      "       1.8118450e-07, 1.8010979e-07, 1.8341754e-07, 1.8046060e-07,\n",
      "       1.7263093e-07, 1.7397036e-07, 1.7877188e-07, 1.7968556e-07,\n",
      "       1.7680701e-07, 1.7830013e-07, 1.7355477e-07, 1.8257911e-07,\n",
      "       1.7884624e-07, 1.5131525e-07, 1.7989056e-07, 1.8491359e-07,\n",
      "       1.7359243e-07, 1.8113158e-07, 1.8099745e-07, 1.7542899e-07,\n",
      "       1.8286583e-07, 1.8311090e-07, 1.7624406e-07, 1.8250520e-07,\n",
      "       1.7382902e-07, 1.8497323e-07, 1.8217375e-07, 1.8342381e-07,\n",
      "       1.8155943e-07, 1.7433685e-07, 1.8162730e-07, 1.7878364e-07,\n",
      "       1.8109786e-07, 1.7818277e-07, 1.8557218e-07, 1.7808215e-07,\n",
      "       1.7867475e-07, 1.6590131e-07, 1.7817462e-07, 1.6358781e-07,\n",
      "       1.8023729e-07, 1.7498623e-07, 1.7808242e-07, 1.8179384e-07,\n",
      "       1.7255073e-07, 1.7235971e-07, 1.6782722e-07, 1.8228680e-07,\n",
      "       1.7140303e-07, 1.7867414e-07, 1.7933729e-07, 1.7969296e-07,\n",
      "       1.7493096e-07, 1.7556427e-07, 1.7649953e-07, 1.8299538e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/Conv2D\n",
      "index : 45\n",
      "shape : [ 36   1   1 144]\n",
      "shape_signature : [ 36   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00143866, 0.00142597, 0.00143547, 0.00143912, 0.00143566,\n",
      "       0.00143297, 0.00140648, 0.00140844, 0.00142174, 0.00142239,\n",
      "       0.00143177, 0.0014167 , 0.00142665, 0.00143696, 0.00144005,\n",
      "       0.00140677, 0.00143428, 0.00140967, 0.00142674, 0.00143117,\n",
      "       0.00142772, 0.00142283, 0.0014142 , 0.00143876, 0.00141764,\n",
      "       0.00143442, 0.00143866, 0.00141135, 0.00142837, 0.00142996,\n",
      "       0.00144002, 0.00143202, 0.00142306, 0.00143076, 0.00141901,\n",
      "       0.00143224], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/BiasAdd;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/BiasAdd/ReadVariableOp/resource\n",
      "index : 46\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.2575775e-07, 1.2464811e-07, 1.2547886e-07, 1.2579784e-07,\n",
      "       1.2549516e-07, 1.2525989e-07, 1.2294504e-07, 1.2311591e-07,\n",
      "       1.2427873e-07, 1.2433540e-07, 1.2515537e-07, 1.2383811e-07,\n",
      "       1.2470754e-07, 1.2560857e-07, 1.2587935e-07, 1.2297002e-07,\n",
      "       1.2537492e-07, 1.2322327e-07, 1.2471540e-07, 1.2510287e-07,\n",
      "       1.2480142e-07, 1.2437397e-07, 1.2361905e-07, 1.2576594e-07,\n",
      "       1.2392030e-07, 1.2538702e-07, 1.2575747e-07, 1.2337036e-07,\n",
      "       1.2485827e-07, 1.2499676e-07, 1.2587677e-07, 1.2517677e-07,\n",
      "       1.2439398e-07, 1.2506717e-07, 1.2403962e-07, 1.2519619e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D\n",
      "index : 47\n",
      "shape : [144   1   1  36]\n",
      "shape_signature : [144   1   1  36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00142176, 0.00142353, 0.00137769, 0.00142037, 0.00141917,\n",
      "       0.00143206, 0.00142472, 0.001377  , 0.00140091, 0.0013581 ,\n",
      "       0.00141636, 0.00140274, 0.00135396, 0.00141434, 0.00143655,\n",
      "       0.00141051, 0.00143633, 0.00134879, 0.001409  , 0.00142921,\n",
      "       0.00139787, 0.00141903, 0.00140296, 0.00134496, 0.00140475,\n",
      "       0.0013476 , 0.00143572, 0.00143391, 0.00140475, 0.00141811,\n",
      "       0.00142651, 0.0013973 , 0.0014105 , 0.00140088, 0.00141539,\n",
      "       0.00142314, 0.0014138 , 0.00139245, 0.00126283, 0.00140471,\n",
      "       0.00143377, 0.00142322, 0.00141458, 0.00133706, 0.00142084,\n",
      "       0.00140258, 0.00143322, 0.00142222, 0.00143935, 0.0013986 ,\n",
      "       0.00140386, 0.0013405 , 0.00136925, 0.00143821, 0.00137945,\n",
      "       0.00143149, 0.00139556, 0.00144277, 0.00139488, 0.00136312,\n",
      "       0.00140874, 0.0014329 , 0.00141406, 0.00141599, 0.00139657,\n",
      "       0.00141391, 0.00142135, 0.00137418, 0.00143903, 0.00142224,\n",
      "       0.00135914, 0.00140061, 0.00140356, 0.0013698 , 0.00142915,\n",
      "       0.00138665, 0.00139005, 0.00143004, 0.00142957, 0.00141263,\n",
      "       0.0014012 , 0.00143351, 0.00142845, 0.00139261, 0.00143445,\n",
      "       0.00143834, 0.00137401, 0.001305  , 0.00138886, 0.00142496,\n",
      "       0.0014258 , 0.00140315, 0.00141843, 0.00142215, 0.00134857,\n",
      "       0.00141833, 0.00142982, 0.00141621, 0.00140309, 0.00132251,\n",
      "       0.00139936, 0.00138449, 0.00141028, 0.00129702, 0.00139386,\n",
      "       0.00139712, 0.00140846, 0.001409  , 0.00143166, 0.00135331,\n",
      "       0.00137076, 0.00132366, 0.0013662 , 0.00142325, 0.00141396,\n",
      "       0.00137988, 0.00140403, 0.00143289, 0.00136379, 0.00143023,\n",
      "       0.00140698, 0.00141914, 0.00135974, 0.00142509, 0.00142218,\n",
      "       0.00142926, 0.00143005, 0.00142306, 0.00142128, 0.00140489,\n",
      "       0.0014175 , 0.00138392, 0.00142558, 0.00141096, 0.0014192 ,\n",
      "       0.00136089, 0.0014279 , 0.00142524, 0.00136982, 0.00142744,\n",
      "       0.00137815, 0.00143077, 0.00138537, 0.00142398], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/BiasAdd;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/BiasAdd/ReadVariableOp/resource\n",
      "index : 48\n",
      "shape : [144]\n",
      "shape_signature : [144]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([5.4057228e-08, 5.4124250e-08, 5.2381665e-08, 5.4004250e-08,\n",
      "       5.3958612e-08, 5.4448808e-08, 5.4169512e-08, 5.2355418e-08,\n",
      "       5.3264543e-08, 5.1636743e-08, 5.3851938e-08, 5.3333935e-08,\n",
      "       5.1479432e-08, 5.3774958e-08, 5.4619274e-08, 5.3629485e-08,\n",
      "       5.4611121e-08, 5.1282861e-08, 5.3571934e-08, 5.4340497e-08,\n",
      "       5.3148732e-08, 5.3953510e-08, 5.3342454e-08, 5.1137089e-08,\n",
      "       5.3410531e-08, 5.1237432e-08, 5.4587900e-08, 5.4519013e-08,\n",
      "       5.3410364e-08, 5.3918324e-08, 5.4237542e-08, 5.3127192e-08,\n",
      "       5.3628810e-08, 5.3263275e-08, 5.3815008e-08, 5.4109716e-08,\n",
      "       5.3754647e-08, 5.2942639e-08, 4.8014325e-08, 5.3408751e-08,\n",
      "       5.4513666e-08, 5.4112448e-08, 5.3783946e-08, 5.0836878e-08,\n",
      "       5.4022138e-08, 5.3328019e-08, 5.4492659e-08, 5.4074562e-08,\n",
      "       5.4725970e-08, 5.3176379e-08, 5.3376670e-08, 5.0967653e-08,\n",
      "       5.2060571e-08, 5.4682712e-08, 5.2448268e-08, 5.4427229e-08,\n",
      "       5.3060813e-08, 5.4855921e-08, 5.3035162e-08, 5.1827481e-08,\n",
      "       5.3562161e-08, 5.4480765e-08, 5.3764271e-08, 5.3837713e-08,\n",
      "       5.3099424e-08, 5.3758519e-08, 5.4041347e-08, 5.2248254e-08,\n",
      "       5.4713777e-08, 5.4075400e-08, 5.1676359e-08, 5.3253142e-08,\n",
      "       5.3365156e-08, 5.2081514e-08, 5.4337974e-08, 5.2722168e-08,\n",
      "       5.2851529e-08, 5.4371814e-08, 5.4353979e-08, 5.3709829e-08,\n",
      "       5.3275397e-08, 5.4503829e-08, 5.4311382e-08, 5.2948877e-08,\n",
      "       5.4539662e-08, 5.4687689e-08, 5.2241603e-08, 4.9617839e-08,\n",
      "       5.2806179e-08, 5.4178823e-08, 5.4210865e-08, 5.3349403e-08,\n",
      "       5.3930638e-08, 5.4072054e-08, 5.1274338e-08, 5.3926598e-08,\n",
      "       5.4363429e-08, 5.3846168e-08, 5.3347250e-08, 5.0283671e-08,\n",
      "       5.3205479e-08, 5.2639926e-08, 5.3620486e-08, 4.9314391e-08,\n",
      "       5.2996274e-08, 5.3120406e-08, 5.3551613e-08, 5.3571924e-08,\n",
      "       5.4433418e-08, 5.1454588e-08, 5.2118153e-08, 5.0327245e-08,\n",
      "       5.1944774e-08, 5.4113897e-08, 5.3760491e-08, 5.2464820e-08,\n",
      "       5.3382852e-08, 5.4480374e-08, 5.1853103e-08, 5.4379129e-08,\n",
      "       5.3495228e-08, 5.3957585e-08, 5.1699189e-08, 5.4183719e-08,\n",
      "       5.4073123e-08, 5.4342209e-08, 5.4372293e-08, 5.4106724e-08,\n",
      "       5.4038864e-08, 5.3415615e-08, 5.3895214e-08, 5.2618240e-08,\n",
      "       5.4202317e-08, 5.3646680e-08, 5.3959759e-08, 5.1742880e-08,\n",
      "       5.4290464e-08, 5.4189421e-08, 5.2082484e-08, 5.4273048e-08,\n",
      "       5.2399162e-08, 5.4399724e-08, 5.2673567e-08, 5.4141555e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/conv2d_16/Conv2D\n",
      "index : 49\n",
      "shape : [ 40   1   1 144]\n",
      "shape_signature : [ 40   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00152099, 0.00151569, 0.00151882, 0.00152894, 0.00152782,\n",
      "       0.00152696, 0.00152474, 0.00151717, 0.00149839, 0.00150799,\n",
      "       0.00151672, 0.00152242, 0.00154028, 0.00153224, 0.00151792,\n",
      "       0.00152924, 0.00152811, 0.00153102, 0.00151353, 0.00151284,\n",
      "       0.00153523, 0.00152749, 0.00153553, 0.00151794, 0.00153088,\n",
      "       0.0015272 , 0.00152062, 0.00153183, 0.0015357 , 0.00153946,\n",
      "       0.0015356 , 0.00152873, 0.00152405, 0.00152991, 0.00153313,\n",
      "       0.00151823, 0.00151428, 0.00151594, 0.00150343, 0.00152276],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_12/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_20/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/conv2d_16/Conv2D\n",
      "index : 50\n",
      "shape : [40]\n",
      "shape_signature : [40]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.0472525e-08, 4.0331528e-08, 4.0414935e-08, 4.0684146e-08,\n",
      "       4.0654431e-08, 4.0631328e-08, 4.0572310e-08, 4.0370931e-08,\n",
      "       3.9871288e-08, 4.0126757e-08, 4.0358888e-08, 4.0510539e-08,\n",
      "       4.0985899e-08, 4.0772033e-08, 4.0390848e-08, 4.0692093e-08,\n",
      "       4.0662076e-08, 4.0739522e-08, 4.0274085e-08, 4.0255639e-08,\n",
      "       4.0851486e-08, 4.0645659e-08, 4.0859582e-08, 4.0391463e-08,\n",
      "       4.0735642e-08, 4.0637957e-08, 4.0462776e-08, 4.0761098e-08,\n",
      "       4.0863931e-08, 4.0964046e-08, 4.0861433e-08, 4.0678547e-08,\n",
      "       4.0554074e-08, 4.0709832e-08, 4.0795573e-08, 4.0399261e-08,\n",
      "       4.0294101e-08, 4.0338346e-08, 4.0005290e-08, 4.0519669e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_17/Conv2D\n",
      "index : 51\n",
      "shape : [240   1   1  40]\n",
      "shape_signature : [240   1   1  40]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00119081, 0.0012061 , 0.00114927, 0.00119576, 0.00120744,\n",
      "       0.00120722, 0.00121418, 0.00121078, 0.00117324, 0.00117958,\n",
      "       0.00122944, 0.00114824, 0.00117939, 0.00122011, 0.0012203 ,\n",
      "       0.00120188, 0.00120769, 0.00116897, 0.00120346, 0.00117505,\n",
      "       0.00120048, 0.00116839, 0.00116693, 0.00120895, 0.00121393,\n",
      "       0.00119157, 0.0011529 , 0.00116091, 0.00122145, 0.00121269,\n",
      "       0.00120199, 0.00122086, 0.00115895, 0.0011862 , 0.00118692,\n",
      "       0.00117599, 0.00120043, 0.00120988, 0.00121111, 0.00119202,\n",
      "       0.00122298, 0.00121255, 0.00119168, 0.00121588, 0.00119559,\n",
      "       0.00120115, 0.00121201, 0.00121832, 0.00121641, 0.00121185,\n",
      "       0.00120577, 0.0011819 , 0.00122365, 0.00118176, 0.00122278,\n",
      "       0.00120515, 0.00121089, 0.00120998, 0.00118106, 0.00113267,\n",
      "       0.00114179, 0.00121481, 0.00121129, 0.00121731, 0.00117664,\n",
      "       0.00122171, 0.00121338, 0.00121697, 0.00123367, 0.00113303,\n",
      "       0.00119365, 0.00117084, 0.00118887, 0.0011701 , 0.0011595 ,\n",
      "       0.00120528, 0.00120027, 0.00122767, 0.00120829, 0.00120989,\n",
      "       0.00118413, 0.00122568, 0.00122645, 0.00121897, 0.00118752,\n",
      "       0.00114476, 0.00108532, 0.00121281, 0.00119949, 0.00122339,\n",
      "       0.00117832, 0.00122128, 0.00115571, 0.00121038, 0.00121293,\n",
      "       0.00123248, 0.00118807, 0.00119237, 0.00121322, 0.0012082 ,\n",
      "       0.00119519, 0.0012219 , 0.00119955, 0.00119507, 0.00119022,\n",
      "       0.00118577, 0.00122146, 0.00119978, 0.00122653, 0.00119474,\n",
      "       0.00114471, 0.00120708, 0.00118815, 0.00122033, 0.00116928,\n",
      "       0.00119524, 0.00121711, 0.00119073, 0.00121513, 0.00121363,\n",
      "       0.0011848 , 0.00118968, 0.00119834, 0.00121255, 0.00112976,\n",
      "       0.00118722, 0.00118797, 0.0011185 , 0.00112408, 0.00120922,\n",
      "       0.00119178, 0.00121125, 0.00117579, 0.00122227, 0.00121521,\n",
      "       0.00116977, 0.00116077, 0.00118788, 0.00121084, 0.00120156,\n",
      "       0.0012133 , 0.00117437, 0.0012196 , 0.00122422, 0.00121092,\n",
      "       0.00123158, 0.00122134, 0.00120559, 0.00122961, 0.00118167,\n",
      "       0.00116504, 0.00120072, 0.00119663, 0.00122862, 0.00117391,\n",
      "       0.00115375, 0.00110892, 0.00119072, 0.00114434, 0.00116948,\n",
      "       0.00119384, 0.00113614, 0.00122571, 0.00121619, 0.00114048,\n",
      "       0.00118931, 0.00117053, 0.00116002, 0.00118944, 0.0011748 ,\n",
      "       0.00122272, 0.0012019 , 0.00119321, 0.00116763, 0.00121094,\n",
      "       0.00122111, 0.00120703, 0.00123134, 0.00116966, 0.00119158,\n",
      "       0.00121301, 0.00118922, 0.00115646, 0.00118321, 0.00121585,\n",
      "       0.00116663, 0.00115017, 0.00118226, 0.00115293, 0.00117509,\n",
      "       0.0012104 , 0.00121579, 0.00117428, 0.00120327, 0.00121419,\n",
      "       0.00122506, 0.0011423 , 0.00120425, 0.00118101, 0.00117239,\n",
      "       0.00120912, 0.00122126, 0.0012012 , 0.00117007, 0.0011712 ,\n",
      "       0.00117812, 0.00117438, 0.00121591, 0.00121015, 0.00120146,\n",
      "       0.00121528, 0.00119303, 0.00119743, 0.0012002 , 0.00121686,\n",
      "       0.00121408, 0.00119676, 0.00123116, 0.00122575, 0.00118607,\n",
      "       0.00121516, 0.00120043, 0.00122822, 0.00116914, 0.00120556,\n",
      "       0.00112933, 0.00120994, 0.00120809, 0.00120751, 0.00119364,\n",
      "       0.00117949, 0.00119965, 0.00120621, 0.00119009, 0.00120201,\n",
      "       0.00122276, 0.00120908, 0.00120412, 0.00120794, 0.00121504],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_13/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_17/Conv2D\n",
      "index : 52\n",
      "shape : [240]\n",
      "shape_signature : [240]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8826699e-07, 1.9068381e-07, 1.8169912e-07, 1.8904898e-07,\n",
      "       1.9089562e-07, 1.9086117e-07, 1.9196179e-07, 1.9142381e-07,\n",
      "       1.8548927e-07, 1.8649169e-07, 1.9437412e-07, 1.8153692e-07,\n",
      "       1.8646162e-07, 1.9289848e-07, 1.9292847e-07, 1.9001713e-07,\n",
      "       1.9093565e-07, 1.8481391e-07, 1.9026612e-07, 1.8577464e-07,\n",
      "       1.8979482e-07, 1.8472218e-07, 1.8449080e-07, 1.9113426e-07,\n",
      "       1.9192167e-07, 1.8838720e-07, 1.8227358e-07, 1.8353951e-07,\n",
      "       1.9311055e-07, 1.9172528e-07, 1.9003329e-07, 1.9301682e-07,\n",
      "       1.8322892e-07, 1.8753836e-07, 1.8765195e-07, 1.8592350e-07,\n",
      "       1.8978699e-07, 1.9128220e-07, 1.9147615e-07, 1.8845810e-07,\n",
      "       1.9335245e-07, 1.9170375e-07, 1.8840427e-07, 1.9223012e-07,\n",
      "       1.8902152e-07, 1.8990085e-07, 1.9161759e-07, 1.9261553e-07,\n",
      "       1.9231386e-07, 1.9159323e-07, 1.9063187e-07, 1.8685748e-07,\n",
      "       1.9345806e-07, 1.8683491e-07, 1.9332057e-07, 1.9053327e-07,\n",
      "       1.9144058e-07, 1.9129659e-07, 1.8672559e-07, 1.7907500e-07,\n",
      "       1.8051594e-07, 1.9206114e-07, 1.9150453e-07, 1.9245637e-07,\n",
      "       1.8602630e-07, 1.9315148e-07, 1.9183419e-07, 1.9240224e-07,\n",
      "       1.9504328e-07, 1.7913219e-07, 1.8871576e-07, 1.8510877e-07,\n",
      "       1.8795919e-07, 1.8499246e-07, 1.8331629e-07, 1.9055449e-07,\n",
      "       1.8976176e-07, 1.9409462e-07, 1.9102927e-07, 1.9128318e-07,\n",
      "       1.8721082e-07, 1.9377960e-07, 1.9390045e-07, 1.9271839e-07,\n",
      "       1.8774578e-07, 1.8098598e-07, 1.7158932e-07, 1.9174435e-07,\n",
      "       1.8963937e-07, 1.9341792e-07, 1.8629116e-07, 1.9308429e-07,\n",
      "       1.8271645e-07, 1.9136101e-07, 1.9176315e-07, 1.9485492e-07,\n",
      "       1.8783290e-07, 1.8851352e-07, 1.9180975e-07, 1.9101600e-07,\n",
      "       1.8895929e-07, 1.9318117e-07, 1.8964748e-07, 1.8894002e-07,\n",
      "       1.8817364e-07, 1.8747005e-07, 1.9311253e-07, 1.8968531e-07,\n",
      "       1.9391440e-07, 1.8888763e-07, 1.8097762e-07, 1.9083856e-07,\n",
      "       1.8784587e-07, 1.9293425e-07, 1.8486284e-07, 1.8896704e-07,\n",
      "       1.9242475e-07, 1.8825413e-07, 1.9211136e-07, 1.9187488e-07,\n",
      "       1.8731555e-07, 1.8808718e-07, 1.8945754e-07, 1.9170344e-07,\n",
      "       1.7861483e-07, 1.8769937e-07, 1.8781812e-07, 1.7683413e-07,\n",
      "       1.7771586e-07, 1.9117701e-07, 1.8841986e-07, 1.9149850e-07,\n",
      "       1.8589122e-07, 1.9324088e-07, 1.9212460e-07, 1.8494002e-07,\n",
      "       1.8351669e-07, 1.8780267e-07, 1.9143303e-07, 1.8996643e-07,\n",
      "       1.9182265e-07, 1.8566701e-07, 1.9281860e-07, 1.9354860e-07,\n",
      "       1.9144554e-07, 1.9471193e-07, 1.9309374e-07, 1.9060261e-07,\n",
      "       1.9440095e-07, 1.8682120e-07, 1.8419176e-07, 1.8983300e-07,\n",
      "       1.8918675e-07, 1.9424365e-07, 1.8559483e-07, 1.8240681e-07,\n",
      "       1.7531988e-07, 1.8825207e-07, 1.8091959e-07, 1.8489483e-07,\n",
      "       1.8874540e-07, 1.7962363e-07, 1.9378444e-07, 1.9227875e-07,\n",
      "       1.8030946e-07, 1.8802869e-07, 1.8505956e-07, 1.8339875e-07,\n",
      "       1.8805032e-07, 1.8573458e-07, 1.9331090e-07, 1.9001902e-07,\n",
      "       1.8864637e-07, 1.8460160e-07, 1.9144962e-07, 1.9305718e-07,\n",
      "       1.9083031e-07, 1.9467480e-07, 1.8492322e-07, 1.8838766e-07,\n",
      "       1.9177568e-07, 1.8801455e-07, 1.8283521e-07, 1.8706544e-07,\n",
      "       1.9222601e-07, 1.8444406e-07, 1.8184056e-07, 1.8691522e-07,\n",
      "       1.8227789e-07, 1.8578129e-07, 1.9136301e-07, 1.9221621e-07,\n",
      "       1.8565255e-07, 1.9023589e-07, 1.9196297e-07, 1.9368119e-07,\n",
      "       1.8059650e-07, 1.9039189e-07, 1.8671768e-07, 1.8535495e-07,\n",
      "       1.9116059e-07, 1.9308114e-07, 1.8990970e-07, 1.8498798e-07,\n",
      "       1.8516690e-07, 1.8626046e-07, 1.8566826e-07, 1.9223535e-07,\n",
      "       1.9132455e-07, 1.8995001e-07, 1.9213515e-07, 1.8861707e-07,\n",
      "       1.8931242e-07, 1.8975079e-07, 1.9238472e-07, 1.9194606e-07,\n",
      "       1.8920738e-07, 1.9464618e-07, 1.9379014e-07, 1.8751784e-07,\n",
      "       1.9211539e-07, 1.8978729e-07, 1.9418027e-07, 1.8484076e-07,\n",
      "       1.9059857e-07, 1.7854600e-07, 1.9129031e-07, 1.9099828e-07,\n",
      "       1.9090730e-07, 1.8871377e-07, 1.8647660e-07, 1.8966482e-07,\n",
      "       1.9070100e-07, 1.8815263e-07, 1.9003673e-07, 1.9331770e-07,\n",
      "       1.9115467e-07, 1.9037039e-07, 1.9097469e-07, 1.9209703e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_14/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_4/depthwise_conv2d_4/depthwise;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D\n",
      "index : 53\n",
      "shape : [  1   5   5 240]\n",
      "shape_signature : [  1   5   5 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00026992, 0.00025815, 0.00024253, 0.00026766, 0.00027092,\n",
      "       0.00026856, 0.00026994, 0.00025749, 0.00026536, 0.00024179,\n",
      "       0.00027103, 0.00025434, 0.00023286, 0.00026015, 0.00025643,\n",
      "       0.00026577, 0.00027042, 0.00027015, 0.0002717 , 0.00026803,\n",
      "       0.00027345, 0.0002577 , 0.00024789, 0.00022825, 0.00026176,\n",
      "       0.00027274, 0.00027222, 0.00024584, 0.00026074, 0.0002487 ,\n",
      "       0.0002712 , 0.00026317, 0.00027287, 0.00027036, 0.00026206,\n",
      "       0.00026028, 0.00025038, 0.00023477, 0.00025873, 0.00027449,\n",
      "       0.00026306, 0.00026199, 0.00026726, 0.00026212, 0.00025285,\n",
      "       0.00026219, 0.0002557 , 0.00024237, 0.00024541, 0.00025248,\n",
      "       0.00026125, 0.00027294, 0.00026465, 0.0002748 , 0.0002467 ,\n",
      "       0.00026125, 0.00026784, 0.00025803, 0.00027201, 0.00025788,\n",
      "       0.00027045, 0.00025259, 0.00026667, 0.00026491, 0.00026351,\n",
      "       0.00027539, 0.00026805, 0.00026527, 0.00025478, 0.00025951,\n",
      "       0.00026445, 0.00026595, 0.00026917, 0.00024977, 0.00026993,\n",
      "       0.00025834, 0.00026109, 0.00027098, 0.00027091, 0.00025973,\n",
      "       0.00026617, 0.00026718, 0.00026111, 0.00026353, 0.00026054,\n",
      "       0.00026721, 0.00026723, 0.00026872, 0.00026999, 0.0001917 ,\n",
      "       0.00027022, 0.00026538, 0.00026967, 0.00026003, 0.00026592,\n",
      "       0.00026716, 0.00027008, 0.00026996, 0.00023934, 0.00023674,\n",
      "       0.00024182, 0.00026213, 0.00025444, 0.00024989, 0.00025266,\n",
      "       0.00025891, 0.00023217, 0.00027824, 0.00027017, 0.00025106,\n",
      "       0.00024869, 0.00024636, 0.00026868, 0.00026525, 0.00024204,\n",
      "       0.00026904, 0.00025902, 0.00024484, 0.0002626 , 0.00026483,\n",
      "       0.00025957, 0.00024164, 0.00026072, 0.0002592 , 0.00027016,\n",
      "       0.00027177, 0.00026704, 0.00025293, 0.00025523, 0.00027052,\n",
      "       0.00027608, 0.0002654 , 0.00026923, 0.00026093, 0.00026324,\n",
      "       0.00027346, 0.00025616, 0.00026613, 0.00023866, 0.00024925,\n",
      "       0.00025724, 0.00023305, 0.00026963, 0.00026518, 0.00026889,\n",
      "       0.00027212, 0.00026455, 0.00025691, 0.00025942, 0.00025439,\n",
      "       0.00025748, 0.00025905, 0.00025211, 0.00027077, 0.0002683 ,\n",
      "       0.00026053, 0.00027029, 0.00026116, 0.00026663, 0.00027045,\n",
      "       0.00026961, 0.00025955, 0.00025741, 0.00027175, 0.00025565,\n",
      "       0.00026898, 0.00026834, 0.00026122, 0.00026077, 0.00027034,\n",
      "       0.00027457, 0.00026259, 0.00027023, 0.00026347, 0.00026503,\n",
      "       0.00026693, 0.00026797, 0.00026903, 0.00026033, 0.00027027,\n",
      "       0.00026937, 0.00024655, 0.00024271, 0.00025741, 0.00025034,\n",
      "       0.00026313, 0.00026461, 0.00026486, 0.00027524, 0.000263  ,\n",
      "       0.0002706 , 0.0002672 , 0.00024851, 0.00024646, 0.00026006,\n",
      "       0.00026572, 0.00027651, 0.00026625, 0.00025755, 0.00024923,\n",
      "       0.00026053, 0.00027334, 0.00025559, 0.00027027, 0.00026375,\n",
      "       0.00026849, 0.00025259, 0.0002572 , 0.0002728 , 0.00025821,\n",
      "       0.00026041, 0.0002631 , 0.00026154, 0.00026068, 0.0002609 ,\n",
      "       0.00026602, 0.00026456, 0.00025975, 0.00023598, 0.00026709,\n",
      "       0.00027153, 0.00024415, 0.00024833, 0.00026675, 0.00026178,\n",
      "       0.00023179, 0.00026203, 0.00025415, 0.00026089, 0.00023068,\n",
      "       0.00026016, 0.00025128, 0.00022443, 0.00026616, 0.00026114,\n",
      "       0.00025255, 0.00027534, 0.00026599, 0.0002754 , 0.00025554],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_14/FusedBatchNormV3\n",
      "index : 54\n",
      "shape : [240]\n",
      "shape_signature : [240]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.52008131e-08, 1.45383119e-08, 1.36586324e-08, 1.50740487e-08,\n",
      "       1.52574238e-08, 1.51247050e-08, 1.52024597e-08, 1.45010528e-08,\n",
      "       1.49440247e-08, 1.36167682e-08, 1.52637512e-08, 1.43236418e-08,\n",
      "       1.31140805e-08, 1.46508921e-08, 1.44414543e-08, 1.49674459e-08,\n",
      "       1.52294870e-08, 1.52140682e-08, 1.53014046e-08, 1.50944128e-08,\n",
      "       1.54000972e-08, 1.45128114e-08, 1.39603138e-08, 1.28541684e-08,\n",
      "       1.47414090e-08, 1.53598823e-08, 1.53307571e-08, 1.38448746e-08,\n",
      "       1.46840451e-08, 1.40062033e-08, 1.52732014e-08, 1.48211416e-08,\n",
      "       1.53673199e-08, 1.52259432e-08, 1.47585499e-08, 1.46579175e-08,\n",
      "       1.41006451e-08, 1.32213307e-08, 1.45708023e-08, 1.54584647e-08,\n",
      "       1.48146428e-08, 1.47547681e-08, 1.50512740e-08, 1.47616079e-08,\n",
      "       1.42396699e-08, 1.47660417e-08, 1.43999843e-08, 1.36494336e-08,\n",
      "       1.38207739e-08, 1.42188883e-08, 1.47128922e-08, 1.53713806e-08,\n",
      "       1.49041508e-08, 1.54758659e-08, 1.38936320e-08, 1.47128221e-08,\n",
      "       1.50840709e-08, 1.45316665e-08, 1.53190669e-08, 1.45229411e-08,\n",
      "       1.52310378e-08, 1.42251384e-08, 1.50183084e-08, 1.49187258e-08,\n",
      "       1.48401096e-08, 1.55088689e-08, 1.50960364e-08, 1.49394417e-08,\n",
      "       1.43483190e-08, 1.46146535e-08, 1.48930672e-08, 1.49772887e-08,\n",
      "       1.51587152e-08, 1.40664316e-08, 1.52019339e-08, 1.45489265e-08,\n",
      "       1.47039758e-08, 1.52608983e-08, 1.52567647e-08, 1.46270391e-08,\n",
      "       1.49900536e-08, 1.50467034e-08, 1.47050363e-08, 1.48412669e-08,\n",
      "       1.46729509e-08, 1.50482684e-08, 1.50494657e-08, 1.51334358e-08,\n",
      "       1.52050248e-08, 1.07958966e-08, 1.52178981e-08, 1.49454724e-08,\n",
      "       1.51871440e-08, 1.46441890e-08, 1.49760542e-08, 1.50454760e-08,\n",
      "       1.52098991e-08, 1.52031756e-08, 1.34786591e-08, 1.33326346e-08,\n",
      "       1.36188270e-08, 1.47626524e-08, 1.43291663e-08, 1.40730858e-08,\n",
      "       1.42289478e-08, 1.45812837e-08, 1.30751792e-08, 1.56697784e-08,\n",
      "       1.52151305e-08, 1.41388705e-08, 1.40055416e-08, 1.38743266e-08,\n",
      "       1.51313895e-08, 1.49382888e-08, 1.36309284e-08, 1.51517661e-08,\n",
      "       1.45875161e-08, 1.37887897e-08, 1.47890358e-08, 1.49144732e-08,\n",
      "       1.46180463e-08, 1.36085090e-08, 1.46828638e-08, 1.45973615e-08,\n",
      "       1.52147450e-08, 1.53051332e-08, 1.50387276e-08, 1.42444776e-08,\n",
      "       1.43740762e-08, 1.52349138e-08, 1.55479700e-08, 1.49465205e-08,\n",
      "       1.51622697e-08, 1.46948338e-08, 1.48248747e-08, 1.54006319e-08,\n",
      "       1.44262211e-08, 1.49876183e-08, 1.34404301e-08, 1.40370942e-08,\n",
      "       1.44871635e-08, 1.31244100e-08, 1.51848276e-08, 1.49338728e-08,\n",
      "       1.51431347e-08, 1.53251261e-08, 1.48987400e-08, 1.44686672e-08,\n",
      "       1.46098573e-08, 1.43266572e-08, 1.45005661e-08, 1.45891335e-08,\n",
      "       1.41979761e-08, 1.52491975e-08, 1.51098050e-08, 1.46720867e-08,\n",
      "       1.52216746e-08, 1.47078181e-08, 1.50160471e-08, 1.52307571e-08,\n",
      "       1.51836161e-08, 1.46173393e-08, 1.44966128e-08, 1.53043480e-08,\n",
      "       1.43975853e-08, 1.51480233e-08, 1.51121267e-08, 1.47109587e-08,\n",
      "       1.46856465e-08, 1.52247299e-08, 1.54628097e-08, 1.47885704e-08,\n",
      "       1.52184931e-08, 1.48379451e-08, 1.49256394e-08, 1.50324659e-08,\n",
      "       1.50910804e-08, 1.51510555e-08, 1.46609960e-08, 1.52205306e-08,\n",
      "       1.51698831e-08, 1.38847422e-08, 1.36689744e-08, 1.44965933e-08,\n",
      "       1.40984326e-08, 1.48189159e-08, 1.49022803e-08, 1.49163704e-08,\n",
      "       1.55008362e-08, 1.48114561e-08, 1.52395305e-08, 1.50478474e-08,\n",
      "       1.39952485e-08, 1.38801264e-08, 1.46455985e-08, 1.49643071e-08,\n",
      "       1.55720379e-08, 1.49945603e-08, 1.45044208e-08, 1.40358063e-08,\n",
      "       1.46721426e-08, 1.53938551e-08, 1.43943462e-08, 1.52209125e-08,\n",
      "       1.48538026e-08, 1.51204738e-08, 1.42248711e-08, 1.44846100e-08,\n",
      "       1.53633373e-08, 1.45414765e-08, 1.46656323e-08, 1.48172452e-08,\n",
      "       1.47291956e-08, 1.46808965e-08, 1.46929340e-08, 1.49812696e-08,\n",
      "       1.48990447e-08, 1.46286263e-08, 1.32895224e-08, 1.50414809e-08,\n",
      "       1.52918886e-08, 1.37496183e-08, 1.39854581e-08, 1.50225965e-08,\n",
      "       1.47426658e-08, 1.30536861e-08, 1.47565071e-08, 1.43131009e-08,\n",
      "       1.46924553e-08, 1.29910172e-08, 1.46512331e-08, 1.41515226e-08,\n",
      "       1.26395108e-08, 1.49891832e-08, 1.47066954e-08, 1.42230698e-08,\n",
      "       1.55063908e-08, 1.49795678e-08, 1.55098991e-08, 1.43914471e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/Conv2D\n",
      "index : 55\n",
      "shape : [ 60   1   1 240]\n",
      "shape_signature : [ 60   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0011013 , 0.0011061 , 0.00110672, 0.00110864, 0.0011082 ,\n",
      "       0.001112  , 0.00110824, 0.00110378, 0.00110669, 0.00111442,\n",
      "       0.00109462, 0.00110868, 0.00110856, 0.00110869, 0.00110724,\n",
      "       0.00111335, 0.00111152, 0.00109259, 0.00111385, 0.0011196 ,\n",
      "       0.00110455, 0.00110215, 0.00111291, 0.00111626, 0.00109782,\n",
      "       0.00111422, 0.00111001, 0.00111555, 0.00111359, 0.00110658,\n",
      "       0.00110642, 0.00111427, 0.00111607, 0.00111076, 0.00110642,\n",
      "       0.00111768, 0.00110808, 0.00110664, 0.00111344, 0.00109889,\n",
      "       0.00110809, 0.00111068, 0.00111186, 0.00111421, 0.00111452,\n",
      "       0.0011132 , 0.00110999, 0.0011141 , 0.00111006, 0.00111339,\n",
      "       0.00111194, 0.00111323, 0.00111251, 0.00110589, 0.00110677,\n",
      "       0.00109928, 0.00111133, 0.00110932, 0.00110898, 0.00110802],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/BiasAdd/ReadVariableOp/resource\n",
      "index : 56\n",
      "shape : [60]\n",
      "shape_signature : [60]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.8669664e-08, 6.8968497e-08, 6.9007427e-08, 6.9126862e-08,\n",
      "       6.9099755e-08, 6.9336259e-08, 6.9101894e-08, 6.8824320e-08,\n",
      "       6.9005480e-08, 6.9487378e-08, 6.8252902e-08, 6.9129698e-08,\n",
      "       6.9122308e-08, 6.9130081e-08, 6.9039544e-08, 6.9420551e-08,\n",
      "       6.9306594e-08, 6.8126127e-08, 6.9452106e-08, 6.9810348e-08,\n",
      "       6.8872190e-08, 6.8722116e-08, 6.9393359e-08, 6.9601960e-08,\n",
      "       6.8452181e-08, 6.9474702e-08, 6.9212419e-08, 6.9558119e-08,\n",
      "       6.9435821e-08, 6.8998524e-08, 6.8988903e-08, 6.9477899e-08,\n",
      "       6.9590378e-08, 6.9259116e-08, 6.8988903e-08, 6.9690998e-08,\n",
      "       6.9092344e-08, 6.9002567e-08, 6.9426243e-08, 6.8519434e-08,\n",
      "       6.9092764e-08, 6.9254192e-08, 6.9327797e-08, 6.9474325e-08,\n",
      "       6.9493872e-08, 6.9411513e-08, 6.9211453e-08, 6.9467362e-08,\n",
      "       6.9215737e-08, 6.9423187e-08, 6.9332586e-08, 6.9413524e-08,\n",
      "       6.9368681e-08, 6.8955565e-08, 6.9010738e-08, 6.8543372e-08,\n",
      "       6.9294735e-08, 6.9169666e-08, 6.9148541e-08, 6.9088323e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/Conv2D\n",
      "index : 57\n",
      "shape : [240   1   1  60]\n",
      "shape_signature : [240   1   1  60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00110346, 0.00110788, 0.00109684, 0.00108696, 0.00111374,\n",
      "       0.0010932 , 0.00110471, 0.00111447, 0.00110097, 0.00109952,\n",
      "       0.00111241, 0.00109627, 0.00110663, 0.00111595, 0.00110864,\n",
      "       0.00110871, 0.00110813, 0.00110851, 0.00109422, 0.00109606,\n",
      "       0.00109356, 0.00111292, 0.00105258, 0.00108321, 0.00107128,\n",
      "       0.00111466, 0.00111093, 0.00110267, 0.00110501, 0.00109073,\n",
      "       0.00109874, 0.00108986, 0.00110469, 0.00108539, 0.00111449,\n",
      "       0.00109939, 0.00106947, 0.00110599, 0.00109852, 0.00109453,\n",
      "       0.0010436 , 0.00111239, 0.0010721 , 0.00111339, 0.00111091,\n",
      "       0.00103332, 0.00106927, 0.00108517, 0.00111497, 0.00108359,\n",
      "       0.00110243, 0.00108098, 0.00107384, 0.00111366, 0.00110095,\n",
      "       0.00109343, 0.00110809, 0.00108513, 0.00110044, 0.00110986,\n",
      "       0.00111053, 0.00110786, 0.00110054, 0.00108518, 0.00111206,\n",
      "       0.00105437, 0.00111449, 0.00109713, 0.00109771, 0.00110325,\n",
      "       0.00109885, 0.00111169, 0.00110831, 0.00108901, 0.00109534,\n",
      "       0.00106653, 0.00111314, 0.0011004 , 0.00109835, 0.00110522,\n",
      "       0.00109187, 0.00110941, 0.00109441, 0.00110695, 0.00109247,\n",
      "       0.00110688, 0.00110134, 0.00109648, 0.00111072, 0.00110178,\n",
      "       0.00111298, 0.00110318, 0.00107205, 0.00108839, 0.00103633,\n",
      "       0.00110458, 0.00110539, 0.00108087, 0.00110533, 0.00110705,\n",
      "       0.00109828, 0.00108939, 0.00109835, 0.00109679, 0.00110794,\n",
      "       0.00111088, 0.00108364, 0.00108464, 0.00108133, 0.00111278,\n",
      "       0.00107928, 0.00106653, 0.00109209, 0.00108203, 0.00110409,\n",
      "       0.00111119, 0.00111112, 0.00110879, 0.00104187, 0.00111007,\n",
      "       0.00110525, 0.00111039, 0.00110428, 0.00109813, 0.0010886 ,\n",
      "       0.00111082, 0.00103119, 0.00108271, 0.00106408, 0.00110996,\n",
      "       0.001109  , 0.00111233, 0.00111498, 0.00108274, 0.00108722,\n",
      "       0.00111083, 0.00103688, 0.00111278, 0.00109487, 0.00110448,\n",
      "       0.00111609, 0.00110355, 0.00110047, 0.00108151, 0.00109969,\n",
      "       0.00108815, 0.00106467, 0.0010923 , 0.00108967, 0.00111026,\n",
      "       0.00110834, 0.00110859, 0.0011129 , 0.00109535, 0.00107908,\n",
      "       0.00107706, 0.0011063 , 0.0010587 , 0.00110575, 0.00109924,\n",
      "       0.00109314, 0.0010936 , 0.00108237, 0.00107205, 0.00110659,\n",
      "       0.00109282, 0.0011057 , 0.00109258, 0.0011024 , 0.00109589,\n",
      "       0.0011088 , 0.00100986, 0.0010863 , 0.00110532, 0.00111295,\n",
      "       0.00107625, 0.00110885, 0.00109635, 0.00107864, 0.00106341,\n",
      "       0.00110237, 0.00109015, 0.00109675, 0.00109201, 0.00110196,\n",
      "       0.00107981, 0.00107805, 0.00110861, 0.00111825, 0.00108726,\n",
      "       0.00109697, 0.00109267, 0.00110998, 0.00108636, 0.00105594,\n",
      "       0.00109778, 0.00110831, 0.00109734, 0.00110385, 0.00111546,\n",
      "       0.00108895, 0.00110973, 0.00110785, 0.00109297, 0.00109441,\n",
      "       0.00109607, 0.0011113 , 0.00110184, 0.0011111 , 0.00110791,\n",
      "       0.00111058, 0.00110568, 0.00110326, 0.00107788, 0.00109942,\n",
      "       0.0011126 , 0.00109337, 0.00109216, 0.0011027 , 0.00110872,\n",
      "       0.00111525, 0.00110224, 0.00109965, 0.00109623, 0.00109472,\n",
      "       0.00110355, 0.00109918, 0.00109671, 0.00109727, 0.00110851,\n",
      "       0.00105128, 0.00109714, 0.0011074 , 0.00109694, 0.00109647,\n",
      "       0.00110241, 0.00110737, 0.00109445, 0.00110028, 0.00109695],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/BiasAdd/ReadVariableOp/resource\n",
      "index : 58\n",
      "shape : [240]\n",
      "shape_signature : [240]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.9125021e-08, 2.9241740e-08, 2.8950218e-08, 2.8689580e-08,\n",
      "       2.9396405e-08, 2.8854085e-08, 2.9157970e-08, 2.9415711e-08,\n",
      "       2.9059366e-08, 2.9021066e-08, 2.9361326e-08, 2.8935162e-08,\n",
      "       2.9208788e-08, 2.9454602e-08, 2.9261823e-08, 2.9263532e-08,\n",
      "       2.9248369e-08, 2.9258400e-08, 2.8880999e-08, 2.8929620e-08,\n",
      "       2.8863608e-08, 2.9374583e-08, 2.7782123e-08, 2.8590442e-08,\n",
      "       2.8275528e-08, 2.9420557e-08, 2.9322159e-08, 2.9104115e-08,\n",
      "       2.9165930e-08, 2.8788952e-08, 2.9000310e-08, 2.8765985e-08,\n",
      "       2.9157487e-08, 2.8648062e-08, 2.9416192e-08, 2.9017677e-08,\n",
      "       2.8227975e-08, 2.9191714e-08, 2.8994606e-08, 2.8889435e-08,\n",
      "       2.7545090e-08, 2.9360587e-08, 2.8297258e-08, 2.9387135e-08,\n",
      "       2.9321729e-08, 2.7273703e-08, 2.8222555e-08, 2.8642196e-08,\n",
      "       2.9428868e-08, 2.8600516e-08, 2.9097711e-08, 2.8531671e-08,\n",
      "       2.8343303e-08, 2.9394233e-08, 2.9058793e-08, 2.8860176e-08,\n",
      "       2.9247280e-08, 2.8641191e-08, 2.9045399e-08, 2.9293979e-08,\n",
      "       2.9311582e-08, 2.9241058e-08, 2.9047804e-08, 2.8642543e-08,\n",
      "       2.9351931e-08, 2.7829213e-08, 2.9416027e-08, 2.8957922e-08,\n",
      "       2.8973178e-08, 2.9119560e-08, 2.9003232e-08, 2.9342361e-08,\n",
      "       2.9252977e-08, 2.8743580e-08, 2.8910804e-08, 2.8150273e-08,\n",
      "       2.9380626e-08, 2.9044280e-08, 2.8990099e-08, 2.9171407e-08,\n",
      "       2.8819155e-08, 2.9282130e-08, 2.8886037e-08, 2.9217077e-08,\n",
      "       2.8834801e-08, 2.9215386e-08, 2.9069046e-08, 2.8940757e-08,\n",
      "       2.9316720e-08, 2.9080590e-08, 2.9376301e-08, 2.9117677e-08,\n",
      "       2.8296062e-08, 2.8727303e-08, 2.7353272e-08, 2.9154544e-08,\n",
      "       2.9176038e-08, 2.8528703e-08, 2.9174295e-08, 2.9219660e-08,\n",
      "       2.8988218e-08, 2.8753673e-08, 2.8990225e-08, 2.8949021e-08,\n",
      "       2.9243196e-08, 2.9320924e-08, 2.8601901e-08, 2.8628326e-08,\n",
      "       2.8540985e-08, 2.9370987e-08, 2.8486875e-08, 2.8150341e-08,\n",
      "       2.8824880e-08, 2.8559342e-08, 2.9141722e-08, 2.9329085e-08,\n",
      "       2.9327191e-08, 2.9265566e-08, 2.7499430e-08, 2.9299535e-08,\n",
      "       2.9172265e-08, 2.9308049e-08, 2.9146657e-08, 2.8984243e-08,\n",
      "       2.8732815e-08, 2.9319368e-08, 2.7217423e-08, 2.8577457e-08,\n",
      "       2.8085559e-08, 2.9296634e-08, 2.9271225e-08, 2.9359072e-08,\n",
      "       2.9429188e-08, 2.8577995e-08, 2.8696245e-08, 2.9319430e-08,\n",
      "       2.7367642e-08, 2.9371046e-08, 2.8898155e-08, 2.9151879e-08,\n",
      "       2.9458322e-08, 2.9127451e-08, 2.9045994e-08, 2.8545658e-08,\n",
      "       2.9025598e-08, 2.8720885e-08, 2.8101217e-08, 2.8830565e-08,\n",
      "       2.8760944e-08, 2.9304449e-08, 2.9253815e-08, 2.9260327e-08,\n",
      "       2.9374100e-08, 2.8910884e-08, 2.8481423e-08, 2.8428266e-08,\n",
      "       2.9199983e-08, 2.7943702e-08, 2.9185365e-08, 2.9013568e-08,\n",
      "       2.8852623e-08, 2.8864687e-08, 2.8568252e-08, 2.8295842e-08,\n",
      "       2.9207646e-08, 2.8844143e-08, 2.9184033e-08, 2.8837789e-08,\n",
      "       2.9097063e-08, 2.8925093e-08, 2.9265932e-08, 2.6654423e-08,\n",
      "       2.8672208e-08, 2.9174139e-08, 2.9375409e-08, 2.8406815e-08,\n",
      "       2.9267401e-08, 2.8937313e-08, 2.8469842e-08, 2.8067950e-08,\n",
      "       2.9096325e-08, 2.8773625e-08, 2.8947801e-08, 2.8822704e-08,\n",
      "       2.9085445e-08, 2.8500880e-08, 2.8454240e-08, 2.9260963e-08,\n",
      "       2.9515407e-08, 2.8697521e-08, 2.8953679e-08, 2.8840287e-08,\n",
      "       2.9297055e-08, 2.8673712e-08, 2.7870746e-08, 2.8974963e-08,\n",
      "       2.9252931e-08, 2.8963385e-08, 2.9135354e-08, 2.9441644e-08,\n",
      "       2.8742019e-08, 2.9290382e-08, 2.9240871e-08, 2.8848014e-08,\n",
      "       2.8886253e-08, 2.8929849e-08, 2.9331844e-08, 2.9082132e-08,\n",
      "       2.9326669e-08, 2.9242496e-08, 2.9313014e-08, 2.9183532e-08,\n",
      "       2.9119601e-08, 2.8449719e-08, 2.9018331e-08, 2.9366372e-08,\n",
      "       2.8858652e-08, 2.8826797e-08, 2.9104902e-08, 2.9263845e-08,\n",
      "       2.9436166e-08, 2.9092702e-08, 2.9024436e-08, 2.8934172e-08,\n",
      "       2.8894437e-08, 2.9127495e-08, 2.9011982e-08, 2.8946774e-08,\n",
      "       2.8961708e-08, 2.9258400e-08, 2.7747667e-08, 2.8958214e-08,\n",
      "       2.9228989e-08, 2.8952932e-08, 2.8940470e-08, 2.9097238e-08,\n",
      "       2.9228117e-08, 2.8887317e-08, 2.9040967e-08, 2.8953067e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_20/Conv2D\n",
      "index : 59\n",
      "shape : [ 40   1   1 240]\n",
      "shape_signature : [ 40   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00124755, 0.00123831, 0.00124131, 0.0012346 , 0.00124178,\n",
      "       0.00123204, 0.00124144, 0.00123197, 0.00124368, 0.0012398 ,\n",
      "       0.00123806, 0.00124992, 0.00124267, 0.00123635, 0.00123438,\n",
      "       0.00124174, 0.00124051, 0.00123877, 0.00123783, 0.00123088,\n",
      "       0.00124099, 0.00123792, 0.0012448 , 0.00124235, 0.00124813,\n",
      "       0.00123651, 0.00125131, 0.00124653, 0.00122574, 0.00122879,\n",
      "       0.0012459 , 0.00123757, 0.00123708, 0.00124126, 0.00120737,\n",
      "       0.00123947, 0.00124147, 0.00122235, 0.00123309, 0.00122715],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_15/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_20/Conv2D\n",
      "index : 60\n",
      "shape : [40]\n",
      "shape_signature : [40]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.9859373e-08, 1.9712239e-08, 1.9760064e-08, 1.9653198e-08,\n",
      "       1.9767604e-08, 1.9612484e-08, 1.9762069e-08, 1.9611408e-08,\n",
      "       1.9797863e-08, 1.9736060e-08, 1.9708393e-08, 1.9897186e-08,\n",
      "       1.9781638e-08, 1.9681082e-08, 1.9649677e-08, 1.9766970e-08,\n",
      "       1.9747379e-08, 1.9719614e-08, 1.9704597e-08, 1.9594065e-08,\n",
      "       1.9754916e-08, 1.9706162e-08, 1.9815683e-08, 1.9776644e-08,\n",
      "       1.9868681e-08, 1.9683574e-08, 1.9919302e-08, 1.9843103e-08,\n",
      "       1.9512189e-08, 1.9560771e-08, 1.9833104e-08, 1.9700556e-08,\n",
      "       1.9692731e-08, 1.9759190e-08, 1.9219842e-08, 1.9730717e-08,\n",
      "       1.9762625e-08, 1.9458261e-08, 1.9629194e-08, 1.9534665e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act/conv2d_65/Conv2D\n",
      "index : 61\n",
      "shape : [64  1  1 40]\n",
      "shape_signature : [64  1  1 40]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00179841, 0.00180062, 0.00175222, 0.00180025, 0.00174805,\n",
      "       0.00179606, 0.00170461, 0.00177725, 0.00175089, 0.00183921,\n",
      "       0.00176062, 0.00182204, 0.0017343 , 0.00177657, 0.00177781,\n",
      "       0.00181396, 0.00174642, 0.00182238, 0.00175578, 0.00174342,\n",
      "       0.00180787, 0.00173826, 0.00180264, 0.00178439, 0.00169494,\n",
      "       0.00179067, 0.00167527, 0.00170545, 0.00182272, 0.00179016,\n",
      "       0.0018032 , 0.00171956, 0.00180714, 0.00177224, 0.00177373,\n",
      "       0.00173647, 0.00165723, 0.00175786, 0.0016533 , 0.0017262 ,\n",
      "       0.00170583, 0.00169809, 0.00182605, 0.00174675, 0.0017603 ,\n",
      "       0.00161669, 0.00181184, 0.00167229, 0.00178695, 0.00169026,\n",
      "       0.00174891, 0.00176195, 0.00176093, 0.00173369, 0.00176742,\n",
      "       0.00174496, 0.00166542, 0.00172651, 0.00175136, 0.00182415,\n",
      "       0.0017029 , 0.00169342, 0.00173187, 0.0018317 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act/batch_normalization_49/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act/conv2d_65/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act/conv2d_65/BiasAdd\n",
      "index : 62\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.0475470e-07, 4.0525100e-07, 3.9435801e-07, 4.0516821e-07,\n",
      "       3.9342038e-07, 4.0422427e-07, 3.8364422e-07, 3.9999239e-07,\n",
      "       3.9405825e-07, 4.1393645e-07, 3.9624956e-07, 4.1007164e-07,\n",
      "       3.9032605e-07, 3.9983766e-07, 4.0011835e-07, 4.0825361e-07,\n",
      "       3.9305198e-07, 4.1014897e-07, 3.9515942e-07, 3.9237830e-07,\n",
      "       4.0688266e-07, 3.9121758e-07, 4.0570598e-07, 4.0159844e-07,\n",
      "       3.8146777e-07, 4.0301177e-07, 3.7703953e-07, 3.8383209e-07,\n",
      "       4.1022568e-07, 4.0289746e-07, 4.0583140e-07, 3.8700765e-07,\n",
      "       4.0671992e-07, 3.9886518e-07, 3.9919917e-07, 3.9081476e-07,\n",
      "       3.7297931e-07, 3.9562676e-07, 3.7209608e-07, 3.8850195e-07,\n",
      "       3.8391846e-07, 3.8217621e-07, 4.1097516e-07, 3.9312752e-07,\n",
      "       3.9617774e-07, 3.6385580e-07, 4.0777599e-07, 3.7636988e-07,\n",
      "       4.0217535e-07, 3.8041247e-07, 3.9361441e-07, 3.9654796e-07,\n",
      "       3.9631763e-07, 3.9018872e-07, 3.9777902e-07, 3.9272416e-07,\n",
      "       3.7482255e-07, 3.8857129e-07, 3.9416514e-07, 4.1054631e-07,\n",
      "       3.8325857e-07, 3.8112378e-07, 3.8977882e-07, 4.1224590e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/strided_slice\n",
      "index : 63\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001962705748155713, -128)\n",
      "quantization_parameters : {'scales': array([0.00196271], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/conv2d_21/Conv2D\n",
      "index : 64\n",
      "shape : [240   1   1  40]\n",
      "shape_signature : [240   1   1  40]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00115179, 0.00110486, 0.00115351, 0.00117049, 0.00116984,\n",
      "       0.00117346, 0.00116668, 0.00117875, 0.00110651, 0.00114562,\n",
      "       0.00118206, 0.00118671, 0.00115137, 0.00115571, 0.00119076,\n",
      "       0.00115165, 0.00113246, 0.00116881, 0.00116279, 0.00112605,\n",
      "       0.00117266, 0.0011739 , 0.00120034, 0.001163  , 0.00116958,\n",
      "       0.00111956, 0.00114962, 0.00118607, 0.00114834, 0.0012043 ,\n",
      "       0.00119659, 0.00116709, 0.00116687, 0.00114508, 0.00111885,\n",
      "       0.00116457, 0.0011608 , 0.00118591, 0.00117962, 0.00119235,\n",
      "       0.00115393, 0.00113631, 0.00114295, 0.00116025, 0.00117292,\n",
      "       0.00117629, 0.00116149, 0.0011892 , 0.00115776, 0.0011529 ,\n",
      "       0.0011982 , 0.00112497, 0.00114188, 0.00110384, 0.00111702,\n",
      "       0.00114251, 0.00116225, 0.00119539, 0.00103106, 0.0011469 ,\n",
      "       0.00112426, 0.001168  , 0.00118543, 0.00115286, 0.0011876 ,\n",
      "       0.00119042, 0.00115743, 0.00119766, 0.00116084, 0.00118878,\n",
      "       0.00118658, 0.0011622 , 0.0011604 , 0.00118813, 0.00113861,\n",
      "       0.00115988, 0.00114919, 0.00117503, 0.00111254, 0.00118871,\n",
      "       0.00116283, 0.00115303, 0.00111887, 0.00117239, 0.00118512,\n",
      "       0.00117013, 0.00119084, 0.00113933, 0.00116386, 0.00113016,\n",
      "       0.00115738, 0.00115657, 0.00117164, 0.00118568, 0.00113237,\n",
      "       0.00117136, 0.0011666 , 0.00115285, 0.00116186, 0.00118603,\n",
      "       0.00112519, 0.0011922 , 0.00116187, 0.00118623, 0.00114463,\n",
      "       0.00114902, 0.00117057, 0.00113311, 0.00112288, 0.00118727,\n",
      "       0.0011729 , 0.00113629, 0.00117328, 0.00119004, 0.00118099,\n",
      "       0.00116586, 0.00111894, 0.00116795, 0.00118808, 0.00112472,\n",
      "       0.00117313, 0.00115728, 0.00115015, 0.00118718, 0.00121324,\n",
      "       0.00115864, 0.00108194, 0.00115623, 0.00117148, 0.00117595,\n",
      "       0.00115454, 0.00114817, 0.00115695, 0.00118548, 0.00116268,\n",
      "       0.00113885, 0.0011653 , 0.00119527, 0.0011601 , 0.00115666,\n",
      "       0.00116309, 0.00118024, 0.00111176, 0.00119475, 0.00113011,\n",
      "       0.00118184, 0.00116905, 0.00118385, 0.00117768, 0.00116747,\n",
      "       0.00119262, 0.0011626 , 0.00116132, 0.00116469, 0.00116918,\n",
      "       0.00115652, 0.00116052, 0.00116698, 0.00119486, 0.00117364,\n",
      "       0.00117884, 0.00116951, 0.00115522, 0.00117514, 0.00116515,\n",
      "       0.00116608, 0.00116497, 0.00116662, 0.0011324 , 0.00118627,\n",
      "       0.00113749, 0.00117525, 0.00117159, 0.0011645 , 0.00117886,\n",
      "       0.00116506, 0.00117448, 0.00118663, 0.00116861, 0.00113797,\n",
      "       0.00116028, 0.00117067, 0.00114054, 0.00119173, 0.0011722 ,\n",
      "       0.00117841, 0.00116095, 0.00113153, 0.00115499, 0.00117209,\n",
      "       0.00117416, 0.00118142, 0.00119115, 0.00117014, 0.00115589,\n",
      "       0.00119322, 0.0011574 , 0.00114329, 0.0011798 , 0.00114938,\n",
      "       0.00111229, 0.00115286, 0.00117976, 0.00116227, 0.0011707 ,\n",
      "       0.00106085, 0.00115954, 0.00117253, 0.00116981, 0.00107652,\n",
      "       0.0011766 , 0.00116461, 0.00106611, 0.00105607, 0.00117173,\n",
      "       0.00114662, 0.00116663, 0.00114123, 0.00117012, 0.00117757,\n",
      "       0.00114184, 0.00118729, 0.00118968, 0.00118233, 0.00102551,\n",
      "       0.0011    , 0.00118493, 0.00116777, 0.00111468, 0.00117771,\n",
      "       0.00108865, 0.00116236, 0.00119044, 0.00116255, 0.00112352,\n",
      "       0.00114915, 0.00112038, 0.0011813 , 0.00116014, 0.00116813],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_16/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/conv2d_21/Conv2D\n",
      "index : 65\n",
      "shape : [240]\n",
      "shape_signature : [240]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.5922364e-07, 2.4866210e-07, 2.5961077e-07, 2.6343236e-07,\n",
      "       2.6328607e-07, 2.6410092e-07, 2.6257624e-07, 2.6529270e-07,\n",
      "       2.4903255e-07, 2.5783663e-07, 2.6603803e-07, 2.6708381e-07,\n",
      "       2.5912888e-07, 2.6010591e-07, 2.6799592e-07, 2.5919292e-07,\n",
      "       2.5487429e-07, 2.6305398e-07, 2.6170005e-07, 2.5343215e-07,\n",
      "       2.6392152e-07, 2.6419937e-07, 2.7015014e-07, 2.6174706e-07,\n",
      "       2.6322803e-07, 2.5197164e-07, 2.5873561e-07, 2.6694056e-07,\n",
      "       2.5844827e-07, 2.7104176e-07, 2.6930732e-07, 2.6266852e-07,\n",
      "       2.6261728e-07, 2.5771428e-07, 2.5181069e-07, 2.6209980e-07,\n",
      "       2.6125312e-07, 2.6690458e-07, 2.6548850e-07, 2.6835357e-07,\n",
      "       2.5970530e-07, 2.5573974e-07, 2.5723580e-07, 2.6112832e-07,\n",
      "       2.6397956e-07, 2.6473901e-07, 2.6140697e-07, 2.6764334e-07,\n",
      "       2.6056796e-07, 2.5947384e-07, 2.6966984e-07, 2.5318846e-07,\n",
      "       2.5699293e-07, 2.4843217e-07, 2.5139857e-07, 2.5713578e-07,\n",
      "       2.6157954e-07, 2.6903697e-07, 2.3205261e-07, 2.5812412e-07,\n",
      "       2.5302805e-07, 2.6287242e-07, 2.6679552e-07, 2.5946562e-07,\n",
      "       2.6728375e-07, 2.6791926e-07, 2.6049369e-07, 2.6954842e-07,\n",
      "       2.6126006e-07, 2.6754935e-07, 2.6705399e-07, 2.6156783e-07,\n",
      "       2.6116237e-07, 2.6740423e-07, 2.5625747e-07, 2.6104470e-07,\n",
      "       2.5863903e-07, 2.6445585e-07, 2.5039066e-07, 2.6753304e-07,\n",
      "       2.6170875e-07, 2.5950402e-07, 2.5181455e-07, 2.6386135e-07,\n",
      "       2.6672566e-07, 2.6335132e-07, 2.6801229e-07, 2.5641916e-07,\n",
      "       2.6194164e-07, 2.5435702e-07, 2.6048258e-07, 2.6030028e-07,\n",
      "       2.6369213e-07, 2.6685228e-07, 2.5485463e-07, 2.6362969e-07,\n",
      "       2.6255839e-07, 2.5946386e-07, 2.6149027e-07, 2.6693070e-07,\n",
      "       2.5323661e-07, 2.6831822e-07, 2.6149249e-07, 2.6697461e-07,\n",
      "       2.5761202e-07, 2.5860015e-07, 2.6345211e-07, 2.5502121e-07,\n",
      "       2.5271805e-07, 2.6721042e-07, 2.6397603e-07, 2.5573488e-07,\n",
      "       2.6405988e-07, 2.6783309e-07, 2.6579602e-07, 2.6239152e-07,\n",
      "       2.5183169e-07, 2.6286239e-07, 2.6739150e-07, 2.5313125e-07,\n",
      "       2.6402793e-07, 2.6046058e-07, 2.5885447e-07, 2.6719042e-07,\n",
      "       2.7305481e-07, 2.6076492e-07, 2.4350430e-07, 2.6022454e-07,\n",
      "       2.6365603e-07, 2.6466188e-07, 2.5984335e-07, 2.5840953e-07,\n",
      "       2.6038646e-07, 2.6680650e-07, 2.6167592e-07, 2.5631175e-07,\n",
      "       2.6226459e-07, 2.6901060e-07, 2.6109356e-07, 2.6032086e-07,\n",
      "       2.6176764e-07, 2.6562651e-07, 2.5021527e-07, 2.6889415e-07,\n",
      "       2.5434571e-07, 2.6598644e-07, 2.6310900e-07, 2.6643971e-07,\n",
      "       2.6505077e-07, 2.6275279e-07, 2.6841306e-07, 2.6165691e-07,\n",
      "       2.6137030e-07, 2.6212797e-07, 2.6313876e-07, 2.6028781e-07,\n",
      "       2.6118994e-07, 2.6264291e-07, 2.6891763e-07, 2.6414165e-07,\n",
      "       2.6531194e-07, 2.6321342e-07, 2.5999717e-07, 2.6447918e-07,\n",
      "       2.6223225e-07, 2.6243987e-07, 2.6219038e-07, 2.6256254e-07,\n",
      "       2.5486042e-07, 2.6698419e-07, 2.5600633e-07, 2.6450365e-07,\n",
      "       2.6368076e-07, 2.6208559e-07, 2.6531617e-07, 2.6220988e-07,\n",
      "       2.6433165e-07, 2.6706650e-07, 2.6301021e-07, 2.5611368e-07,\n",
      "       2.6113477e-07, 2.6347413e-07, 2.5669291e-07, 2.6821326e-07,\n",
      "       2.6381736e-07, 2.6521494e-07, 2.6128481e-07, 2.5466375e-07,\n",
      "       2.5994538e-07, 2.6379368e-07, 2.6425835e-07, 2.6589376e-07,\n",
      "       2.6808314e-07, 2.6335502e-07, 2.6014632e-07, 2.6854789e-07,\n",
      "       2.6048747e-07, 2.5731032e-07, 2.6552911e-07, 2.5868192e-07,\n",
      "       2.5033509e-07, 2.5946417e-07, 2.6551945e-07, 2.6158210e-07,\n",
      "       2.6348076e-07, 2.3875799e-07, 2.6096862e-07, 2.6389318e-07,\n",
      "       2.6328030e-07, 2.4228450e-07, 2.6480799e-07, 2.6210955e-07,\n",
      "       2.3994173e-07, 2.3768128e-07, 2.6371171e-07, 2.5806062e-07,\n",
      "       2.6256464e-07, 2.5684662e-07, 2.6334939e-07, 2.6502582e-07,\n",
      "       2.5698606e-07, 2.6721511e-07, 2.6775220e-07, 2.6609800e-07,\n",
      "       2.3080452e-07, 2.4756758e-07, 2.6668243e-07, 2.6282032e-07,\n",
      "       2.5087252e-07, 2.6505705e-07, 2.4501307e-07, 2.6160217e-07,\n",
      "       2.6792313e-07, 2.6164696e-07, 2.5286298e-07, 2.5862971e-07,\n",
      "       2.5215436e-07, 2.6586562e-07, 2.6110291e-07, 2.6290112e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_17/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/depthwise_conv2d_5/depthwise;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D\n",
      "index : 66\n",
      "shape : [  1   3   3 240]\n",
      "shape_signature : [  1   3   3 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00038647, 0.0003814 , 0.00043943, 0.00034083, 0.00038871,\n",
      "       0.0004187 , 0.00041929, 0.00041826, 0.00045266, 0.0003457 ,\n",
      "       0.00044084, 0.00043269, 0.00037894, 0.00042316, 0.00040646,\n",
      "       0.00037494, 0.00043404, 0.00038872, 0.00043559, 0.00041977,\n",
      "       0.00044452, 0.00043625, 0.00036156, 0.00042836, 0.0004272 ,\n",
      "       0.00044387, 0.0003925 , 0.00039298, 0.00040933, 0.00044365,\n",
      "       0.00042777, 0.00042378, 0.00026681, 0.00042567, 0.0004417 ,\n",
      "       0.00037279, 0.00044634, 0.00041967, 0.00043075, 0.00044812,\n",
      "       0.00041624, 0.00044563, 0.00034467, 0.00039488, 0.00045411,\n",
      "       0.0003617 , 0.00039051, 0.00044516, 0.000429  , 0.00041688,\n",
      "       0.00041305, 0.00043241, 0.00043097, 0.00041628, 0.00038743,\n",
      "       0.00039428, 0.00045049, 0.00039669, 0.00043379, 0.00043708,\n",
      "       0.00044225, 0.00039173, 0.00042021, 0.00021862, 0.00041021,\n",
      "       0.00045022, 0.00040343, 0.00041061, 0.00043853, 0.0004488 ,\n",
      "       0.00036434, 0.00030127, 0.0003014 , 0.00041544, 0.00041129,\n",
      "       0.00044722, 0.00041492, 0.00040391, 0.00039714, 0.00042521,\n",
      "       0.00038634, 0.00036932, 0.00036746, 0.00032222, 0.00032265,\n",
      "       0.00042621, 0.00042097, 0.00036698, 0.00042368, 0.00037584,\n",
      "       0.00043056, 0.0003558 , 0.00043965, 0.00025134, 0.00042684,\n",
      "       0.00043885, 0.00042678, 0.00037612, 0.00042048, 0.00042783,\n",
      "       0.00044575, 0.00041176, 0.0003514 , 0.0004121 , 0.00044707,\n",
      "       0.00040468, 0.00045037, 0.00040955, 0.00044582, 0.00044329,\n",
      "       0.00039267, 0.00043391, 0.00030146, 0.00037475, 0.00035907,\n",
      "       0.00031522, 0.00036852, 0.00041321, 0.00033185, 0.00042301,\n",
      "       0.00041446, 0.00041039, 0.0004421 , 0.000416  , 0.00042454,\n",
      "       0.00036428, 0.00039849, 0.00043508, 0.00040899, 0.00042467,\n",
      "       0.00040395, 0.0004501 , 0.00044339, 0.00042024, 0.00038536,\n",
      "       0.00033973, 0.00041294, 0.00040033, 0.00043636, 0.00038555,\n",
      "       0.00043858, 0.00044253, 0.00034468, 0.00043506, 0.00041479,\n",
      "       0.00042444, 0.00040755, 0.00042266, 0.00044544, 0.00044784,\n",
      "       0.00041135, 0.00039985, 0.00042972, 0.00042823, 0.00043367,\n",
      "       0.00039127, 0.00045002, 0.00041596, 0.00036104, 0.00043434,\n",
      "       0.00042534, 0.0002651 , 0.0004435 , 0.00044314, 0.00038017,\n",
      "       0.00043802, 0.00045293, 0.00039411, 0.00045051, 0.00044748,\n",
      "       0.00044805, 0.00041168, 0.00035379, 0.00042824, 0.00044491,\n",
      "       0.00039799, 0.00044062, 0.00034425, 0.00033691, 0.00036415,\n",
      "       0.00029116, 0.0004051 , 0.00041988, 0.00034523, 0.00035647,\n",
      "       0.00030262, 0.00041319, 0.00045063, 0.00030757, 0.00044096,\n",
      "       0.000445  , 0.00043287, 0.00030244, 0.0004145 , 0.00042729,\n",
      "       0.00037567, 0.00043097, 0.0004162 , 0.0004437 , 0.00043279,\n",
      "       0.00038807, 0.0004457 , 0.00044568, 0.00044541, 0.00040664,\n",
      "       0.00045088, 0.00040668, 0.0004107 , 0.00042506, 0.00028284,\n",
      "       0.00043132, 0.0004399 , 0.00032927, 0.00040658, 0.00040771,\n",
      "       0.00042491, 0.00038052, 0.00040949, 0.00037894, 0.00043356,\n",
      "       0.00040258, 0.00043794, 0.00030477, 0.00036959, 0.0004253 ,\n",
      "       0.00035517, 0.00045058, 0.00027429, 0.00040373, 0.00043226,\n",
      "       0.00044509, 0.00037054, 0.00040719, 0.00039403, 0.000447  ,\n",
      "       0.00037338, 0.00035422, 0.00042116, 0.00044086, 0.00044065],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_17/FusedBatchNormV3\n",
      "index : 67\n",
      "shape : [240]\n",
      "shape_signature : [240]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.9579638e-08, 2.9191531e-08, 3.3632947e-08, 2.6086319e-08,\n",
      "       2.9751005e-08, 3.2046607e-08, 3.2091869e-08, 3.2013073e-08,\n",
      "       3.4645794e-08, 2.6458782e-08, 3.3740978e-08, 3.3117221e-08,\n",
      "       2.9003084e-08, 3.2387771e-08, 3.1109209e-08, 2.8697078e-08,\n",
      "       3.3220125e-08, 2.9751762e-08, 3.3339234e-08, 3.2128526e-08,\n",
      "       3.4022797e-08, 3.3389792e-08, 2.7672701e-08, 3.2785490e-08,\n",
      "       3.2697269e-08, 3.3972697e-08, 3.0041434e-08, 3.0078059e-08,\n",
      "       3.1329222e-08, 3.3955864e-08, 3.2740267e-08, 3.2435103e-08,\n",
      "       2.0420838e-08, 3.2579766e-08, 3.3806696e-08, 2.8532872e-08,\n",
      "       3.4161914e-08, 3.2120912e-08, 3.2968611e-08, 3.4298246e-08,\n",
      "       3.1858313e-08, 3.4107291e-08, 2.6380295e-08, 3.0223024e-08,\n",
      "       3.4756329e-08, 2.7684090e-08, 2.9889048e-08, 3.4071729e-08,\n",
      "       3.2834727e-08, 3.1906815e-08, 3.1614210e-08, 3.3095713e-08,\n",
      "       3.2985415e-08, 3.1861553e-08, 2.9653117e-08, 3.0177443e-08,\n",
      "       3.4479324e-08, 3.0361686e-08, 3.3201076e-08, 3.3453077e-08,\n",
      "       3.3848675e-08, 2.9982179e-08, 3.2162063e-08, 1.6732377e-08,\n",
      "       3.1396961e-08, 3.4458658e-08, 3.0877459e-08, 3.1427373e-08,\n",
      "       3.3564074e-08, 3.4350052e-08, 2.7885822e-08, 2.3058545e-08,\n",
      "       2.3068205e-08, 3.1796752e-08, 3.1478908e-08, 3.4229210e-08,\n",
      "       3.1757374e-08, 3.0914759e-08, 3.0395885e-08, 3.2544495e-08,\n",
      "       2.9569735e-08, 2.8266710e-08, 2.8124832e-08, 2.4662153e-08,\n",
      "       2.4694707e-08, 3.2621433e-08, 3.2220068e-08, 2.8087845e-08,\n",
      "       3.2427835e-08, 2.8765989e-08, 3.2954279e-08, 2.7231957e-08,\n",
      "       3.3649972e-08, 1.9237156e-08, 3.2669380e-08, 3.3588449e-08,\n",
      "       3.2665032e-08, 2.8787801e-08, 3.2182850e-08, 3.2745547e-08,\n",
      "       3.4116525e-08, 3.1515118e-08, 2.6895060e-08, 3.1541497e-08,\n",
      "       3.4217791e-08, 3.0973275e-08, 3.4470155e-08, 3.1346111e-08,\n",
      "       3.4122284e-08, 3.3928362e-08, 3.0054142e-08, 3.3210803e-08,\n",
      "       2.3073049e-08, 2.8682644e-08, 2.7482288e-08, 2.4126191e-08,\n",
      "       2.8205575e-08, 3.1626207e-08, 2.5398819e-08, 3.2376217e-08,\n",
      "       3.1721608e-08, 3.1410039e-08, 3.3837331e-08, 3.1839932e-08,\n",
      "       3.2493119e-08, 2.7881496e-08, 3.0499521e-08, 3.3300307e-08,\n",
      "       3.1303586e-08, 3.2503547e-08, 3.0917242e-08, 3.4449677e-08,\n",
      "       3.3935990e-08, 3.2164643e-08, 2.9494538e-08, 2.6002295e-08,\n",
      "       3.1605925e-08, 3.0640209e-08, 3.3398194e-08, 2.9509321e-08,\n",
      "       3.3568355e-08, 3.3870002e-08, 2.6381228e-08, 3.3298786e-08,\n",
      "       3.1747120e-08, 3.2485410e-08, 3.1193352e-08, 3.2349849e-08,\n",
      "       3.4093169e-08, 3.4276958e-08, 3.1483733e-08, 3.0603726e-08,\n",
      "       3.2889609e-08, 3.2776047e-08, 3.3192350e-08, 2.9947177e-08,\n",
      "       3.4443765e-08, 3.1836450e-08, 2.7633192e-08, 3.3243396e-08,\n",
      "       3.2554794e-08, 2.0290322e-08, 3.3944911e-08, 3.3917040e-08,\n",
      "       2.9097148e-08, 3.3524813e-08, 3.4666225e-08, 3.0164358e-08,\n",
      "       3.4480848e-08, 3.4249144e-08, 3.4293095e-08, 3.1509213e-08,\n",
      "       2.7078624e-08, 3.2776281e-08, 3.4052576e-08, 3.0461194e-08,\n",
      "       3.3724419e-08, 2.6348383e-08, 2.5786623e-08, 2.7871630e-08,\n",
      "       2.2284869e-08, 3.1005495e-08, 3.2136565e-08, 2.6423166e-08,\n",
      "       2.7283106e-08, 2.3161801e-08, 3.1624968e-08, 3.4489933e-08,\n",
      "       2.3540727e-08, 3.3750155e-08, 3.4059443e-08, 3.3130586e-08,\n",
      "       2.3148470e-08, 3.1725040e-08, 3.2703799e-08, 2.8753044e-08,\n",
      "       3.2985653e-08, 3.1854693e-08, 3.3959708e-08, 3.3125055e-08,\n",
      "       2.9701727e-08, 3.4113114e-08, 3.4111391e-08, 3.4090863e-08,\n",
      "       3.1123029e-08, 3.4509597e-08, 3.1126127e-08, 3.1433832e-08,\n",
      "       3.2533261e-08, 2.1647624e-08, 3.3012430e-08, 3.3668879e-08,\n",
      "       2.5201297e-08, 3.1118528e-08, 3.1205353e-08, 3.2521562e-08,\n",
      "       2.9124568e-08, 3.1341195e-08, 2.9002985e-08, 3.3183785e-08,\n",
      "       3.0812714e-08, 3.3518699e-08, 2.3326459e-08, 2.8287479e-08,\n",
      "       3.2551792e-08, 2.7183855e-08, 3.4486256e-08, 2.0993843e-08,\n",
      "       3.0900896e-08, 3.3083889e-08, 3.4066414e-08, 2.8359992e-08,\n",
      "       3.1165118e-08, 3.0158521e-08, 3.4212171e-08, 2.8577880e-08,\n",
      "       2.7111579e-08, 3.2234688e-08, 3.3742545e-08, 3.3726209e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/Conv2D\n",
      "index : 68\n",
      "shape : [ 60   1   1 240]\n",
      "shape_signature : [ 60   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00110682, 0.00111401, 0.00111337, 0.00111303, 0.00110912,\n",
      "       0.0011041 , 0.00111482, 0.00110966, 0.0011027 , 0.00110606,\n",
      "       0.0011107 , 0.00110816, 0.00111732, 0.00111193, 0.00110844,\n",
      "       0.00110251, 0.00111087, 0.00110737, 0.00111496, 0.00110687,\n",
      "       0.00111365, 0.00111454, 0.00110853, 0.00110667, 0.00111087,\n",
      "       0.00111274, 0.00110618, 0.00111197, 0.00111581, 0.00109898,\n",
      "       0.00111435, 0.00111356, 0.00110851, 0.00111467, 0.00111429,\n",
      "       0.00110854, 0.00111218, 0.00110598, 0.00111566, 0.00111   ,\n",
      "       0.00110634, 0.00111425, 0.00111765, 0.00111245, 0.00111137,\n",
      "       0.00111178, 0.00111478, 0.00110941, 0.00110442, 0.00110717,\n",
      "       0.00110335, 0.0011157 , 0.00110935, 0.00110986, 0.00111377,\n",
      "       0.0011134 , 0.00110401, 0.00111304, 0.00111716, 0.00110624],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/BiasAdd/ReadVariableOp/resource\n",
      "index : 69\n",
      "shape : [60]\n",
      "shape_signature : [60]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.7620810e-08, 6.8060388e-08, 6.8021038e-08, 6.8000638e-08,\n",
      "       6.7761384e-08, 6.7454692e-08, 6.8109749e-08, 6.7794588e-08,\n",
      "       6.7369626e-08, 6.7574689e-08, 6.7858466e-08, 6.7703013e-08,\n",
      "       6.8262686e-08, 6.7933563e-08, 6.7719888e-08, 6.7357895e-08,\n",
      "       6.7868726e-08, 6.7654462e-08, 6.8118531e-08, 6.7624043e-08,\n",
      "       6.8038474e-08, 6.8093009e-08, 6.7725772e-08, 6.7612106e-08,\n",
      "       6.7868356e-08, 6.7982640e-08, 6.7582171e-08, 6.7936028e-08,\n",
      "       6.8170401e-08, 6.7142011e-08, 6.8081427e-08, 6.8032918e-08,\n",
      "       6.7724443e-08, 6.8100967e-08, 6.8077263e-08, 6.7726482e-08,\n",
      "       6.7948513e-08, 6.7569587e-08, 6.8161185e-08, 6.7815691e-08,\n",
      "       6.7591508e-08, 6.8074904e-08, 6.8282993e-08, 6.7964812e-08,\n",
      "       6.7899386e-08, 6.7924361e-08, 6.8107305e-08, 6.7779602e-08,\n",
      "       6.7474389e-08, 6.7642425e-08, 6.7409019e-08, 6.8163502e-08,\n",
      "       6.7775375e-08, 6.7806575e-08, 6.8045559e-08, 6.8022835e-08,\n",
      "       6.7449157e-08, 6.8000865e-08, 6.8252632e-08, 6.7585390e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D\n",
      "index : 70\n",
      "shape : [240   1   1  60]\n",
      "shape_signature : [240   1   1  60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00110246, 0.00106832, 0.0010831 , 0.00109986, 0.00111139,\n",
      "       0.00109186, 0.00110359, 0.00110764, 0.00110687, 0.00110036,\n",
      "       0.00110006, 0.00109447, 0.00111146, 0.00108531, 0.00108401,\n",
      "       0.001113  , 0.00111735, 0.00110247, 0.00110527, 0.00108957,\n",
      "       0.00111242, 0.00109701, 0.00107386, 0.00109623, 0.00110188,\n",
      "       0.00110713, 0.00111261, 0.00111407, 0.00110475, 0.00111476,\n",
      "       0.00105557, 0.00108125, 0.0011047 , 0.00108859, 0.00108181,\n",
      "       0.00109583, 0.00109776, 0.00109912, 0.00108118, 0.00110995,\n",
      "       0.00109265, 0.00110974, 0.0011141 , 0.0010819 , 0.00105564,\n",
      "       0.0010933 , 0.00108961, 0.00110108, 0.00110709, 0.0010855 ,\n",
      "       0.0010757 , 0.00110575, 0.00111367, 0.00110868, 0.00110972,\n",
      "       0.00108258, 0.00111236, 0.00108342, 0.00111568, 0.0011057 ,\n",
      "       0.00110725, 0.00105605, 0.00111067, 0.00108655, 0.00109946,\n",
      "       0.00110718, 0.00111155, 0.00106955, 0.0011115 , 0.00109888,\n",
      "       0.00111019, 0.00108967, 0.00108349, 0.00109451, 0.00105722,\n",
      "       0.00109505, 0.00110729, 0.00110444, 0.00110009, 0.00111223,\n",
      "       0.00110767, 0.00110773, 0.00110294, 0.00105508, 0.00110663,\n",
      "       0.00111589, 0.00111301, 0.00111463, 0.0011125 , 0.00111795,\n",
      "       0.00108062, 0.00111651, 0.00104261, 0.00104845, 0.00105723,\n",
      "       0.00110687, 0.00109512, 0.00111323, 0.00108946, 0.00109137,\n",
      "       0.00110736, 0.0010936 , 0.00109604, 0.00105874, 0.0011067 ,\n",
      "       0.00109215, 0.00109979, 0.00108843, 0.00109324, 0.00108046,\n",
      "       0.0011121 , 0.00111666, 0.00108561, 0.00110912, 0.00110746,\n",
      "       0.00109979, 0.00111003, 0.00109304, 0.00110561, 0.00109931,\n",
      "       0.00106306, 0.00109191, 0.00110733, 0.00105194, 0.00110856,\n",
      "       0.00110724, 0.00110613, 0.00111256, 0.00109458, 0.00108642,\n",
      "       0.00110433, 0.00107831, 0.00110567, 0.0010324 , 0.00109134,\n",
      "       0.00109299, 0.00111022, 0.00108952, 0.00109471, 0.00109812,\n",
      "       0.00108561, 0.00110204, 0.00109951, 0.00111274, 0.00109554,\n",
      "       0.00106892, 0.00110829, 0.00110193, 0.00110345, 0.00109507,\n",
      "       0.00107358, 0.00108661, 0.0011091 , 0.00109229, 0.00110539,\n",
      "       0.00106929, 0.00110341, 0.00109538, 0.0011079 , 0.0010723 ,\n",
      "       0.0011171 , 0.00106011, 0.00109406, 0.00109219, 0.0010637 ,\n",
      "       0.00110365, 0.00110513, 0.00109325, 0.00110847, 0.00108888,\n",
      "       0.00110479, 0.00109268, 0.00105647, 0.00108124, 0.00111029,\n",
      "       0.00106442, 0.00108724, 0.00105054, 0.00111043, 0.00109736,\n",
      "       0.00108908, 0.0010999 , 0.00109777, 0.00109697, 0.00108821,\n",
      "       0.00110907, 0.00111108, 0.0010978 , 0.00110995, 0.00110417,\n",
      "       0.00111488, 0.00106707, 0.00110774, 0.0011143 , 0.00108654,\n",
      "       0.00111504, 0.00108393, 0.00102371, 0.00110561, 0.00110531,\n",
      "       0.00109566, 0.00111   , 0.00110687, 0.00110775, 0.00107214,\n",
      "       0.00106697, 0.00111405, 0.00111076, 0.00110267, 0.00111681,\n",
      "       0.00108114, 0.00106283, 0.00109959, 0.00110836, 0.00109926,\n",
      "       0.00110311, 0.00110885, 0.00106764, 0.00111101, 0.0011134 ,\n",
      "       0.0011035 , 0.00110526, 0.00102272, 0.00108646, 0.0011055 ,\n",
      "       0.00110066, 0.00111068, 0.00110348, 0.001109  , 0.00107088,\n",
      "       0.00110246, 0.00107693, 0.0011085 , 0.00110576, 0.00109298,\n",
      "       0.00105977, 0.00110713, 0.00107113, 0.00110462, 0.00108833],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/BiasAdd/ReadVariableOp/resource\n",
      "index : 71\n",
      "shape : [240]\n",
      "shape_signature : [240]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.1101700e-08, 3.9828766e-08, 4.0379980e-08, 4.1004821e-08,\n",
      "       4.1434635e-08, 4.0706503e-08, 4.1143693e-08, 4.1294747e-08,\n",
      "       4.1265949e-08, 4.1023331e-08, 4.1012228e-08, 4.0803748e-08,\n",
      "       4.1437286e-08, 4.0462179e-08, 4.0413617e-08, 4.1494442e-08,\n",
      "       4.1656527e-08, 4.1101789e-08, 4.1206452e-08, 4.0620893e-08,\n",
      "       4.1472720e-08, 4.0898222e-08, 4.0035324e-08, 4.0869143e-08,\n",
      "       4.1079854e-08, 4.1275598e-08, 4.1479964e-08, 4.1534534e-08,\n",
      "       4.1187032e-08, 4.1560323e-08, 3.9353619e-08, 4.0310766e-08,\n",
      "       4.1184929e-08, 4.0584332e-08, 4.0331578e-08, 4.0854314e-08,\n",
      "       4.0926427e-08, 4.0976985e-08, 4.0308386e-08, 4.1380904e-08,\n",
      "       4.0735877e-08, 4.1372999e-08, 4.1535483e-08, 4.0334960e-08,\n",
      "       3.9356117e-08, 4.0760128e-08, 4.0622606e-08, 4.1050175e-08,\n",
      "       4.1274031e-08, 4.0469214e-08, 4.0103956e-08, 4.1224077e-08,\n",
      "       4.1519382e-08, 4.1333461e-08, 4.1372310e-08, 4.0360241e-08,\n",
      "       4.1470685e-08, 4.0391843e-08, 4.1594546e-08, 4.1222297e-08,\n",
      "       4.1280018e-08, 3.9371219e-08, 4.1407734e-08, 4.0508564e-08,\n",
      "       4.0989882e-08, 4.1277627e-08, 4.1440586e-08, 3.9874600e-08,\n",
      "       4.1438671e-08, 4.0968221e-08, 4.1389690e-08, 4.0624791e-08,\n",
      "       4.0394163e-08, 4.0805151e-08, 3.9414985e-08, 4.0825338e-08,\n",
      "       4.1281602e-08, 4.1175429e-08, 4.1013102e-08, 4.1465871e-08,\n",
      "       4.1295987e-08, 4.1297938e-08, 4.1119474e-08, 3.9334999e-08,\n",
      "       4.1256968e-08, 4.1602227e-08, 4.1494975e-08, 4.1555186e-08,\n",
      "       4.1475776e-08, 4.1679037e-08, 4.0287439e-08, 4.1625263e-08,\n",
      "       3.8870247e-08, 3.9088050e-08, 3.9415184e-08, 4.1266144e-08,\n",
      "       4.0828002e-08, 4.1503050e-08, 4.0616879e-08, 4.0688100e-08,\n",
      "       4.1284096e-08, 4.0771418e-08, 4.0862364e-08, 3.9471775e-08,\n",
      "       4.1259540e-08, 4.0717353e-08, 4.1002046e-08, 4.0578691e-08,\n",
      "       4.0757804e-08, 4.0281332e-08, 4.1461099e-08, 4.1630845e-08,\n",
      "       4.0473385e-08, 4.1349796e-08, 4.1287890e-08, 4.1002167e-08,\n",
      "       4.1383895e-08, 4.0750557e-08, 4.1218833e-08, 4.0984240e-08,\n",
      "       3.9632777e-08, 4.0708240e-08, 4.1283275e-08, 3.9218268e-08,\n",
      "       4.1329031e-08, 4.1279701e-08, 4.1238504e-08, 4.1478209e-08,\n",
      "       4.0807851e-08, 4.0503565e-08, 4.1171234e-08, 4.0201325e-08,\n",
      "       4.1221419e-08, 3.8489716e-08, 4.0686828e-08, 4.0748382e-08,\n",
      "       4.1390916e-08, 4.0619323e-08, 4.0812665e-08, 4.0939621e-08,\n",
      "       4.0473278e-08, 4.1086071e-08, 4.0991626e-08, 4.1484842e-08,\n",
      "       4.0843631e-08, 3.9851049e-08, 4.1318927e-08, 4.1081858e-08,\n",
      "       4.1138364e-08, 4.0826109e-08, 4.0024972e-08, 4.0510507e-08,\n",
      "       4.1349104e-08, 4.0722341e-08, 4.1210896e-08, 3.9865000e-08,\n",
      "       4.1137138e-08, 4.0837566e-08, 4.1304315e-08, 3.9977301e-08,\n",
      "       4.1647553e-08, 3.9522604e-08, 4.0788358e-08, 4.0718820e-08,\n",
      "       3.9656637e-08, 4.1145967e-08, 4.1201279e-08, 4.0758309e-08,\n",
      "       4.1325503e-08, 4.0595214e-08, 4.1188361e-08, 4.0736875e-08,\n",
      "       3.9387160e-08, 4.0310599e-08, 4.1393378e-08, 3.9683485e-08,\n",
      "       4.0534278e-08, 3.9165869e-08, 4.1398824e-08, 4.0911530e-08,\n",
      "       4.0602838e-08, 4.1006178e-08, 4.0926551e-08, 4.0896914e-08,\n",
      "       4.0570434e-08, 4.1348109e-08, 4.1422851e-08, 4.0927745e-08,\n",
      "       4.1380826e-08, 4.1165386e-08, 4.1564604e-08, 3.9782179e-08,\n",
      "       4.1298364e-08, 4.1543153e-08, 4.0507942e-08, 4.1570598e-08,\n",
      "       4.0410743e-08, 3.8165481e-08, 4.1218851e-08, 4.1207940e-08,\n",
      "       4.0848096e-08, 4.1382787e-08, 4.1265988e-08, 4.1298922e-08,\n",
      "       3.9971230e-08, 3.9778357e-08, 4.1533557e-08, 4.1410910e-08,\n",
      "       4.1109345e-08, 4.1636621e-08, 4.0306659e-08, 3.9624229e-08,\n",
      "       4.0994575e-08, 4.1321705e-08, 4.0982417e-08, 4.1125816e-08,\n",
      "       4.1339973e-08, 3.9803368e-08, 4.1420190e-08, 4.1509484e-08,\n",
      "       4.1140254e-08, 4.1205990e-08, 3.8128697e-08, 4.0505139e-08,\n",
      "       4.1214928e-08, 4.1034603e-08, 4.1408040e-08, 4.1139508e-08,\n",
      "       4.1345380e-08, 3.9924263e-08, 4.1101444e-08, 4.0149899e-08,\n",
      "       4.1326704e-08, 4.1224450e-08, 4.0748084e-08, 3.9510009e-08,\n",
      "       4.1275751e-08, 3.9933720e-08, 4.1182265e-08, 4.0574768e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/conv2d_24/Conv2D\n",
      "index : 72\n",
      "shape : [ 80   1   1 240]\n",
      "shape_signature : [ 80   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00116252, 0.00117034, 0.00116077, 0.00117052, 0.00114936,\n",
      "       0.00116149, 0.00115603, 0.00116168, 0.00116143, 0.00116032,\n",
      "       0.0011567 , 0.00116405, 0.00116113, 0.00115551, 0.00116218,\n",
      "       0.00116341, 0.00116464, 0.00115939, 0.00115536, 0.00116382,\n",
      "       0.00116077, 0.00116856, 0.00116623, 0.00115367, 0.00115639,\n",
      "       0.00114892, 0.00116195, 0.00114745, 0.00115849, 0.00115442,\n",
      "       0.00115142, 0.00116235, 0.00116159, 0.00117088, 0.00116932,\n",
      "       0.00115893, 0.00116379, 0.00115457, 0.00114938, 0.00115993,\n",
      "       0.00114597, 0.00116446, 0.00114322, 0.00116335, 0.00115354,\n",
      "       0.00116123, 0.00115943, 0.00116366, 0.00115866, 0.00114735,\n",
      "       0.00115703, 0.00116744, 0.00116337, 0.00116159, 0.0011587 ,\n",
      "       0.00116151, 0.00116473, 0.00115949, 0.00115669, 0.00115916,\n",
      "       0.00115569, 0.00116099, 0.00113819, 0.00116479, 0.00115712,\n",
      "       0.00116877, 0.00116358, 0.00116464, 0.00115477, 0.00114755,\n",
      "       0.00116146, 0.00116391, 0.00115697, 0.0011576 , 0.00115032,\n",
      "       0.00116746, 0.00115071, 0.00115876, 0.00114883, 0.00116836],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_18/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/conv2d_24/Conv2D\n",
      "index : 73\n",
      "shape : [80]\n",
      "shape_signature : [80]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.7840959e-08, 1.7960973e-08, 1.7814033e-08, 1.7963659e-08,\n",
      "       1.7638966e-08, 1.7825185e-08, 1.7741337e-08, 1.7828098e-08,\n",
      "       1.7824160e-08, 1.7807174e-08, 1.7751640e-08, 1.7864449e-08,\n",
      "       1.7819563e-08, 1.7733388e-08, 1.7835658e-08, 1.7854600e-08,\n",
      "       1.7873408e-08, 1.7792869e-08, 1.7730988e-08, 1.7860827e-08,\n",
      "       1.7814004e-08, 1.7933640e-08, 1.7897824e-08, 1.7705140e-08,\n",
      "       1.7746798e-08, 1.7632173e-08, 1.7832216e-08, 1.7609660e-08,\n",
      "       1.7779017e-08, 1.7716671e-08, 1.7670535e-08, 1.7838287e-08,\n",
      "       1.7826711e-08, 1.7969267e-08, 1.7945359e-08, 1.7785879e-08,\n",
      "       1.7860424e-08, 1.7718957e-08, 1.7639215e-08, 1.7801165e-08,\n",
      "       1.7586883e-08, 1.7870651e-08, 1.7544711e-08, 1.7853619e-08,\n",
      "       1.7703178e-08, 1.7821165e-08, 1.7793516e-08, 1.7858355e-08,\n",
      "       1.7781620e-08, 1.7608194e-08, 1.7756626e-08, 1.7916459e-08,\n",
      "       1.7854019e-08, 1.7826631e-08, 1.7782337e-08, 1.7825430e-08,\n",
      "       1.7874878e-08, 1.7794360e-08, 1.7751438e-08, 1.7789368e-08,\n",
      "       1.7736122e-08, 1.7817431e-08, 1.7467546e-08, 1.7875815e-08,\n",
      "       1.7758127e-08, 1.7936856e-08, 1.7857138e-08, 1.7873431e-08,\n",
      "       1.7721977e-08, 1.7611214e-08, 1.7824627e-08, 1.7862281e-08,\n",
      "       1.7755735e-08, 1.7765403e-08, 1.7653679e-08, 1.7916674e-08,\n",
      "       1.7659703e-08, 1.7783220e-08, 1.7630889e-08, 1.7930526e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/conv2d_25/Conv2D\n",
      "index : 74\n",
      "shape : [480   1   1  80]\n",
      "shape_signature : [480   1   1  80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00086388, 0.00085738, 0.00084568, 0.00086203, 0.00083593,\n",
      "       0.00086235, 0.00085328, 0.00084454, 0.00086351, 0.0008419 ,\n",
      "       0.00085207, 0.00085951, 0.00084055, 0.00084775, 0.00086403,\n",
      "       0.00086364, 0.00085836, 0.00086392, 0.0008469 , 0.00085887,\n",
      "       0.00085912, 0.00087274, 0.00085905, 0.00083706, 0.00084059,\n",
      "       0.00083053, 0.00086611, 0.00086491, 0.00083256, 0.00082846,\n",
      "       0.00085328, 0.00086339, 0.00084868, 0.00085388, 0.00085206,\n",
      "       0.00085453, 0.00083635, 0.00085778, 0.00083163, 0.00084951,\n",
      "       0.0008208 , 0.00083349, 0.00085372, 0.00084871, 0.00085853,\n",
      "       0.00087235, 0.00087084, 0.00086186, 0.00083903, 0.00085291,\n",
      "       0.00085891, 0.00085583, 0.00085471, 0.00085563, 0.00086918,\n",
      "       0.00085192, 0.00085404, 0.00083161, 0.00086197, 0.00085925,\n",
      "       0.00085958, 0.00081766, 0.00086785, 0.00086655, 0.00085964,\n",
      "       0.00084012, 0.00086089, 0.00085684, 0.00086331, 0.00085313,\n",
      "       0.00083183, 0.00085017, 0.00086386, 0.00085467, 0.00086234,\n",
      "       0.00086803, 0.0008709 , 0.0008631 , 0.00087073, 0.00085511,\n",
      "       0.00086663, 0.00085513, 0.00084258, 0.00085509, 0.00083019,\n",
      "       0.00086425, 0.00087073, 0.00082742, 0.00084971, 0.00085774,\n",
      "       0.00085258, 0.00084851, 0.00084174, 0.0008577 , 0.00086238,\n",
      "       0.00085825, 0.00086504, 0.00085423, 0.00080687, 0.00084755,\n",
      "       0.00087207, 0.00085174, 0.00085917, 0.00086889, 0.00084017,\n",
      "       0.00086476, 0.00086783, 0.00086629, 0.00085127, 0.00087012,\n",
      "       0.00084316, 0.00084896, 0.00083777, 0.00085737, 0.00086227,\n",
      "       0.0008654 , 0.00082216, 0.00085606, 0.00085794, 0.000863  ,\n",
      "       0.00085789, 0.00086567, 0.00085746, 0.00084301, 0.0008515 ,\n",
      "       0.00086718, 0.00084398, 0.00086041, 0.00085832, 0.00086102,\n",
      "       0.00081828, 0.00083477, 0.00086257, 0.00082376, 0.00085154,\n",
      "       0.00084696, 0.00085838, 0.00086111, 0.00087267, 0.00085596,\n",
      "       0.00086196, 0.000859  , 0.00085764, 0.00085922, 0.00085571,\n",
      "       0.00086196, 0.00083556, 0.00085653, 0.00086768, 0.00085636,\n",
      "       0.00084572, 0.00085018, 0.00083647, 0.00086852, 0.00084322,\n",
      "       0.00086726, 0.00085253, 0.00083611, 0.00084712, 0.00084418,\n",
      "       0.00085113, 0.0008505 , 0.0008444 , 0.00086185, 0.00084398,\n",
      "       0.00086635, 0.00084899, 0.00083845, 0.00086623, 0.00085767,\n",
      "       0.00085363, 0.00086072, 0.00084805, 0.00082378, 0.00084799,\n",
      "       0.00083992, 0.0008654 , 0.00085968, 0.00087296, 0.00086311,\n",
      "       0.00085528, 0.00084989, 0.00085392, 0.00085888, 0.00084866,\n",
      "       0.0008633 , 0.00085258, 0.00086488, 0.00085568, 0.00085451,\n",
      "       0.00086024, 0.00085545, 0.00085894, 0.00086695, 0.00084569,\n",
      "       0.00086566, 0.00087056, 0.00086712, 0.0008691 , 0.00087064,\n",
      "       0.00083013, 0.0008104 , 0.0008751 , 0.00083658, 0.00086146,\n",
      "       0.00085929, 0.00085777, 0.0008576 , 0.0008558 , 0.00085034,\n",
      "       0.00087303, 0.00086291, 0.00086209, 0.00085193, 0.00085081,\n",
      "       0.00084592, 0.00086701, 0.00086062, 0.00085843, 0.00085844,\n",
      "       0.00084608, 0.00086885, 0.00083706, 0.00085568, 0.00086566,\n",
      "       0.00084253, 0.00084916, 0.00085709, 0.00083154, 0.00082218,\n",
      "       0.00083491, 0.0008641 , 0.00084738, 0.00086411, 0.000856  ,\n",
      "       0.00086042, 0.00084096, 0.00086188, 0.00086421, 0.00086636,\n",
      "       0.00086128, 0.00086656, 0.00082965, 0.00086584, 0.00085126,\n",
      "       0.00084831, 0.00084931, 0.00085514, 0.00084467, 0.00086729,\n",
      "       0.00086506, 0.00085824, 0.00085711, 0.00085717, 0.00085461,\n",
      "       0.00085967, 0.00086725, 0.00086451, 0.00086153, 0.00087072,\n",
      "       0.00086288, 0.00086344, 0.0008411 , 0.0008715 , 0.00085701,\n",
      "       0.00086311, 0.00086766, 0.00082654, 0.00085382, 0.00086637,\n",
      "       0.00086094, 0.00086269, 0.0008507 , 0.00085623, 0.00083356,\n",
      "       0.00084662, 0.00087066, 0.00085809, 0.00086413, 0.00085821,\n",
      "       0.00082322, 0.00083326, 0.00085201, 0.0008679 , 0.00085155,\n",
      "       0.0008592 , 0.00086226, 0.00084334, 0.00086486, 0.00086254,\n",
      "       0.0008743 , 0.00084038, 0.00086053, 0.00084908, 0.00085956,\n",
      "       0.00086743, 0.00085959, 0.00086837, 0.00086699, 0.00086169,\n",
      "       0.00086598, 0.00085799, 0.00085178, 0.00086561, 0.00086612,\n",
      "       0.00085982, 0.00083934, 0.00085461, 0.00085988, 0.00087082,\n",
      "       0.00086079, 0.00085045, 0.00084753, 0.0008562 , 0.00086193,\n",
      "       0.00086441, 0.00086956, 0.00084034, 0.00085206, 0.00084796,\n",
      "       0.00084736, 0.00085901, 0.00086192, 0.00086498, 0.00086214,\n",
      "       0.00084397, 0.0008576 , 0.00085531, 0.00085817, 0.00086147,\n",
      "       0.00086061, 0.00085826, 0.00085672, 0.00086818, 0.00086079,\n",
      "       0.00086426, 0.0008561 , 0.00086338, 0.00084371, 0.00085879,\n",
      "       0.00085521, 0.00085851, 0.00086883, 0.00086349, 0.00086296,\n",
      "       0.00086856, 0.0008699 , 0.00086309, 0.00085479, 0.00085945,\n",
      "       0.00085949, 0.00084303, 0.00086621, 0.00085538, 0.00085567,\n",
      "       0.00086052, 0.00087033, 0.00086832, 0.00086702, 0.00085063,\n",
      "       0.00083447, 0.00086103, 0.00086266, 0.00086309, 0.00086008,\n",
      "       0.00084542, 0.00086683, 0.00081734, 0.00085716, 0.0008501 ,\n",
      "       0.00084132, 0.00086414, 0.00085761, 0.00086513, 0.00085546,\n",
      "       0.00080594, 0.00085284, 0.00086341, 0.00085878, 0.0008475 ,\n",
      "       0.00086587, 0.00086278, 0.0008486 , 0.00085294, 0.00085308,\n",
      "       0.0008346 , 0.00085946, 0.00086475, 0.00085292, 0.00085542,\n",
      "       0.0008589 , 0.00085041, 0.00085797, 0.00086011, 0.000857  ,\n",
      "       0.00084814, 0.00085693, 0.00084554, 0.00085321, 0.00085124,\n",
      "       0.00086075, 0.00085668, 0.00084427, 0.00085591, 0.00086192,\n",
      "       0.00085643, 0.00086915, 0.00086291, 0.00087681, 0.00084444,\n",
      "       0.00082874, 0.00086537, 0.00086643, 0.00085091, 0.00087163,\n",
      "       0.00086076, 0.00086421, 0.00086965, 0.00086468, 0.00086111,\n",
      "       0.00084175, 0.00081467, 0.00086414, 0.00085849, 0.00086195,\n",
      "       0.00087377, 0.00084787, 0.00086349, 0.00085758, 0.00085115,\n",
      "       0.00086379, 0.00086097, 0.00086119, 0.00086697, 0.00087205,\n",
      "       0.0008587 , 0.00086493, 0.00087048, 0.00086253, 0.00087404,\n",
      "       0.00085491, 0.00084208, 0.00082462, 0.0008599 , 0.00086023,\n",
      "       0.00086881, 0.00084705, 0.00084371, 0.00085763, 0.00086694,\n",
      "       0.00085414, 0.00085721, 0.0008406 , 0.00086203, 0.00086568,\n",
      "       0.00087092, 0.00086972, 0.00085045, 0.00085551, 0.00086255,\n",
      "       0.00083937, 0.00083892, 0.0008614 , 0.00085659, 0.0008712 ,\n",
      "       0.00085928, 0.00086033, 0.00087104, 0.00085256, 0.00086161,\n",
      "       0.00084643, 0.00085139, 0.00085709, 0.00086693, 0.00086481,\n",
      "       0.00086433, 0.00086038, 0.0008398 , 0.00085602, 0.00086436],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_19/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/conv2d_25/Conv2D\n",
      "index : 75\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.3024857e-07, 1.2926799e-07, 1.2750453e-07, 1.2996935e-07,\n",
      "       1.2603391e-07, 1.3001694e-07, 1.2864895e-07, 1.2733229e-07,\n",
      "       1.3019162e-07, 1.2693360e-07, 1.2846731e-07, 1.2958873e-07,\n",
      "       1.2673028e-07, 1.2781642e-07, 1.3027062e-07, 1.3021231e-07,\n",
      "       1.2941571e-07, 1.3025455e-07, 1.2768749e-07, 1.2949198e-07,\n",
      "       1.2953066e-07, 1.3158412e-07, 1.2951905e-07, 1.2620421e-07,\n",
      "       1.2673691e-07, 1.2521951e-07, 1.3058461e-07, 1.3040300e-07,\n",
      "       1.2552626e-07, 1.2490777e-07, 1.2864949e-07, 1.3017463e-07,\n",
      "       1.2795640e-07, 1.2873984e-07, 1.2846508e-07, 1.2883831e-07,\n",
      "       1.2609735e-07, 1.2932767e-07, 1.2538484e-07, 1.2808118e-07,\n",
      "       1.2375230e-07, 1.2566565e-07, 1.2871547e-07, 1.2796094e-07,\n",
      "       1.2944054e-07, 1.3152410e-07, 1.3129679e-07, 1.2994344e-07,\n",
      "       1.2650104e-07, 1.2859320e-07, 1.2949783e-07, 1.2903372e-07,\n",
      "       1.2886510e-07, 1.2900406e-07, 1.3104625e-07, 1.2844444e-07,\n",
      "       1.2876414e-07, 1.2538258e-07, 1.2995942e-07, 1.2954902e-07,\n",
      "       1.2959993e-07, 1.2327851e-07, 1.3084571e-07, 1.3065033e-07,\n",
      "       1.2960830e-07, 1.2666487e-07, 1.2979771e-07, 1.2918707e-07,\n",
      "       1.3016133e-07, 1.2862678e-07, 1.2541564e-07, 1.2818010e-07,\n",
      "       1.3024423e-07, 1.2885864e-07, 1.3001579e-07, 1.3087320e-07,\n",
      "       1.3130592e-07, 1.3012948e-07, 1.3127989e-07, 1.2892573e-07,\n",
      "       1.3066192e-07, 1.2892869e-07, 1.2703612e-07, 1.2892257e-07,\n",
      "       1.2516909e-07, 1.3030400e-07, 1.3128010e-07, 1.2475033e-07,\n",
      "       1.2811068e-07, 1.2932264e-07, 1.2854464e-07, 1.2793056e-07,\n",
      "       1.2690958e-07, 1.2931639e-07, 1.3002185e-07, 1.2939897e-07,\n",
      "       1.3042327e-07, 1.2879349e-07, 1.2165208e-07, 1.2778557e-07,\n",
      "       1.3148308e-07, 1.2841762e-07, 1.2953824e-07, 1.3100352e-07,\n",
      "       1.2667273e-07, 1.3038007e-07, 1.3084356e-07, 1.3061083e-07,\n",
      "       1.2834724e-07, 1.3118927e-07, 1.2712374e-07, 1.2799880e-07,\n",
      "       1.2631106e-07, 1.2926643e-07, 1.3000496e-07, 1.3047770e-07,\n",
      "       1.2395745e-07, 1.2906899e-07, 1.2935274e-07, 1.3011544e-07,\n",
      "       1.2934406e-07, 1.3051803e-07, 1.2928056e-07, 1.2710190e-07,\n",
      "       1.2838196e-07, 1.3074533e-07, 1.2724732e-07, 1.2972444e-07,\n",
      "       1.2940960e-07, 1.2981683e-07, 1.2337290e-07, 1.2585902e-07,\n",
      "       1.3005005e-07, 1.2419875e-07, 1.2838700e-07, 1.2769732e-07,\n",
      "       1.2941908e-07, 1.2983077e-07, 1.3157266e-07, 1.2905379e-07,\n",
      "       1.2995859e-07, 1.2951166e-07, 1.2930742e-07, 1.2954557e-07,\n",
      "       1.2901563e-07, 1.2995805e-07, 1.2597749e-07, 1.2914028e-07,\n",
      "       1.3082146e-07, 1.2911353e-07, 1.2750949e-07, 1.2818217e-07,\n",
      "       1.2611592e-07, 1.3094771e-07, 1.2713265e-07, 1.3075758e-07,\n",
      "       1.2853597e-07, 1.2606029e-07, 1.2772090e-07, 1.2727746e-07,\n",
      "       1.2832622e-07, 1.2823081e-07, 1.2731013e-07, 1.2994181e-07,\n",
      "       1.2724701e-07, 1.3061995e-07, 1.2800298e-07, 1.2641424e-07,\n",
      "       1.3060287e-07, 1.2931203e-07, 1.2870196e-07, 1.2977145e-07,\n",
      "       1.2786168e-07, 1.2420266e-07, 1.2785176e-07, 1.2663541e-07,\n",
      "       1.3047759e-07, 1.2961519e-07, 1.3161751e-07, 1.3013189e-07,\n",
      "       1.2895050e-07, 1.2813807e-07, 1.2874689e-07, 1.2949414e-07,\n",
      "       1.2795270e-07, 1.3015988e-07, 1.2854422e-07, 1.3039853e-07,\n",
      "       1.2901113e-07, 1.2883513e-07, 1.2969896e-07, 1.2897694e-07,\n",
      "       1.2950345e-07, 1.3071113e-07, 1.2750546e-07, 1.3051597e-07,\n",
      "       1.3125474e-07, 1.3073581e-07, 1.3103424e-07, 1.3126693e-07,\n",
      "       1.2515993e-07, 1.2218521e-07, 1.3193953e-07, 1.2613218e-07,\n",
      "       1.2988291e-07, 1.2955626e-07, 1.2932612e-07, 1.2930080e-07,\n",
      "       1.2902947e-07, 1.2820661e-07, 1.3162709e-07, 1.3010201e-07,\n",
      "       1.2997842e-07, 1.2844684e-07, 1.2827671e-07, 1.2754056e-07,\n",
      "       1.3071943e-07, 1.2975659e-07, 1.2942540e-07, 1.2942718e-07,\n",
      "       1.2756416e-07, 1.3099789e-07, 1.2620431e-07, 1.2901117e-07,\n",
      "       1.3051604e-07, 1.2702866e-07, 1.2802896e-07, 1.2922402e-07,\n",
      "       1.2537228e-07, 1.2396065e-07, 1.2587928e-07, 1.3028171e-07,\n",
      "       1.2776063e-07, 1.3028246e-07, 1.2905944e-07, 1.2972625e-07,\n",
      "       1.2679244e-07, 1.2994569e-07, 1.3029721e-07, 1.3062215e-07,\n",
      "       1.2985531e-07, 1.3065238e-07, 1.2508661e-07, 1.3054259e-07,\n",
      "       1.2834559e-07, 1.2789961e-07, 1.2805148e-07, 1.2893034e-07,\n",
      "       1.2735141e-07, 1.3076169e-07, 1.3042640e-07, 1.2939672e-07,\n",
      "       1.2922763e-07, 1.2923589e-07, 1.2884948e-07, 1.2961273e-07,\n",
      "       1.3075646e-07, 1.3034267e-07, 1.2989422e-07, 1.3127861e-07,\n",
      "       1.3009675e-07, 1.3018101e-07, 1.2681387e-07, 1.3139709e-07,\n",
      "       1.2921261e-07, 1.3013171e-07, 1.3081757e-07, 1.2461761e-07,\n",
      "       1.2873102e-07, 1.3062260e-07, 1.2980399e-07, 1.3006883e-07,\n",
      "       1.2826065e-07, 1.2909506e-07, 1.2567702e-07, 1.2764572e-07,\n",
      "       1.3126940e-07, 1.2937465e-07, 1.3028603e-07, 1.2939250e-07,\n",
      "       1.2411735e-07, 1.2563098e-07, 1.2845844e-07, 1.3085388e-07,\n",
      "       1.2838937e-07, 1.2954230e-07, 1.3000424e-07, 1.2715158e-07,\n",
      "       1.3039539e-07, 1.3004565e-07, 1.3181860e-07, 1.2670480e-07,\n",
      "       1.2974283e-07, 1.2801631e-07, 1.2959673e-07, 1.3078341e-07,\n",
      "       1.2960145e-07, 1.3092408e-07, 1.3071603e-07, 1.2991786e-07,\n",
      "       1.3056378e-07, 1.2935926e-07, 1.2842388e-07, 1.3050925e-07,\n",
      "       1.3058551e-07, 1.2963535e-07, 1.2654854e-07, 1.2885009e-07,\n",
      "       1.2964493e-07, 1.3129458e-07, 1.2978211e-07, 1.2822279e-07,\n",
      "       1.2778276e-07, 1.2908964e-07, 1.2995415e-07, 1.3032711e-07,\n",
      "       1.3110392e-07, 1.2669858e-07, 1.2846508e-07, 1.2784700e-07,\n",
      "       1.2775722e-07, 1.2951395e-07, 1.2995299e-07, 1.3041371e-07,\n",
      "       1.2998566e-07, 1.2724630e-07, 1.2930072e-07, 1.2895595e-07,\n",
      "       1.2938652e-07, 1.2988417e-07, 1.2975555e-07, 1.2940072e-07,\n",
      "       1.2916765e-07, 1.3089669e-07, 1.2978252e-07, 1.3030541e-07,\n",
      "       1.2907476e-07, 1.3017186e-07, 1.2720639e-07, 1.2947980e-07,\n",
      "       1.2894080e-07, 1.2943842e-07, 1.3099434e-07, 1.3018906e-07,\n",
      "       1.3010843e-07, 1.3095388e-07, 1.3115495e-07, 1.3012826e-07,\n",
      "       1.2887672e-07, 1.2958058e-07, 1.2958577e-07, 1.2710441e-07,\n",
      "       1.3059925e-07, 1.2896585e-07, 1.2900990e-07, 1.2974178e-07,\n",
      "       1.3122092e-07, 1.3091768e-07, 1.3072057e-07, 1.2824999e-07,\n",
      "       1.2581310e-07, 1.2981870e-07, 1.3006326e-07, 1.3012811e-07,\n",
      "       1.2967433e-07, 1.2746428e-07, 1.3069203e-07, 1.2323098e-07,\n",
      "       1.2923537e-07, 1.2816984e-07, 1.2684650e-07, 1.3028709e-07,\n",
      "       1.2930209e-07, 1.3043666e-07, 1.2897802e-07, 1.2151160e-07,\n",
      "       1.2858327e-07, 1.3017670e-07, 1.2947902e-07, 1.2777808e-07,\n",
      "       1.3054832e-07, 1.3008211e-07, 1.2794375e-07, 1.2859837e-07,\n",
      "       1.2862024e-07, 1.2583311e-07, 1.2958120e-07, 1.3037830e-07,\n",
      "       1.2859506e-07, 1.2897240e-07, 1.2949718e-07, 1.2821646e-07,\n",
      "       1.2935615e-07, 1.2967946e-07, 1.2921083e-07, 1.2787513e-07,\n",
      "       1.2919979e-07, 1.2748244e-07, 1.2863943e-07, 1.2834219e-07,\n",
      "       1.2977551e-07, 1.2916178e-07, 1.2729060e-07, 1.2904582e-07,\n",
      "       1.2995166e-07, 1.2912432e-07, 1.3104237e-07, 1.3010093e-07,\n",
      "       1.3219659e-07, 1.2731617e-07, 1.2495003e-07, 1.3047303e-07,\n",
      "       1.3063165e-07, 1.2829203e-07, 1.3141634e-07, 1.2977686e-07,\n",
      "       1.3029711e-07, 1.3111844e-07, 1.3036902e-07, 1.2983081e-07,\n",
      "       1.2691183e-07, 1.2282841e-07, 1.3028654e-07, 1.2943575e-07,\n",
      "       1.2995625e-07, 1.3173937e-07, 1.2783383e-07, 1.3018972e-07,\n",
      "       1.2929851e-07, 1.2832889e-07, 1.3023426e-07, 1.2980971e-07,\n",
      "       1.2984270e-07, 1.3071424e-07, 1.3148009e-07, 1.2946663e-07,\n",
      "       1.3040538e-07, 1.3124240e-07, 1.3004373e-07, 1.3177900e-07,\n",
      "       1.2889552e-07, 1.2696071e-07, 1.2432814e-07, 1.2964774e-07,\n",
      "       1.2969805e-07, 1.3099159e-07, 1.2770967e-07, 1.2720690e-07,\n",
      "       1.2930604e-07, 1.3070917e-07, 1.2877905e-07, 1.2924160e-07,\n",
      "       1.2673802e-07, 1.2996883e-07, 1.3051924e-07, 1.3130891e-07,\n",
      "       1.3112808e-07, 1.2822363e-07, 1.2898589e-07, 1.3004775e-07,\n",
      "       1.2655198e-07, 1.2648447e-07, 1.2987431e-07, 1.2914876e-07,\n",
      "       1.3135192e-07, 1.2955428e-07, 1.2971229e-07, 1.3132662e-07,\n",
      "       1.2854107e-07, 1.2990616e-07, 1.2761635e-07, 1.2836449e-07,\n",
      "       1.2922457e-07, 1.3070823e-07, 1.3038809e-07, 1.3031588e-07,\n",
      "       1.2971962e-07, 1.2661772e-07, 1.2906291e-07, 1.3032080e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_20/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_6/depthwise_conv2d_6/depthwise;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D\n",
      "index : 76\n",
      "shape : [  1   3   3 480]\n",
      "shape_signature : [  1   3   3 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00031362, 0.00030759, 0.00027903, 0.00030912, 0.00030466,\n",
      "       0.00031571, 0.00030762, 0.00031656, 0.00030899, 0.00026156,\n",
      "       0.0002733 , 0.00028235, 0.00026613, 0.00029868, 0.00028858,\n",
      "       0.00030558, 0.00025517, 0.00019538, 0.00030009, 0.00031196,\n",
      "       0.0002678 , 0.00026401, 0.00028209, 0.00028741, 0.00031615,\n",
      "       0.00031047, 0.00029961, 0.00031102, 0.00031264, 0.00030339,\n",
      "       0.00022705, 0.0002946 , 0.00030359, 0.00029922, 0.00029171,\n",
      "       0.00023825, 0.0002574 , 0.00030807, 0.0002593 , 0.00030152,\n",
      "       0.00029775, 0.00025843, 0.00030802, 0.00030073, 0.0003174 ,\n",
      "       0.00027566, 0.00030386, 0.00030866, 0.00030335, 0.0002927 ,\n",
      "       0.00028874, 0.00022758, 0.00030073, 0.00027832, 0.00027256,\n",
      "       0.00026014, 0.00026816, 0.00027618, 0.00028757, 0.00023272,\n",
      "       0.00027608, 0.00026676, 0.00028227, 0.00030576, 0.00031039,\n",
      "       0.0002696 , 0.00028376, 0.00023661, 0.00031959, 0.00031984,\n",
      "       0.00028187, 0.00029881, 0.00024122, 0.00029961, 0.00027962,\n",
      "       0.00031467, 0.00028288, 0.00030027, 0.00025701, 0.00030559,\n",
      "       0.00029644, 0.00029301, 0.000306  , 0.00031273, 0.00029985,\n",
      "       0.00028209, 0.00026976, 0.00030407, 0.00026241, 0.00028866,\n",
      "       0.0003108 , 0.00026512, 0.00029904, 0.00029746, 0.00028182,\n",
      "       0.00029135, 0.00027638, 0.00031275, 0.0002915 , 0.00027249,\n",
      "       0.00022989, 0.00023859, 0.00026615, 0.00023595, 0.00032042,\n",
      "       0.00021112, 0.00027244, 0.00029258, 0.00030901, 0.00032066,\n",
      "       0.00029407, 0.00032739, 0.00027402, 0.00030397, 0.0002629 ,\n",
      "       0.00013833, 0.00030849, 0.00024828, 0.00028473, 0.00029916,\n",
      "       0.00029552, 0.00023443, 0.00031542, 0.00031171, 0.000284  ,\n",
      "       0.00032024, 0.00031437, 0.00027007, 0.00029736, 0.00032049,\n",
      "       0.0002669 , 0.00031224, 0.00025801, 0.00028986, 0.00025741,\n",
      "       0.00027472, 0.000285  , 0.0002819 , 0.00025125, 0.0002906 ,\n",
      "       0.00027373, 0.00032167, 0.00031192, 0.00030108, 0.0003179 ,\n",
      "       0.00027833, 0.00032183, 0.00024068, 0.00022903, 0.00029615,\n",
      "       0.00030564, 0.00030862, 0.00029951, 0.00020398, 0.00030856,\n",
      "       0.0003095 , 0.00030528, 0.00030991, 0.00030033, 0.00030388,\n",
      "       0.00027981, 0.00029889, 0.00030082, 0.00026226, 0.0003136 ,\n",
      "       0.00024691, 0.00032478, 0.0003033 , 0.00023803, 0.00031247,\n",
      "       0.00030957, 0.00025988, 0.00028357, 0.00024794, 0.00031383,\n",
      "       0.00030202, 0.00029898, 0.00025102, 0.00021166, 0.0002337 ,\n",
      "       0.00031272, 0.00025607, 0.0003079 , 0.00031549, 0.00032025,\n",
      "       0.00028849, 0.00032201, 0.000303  , 0.00031255, 0.00026757,\n",
      "       0.00031952, 0.00029206, 0.00029982, 0.00030016, 0.000298  ,\n",
      "       0.00030515, 0.00028513, 0.00025453, 0.00027311, 0.00030193,\n",
      "       0.00029657, 0.00030854, 0.0002889 , 0.00030592, 0.00030874,\n",
      "       0.0002121 , 0.00028797, 0.0002827 , 0.00030684, 0.00027753,\n",
      "       0.00030028, 0.00029863, 0.00031542, 0.00026882, 0.00031243,\n",
      "       0.00030948, 0.00029671, 0.00029825, 0.00031245, 0.00030094,\n",
      "       0.00028154, 0.00029871, 0.0003052 , 0.00025334, 0.00030673,\n",
      "       0.00023017, 0.0002571 , 0.00030053, 0.00029932, 0.0002874 ,\n",
      "       0.00027364, 0.00024313, 0.00032227, 0.00031344, 0.00030073,\n",
      "       0.00030662, 0.00021857, 0.00024658, 0.00028942, 0.00022525,\n",
      "       0.00030365, 0.000299  , 0.0002124 , 0.00029932, 0.00026517,\n",
      "       0.00023717, 0.00028774, 0.0003046 , 0.00029601, 0.00031123,\n",
      "       0.00027478, 0.00020743, 0.00026113, 0.00030296, 0.00030493,\n",
      "       0.00030072, 0.00031763, 0.00028974, 0.00031314, 0.00028319,\n",
      "       0.00028274, 0.00028136, 0.00030091, 0.00029655, 0.00029963,\n",
      "       0.00028646, 0.00031338, 0.00028781, 0.00030701, 0.00031806,\n",
      "       0.00029918, 0.00028995, 0.00031522, 0.00030227, 0.00031224,\n",
      "       0.00029731, 0.00032113, 0.00027285, 0.00024171, 0.00017068,\n",
      "       0.00028942, 0.00026983, 0.00026774, 0.00031146, 0.0002742 ,\n",
      "       0.00029346, 0.00026814, 0.00028623, 0.00029964, 0.00031412,\n",
      "       0.00026328, 0.00026041, 0.00029514, 0.00031836, 0.00024499,\n",
      "       0.00024599, 0.00031339, 0.00029906, 0.00029874, 0.00031197,\n",
      "       0.00028954, 0.00030461, 0.00023892, 0.00017999, 0.0002699 ,\n",
      "       0.00021704, 0.00028118, 0.00029849, 0.00029034, 0.00026134,\n",
      "       0.00026271, 0.0002973 , 0.00024777, 0.0002799 , 0.00026106,\n",
      "       0.00030503, 0.00030371, 0.00025617, 0.00031418, 0.00029958,\n",
      "       0.00031144, 0.00031267, 0.00029768, 0.00031177, 0.00031798,\n",
      "       0.00032019, 0.00026384, 0.00029725, 0.00028201, 0.00030039,\n",
      "       0.00027702, 0.00017717, 0.00031687, 0.0002972 , 0.00032108,\n",
      "       0.00023735, 0.00026641, 0.00027375, 0.00027019, 0.00023829,\n",
      "       0.00020976, 0.00031785, 0.00030649, 0.00026688, 0.00025277,\n",
      "       0.00030668, 0.00029826, 0.00024825, 0.00027587, 0.00026449,\n",
      "       0.00030075, 0.00028386, 0.00025511, 0.00024326, 0.00029945,\n",
      "       0.00030244, 0.00027015, 0.00032115, 0.00026213, 0.00031831,\n",
      "       0.00030567, 0.0002952 , 0.00029854, 0.00032013, 0.00030469,\n",
      "       0.00027094, 0.00017496, 0.000316  , 0.00023875, 0.00024539,\n",
      "       0.00030168, 0.00032021, 0.00030862, 0.00031101, 0.00029331,\n",
      "       0.00031857, 0.00028049, 0.00031301, 0.0003188 , 0.00029893,\n",
      "       0.0003004 , 0.00026296, 0.00028075, 0.00032091, 0.0003007 ,\n",
      "       0.00029293, 0.00029418, 0.00027599, 0.00030173, 0.00026665,\n",
      "       0.00029358, 0.00028627, 0.00030495, 0.00031766, 0.00031919,\n",
      "       0.00028535, 0.0002637 , 0.00030806, 0.00030641, 0.00030998,\n",
      "       0.00031153, 0.00031155, 0.00029946, 0.00023876, 0.00029704,\n",
      "       0.00031287, 0.00030993, 0.00031137, 0.00029913, 0.00029475,\n",
      "       0.00030964, 0.00028711, 0.00030644, 0.00028115, 0.00030008,\n",
      "       0.00029887, 0.0002724 , 0.00029974, 0.00030665, 0.00030511,\n",
      "       0.00030947, 0.00025555, 0.00031113, 0.00026819, 0.00026011,\n",
      "       0.00026627, 0.00027687, 0.00031307, 0.00030915, 0.00028243,\n",
      "       0.0002432 , 0.0003119 , 0.00031641, 0.00028525, 0.00031713,\n",
      "       0.00027703, 0.00031549, 0.00028182, 0.0003098 , 0.00027584,\n",
      "       0.00026577, 0.00031254, 0.00031281, 0.00026629, 0.00026893,\n",
      "       0.00025619, 0.00029342, 0.00023621, 0.00031187, 0.0002974 ,\n",
      "       0.00016377, 0.00028768, 0.00030563, 0.00031001, 0.00025149,\n",
      "       0.00030955, 0.0002893 , 0.00031736, 0.00024195, 0.00031686,\n",
      "       0.0003118 , 0.00031576, 0.00030633, 0.00029358, 0.00030996,\n",
      "       0.00027693, 0.00028396, 0.00020789, 0.00024329, 0.00027946,\n",
      "       0.0003172 , 0.00029865, 0.00031403, 0.00023294, 0.00032046,\n",
      "       0.00030066, 0.00026199, 0.00029741, 0.00031607, 0.00028156],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_20/FusedBatchNormV3\n",
      "index : 77\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.62817937e-08, 1.59688760e-08, 1.44862522e-08, 1.60479736e-08,\n",
      "       1.58168056e-08, 1.63902296e-08, 1.59704054e-08, 1.64345337e-08,\n",
      "       1.60412945e-08, 1.35791032e-08, 1.41884735e-08, 1.46585259e-08,\n",
      "       1.38164076e-08, 1.55061120e-08, 1.49818664e-08, 1.58642504e-08,\n",
      "       1.32472060e-08, 1.01432400e-08, 1.55791255e-08, 1.61954894e-08,\n",
      "       1.39032279e-08, 1.37062210e-08, 1.46447379e-08, 1.49212340e-08,\n",
      "       1.64131322e-08, 1.61180420e-08, 1.55545834e-08, 1.61466875e-08,\n",
      "       1.62310947e-08, 1.57508815e-08, 1.17873284e-08, 1.52941588e-08,\n",
      "       1.57612199e-08, 1.55344235e-08, 1.51445647e-08, 1.23690400e-08,\n",
      "       1.33630325e-08, 1.59935265e-08, 1.34615457e-08, 1.56534981e-08,\n",
      "       1.54577400e-08, 1.34167113e-08, 1.59913025e-08, 1.56128106e-08,\n",
      "       1.64782179e-08, 1.43108192e-08, 1.57750009e-08, 1.60241402e-08,\n",
      "       1.57488067e-08, 1.51956723e-08, 1.49900625e-08, 1.18147119e-08,\n",
      "       1.56124944e-08, 1.44492489e-08, 1.41500491e-08, 1.35052334e-08,\n",
      "       1.39216407e-08, 1.43380978e-08, 1.49292365e-08, 1.20816974e-08,\n",
      "       1.43329881e-08, 1.38488279e-08, 1.46544608e-08, 1.58735407e-08,\n",
      "       1.61140683e-08, 1.39966998e-08, 1.47318309e-08, 1.22836488e-08,\n",
      "       1.65914997e-08, 1.66045044e-08, 1.46335255e-08, 1.55131037e-08,\n",
      "       1.25232527e-08, 1.55545266e-08, 1.45167585e-08, 1.63364433e-08,\n",
      "       1.46859556e-08, 1.55886291e-08, 1.33430200e-08, 1.58651350e-08,\n",
      "       1.53899151e-08, 1.52120450e-08, 1.58862878e-08, 1.62357416e-08,\n",
      "       1.55669504e-08, 1.46449048e-08, 1.40049856e-08, 1.57859663e-08,\n",
      "       1.36229872e-08, 1.49861812e-08, 1.61353775e-08, 1.37640797e-08,\n",
      "       1.55246891e-08, 1.54425930e-08, 1.46309915e-08, 1.51255826e-08,\n",
      "       1.43484540e-08, 1.62365321e-08, 1.51335620e-08, 1.41464032e-08,\n",
      "       1.19346462e-08, 1.23866011e-08, 1.38175951e-08, 1.22496271e-08,\n",
      "       1.66349725e-08, 1.09605756e-08, 1.41440575e-08, 1.51893236e-08,\n",
      "       1.60423941e-08, 1.66474585e-08, 1.52666182e-08, 1.69964274e-08,\n",
      "       1.42257655e-08, 1.57809019e-08, 1.36488714e-08, 7.18169701e-09,\n",
      "       1.60157043e-08, 1.28896911e-08, 1.47821071e-08, 1.55313042e-08,\n",
      "       1.53420281e-08, 1.21704282e-08, 1.63752460e-08, 1.61825504e-08,\n",
      "       1.47442352e-08, 1.66253571e-08, 1.63208416e-08, 1.40207392e-08,\n",
      "       1.54378448e-08, 1.66383618e-08, 1.38564218e-08, 1.62100058e-08,\n",
      "       1.33949536e-08, 1.50483004e-08, 1.33634677e-08, 1.42621515e-08,\n",
      "       1.47958845e-08, 1.46348578e-08, 1.30440112e-08, 1.50865418e-08,\n",
      "       1.42108689e-08, 1.66995378e-08, 1.61934999e-08, 1.56305582e-08,\n",
      "       1.65038632e-08, 1.44498395e-08, 1.67079861e-08, 1.24948434e-08,\n",
      "       1.18903056e-08, 1.53750523e-08, 1.58676290e-08, 1.60220850e-08,\n",
      "       1.55493485e-08, 1.05899911e-08, 1.60189106e-08, 1.60678688e-08,\n",
      "       1.58487747e-08, 1.60892633e-08, 1.55916471e-08, 1.57762834e-08,\n",
      "       1.45263908e-08, 1.55168944e-08, 1.56171360e-08, 1.36156366e-08,\n",
      "       1.62807243e-08, 1.28186297e-08, 1.68612360e-08, 1.57460835e-08,\n",
      "       1.23574804e-08, 1.62221774e-08, 1.60716276e-08, 1.34917357e-08,\n",
      "       1.47219881e-08, 1.28720234e-08, 1.62924589e-08, 1.56794648e-08,\n",
      "       1.55217421e-08, 1.30319311e-08, 1.09884457e-08, 1.21327579e-08,\n",
      "       1.62349298e-08, 1.32941302e-08, 1.59846838e-08, 1.63787242e-08,\n",
      "       1.66261440e-08, 1.49771378e-08, 1.67175251e-08, 1.57305369e-08,\n",
      "       1.62264957e-08, 1.38911060e-08, 1.65882330e-08, 1.51627404e-08,\n",
      "       1.55655240e-08, 1.55829394e-08, 1.54710431e-08, 1.58422448e-08,\n",
      "       1.48029384e-08, 1.32141613e-08, 1.41788217e-08, 1.56748374e-08,\n",
      "       1.53964645e-08, 1.60179976e-08, 1.49985482e-08, 1.58822075e-08,\n",
      "       1.60284159e-08, 1.10112337e-08, 1.49501105e-08, 1.46765560e-08,\n",
      "       1.59298885e-08, 1.44080596e-08, 1.55890820e-08, 1.55036624e-08,\n",
      "       1.63753953e-08, 1.39559706e-08, 1.62199463e-08, 1.60670854e-08,\n",
      "       1.54037227e-08, 1.54838897e-08, 1.62211453e-08, 1.56235664e-08,\n",
      "       1.46162105e-08, 1.55075863e-08, 1.58448081e-08, 1.31521416e-08,\n",
      "       1.59240763e-08, 1.19493242e-08, 1.33474334e-08, 1.56021134e-08,\n",
      "       1.55395288e-08, 1.49206247e-08, 1.42062486e-08, 1.26224728e-08,\n",
      "       1.67306684e-08, 1.62726455e-08, 1.56128195e-08, 1.59186175e-08,\n",
      "       1.13469971e-08, 1.28015722e-08, 1.50252024e-08, 1.16939987e-08,\n",
      "       1.57643267e-08, 1.55228292e-08, 1.10266747e-08, 1.55393174e-08,\n",
      "       1.37663516e-08, 1.23125981e-08, 1.49380348e-08, 1.58136970e-08,\n",
      "       1.53675401e-08, 1.61577347e-08, 1.42656225e-08, 1.07689981e-08,\n",
      "       1.35565736e-08, 1.57281406e-08, 1.58307678e-08, 1.56118478e-08,\n",
      "       1.64897536e-08, 1.50419552e-08, 1.62568412e-08, 1.47019046e-08,\n",
      "       1.46784789e-08, 1.46067594e-08, 1.56218363e-08, 1.53954840e-08,\n",
      "       1.55555355e-08, 1.48716595e-08, 1.62690927e-08, 1.49418113e-08,\n",
      "       1.59387969e-08, 1.65123115e-08, 1.55318887e-08, 1.50531640e-08,\n",
      "       1.63647442e-08, 1.56924536e-08, 1.62099081e-08, 1.54351643e-08,\n",
      "       1.66716880e-08, 1.41650043e-08, 1.25486972e-08, 8.86093066e-09,\n",
      "       1.50252806e-08, 1.40085428e-08, 1.38997684e-08, 1.61694942e-08,\n",
      "       1.42352041e-08, 1.52351483e-08, 1.39209257e-08, 1.48598724e-08,\n",
      "       1.55557967e-08, 1.63079754e-08, 1.36684619e-08, 1.35194904e-08,\n",
      "       1.53223230e-08, 1.65276202e-08, 1.27189006e-08, 1.27706263e-08,\n",
      "       1.62697891e-08, 1.55256537e-08, 1.55094515e-08, 1.61960187e-08,\n",
      "       1.50317838e-08, 1.58140701e-08, 1.24037909e-08, 9.34424715e-09,\n",
      "       1.40120964e-08, 1.12679945e-08, 1.45976742e-08, 1.54965054e-08,\n",
      "       1.50731747e-08, 1.35674885e-08, 1.36387763e-08, 1.54347415e-08,\n",
      "       1.28633229e-08, 1.45312100e-08, 1.35529250e-08, 1.58359352e-08,\n",
      "       1.57673661e-08, 1.32992373e-08, 1.63110290e-08, 1.55526756e-08,\n",
      "       1.61684621e-08, 1.62322458e-08, 1.54542086e-08, 1.61857745e-08,\n",
      "       1.65079204e-08, 1.66228933e-08, 1.36972815e-08, 1.54319064e-08,\n",
      "       1.46406602e-08, 1.55949333e-08, 1.43817296e-08, 9.19797216e-09,\n",
      "       1.64503895e-08, 1.54293147e-08, 1.66688796e-08, 1.23219435e-08,\n",
      "       1.38310536e-08, 1.42117358e-08, 1.40271528e-08, 1.23709141e-08,\n",
      "       1.08896252e-08, 1.65013763e-08, 1.59115885e-08, 1.38550309e-08,\n",
      "       1.31228450e-08, 1.59212821e-08, 1.54843711e-08, 1.28878668e-08,\n",
      "       1.43220564e-08, 1.37311513e-08, 1.56134430e-08, 1.47369255e-08,\n",
      "       1.32441142e-08, 1.26289246e-08, 1.55459876e-08, 1.57014473e-08,\n",
      "       1.40250922e-08, 1.66728640e-08, 1.36086742e-08, 1.65251066e-08,\n",
      "       1.58692917e-08, 1.53255186e-08, 1.54989017e-08, 1.66196710e-08,\n",
      "       1.58183227e-08, 1.40660541e-08, 9.08331010e-09, 1.64055383e-08,\n",
      "       1.23949970e-08, 1.27397746e-08, 1.56618132e-08, 1.66238667e-08,\n",
      "       1.60220246e-08, 1.61460658e-08, 1.52272630e-08, 1.65386602e-08,\n",
      "       1.45615822e-08, 1.62503646e-08, 1.65508904e-08, 1.55190705e-08,\n",
      "       1.55952851e-08, 1.36516585e-08, 1.45752086e-08, 1.66604899e-08,\n",
      "       1.56110822e-08, 1.52078812e-08, 1.52725228e-08, 1.43283376e-08,\n",
      "       1.56644102e-08, 1.38432874e-08, 1.52411648e-08, 1.48616977e-08,\n",
      "       1.58317661e-08, 1.64916241e-08, 1.65709011e-08, 1.48140664e-08,\n",
      "       1.36901805e-08, 1.59933418e-08, 1.59076627e-08, 1.60930718e-08,\n",
      "       1.61734022e-08, 1.61741607e-08, 1.55468225e-08, 1.23951889e-08,\n",
      "       1.54208646e-08, 1.62427796e-08, 1.60900502e-08, 1.61647655e-08,\n",
      "       1.55296291e-08, 1.53022555e-08, 1.60750133e-08, 1.49055079e-08,\n",
      "       1.59089222e-08, 1.45962176e-08, 1.55786601e-08, 1.55160063e-08,\n",
      "       1.41416994e-08, 1.55611630e-08, 1.59196887e-08, 1.58400759e-08,\n",
      "       1.60662381e-08, 1.32668729e-08, 1.61525282e-08, 1.39232155e-08,\n",
      "       1.35039295e-08, 1.38235698e-08, 1.43741206e-08, 1.62530771e-08,\n",
      "       1.60498423e-08, 1.46623886e-08, 1.26259501e-08, 1.61926330e-08,\n",
      "       1.64268634e-08, 1.48091415e-08, 1.64641936e-08, 1.43821755e-08,\n",
      "       1.63788290e-08, 1.46308148e-08, 1.60836287e-08, 1.43202312e-08,\n",
      "       1.37978020e-08, 1.62259077e-08, 1.62399623e-08, 1.38247698e-08,\n",
      "       1.39618450e-08, 1.33002178e-08, 1.52333293e-08, 1.22630626e-08,\n",
      "       1.61907749e-08, 1.54396034e-08, 8.50247961e-09, 1.49349209e-08,\n",
      "       1.58671849e-08, 1.60945550e-08, 1.30562272e-08, 1.60706399e-08,\n",
      "       1.50194346e-08, 1.64760241e-08, 1.25608990e-08, 1.64500982e-08,\n",
      "       1.61873448e-08, 1.63930576e-08, 1.59035558e-08, 1.52415343e-08,\n",
      "       1.60917732e-08, 1.43769370e-08, 1.47419845e-08, 1.07926921e-08,\n",
      "       1.26307809e-08, 1.45085872e-08, 1.64674709e-08, 1.55047850e-08,\n",
      "       1.63028471e-08, 1.20932198e-08, 1.66371414e-08, 1.56092241e-08,\n",
      "       1.36012899e-08, 1.54400599e-08, 1.64087766e-08, 1.46175125e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/Conv2D\n",
      "index : 78\n",
      "shape : [120   1   1 480]\n",
      "shape_signature : [120   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078909, 0.00078454, 0.0007898 , 0.00078742, 0.00078429,\n",
      "       0.00078537, 0.00078845, 0.00078813, 0.00078884, 0.00078431,\n",
      "       0.00078781, 0.00078439, 0.00078672, 0.00078695, 0.00079185,\n",
      "       0.00078755, 0.00078543, 0.000785  , 0.0007874 , 0.00078694,\n",
      "       0.00078814, 0.0007904 , 0.00078116, 0.00078438, 0.00078827,\n",
      "       0.00078557, 0.00078192, 0.00079014, 0.00078773, 0.00078763,\n",
      "       0.00078645, 0.00078566, 0.00077826, 0.00078693, 0.00078809,\n",
      "       0.00078669, 0.00079213, 0.00078791, 0.00079311, 0.00079149,\n",
      "       0.00078553, 0.00078597, 0.00078916, 0.00078938, 0.00079172,\n",
      "       0.0007874 , 0.00078631, 0.00078311, 0.00078697, 0.00078607,\n",
      "       0.00078386, 0.00078859, 0.0007867 , 0.00078727, 0.00078274,\n",
      "       0.00078471, 0.0007818 , 0.00078589, 0.00078873, 0.00078675,\n",
      "       0.0007859 , 0.0007907 , 0.00078605, 0.00079026, 0.0007894 ,\n",
      "       0.00078833, 0.00078721, 0.00078727, 0.0007867 , 0.0007902 ,\n",
      "       0.00079105, 0.00078928, 0.00078696, 0.00079194, 0.00078407,\n",
      "       0.00078652, 0.00078654, 0.00078279, 0.00078919, 0.0007836 ,\n",
      "       0.00078781, 0.00078603, 0.00078548, 0.00077973, 0.00078774,\n",
      "       0.00078814, 0.00078948, 0.00078254, 0.00078596, 0.0007852 ,\n",
      "       0.00079006, 0.00078641, 0.00078525, 0.00078985, 0.00078605,\n",
      "       0.00078557, 0.00079042, 0.00078437, 0.00078886, 0.00078247,\n",
      "       0.00078976, 0.00079161, 0.00078701, 0.00079087, 0.0007903 ,\n",
      "       0.00078826, 0.00079041, 0.0007828 , 0.00078532, 0.00078844,\n",
      "       0.00078691, 0.00079065, 0.000787  , 0.00078809, 0.00078484,\n",
      "       0.00078568, 0.0007844 , 0.00078452, 0.00078736, 0.0007883 ],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/BiasAdd/ReadVariableOp/resource\n",
      "index : 79\n",
      "shape : [120]\n",
      "shape_signature : [120]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.4485961e-08, 3.4287467e-08, 3.4517143e-08, 3.4413130e-08,\n",
      "       3.4276429e-08, 3.4323456e-08, 3.4458285e-08, 3.4444191e-08,\n",
      "       3.4475239e-08, 3.4277107e-08, 3.4430144e-08, 3.4280731e-08,\n",
      "       3.4382623e-08, 3.4392500e-08, 3.4606799e-08, 3.4418960e-08,\n",
      "       3.4326053e-08, 3.4307241e-08, 3.4412331e-08, 3.4392045e-08,\n",
      "       3.4444703e-08, 3.4543309e-08, 3.4139568e-08, 3.4280383e-08,\n",
      "       3.4450419e-08, 3.4332317e-08, 3.4172626e-08, 3.4532121e-08,\n",
      "       3.4426751e-08, 3.4422253e-08, 3.4370871e-08, 3.4336125e-08,\n",
      "       3.4012949e-08, 3.4391540e-08, 3.4442614e-08, 3.4381070e-08,\n",
      "       3.4618985e-08, 3.4434724e-08, 3.4661742e-08, 3.4590812e-08,\n",
      "       3.4330370e-08, 3.4349959e-08, 3.4489165e-08, 3.4498662e-08,\n",
      "       3.4600863e-08, 3.4412242e-08, 3.4364529e-08, 3.4224641e-08,\n",
      "       3.4393651e-08, 3.4354059e-08, 3.4257386e-08, 3.4464250e-08,\n",
      "       3.4381824e-08, 3.4406593e-08, 3.4208437e-08, 3.4294846e-08,\n",
      "       3.4167631e-08, 3.4346421e-08, 3.4470514e-08, 3.4384076e-08,\n",
      "       3.4346666e-08, 3.4556443e-08, 3.4353210e-08, 3.4537436e-08,\n",
      "       3.4499532e-08, 3.4452917e-08, 3.4404010e-08, 3.4406721e-08,\n",
      "       3.4381536e-08, 3.4534832e-08, 3.4571958e-08, 3.4494541e-08,\n",
      "       3.4392968e-08, 3.4610849e-08, 3.4266773e-08, 3.4373688e-08,\n",
      "       3.4374644e-08, 3.4210785e-08, 3.4490547e-08, 3.4246135e-08,\n",
      "       3.4430268e-08, 3.4352574e-08, 3.4328338e-08, 3.4076940e-08,\n",
      "       3.4427202e-08, 3.4444668e-08, 3.4503135e-08, 3.4199974e-08,\n",
      "       3.4349338e-08, 3.4316017e-08, 3.4528661e-08, 3.4368867e-08,\n",
      "       3.4318127e-08, 3.4519537e-08, 3.4353278e-08, 3.4332441e-08,\n",
      "       3.4544243e-08, 3.4279747e-08, 3.4476031e-08, 3.4197019e-08,\n",
      "       3.4515466e-08, 3.4596177e-08, 3.4395285e-08, 3.4563801e-08,\n",
      "       3.4539077e-08, 3.4449933e-08, 3.4543714e-08, 3.4211286e-08,\n",
      "       3.4321513e-08, 3.4457905e-08, 3.4390915e-08, 3.4554368e-08,\n",
      "       3.4394979e-08, 3.4442397e-08, 3.4300307e-08, 3.4337251e-08,\n",
      "       3.4281314e-08, 3.4286483e-08, 3.4410384e-08, 3.4451602e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/Conv2D\n",
      "index : 80\n",
      "shape : [480   1   1 120]\n",
      "shape_signature : [480   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078569, 0.00078601, 0.00078602, 0.00078696, 0.00078249,\n",
      "       0.00078238, 0.000781  , 0.0007624 , 0.00078312, 0.00076482,\n",
      "       0.00077366, 0.00077443, 0.00077937, 0.00078326, 0.00078203,\n",
      "       0.00078253, 0.00074619, 0.00078381, 0.00077698, 0.00075433,\n",
      "       0.00077858, 0.00079172, 0.00077739, 0.00077814, 0.00078305,\n",
      "       0.00078674, 0.00077592, 0.00077715, 0.00078376, 0.00078199,\n",
      "       0.00078845, 0.00077134, 0.00078238, 0.00078687, 0.0007801 ,\n",
      "       0.00078421, 0.0007837 , 0.00079185, 0.00078283, 0.00078161,\n",
      "       0.00078226, 0.00078466, 0.00077518, 0.00078992, 0.00078253,\n",
      "       0.00078362, 0.000776  , 0.00078847, 0.00078916, 0.00077724,\n",
      "       0.00076363, 0.00078245, 0.0007873 , 0.00077921, 0.00076756,\n",
      "       0.0007924 , 0.00077198, 0.00078275, 0.0007816 , 0.0007651 ,\n",
      "       0.00077086, 0.00078549, 0.00078733, 0.00077391, 0.00076726,\n",
      "       0.00078316, 0.00078601, 0.0007795 , 0.00078644, 0.00077577,\n",
      "       0.0007843 , 0.00078373, 0.00078952, 0.00078733, 0.00079192,\n",
      "       0.00078242, 0.00077166, 0.00078219, 0.00077987, 0.00078309,\n",
      "       0.00078185, 0.00077233, 0.0007876 , 0.00077973, 0.00078684,\n",
      "       0.00076231, 0.00078077, 0.00077347, 0.0007858 , 0.00078709,\n",
      "       0.00078565, 0.00076811, 0.00078584, 0.00078586, 0.0007589 ,\n",
      "       0.00078469, 0.00078414, 0.00078979, 0.00077245, 0.00078796,\n",
      "       0.00076729, 0.00078446, 0.00074783, 0.0007863 , 0.00078153,\n",
      "       0.00077788, 0.00078552, 0.00078976, 0.00078773, 0.00077521,\n",
      "       0.00077381, 0.00077321, 0.00075829, 0.00076561, 0.00078433,\n",
      "       0.00079161, 0.00077354, 0.0007794 , 0.00078566, 0.00078007,\n",
      "       0.00078768, 0.00078413, 0.00078414, 0.00077707, 0.00078906,\n",
      "       0.00076794, 0.00077813, 0.00078734, 0.0007875 , 0.00078176,\n",
      "       0.00078744, 0.00078171, 0.00077966, 0.00078993, 0.00078492,\n",
      "       0.00075966, 0.00078612, 0.00078523, 0.00078757, 0.00078337,\n",
      "       0.00077471, 0.00078502, 0.00079098, 0.00077983, 0.00077216,\n",
      "       0.00077473, 0.00078482, 0.00078593, 0.00078021, 0.00078462,\n",
      "       0.00078022, 0.00076385, 0.00076558, 0.00078138, 0.00078462,\n",
      "       0.00076371, 0.00078383, 0.00078949, 0.00078801, 0.0007922 ,\n",
      "       0.00077253, 0.00076922, 0.00078734, 0.00077044, 0.00078597,\n",
      "       0.00078647, 0.00078805, 0.00078762, 0.00077224, 0.0007893 ,\n",
      "       0.000791  , 0.0007834 , 0.00078879, 0.00078073, 0.00078646,\n",
      "       0.00078907, 0.00078717, 0.00078331, 0.00077743, 0.00078622,\n",
      "       0.00078539, 0.00077326, 0.00078315, 0.00077585, 0.00078511,\n",
      "       0.00078584, 0.00077583, 0.0007889 , 0.00078462, 0.00078535,\n",
      "       0.00076841, 0.00078268, 0.00078434, 0.00078567, 0.00077786,\n",
      "       0.00078739, 0.0007851 , 0.00077305, 0.00076192, 0.00078449,\n",
      "       0.00078243, 0.00077477, 0.00077678, 0.00078296, 0.00078485,\n",
      "       0.00079151, 0.0007849 , 0.00078136, 0.00078206, 0.00079072,\n",
      "       0.00078966, 0.00078182, 0.00076983, 0.00077937, 0.000783  ,\n",
      "       0.00077656, 0.00077231, 0.00078532, 0.00078307, 0.00077889,\n",
      "       0.0007864 , 0.00078236, 0.00076401, 0.00078535, 0.00078549,\n",
      "       0.00078398, 0.00078664, 0.00077813, 0.00078824, 0.00078751,\n",
      "       0.00078945, 0.00078568, 0.00078023, 0.00078472, 0.00077671,\n",
      "       0.00079051, 0.00078295, 0.0007837 , 0.00078124, 0.00077655,\n",
      "       0.00078528, 0.00078588, 0.00078294, 0.00078233, 0.00076595,\n",
      "       0.0007809 , 0.00078622, 0.00078455, 0.00078021, 0.00076527,\n",
      "       0.0007819 , 0.00077861, 0.00078021, 0.00078435, 0.00077772,\n",
      "       0.00076853, 0.00078296, 0.00078588, 0.00077406, 0.00078584,\n",
      "       0.00078336, 0.00077946, 0.00078775, 0.00076848, 0.00078282,\n",
      "       0.00078352, 0.00078426, 0.00078007, 0.00078402, 0.00077784,\n",
      "       0.00078581, 0.00077495, 0.00078905, 0.00078618, 0.00078776,\n",
      "       0.00077928, 0.00078496, 0.00078486, 0.00077565, 0.00078862,\n",
      "       0.00078752, 0.00078606, 0.00074188, 0.00078116, 0.00078069,\n",
      "       0.00076902, 0.00078718, 0.00077727, 0.00077512, 0.00078139,\n",
      "       0.00078206, 0.00077457, 0.00078737, 0.0007837 , 0.00078492,\n",
      "       0.00077926, 0.00078534, 0.00078574, 0.00078639, 0.00078738,\n",
      "       0.00078567, 0.00078579, 0.00078168, 0.00078787, 0.00076911,\n",
      "       0.00078156, 0.00078931, 0.00078413, 0.00078149, 0.00078147,\n",
      "       0.00077464, 0.00078654, 0.00075638, 0.00078399, 0.00079095,\n",
      "       0.00077136, 0.00078463, 0.00078233, 0.00077254, 0.0007859 ,\n",
      "       0.00078672, 0.00078935, 0.00078471, 0.00077169, 0.00078368,\n",
      "       0.00077879, 0.00078963, 0.00078088, 0.00077924, 0.00077423,\n",
      "       0.00078203, 0.00078073, 0.00078487, 0.00078357, 0.00077911,\n",
      "       0.0007809 , 0.00079271, 0.00078613, 0.00078377, 0.00078218,\n",
      "       0.00077338, 0.0007797 , 0.00078295, 0.00077889, 0.00078335,\n",
      "       0.00079042, 0.00078909, 0.00078091, 0.00077645, 0.00076661,\n",
      "       0.00078867, 0.00079082, 0.00078399, 0.00077619, 0.00078767,\n",
      "       0.00079024, 0.00078021, 0.00078507, 0.00078362, 0.00078879,\n",
      "       0.00077345, 0.00076966, 0.00077199, 0.00078115, 0.00078498,\n",
      "       0.00078333, 0.00077721, 0.0007642 , 0.00078816, 0.00078603,\n",
      "       0.0007873 , 0.00078608, 0.00078276, 0.00078317, 0.00078649,\n",
      "       0.00078175, 0.00078525, 0.00077643, 0.00077832, 0.00078984,\n",
      "       0.0007812 , 0.00078012, 0.00078518, 0.00078781, 0.00077679,\n",
      "       0.00078124, 0.0007848 , 0.00077496, 0.00078033, 0.00078247,\n",
      "       0.00078726, 0.00078165, 0.00078677, 0.00078191, 0.00079066,\n",
      "       0.00077671, 0.00078294, 0.0007692 , 0.00077542, 0.00078249,\n",
      "       0.00078354, 0.00077392, 0.00076754, 0.00077789, 0.00078042,\n",
      "       0.00077625, 0.00078401, 0.00075141, 0.00078609, 0.00076925,\n",
      "       0.0007886 , 0.00078768, 0.00079114, 0.00076192, 0.00077087,\n",
      "       0.000785  , 0.0007837 , 0.00079009, 0.00078705, 0.0007811 ,\n",
      "       0.00078583, 0.00078841, 0.00077955, 0.00078338, 0.0007896 ,\n",
      "       0.0007629 , 0.00078361, 0.00078648, 0.00077966, 0.00078401,\n",
      "       0.00077562, 0.00078594, 0.00078698, 0.00078132, 0.00078359,\n",
      "       0.00078092, 0.00078105, 0.00077899, 0.00077896, 0.0007752 ,\n",
      "       0.00078878, 0.00078141, 0.00078472, 0.0007894 , 0.00077907,\n",
      "       0.00078434, 0.00078598, 0.00077707, 0.00078899, 0.00078811,\n",
      "       0.00078835, 0.00077028, 0.0007805 , 0.0007811 , 0.00078229,\n",
      "       0.00078682, 0.00077841, 0.00078983, 0.00078626, 0.00077841,\n",
      "       0.0007851 , 0.00078797, 0.00075856, 0.00078645, 0.00078878,\n",
      "       0.00077757, 0.00077746, 0.00077749, 0.0007837 , 0.00078163,\n",
      "       0.00078505, 0.0007819 , 0.0007863 , 0.00077916, 0.00078105,\n",
      "       0.00077495, 0.00078625, 0.00075847, 0.00078156, 0.0007868 ],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/BiasAdd/ReadVariableOp/resource\n",
      "index : 81\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.9391612e-08, 1.9399280e-08, 1.9399613e-08, 1.9422792e-08,\n",
      "       1.9312587e-08, 1.9309860e-08, 1.9275664e-08, 1.8816804e-08,\n",
      "       1.9328018e-08, 1.8876351e-08, 1.9094614e-08, 1.9113511e-08,\n",
      "       1.9235605e-08, 1.9331576e-08, 1.9301151e-08, 1.9313450e-08,\n",
      "       1.8416650e-08, 1.9345013e-08, 1.9176630e-08, 1.8617445e-08,\n",
      "       1.9216042e-08, 1.9540327e-08, 1.9186684e-08, 1.9205096e-08,\n",
      "       1.9326446e-08, 1.9417396e-08, 1.9150296e-08, 1.9180741e-08,\n",
      "       1.9343764e-08, 1.9300105e-08, 1.9459721e-08, 1.9037286e-08,\n",
      "       1.9309775e-08, 1.9420559e-08, 1.9253621e-08, 1.9354907e-08,\n",
      "       1.9342467e-08, 1.9543563e-08, 1.9320856e-08, 1.9290782e-08,\n",
      "       1.9306901e-08, 1.9366071e-08, 1.9132010e-08, 1.9495884e-08,\n",
      "       1.9313578e-08, 1.9340485e-08, 1.9152390e-08, 1.9460163e-08,\n",
      "       1.9477200e-08, 1.9182993e-08, 1.8847135e-08, 1.9311633e-08,\n",
      "       1.9431305e-08, 1.9231571e-08, 1.8944057e-08, 1.9556985e-08,\n",
      "       1.9053095e-08, 1.9319053e-08, 1.9290599e-08, 1.8883297e-08,\n",
      "       1.9025434e-08, 1.9386558e-08, 1.9431958e-08, 1.9100673e-08,\n",
      "       1.8936712e-08, 1.9329104e-08, 1.9399426e-08, 1.9238826e-08,\n",
      "       1.9409901e-08, 1.9146738e-08, 1.9357079e-08, 1.9343148e-08,\n",
      "       1.9486000e-08, 1.9432022e-08, 1.9545196e-08, 1.9310686e-08,\n",
      "       1.9045245e-08, 1.9305226e-08, 1.9247882e-08, 1.9327327e-08,\n",
      "       1.9296621e-08, 1.9061861e-08, 1.9438655e-08, 1.9244339e-08,\n",
      "       1.9419796e-08, 1.8814529e-08, 1.9270161e-08, 1.9089887e-08,\n",
      "       1.9394101e-08, 1.9426009e-08, 1.9390473e-08, 1.8957731e-08,\n",
      "       1.9395301e-08, 1.9395772e-08, 1.8730390e-08, 1.9366892e-08,\n",
      "       1.9353314e-08, 1.9492777e-08, 1.9064739e-08, 1.9447624e-08,\n",
      "       1.8937262e-08, 1.9361080e-08, 1.8457083e-08, 1.9406501e-08,\n",
      "       1.9288805e-08, 1.9198854e-08, 1.9387398e-08, 1.9491919e-08,\n",
      "       1.9441782e-08, 1.9132845e-08, 1.9098328e-08, 1.9083416e-08,\n",
      "       1.8715252e-08, 1.8895822e-08, 1.9357941e-08, 1.9537651e-08,\n",
      "       1.9091676e-08, 1.9236213e-08, 1.9390678e-08, 1.9252694e-08,\n",
      "       1.9440501e-08, 1.9353113e-08, 1.9353280e-08, 1.9178763e-08,\n",
      "       1.9474593e-08, 1.8953505e-08, 1.9205009e-08, 1.9432308e-08,\n",
      "       1.9436083e-08, 1.9294619e-08, 1.9434632e-08, 1.9293257e-08,\n",
      "       1.9242696e-08, 1.9496202e-08, 1.9372578e-08, 1.8749107e-08,\n",
      "       1.9402210e-08, 1.9380055e-08, 1.9438019e-08, 1.9334239e-08,\n",
      "       1.9120415e-08, 1.9374971e-08, 1.9522133e-08, 1.9246892e-08,\n",
      "       1.9057559e-08, 1.9121106e-08, 1.9370102e-08, 1.9397508e-08,\n",
      "       1.9256168e-08, 1.9365153e-08, 1.9256557e-08, 1.8852566e-08,\n",
      "       1.8895246e-08, 1.9285205e-08, 1.9365054e-08, 1.8848946e-08,\n",
      "       1.9345483e-08, 1.9485329e-08, 1.9448770e-08, 1.9552164e-08,\n",
      "       1.9066796e-08, 1.8985068e-08, 1.9432139e-08, 1.9015115e-08,\n",
      "       1.9398325e-08, 1.9410781e-08, 1.9449743e-08, 1.9439140e-08,\n",
      "       1.9059510e-08, 1.9480510e-08, 1.9522457e-08, 1.9334937e-08,\n",
      "       1.9468043e-08, 1.9269180e-08, 1.9410610e-08, 1.9474992e-08,\n",
      "       1.9428057e-08, 1.9332823e-08, 1.9187647e-08, 1.9404608e-08,\n",
      "       1.9384217e-08, 1.9084826e-08, 1.9328706e-08, 1.9148619e-08,\n",
      "       1.9377065e-08, 1.9395118e-08, 1.9148148e-08, 1.9470631e-08,\n",
      "       1.9365144e-08, 1.9383210e-08, 1.8965022e-08, 1.9317138e-08,\n",
      "       1.9358113e-08, 1.9391107e-08, 1.9198188e-08, 1.9433347e-08,\n",
      "       1.9376863e-08, 1.9079442e-08, 1.8804743e-08, 1.9361840e-08,\n",
      "       1.9311106e-08, 1.9121915e-08, 1.9171598e-08, 1.9324171e-08,\n",
      "       1.9370686e-08, 1.9535097e-08, 1.9372122e-08, 1.9284510e-08,\n",
      "       1.9301858e-08, 1.9515756e-08, 1.9489503e-08, 1.9295950e-08,\n",
      "       1.9000097e-08, 1.9235616e-08, 1.9325199e-08, 1.9166125e-08,\n",
      "       1.9061304e-08, 1.9382412e-08, 1.9326862e-08, 1.9223773e-08,\n",
      "       1.9409137e-08, 1.9309210e-08, 1.8856506e-08, 1.9383057e-08,\n",
      "       1.9386443e-08, 1.9349176e-08, 1.9414907e-08, 1.9204931e-08,\n",
      "       1.9454324e-08, 1.9436428e-08, 1.9484389e-08, 1.9391138e-08,\n",
      "       1.9256635e-08, 1.9367578e-08, 1.9169818e-08, 1.9510544e-08,\n",
      "       1.9323982e-08, 1.9342430e-08, 1.9281655e-08, 1.9165846e-08,\n",
      "       1.9381325e-08, 1.9396303e-08, 1.9323647e-08, 1.9308612e-08,\n",
      "       1.8904393e-08, 1.9273322e-08, 1.9404602e-08, 1.9363446e-08,\n",
      "       1.9256230e-08, 1.8887548e-08, 1.9297936e-08, 1.9216648e-08,\n",
      "       1.9256312e-08, 1.9358488e-08, 1.9194681e-08, 1.8968013e-08,\n",
      "       1.9324112e-08, 1.9396234e-08, 1.9104341e-08, 1.9395133e-08,\n",
      "       1.9333905e-08, 1.9237662e-08, 1.9442293e-08, 1.8966761e-08,\n",
      "       1.9320712e-08, 1.9337890e-08, 1.9356115e-08, 1.9252699e-08,\n",
      "       1.9350235e-08, 1.9197770e-08, 1.9394349e-08, 1.9126437e-08,\n",
      "       1.9474372e-08, 1.9403551e-08, 1.9442698e-08, 1.9233195e-08,\n",
      "       1.9373360e-08, 1.9371081e-08, 1.9143709e-08, 1.9463934e-08,\n",
      "       1.9436666e-08, 1.9400575e-08, 1.8310283e-08, 1.9279771e-08,\n",
      "       1.9268194e-08, 1.8980097e-08, 1.9428338e-08, 1.9183567e-08,\n",
      "       1.9130532e-08, 1.9285382e-08, 1.9301892e-08, 1.9117000e-08,\n",
      "       1.9432852e-08, 1.9342449e-08, 1.9372388e-08, 1.9232884e-08,\n",
      "       1.9382856e-08, 1.9392667e-08, 1.9408860e-08, 1.9433287e-08,\n",
      "       1.9391029e-08, 1.9393894e-08, 1.9292546e-08, 1.9445363e-08,\n",
      "       1.8982256e-08, 1.9289489e-08, 1.9480765e-08, 1.9352884e-08,\n",
      "       1.9287800e-08, 1.9287251e-08, 1.9118778e-08, 1.9412420e-08,\n",
      "       1.8668052e-08, 1.9349468e-08, 1.9521245e-08, 1.9037818e-08,\n",
      "       1.9365332e-08, 1.9308533e-08, 1.9066869e-08, 1.9396772e-08,\n",
      "       1.9416975e-08, 1.9481908e-08, 1.9367342e-08, 1.9046052e-08,\n",
      "       1.9341824e-08, 1.9221185e-08, 1.9488835e-08, 1.9272900e-08,\n",
      "       1.9232351e-08, 1.9108588e-08, 1.9301101e-08, 1.9268962e-08,\n",
      "       1.9371289e-08, 1.9339204e-08, 1.9229104e-08, 1.9273326e-08,\n",
      "       1.9564686e-08, 1.9402281e-08, 1.9344103e-08, 1.9304961e-08,\n",
      "       1.9087658e-08, 1.9243599e-08, 1.9323823e-08, 1.9223569e-08,\n",
      "       1.9333861e-08, 1.9508169e-08, 1.9475488e-08, 1.9273521e-08,\n",
      "       1.9163336e-08, 1.8920666e-08, 1.9465046e-08, 1.9518053e-08,\n",
      "       1.9349431e-08, 1.9156943e-08, 1.9440462e-08, 1.9503801e-08,\n",
      "       1.9256147e-08, 1.9376257e-08, 1.9340412e-08, 1.9468107e-08,\n",
      "       1.9089482e-08, 1.8995935e-08, 1.9053461e-08, 1.9279369e-08,\n",
      "       1.9373912e-08, 1.9333342e-08, 1.9182291e-08, 1.8861048e-08,\n",
      "       1.9452381e-08, 1.9399844e-08, 1.9431225e-08, 1.9401098e-08,\n",
      "       1.9319193e-08, 1.9329232e-08, 1.9411196e-08, 1.9294259e-08,\n",
      "       1.9380712e-08, 1.9163055e-08, 1.9209555e-08, 1.9493847e-08,\n",
      "       1.9280575e-08, 1.9254044e-08, 1.9378957e-08, 1.9443897e-08,\n",
      "       1.9171921e-08, 1.9281583e-08, 1.9369567e-08, 1.9126665e-08,\n",
      "       1.9259140e-08, 1.9312013e-08, 1.9430368e-08, 1.9291859e-08,\n",
      "       1.9418195e-08, 1.9298215e-08, 1.9514077e-08, 1.9169979e-08,\n",
      "       1.9323577e-08, 1.8984521e-08, 1.9138017e-08, 1.9312564e-08,\n",
      "       1.9338401e-08, 1.9101059e-08, 1.8943441e-08, 1.9199092e-08,\n",
      "       1.9261337e-08, 1.9158575e-08, 1.9349963e-08, 1.8545331e-08,\n",
      "       1.9401387e-08, 1.8985647e-08, 1.9463315e-08, 1.9440654e-08,\n",
      "       1.9525929e-08, 1.8804958e-08, 1.9025839e-08, 1.9374578e-08,\n",
      "       1.9342274e-08, 1.9500002e-08, 1.9425050e-08, 1.9278144e-08,\n",
      "       1.9394989e-08, 1.9458545e-08, 1.9239845e-08, 1.9334559e-08,\n",
      "       1.9487976e-08, 1.8829116e-08, 1.9340179e-08, 1.9410994e-08,\n",
      "       1.9242711e-08, 1.9350118e-08, 1.9142886e-08, 1.9397604e-08,\n",
      "       1.9423283e-08, 1.9283679e-08, 1.9339771e-08, 1.9273802e-08,\n",
      "       1.9277046e-08, 1.9226032e-08, 1.9225320e-08, 1.9132706e-08,\n",
      "       1.9467839e-08, 1.9285974e-08, 1.9367517e-08, 1.9482959e-08,\n",
      "       1.9228040e-08, 1.9358099e-08, 1.9398584e-08, 1.9178868e-08,\n",
      "       1.9472948e-08, 1.9451321e-08, 1.9457158e-08, 1.9011267e-08,\n",
      "       1.9263508e-08, 1.9278117e-08, 1.9307546e-08, 1.9419293e-08,\n",
      "       1.9211907e-08, 1.9493738e-08, 1.9405594e-08, 1.9211781e-08,\n",
      "       1.9376847e-08, 1.9447668e-08, 1.8721911e-08, 1.9410237e-08,\n",
      "       1.9467826e-08, 1.9191182e-08, 1.9188350e-08, 1.9189150e-08,\n",
      "       1.9342426e-08, 1.9291328e-08, 1.9375644e-08, 1.9297890e-08,\n",
      "       1.9406524e-08, 1.9230285e-08, 1.9276916e-08, 1.9126409e-08,\n",
      "       1.9405284e-08, 1.8719568e-08, 1.9289503e-08, 1.9419010e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/conv2d_28/Conv2D\n",
      "index : 82\n",
      "shape : [ 80   1   1 480]\n",
      "shape_signature : [ 80   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00088044, 0.00088181, 0.0008878 , 0.00088656, 0.00088065,\n",
      "       0.0008804 , 0.0008824 , 0.0008767 , 0.0008876 , 0.000884  ,\n",
      "       0.00087893, 0.00087743, 0.00088003, 0.00087954, 0.00087449,\n",
      "       0.00087725, 0.00088536, 0.00088215, 0.00088306, 0.00088248,\n",
      "       0.00088147, 0.00088048, 0.00087635, 0.00088404, 0.00087669,\n",
      "       0.00088403, 0.00088832, 0.00087538, 0.00088111, 0.00088446,\n",
      "       0.00087869, 0.00087937, 0.00088562, 0.00088198, 0.00087895,\n",
      "       0.00088163, 0.0008858 , 0.00088417, 0.00088158, 0.00088107,\n",
      "       0.00088274, 0.00088182, 0.00088303, 0.00088019, 0.00088393,\n",
      "       0.00087783, 0.00088338, 0.00087743, 0.00088348, 0.00087853,\n",
      "       0.00088594, 0.00087905, 0.00087322, 0.00087814, 0.0008812 ,\n",
      "       0.00087976, 0.00088214, 0.00088034, 0.00088516, 0.00087557,\n",
      "       0.00088832, 0.00088346, 0.00087635, 0.00088241, 0.00088002,\n",
      "       0.00088362, 0.00087947, 0.00088   , 0.0008801 , 0.00088363,\n",
      "       0.00088317, 0.00088051, 0.00088   , 0.00088567, 0.00088224,\n",
      "       0.0008798 , 0.00088026, 0.00087841, 0.00088433, 0.00088507],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_21/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/conv2d_28/Conv2D\n",
      "index : 83\n",
      "shape : [80]\n",
      "shape_signature : [80]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.9399369e-09, 9.9553841e-09, 1.0023107e-08, 1.0009122e-08,\n",
      "       9.9423447e-09, 9.9394724e-09, 9.9620809e-09, 9.8977253e-09,\n",
      "       1.0020820e-08, 9.9801465e-09, 9.9228892e-09, 9.9059658e-09,\n",
      "       9.9353112e-09, 9.9298143e-09, 9.8728039e-09, 9.9039701e-09,\n",
      "       9.9954747e-09, 9.9592796e-09, 9.9695132e-09, 9.9629771e-09,\n",
      "       9.9516040e-09, 9.9404707e-09, 9.8938271e-09, 9.9805924e-09,\n",
      "       9.8976054e-09, 9.9804565e-09, 1.0028980e-08, 9.8828421e-09,\n",
      "       9.9474837e-09, 9.9853068e-09, 9.9202246e-09, 9.9278754e-09,\n",
      "       9.9984989e-09, 9.9574056e-09, 9.9230961e-09, 9.9534425e-09,\n",
      "       1.0000441e-08, 9.9821156e-09, 9.9528599e-09, 9.9470618e-09,\n",
      "       9.9659392e-09, 9.9555235e-09, 9.9692530e-09, 9.9371631e-09,\n",
      "       9.9793853e-09, 9.9105204e-09, 9.9732178e-09, 9.9059481e-09,\n",
      "       9.9743032e-09, 9.9184456e-09, 1.0002068e-08, 9.9242419e-09,\n",
      "       9.8585140e-09, 9.9139728e-09, 9.9485922e-09, 9.9323323e-09,\n",
      "       9.9591784e-09, 9.9387991e-09, 9.9932622e-09, 9.8849355e-09,\n",
      "       1.0028962e-08, 9.9741033e-09, 9.8938200e-09, 9.9621857e-09,\n",
      "       9.9351753e-09, 9.9758433e-09, 9.9290096e-09, 9.9350563e-09,\n",
      "       9.9361124e-09, 9.9760387e-09, 9.9707993e-09, 9.9407114e-09,\n",
      "       9.9350190e-09, 9.9989848e-09, 9.9602904e-09, 9.9327320e-09,\n",
      "       9.9379776e-09, 9.9170334e-09, 9.9839168e-09, 9.9922675e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_29/Conv2D\n",
      "index : 84\n",
      "shape : [480   1   1  80]\n",
      "shape_signature : [480   1   1  80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00084031, 0.00084474, 0.00083225, 0.00082872, 0.00081602,\n",
      "       0.00081052, 0.00083327, 0.00085106, 0.00078901, 0.00084305,\n",
      "       0.00083854, 0.00084649, 0.00083353, 0.00083636, 0.00081809,\n",
      "       0.00080981, 0.00081607, 0.00083027, 0.00083734, 0.00081829,\n",
      "       0.00083087, 0.00079971, 0.00083073, 0.00082299, 0.00082804,\n",
      "       0.00084008, 0.00080895, 0.00083429, 0.00084061, 0.00083153,\n",
      "       0.00082887, 0.00083764, 0.00082469, 0.00082805, 0.00081752,\n",
      "       0.00083325, 0.00083618, 0.00083188, 0.00082966, 0.00084016,\n",
      "       0.00085677, 0.00079834, 0.00082616, 0.00084185, 0.00082391,\n",
      "       0.00083078, 0.00084007, 0.00083962, 0.00081946, 0.00082107,\n",
      "       0.00083596, 0.00083819, 0.00083039, 0.00083156, 0.00082352,\n",
      "       0.00084746, 0.00083448, 0.0008262 , 0.00083266, 0.00084572,\n",
      "       0.0008419 , 0.00084315, 0.00082943, 0.00082436, 0.00082634,\n",
      "       0.00084143, 0.00082797, 0.00082977, 0.0008146 , 0.00083267,\n",
      "       0.00082707, 0.00082955, 0.00083885, 0.00082755, 0.00081363,\n",
      "       0.00082124, 0.00084868, 0.00083199, 0.00083916, 0.00081025,\n",
      "       0.00083472, 0.00081831, 0.00084508, 0.00082527, 0.00084416,\n",
      "       0.00082829, 0.00083779, 0.000848  , 0.00083507, 0.00085106,\n",
      "       0.00083433, 0.00081232, 0.00083554, 0.00082787, 0.00084846,\n",
      "       0.00083757, 0.00082108, 0.00084148, 0.00083411, 0.00083963,\n",
      "       0.00083447, 0.00085107, 0.00084916, 0.00080028, 0.00083967,\n",
      "       0.00084286, 0.00082188, 0.00083158, 0.00082324, 0.00081358,\n",
      "       0.00084631, 0.00082853, 0.00084338, 0.00084246, 0.00083165,\n",
      "       0.00081213, 0.00082835, 0.00084307, 0.00083198, 0.00083331,\n",
      "       0.00082734, 0.00084601, 0.00084811, 0.00083595, 0.00083875,\n",
      "       0.00083709, 0.00083459, 0.00083359, 0.00082441, 0.00082042,\n",
      "       0.0008486 , 0.00083801, 0.00082334, 0.00084106, 0.00083119,\n",
      "       0.00080639, 0.00083621, 0.00084446, 0.00081283, 0.00084069,\n",
      "       0.00083706, 0.00084029, 0.00081736, 0.00083341, 0.00082055,\n",
      "       0.00082528, 0.00083493, 0.0008446 , 0.00081349, 0.00082445,\n",
      "       0.00084228, 0.00082801, 0.00084588, 0.00082488, 0.00081879,\n",
      "       0.00082493, 0.00082021, 0.0008214 , 0.00082986, 0.00080699,\n",
      "       0.00084379, 0.00082612, 0.00080949, 0.00081892, 0.0008413 ,\n",
      "       0.00082771, 0.00083406, 0.00084007, 0.00080684, 0.00084034,\n",
      "       0.0008352 , 0.00084292, 0.00084617, 0.00082785, 0.00084194,\n",
      "       0.00083679, 0.00084814, 0.0008374 , 0.00079569, 0.00083554,\n",
      "       0.00082124, 0.00083401, 0.00083777, 0.00083777, 0.00083144,\n",
      "       0.00080878, 0.00081212, 0.00084797, 0.00083706, 0.0008264 ,\n",
      "       0.00080799, 0.00083963, 0.00084214, 0.00082161, 0.00081079,\n",
      "       0.00083135, 0.00079325, 0.00084516, 0.00084161, 0.00083539,\n",
      "       0.0008218 , 0.00084222, 0.00081136, 0.00081057, 0.00083082,\n",
      "       0.0008221 , 0.0008221 , 0.00082683, 0.00082939, 0.00083573,\n",
      "       0.00080693, 0.00082068, 0.00083709, 0.00083201, 0.00083756,\n",
      "       0.0008291 , 0.00084506, 0.00084532, 0.00083388, 0.00083219,\n",
      "       0.00082568, 0.00083476, 0.00083906, 0.00083777, 0.00084412,\n",
      "       0.00083088, 0.0008414 , 0.00082562, 0.00083383, 0.00084116,\n",
      "       0.00082438, 0.0007977 , 0.00083042, 0.0008326 , 0.00081588,\n",
      "       0.00083569, 0.00084052, 0.00080702, 0.00083044, 0.00083657,\n",
      "       0.00084126, 0.00084219, 0.0008337 , 0.00083263, 0.00083347,\n",
      "       0.00081117, 0.00082886, 0.00081545, 0.00084191, 0.00084585,\n",
      "       0.00084592, 0.00082688, 0.00083669, 0.00084488, 0.00085264,\n",
      "       0.00081408, 0.00082528, 0.00080153, 0.00084238, 0.00084766,\n",
      "       0.00081065, 0.00083614, 0.0008218 , 0.00081842, 0.00081398,\n",
      "       0.00081267, 0.0008151 , 0.00080425, 0.00083141, 0.00084611,\n",
      "       0.00083812, 0.00082941, 0.00082066, 0.00082798, 0.00083762,\n",
      "       0.00084789, 0.00084417, 0.00082169, 0.00082802, 0.00083654,\n",
      "       0.00084   , 0.00082876, 0.0008114 , 0.00082418, 0.00083711,\n",
      "       0.00084018, 0.00083951, 0.00083848, 0.00084374, 0.00082527,\n",
      "       0.0008421 , 0.00081699, 0.00083344, 0.00084212, 0.00084291,\n",
      "       0.0008526 , 0.00083831, 0.00082662, 0.0008254 , 0.00083968,\n",
      "       0.00083468, 0.00081745, 0.00083477, 0.0008407 , 0.00084392,\n",
      "       0.00080218, 0.00084058, 0.00084656, 0.00080215, 0.00083671,\n",
      "       0.00084262, 0.00083648, 0.00083271, 0.00082465, 0.00083077,\n",
      "       0.00083267, 0.00084683, 0.00082885, 0.00082794, 0.00083879,\n",
      "       0.00079864, 0.00074753, 0.00084089, 0.00084251, 0.00083562,\n",
      "       0.00083047, 0.00081847, 0.00080191, 0.00082111, 0.00084372,\n",
      "       0.00084764, 0.00084004, 0.00084207, 0.00079723, 0.00082862,\n",
      "       0.00084489, 0.00084123, 0.00082405, 0.00079256, 0.00083029,\n",
      "       0.00084494, 0.0008344 , 0.00084027, 0.00080685, 0.00083908,\n",
      "       0.00082553, 0.00083743, 0.00082226, 0.00083661, 0.00083403,\n",
      "       0.00083216, 0.00082801, 0.00083028, 0.00083433, 0.00083526,\n",
      "       0.00082688, 0.00082976, 0.00084803, 0.00083742, 0.00078786,\n",
      "       0.00084895, 0.00082322, 0.00084037, 0.00084409, 0.00084219,\n",
      "       0.00084079, 0.0008381 , 0.00080586, 0.00083467, 0.00083389,\n",
      "       0.00082655, 0.00084275, 0.00084889, 0.00084179, 0.00082157,\n",
      "       0.00084058, 0.00079556, 0.00084086, 0.00083156, 0.00083043,\n",
      "       0.00079624, 0.00084406, 0.00082582, 0.00084257, 0.0008358 ,\n",
      "       0.00084546, 0.00082988, 0.00081259, 0.00083875, 0.00080934,\n",
      "       0.00084644, 0.00081809, 0.00084124, 0.00076913, 0.00080082,\n",
      "       0.00084584, 0.00083919, 0.00084053, 0.00083234, 0.00084229,\n",
      "       0.00084089, 0.00082712, 0.00082193, 0.00083888, 0.00082556,\n",
      "       0.00082389, 0.00082902, 0.0008418 , 0.00083959, 0.00083309,\n",
      "       0.00081798, 0.00082371, 0.00081557, 0.00083168, 0.00083696,\n",
      "       0.00084482, 0.00083731, 0.00081983, 0.00082803, 0.00084673,\n",
      "       0.00083383, 0.00082005, 0.00081779, 0.00082968, 0.00083778,\n",
      "       0.00083346, 0.00082527, 0.00082753, 0.00083449, 0.00085327,\n",
      "       0.00080466, 0.00082103, 0.00082079, 0.00084009, 0.00080947,\n",
      "       0.00083496, 0.00084808, 0.00082206, 0.00083494, 0.00083894,\n",
      "       0.00082291, 0.00084216, 0.0008451 , 0.00079138, 0.0008255 ,\n",
      "       0.00082716, 0.00082755, 0.00082737, 0.00083046, 0.00082655,\n",
      "       0.00084271, 0.0008348 , 0.00081057, 0.00082178, 0.00083194,\n",
      "       0.00082059, 0.0008343 , 0.00080007, 0.00080259, 0.00082335,\n",
      "       0.00082025, 0.0008196 , 0.00083023, 0.00083286, 0.00084557,\n",
      "       0.00084403, 0.00081684, 0.00082609, 0.00083615, 0.00083827,\n",
      "       0.00083141, 0.00082409, 0.00085036, 0.00081685, 0.00085147,\n",
      "       0.00084281, 0.00082926, 0.00083695, 0.00083998, 0.000799  ],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_22/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_29/Conv2D\n",
      "index : 85\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.7037765e-07, 1.7127542e-07, 1.6874432e-07, 1.6802822e-07,\n",
      "       1.6545332e-07, 1.6433761e-07, 1.6895086e-07, 1.7255722e-07,\n",
      "       1.5997713e-07, 1.7093406e-07, 1.7001986e-07, 1.7163154e-07,\n",
      "       1.6900377e-07, 1.6957611e-07, 1.6587310e-07, 1.6419443e-07,\n",
      "       1.6546353e-07, 1.6834173e-07, 1.6977458e-07, 1.6591396e-07,\n",
      "       1.6846342e-07, 1.6214487e-07, 1.6843502e-07, 1.6686563e-07,\n",
      "       1.6789058e-07, 1.7033112e-07, 1.6401968e-07, 1.6915737e-07,\n",
      "       1.7043926e-07, 1.6859661e-07, 1.6805828e-07, 1.6983724e-07,\n",
      "       1.6721053e-07, 1.6789140e-07, 1.6575710e-07, 1.6894710e-07,\n",
      "       1.6954121e-07, 1.6866758e-07, 1.6821859e-07, 1.7034756e-07,\n",
      "       1.7371539e-07, 1.6186827e-07, 1.6750936e-07, 1.7069027e-07,\n",
      "       1.6705252e-07, 1.6844602e-07, 1.7032890e-07, 1.7023750e-07,\n",
      "       1.6614996e-07, 1.6647704e-07, 1.6949646e-07, 1.6994694e-07,\n",
      "       1.6836668e-07, 1.6860294e-07, 1.6697427e-07, 1.7182754e-07,\n",
      "       1.6919475e-07, 1.6751642e-07, 1.6882667e-07, 1.7147383e-07,\n",
      "       1.7070069e-07, 1.7095404e-07, 1.6817083e-07, 1.6714414e-07,\n",
      "       1.6754439e-07, 1.7060468e-07, 1.6787585e-07, 1.6824056e-07,\n",
      "       1.6516398e-07, 1.6882943e-07, 1.6769344e-07, 1.6819548e-07,\n",
      "       1.7008109e-07, 1.6779040e-07, 1.6496914e-07, 1.6651175e-07,\n",
      "       1.7207454e-07, 1.6869173e-07, 1.7014386e-07, 1.6428204e-07,\n",
      "       1.6924395e-07, 1.6591707e-07, 1.7134585e-07, 1.6732830e-07,\n",
      "       1.7115889e-07, 1.6794012e-07, 1.6986759e-07, 1.7193683e-07,\n",
      "       1.6931445e-07, 1.7255806e-07, 1.6916469e-07, 1.6470280e-07,\n",
      "       1.6941027e-07, 1.6785479e-07, 1.7202943e-07, 1.6982266e-07,\n",
      "       1.6647839e-07, 1.7061515e-07, 1.6912018e-07, 1.7024087e-07,\n",
      "       1.6919316e-07, 1.7255853e-07, 1.7217282e-07, 1.6226065e-07,\n",
      "       1.7024723e-07, 1.7089418e-07, 1.6664094e-07, 1.6860720e-07,\n",
      "       1.6691754e-07, 1.6495711e-07, 1.7159516e-07, 1.6798829e-07,\n",
      "       1.7099939e-07, 1.7081317e-07, 1.6862231e-07, 1.6466390e-07,\n",
      "       1.6795371e-07, 1.7093701e-07, 1.6868829e-07, 1.6895842e-07,\n",
      "       1.6774881e-07, 1.7153297e-07, 1.7195873e-07, 1.6949342e-07,\n",
      "       1.7006100e-07, 1.6972585e-07, 1.6921722e-07, 1.6901589e-07,\n",
      "       1.6715462e-07, 1.6634473e-07, 1.7205805e-07, 1.6991051e-07,\n",
      "       1.6693637e-07, 1.7052942e-07, 1.6852793e-07, 1.6350077e-07,\n",
      "       1.6954728e-07, 1.7121849e-07, 1.6480618e-07, 1.7045444e-07,\n",
      "       1.6971862e-07, 1.7037293e-07, 1.6572523e-07, 1.6897793e-07,\n",
      "       1.6637051e-07, 1.6732947e-07, 1.6928762e-07, 1.7124705e-07,\n",
      "       1.6494010e-07, 1.6716253e-07, 1.7077714e-07, 1.6788381e-07,\n",
      "       1.7150630e-07, 1.6724881e-07, 1.6601520e-07, 1.6725916e-07,\n",
      "       1.6630150e-07, 1.6654299e-07, 1.6825851e-07, 1.6362233e-07,\n",
      "       1.7108302e-07, 1.6750013e-07, 1.6412787e-07, 1.6604027e-07,\n",
      "       1.7057928e-07, 1.6782381e-07, 1.6911036e-07, 1.7032988e-07,\n",
      "       1.6359166e-07, 1.7038286e-07, 1.6934133e-07, 1.7090790e-07,\n",
      "       1.7156667e-07, 1.6785060e-07, 1.7070762e-07, 1.6966456e-07,\n",
      "       1.7196503e-07, 1.6978844e-07, 1.6133090e-07, 1.6941114e-07,\n",
      "       1.6651114e-07, 1.6909992e-07, 1.6986314e-07, 1.6986293e-07,\n",
      "       1.6857973e-07, 1.6398562e-07, 1.6466115e-07, 1.7193028e-07,\n",
      "       1.6971873e-07, 1.6755760e-07, 1.6382410e-07, 1.7023969e-07,\n",
      "       1.7074935e-07, 1.6658676e-07, 1.6439253e-07, 1.6856201e-07,\n",
      "       1.6083672e-07, 1.7136090e-07, 1.7064060e-07, 1.6938034e-07,\n",
      "       1.6662544e-07, 1.7076420e-07, 1.6450747e-07, 1.6434851e-07,\n",
      "       1.6845431e-07, 1.6668557e-07, 1.6668494e-07, 1.6764484e-07,\n",
      "       1.6816391e-07, 1.6944975e-07, 1.6360900e-07, 1.6639737e-07,\n",
      "       1.6972410e-07, 1.6869399e-07, 1.6981969e-07, 1.6810573e-07,\n",
      "       1.7134067e-07, 1.7139402e-07, 1.6907374e-07, 1.6873187e-07,\n",
      "       1.6741080e-07, 1.6925316e-07, 1.7012403e-07, 1.6986293e-07,\n",
      "       1.7114932e-07, 1.6846592e-07, 1.7059945e-07, 1.6739845e-07,\n",
      "       1.6906459e-07, 1.7055059e-07, 1.6714866e-07, 1.6173904e-07,\n",
      "       1.6837301e-07, 1.6881532e-07, 1.6542386e-07, 1.6944051e-07,\n",
      "       1.7042068e-07, 1.6362821e-07, 1.6837708e-07, 1.6961874e-07,\n",
      "       1.7056939e-07, 1.7075791e-07, 1.6903655e-07, 1.6882132e-07,\n",
      "       1.6899010e-07, 1.6446872e-07, 1.6805555e-07, 1.6533797e-07,\n",
      "       1.7070133e-07, 1.7150072e-07, 1.7151503e-07, 1.6765406e-07,\n",
      "       1.6964346e-07, 1.7130404e-07, 1.7287707e-07, 1.6506019e-07,\n",
      "       1.6732940e-07, 1.6251572e-07, 1.7079795e-07, 1.7186890e-07,\n",
      "       1.6436333e-07, 1.6953146e-07, 1.6662443e-07, 1.6593886e-07,\n",
      "       1.6503857e-07, 1.6477314e-07, 1.6526698e-07, 1.6306643e-07,\n",
      "       1.6857386e-07, 1.7155330e-07, 1.6993317e-07, 1.6816703e-07,\n",
      "       1.6639278e-07, 1.6787712e-07, 1.6983245e-07, 1.7191383e-07,\n",
      "       1.7116088e-07, 1.6660161e-07, 1.6788654e-07, 1.6961360e-07,\n",
      "       1.7031432e-07, 1.6803625e-07, 1.6451602e-07, 1.6710794e-07,\n",
      "       1.6972947e-07, 1.7035192e-07, 1.7021611e-07, 1.7000640e-07,\n",
      "       1.7107304e-07, 1.6732771e-07, 1.7073982e-07, 1.6564853e-07,\n",
      "       1.6898385e-07, 1.7074440e-07, 1.7090490e-07, 1.7286884e-07,\n",
      "       1.6997251e-07, 1.6760239e-07, 1.6735409e-07, 1.7025042e-07,\n",
      "       1.6923671e-07, 1.6574302e-07, 1.6925543e-07, 1.7045659e-07,\n",
      "       1.7110973e-07, 1.6264578e-07, 1.7043153e-07, 1.7164416e-07,\n",
      "       1.6263974e-07, 1.6964746e-07, 1.7084591e-07, 1.6960038e-07,\n",
      "       1.6883673e-07, 1.6720347e-07, 1.6844440e-07, 1.6882916e-07,\n",
      "       1.7169961e-07, 1.6805363e-07, 1.6787023e-07, 1.7007019e-07,\n",
      "       1.6192791e-07, 1.5156691e-07, 1.7049553e-07, 1.7082324e-07,\n",
      "       1.6942666e-07, 1.6838177e-07, 1.6594967e-07, 1.6259192e-07,\n",
      "       1.6648414e-07, 1.7106815e-07, 1.7186487e-07, 1.7032258e-07,\n",
      "       1.7073449e-07, 1.6164230e-07, 1.6800837e-07, 1.7130546e-07,\n",
      "       1.7056493e-07, 1.6708087e-07, 1.6069642e-07, 1.6834521e-07,\n",
      "       1.7131561e-07, 1.6917873e-07, 1.7036913e-07, 1.6359299e-07,\n",
      "       1.7012748e-07, 1.6738043e-07, 1.6979425e-07, 1.6671751e-07,\n",
      "       1.6962719e-07, 1.6910413e-07, 1.6872583e-07, 1.6788471e-07,\n",
      "       1.6834460e-07, 1.6916454e-07, 1.6935370e-07, 1.6765405e-07,\n",
      "       1.6823883e-07, 1.7194341e-07, 1.6979156e-07, 1.5974354e-07,\n",
      "       1.7212886e-07, 1.6691344e-07, 1.7038948e-07, 1.7114337e-07,\n",
      "       1.7075847e-07, 1.7047476e-07, 1.6992887e-07, 1.6339261e-07,\n",
      "       1.6923389e-07, 1.6907677e-07, 1.6758757e-07, 1.7087166e-07,\n",
      "       1.7211637e-07, 1.7067781e-07, 1.6657818e-07, 1.7043298e-07,\n",
      "       1.6130367e-07, 1.7048974e-07, 1.6860413e-07, 1.6837409e-07,\n",
      "       1.6144290e-07, 1.7113804e-07, 1.6743887e-07, 1.7083576e-07,\n",
      "       1.6946369e-07, 1.7142240e-07, 1.6826257e-07, 1.6475782e-07,\n",
      "       1.7006218e-07, 1.6409786e-07, 1.7161989e-07, 1.6587246e-07,\n",
      "       1.7056665e-07, 1.5594638e-07, 1.6237053e-07, 1.7149861e-07,\n",
      "       1.7015084e-07, 1.7042164e-07, 1.6876193e-07, 1.7077868e-07,\n",
      "       1.7049513e-07, 1.6770288e-07, 1.6665129e-07, 1.7008850e-07,\n",
      "       1.6738655e-07, 1.6704911e-07, 1.6808798e-07, 1.7068027e-07,\n",
      "       1.7023102e-07, 1.6891431e-07, 1.6585045e-07, 1.6701138e-07,\n",
      "       1.6536103e-07, 1.6862720e-07, 1.6969889e-07, 1.7129236e-07,\n",
      "       1.6976892e-07, 1.6622582e-07, 1.6788812e-07, 1.7167970e-07,\n",
      "       1.6906485e-07, 1.6627088e-07, 1.6581102e-07, 1.6822175e-07,\n",
      "       1.6986529e-07, 1.6898882e-07, 1.6732899e-07, 1.6778597e-07,\n",
      "       1.6919851e-07, 1.7300472e-07, 1.6315046e-07, 1.6646831e-07,\n",
      "       1.6641992e-07, 1.7033240e-07, 1.6412490e-07, 1.6929290e-07,\n",
      "       1.7195407e-07, 1.6667653e-07, 1.6928965e-07, 1.7010080e-07,\n",
      "       1.6685031e-07, 1.7075236e-07, 1.7134982e-07, 1.6045593e-07,\n",
      "       1.6737398e-07, 1.6771115e-07, 1.6779035e-07, 1.6775337e-07,\n",
      "       1.6837963e-07, 1.6758695e-07, 1.7086346e-07, 1.6926116e-07,\n",
      "       1.6434778e-07, 1.6662020e-07, 1.6868036e-07, 1.6637861e-07,\n",
      "       1.6916016e-07, 1.6221789e-07, 1.6273074e-07, 1.6693929e-07,\n",
      "       1.6631056e-07, 1.6617774e-07, 1.6833454e-07, 1.6886662e-07,\n",
      "       1.7144367e-07, 1.7113122e-07, 1.6561941e-07, 1.6749372e-07,\n",
      "       1.6953481e-07, 1.6996442e-07, 1.6857349e-07, 1.6708961e-07,\n",
      "       1.7241480e-07, 1.6562043e-07, 1.7264094e-07, 1.7088469e-07,\n",
      "       1.6813786e-07, 1.6969555e-07, 1.7031043e-07, 1.6200279e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_23/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/depthwise_conv2d_7/depthwise;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D\n",
      "index : 86\n",
      "shape : [  1   3   3 480]\n",
      "shape_signature : [  1   3   3 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00026376, 0.00028896, 0.00030605, 0.00029384, 0.00027462,\n",
      "       0.00030233, 0.00029337, 0.00030632, 0.0002942 , 0.00030787,\n",
      "       0.00030399, 0.00030495, 0.00031203, 0.00030432, 0.00013348,\n",
      "       0.0002746 , 0.0002579 , 0.00026019, 0.00030009, 0.00025705,\n",
      "       0.00026026, 0.00028077, 0.00028647, 0.0002462 , 0.00030805,\n",
      "       0.00030369, 0.00031725, 0.00029108, 0.00026046, 0.00029214,\n",
      "       0.00024452, 0.00028845, 0.00031217, 0.00031952, 0.00030833,\n",
      "       0.00031244, 0.0003029 , 0.00029038, 0.00024828, 0.00030363,\n",
      "       0.00026866, 0.00029445, 0.00031421, 0.00030497, 0.00031669,\n",
      "       0.00030957, 0.0003016 , 0.00027459, 0.00029039, 0.00027449,\n",
      "       0.00029108, 0.00031646, 0.00021795, 0.0003028 , 0.00031444,\n",
      "       0.00030293, 0.00025452, 0.00028193, 0.00027188, 0.00031373,\n",
      "       0.00032306, 0.00031719, 0.00031381, 0.00026257, 0.00031388,\n",
      "       0.00028271, 0.00030523, 0.00031488, 0.00030805, 0.00028608,\n",
      "       0.00031544, 0.00029492, 0.00031037, 0.00025217, 0.00030837,\n",
      "       0.00026334, 0.00028882, 0.00027981, 0.00031848, 0.00030268,\n",
      "       0.00023404, 0.00030865, 0.00031431, 0.00027164, 0.00024337,\n",
      "       0.00027173, 0.00031312, 0.00029284, 0.00023935, 0.00029691,\n",
      "       0.00029296, 0.0002923 , 0.00021291, 0.00028917, 0.0002734 ,\n",
      "       0.00025792, 0.00030711, 0.00028678, 0.00031061, 0.00031372,\n",
      "       0.00030401, 0.00027983, 0.00031724, 0.0002952 , 0.00030532,\n",
      "       0.0002993 , 0.00031549, 0.00028922, 0.00028641, 0.00027693,\n",
      "       0.00031981, 0.00029176, 0.00031589, 0.00031006, 0.000311  ,\n",
      "       0.0002379 , 0.00028526, 0.00027366, 0.00030996, 0.00025448,\n",
      "       0.00025434, 0.00029857, 0.00032012, 0.00031681, 0.00030806,\n",
      "       0.00031153, 0.0003123 , 0.00028069, 0.00030264, 0.00022834,\n",
      "       0.00028831, 0.00030581, 0.00028621, 0.00029542, 0.00027062,\n",
      "       0.00027993, 0.00028951, 0.0003035 , 0.00028525, 0.00024327,\n",
      "       0.00027268, 0.00028736, 0.00025979, 0.00028569, 0.00031595,\n",
      "       0.00028126, 0.00031034, 0.0002998 , 0.00028306, 0.00030323,\n",
      "       0.00024605, 0.00031795, 0.0002393 , 0.00030615, 0.00028825,\n",
      "       0.00031593, 0.00029955, 0.00029232, 0.00031379, 0.00027971,\n",
      "       0.00028979, 0.00030926, 0.0001985 , 0.00030705, 0.00031619,\n",
      "       0.00031345, 0.0003167 , 0.00031785, 0.00031978, 0.00023008,\n",
      "       0.00029261, 0.00029191, 0.00028993, 0.00031306, 0.00030987,\n",
      "       0.00030029, 0.0002636 , 0.00026647, 0.00031441, 0.00028781,\n",
      "       0.00028202, 0.00030922, 0.00028829, 0.00029713, 0.00030929,\n",
      "       0.00028289, 0.00031104, 0.00030074, 0.00026386, 0.00027174,\n",
      "       0.00027655, 0.00030346, 0.00026614, 0.0003059 , 0.00022591,\n",
      "       0.00030687, 0.00025586, 0.00032084, 0.00031354, 0.00024969,\n",
      "       0.0002831 , 0.00030525, 0.00028022, 0.00028028, 0.00021459,\n",
      "       0.0003045 , 0.00028354, 0.00025911, 0.00028448, 0.00026796,\n",
      "       0.00023067, 0.00031072, 0.0002449 , 0.00030106, 0.00028156,\n",
      "       0.0002832 , 0.00027166, 0.00031627, 0.00024528, 0.00027767,\n",
      "       0.00028933, 0.00029107, 0.00030758, 0.00029545, 0.00024483,\n",
      "       0.00028936, 0.00030818, 0.00029502, 0.00031148, 0.00029121,\n",
      "       0.00028686, 0.00027322, 0.00030698, 0.00029939, 0.00030937,\n",
      "       0.00029922, 0.00031437, 0.00030658, 0.00028181, 0.00029336,\n",
      "       0.00024208, 0.00027163, 0.00031329, 0.00028364, 0.00019828,\n",
      "       0.00031103, 0.00017441, 0.00031184, 0.00030323, 0.00031626,\n",
      "       0.00029936, 0.0002253 , 0.00027063, 0.00029832, 0.00030138,\n",
      "       0.00023637, 0.00030975, 0.00029241, 0.00023005, 0.00029476,\n",
      "       0.00030917, 0.00030683, 0.0002795 , 0.00030003, 0.0002803 ,\n",
      "       0.00030068, 0.00029239, 0.00023332, 0.00026824, 0.00024628,\n",
      "       0.00028756, 0.00031732, 0.00026981, 0.00031225, 0.00028417,\n",
      "       0.00030204, 0.0002124 , 0.00028485, 0.00030989, 0.00025892,\n",
      "       0.00026319, 0.00029442, 0.0003028 , 0.00029172, 0.00021665,\n",
      "       0.00023612, 0.00020664, 0.00029453, 0.00031115, 0.00027447,\n",
      "       0.00027242, 0.00025897, 0.00021732, 0.0003056 , 0.00025716,\n",
      "       0.00025731, 0.00028844, 0.00022488, 0.0002129 , 0.00031686,\n",
      "       0.00030487, 0.00029907, 0.00021623, 0.00030881, 0.00027024,\n",
      "       0.00029928, 0.00018498, 0.00031572, 0.00024284, 0.00025399,\n",
      "       0.00029013, 0.00029471, 0.0003106 , 0.00031279, 0.00027634,\n",
      "       0.00025475, 0.00023788, 0.00028066, 0.00025009, 0.00030157,\n",
      "       0.00031291, 0.00028231, 0.00031888, 0.00025952, 0.00030714,\n",
      "       0.00023987, 0.00029274, 0.00030652, 0.00025225, 0.0003102 ,\n",
      "       0.00029068, 0.00030249, 0.00030943, 0.00023145, 0.00030125,\n",
      "       0.00029243, 0.00031325, 0.00026133, 0.0002842 , 0.00028864,\n",
      "       0.00031513, 0.0002581 , 0.00025206, 0.00024489, 0.00032104,\n",
      "       0.00029511, 0.00024698, 0.00025173, 0.00028865, 0.00023589,\n",
      "       0.00029855, 0.00026045, 0.00028549, 0.00029113, 0.00031035,\n",
      "       0.00031392, 0.00030798, 0.0003132 , 0.00013138, 0.00025565,\n",
      "       0.00025465, 0.00029108, 0.00032324, 0.00028906, 0.00028941,\n",
      "       0.0003095 , 0.00030183, 0.0003159 , 0.00029605, 0.00023211,\n",
      "       0.00028034, 0.00031225, 0.00028095, 0.00025984, 0.00030963,\n",
      "       0.00030875, 0.00030894, 0.00031056, 0.00027427, 0.00031133,\n",
      "       0.00028307, 0.00030067, 0.00030678, 0.00027303, 0.00030567,\n",
      "       0.00031658, 0.00028468, 0.00025245, 0.0002179 , 0.00031831,\n",
      "       0.00020104, 0.00030417, 0.00030339, 0.00030105, 0.00028573,\n",
      "       0.00030049, 0.00031419, 0.00025478, 0.00031999, 0.00028724,\n",
      "       0.00030591, 0.00032477, 0.00030615, 0.00025789, 0.00029562,\n",
      "       0.00030971, 0.00022472, 0.00025743, 0.00029727, 0.00029857,\n",
      "       0.00029635, 0.00026694, 0.00025405, 0.00029258, 0.00030378,\n",
      "       0.00030663, 0.00024585, 0.0003138 , 0.00031884, 0.00029825,\n",
      "       0.0002981 , 0.00031591, 0.00026938, 0.0003023 , 0.00031514,\n",
      "       0.00030833, 0.00030047, 0.00028088, 0.00031104, 0.00028249,\n",
      "       0.00023803, 0.00029099, 0.00027089, 0.0002816 , 0.00031684,\n",
      "       0.00027893, 0.00029906, 0.0002858 , 0.00030227, 0.00031623,\n",
      "       0.00024101, 0.00029078, 0.00022841, 0.00023897, 0.00030429,\n",
      "       0.00031448, 0.00029485, 0.00024696, 0.00026517, 0.00030106,\n",
      "       0.00031489, 0.0002757 , 0.00030194, 0.00027888, 0.00030028,\n",
      "       0.00030677, 0.00028838, 0.00026184, 0.00026937, 0.00027599,\n",
      "       0.00031148, 0.00025585, 0.00019478, 0.00031609, 0.00031765,\n",
      "       0.00029372, 0.00029264, 0.00027797, 0.00031047, 0.0002737 ,\n",
      "       0.00028783, 0.00025085, 0.00030949, 0.00024715, 0.00027145,\n",
      "       0.0002917 , 0.00031999, 0.00029052, 0.00023176, 0.00029952],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_23/FusedBatchNormV3\n",
      "index : 87\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.57174682e-08, 1.72190280e-08, 1.82374773e-08, 1.75097554e-08,\n",
      "       1.63641332e-08, 1.80157631e-08, 1.74815096e-08, 1.82533277e-08,\n",
      "       1.75312156e-08, 1.83455597e-08, 1.81146689e-08, 1.81719280e-08,\n",
      "       1.85933331e-08, 1.81339086e-08, 7.95380384e-09, 1.63632450e-08,\n",
      "       1.53679629e-08, 1.55041722e-08, 1.78820123e-08, 1.53173811e-08,\n",
      "       1.55084834e-08, 1.67309366e-08, 1.70703967e-08, 1.46710244e-08,\n",
      "       1.83564843e-08, 1.80967348e-08, 1.89046077e-08, 1.73450889e-08,\n",
      "       1.55206727e-08, 1.74080892e-08, 1.45705581e-08, 1.71886647e-08,\n",
      "       1.86019413e-08, 1.90396534e-08, 1.83731199e-08, 1.86178095e-08,\n",
      "       1.80493771e-08, 1.73032930e-08, 1.47948853e-08, 1.80932940e-08,\n",
      "       1.60090252e-08, 1.75460251e-08, 1.87234743e-08, 1.81730897e-08,\n",
      "       1.88714413e-08, 1.84470981e-08, 1.79722157e-08, 1.63627369e-08,\n",
      "       1.73038934e-08, 1.63564806e-08, 1.73451991e-08, 1.88576621e-08,\n",
      "       1.29876421e-08, 1.80437159e-08, 1.87368983e-08, 1.80515762e-08,\n",
      "       1.51667070e-08, 1.67997065e-08, 1.62008611e-08, 1.86946139e-08,\n",
      "       1.92510399e-08, 1.89008347e-08, 1.86995663e-08, 1.56462221e-08,\n",
      "       1.87037248e-08, 1.68465277e-08, 1.81882420e-08, 1.87634654e-08,\n",
      "       1.83563369e-08, 1.70474532e-08, 1.87968112e-08, 1.75738375e-08,\n",
      "       1.84943847e-08, 1.50267905e-08, 1.83754008e-08, 1.56921409e-08,\n",
      "       1.72107395e-08, 1.66735248e-08, 1.89781471e-08, 1.80363138e-08,\n",
      "       1.39463374e-08, 1.83923650e-08, 1.87292439e-08, 1.61866698e-08,\n",
      "       1.45022545e-08, 1.61919722e-08, 1.86586320e-08, 1.74498052e-08,\n",
      "       1.42627545e-08, 1.76928072e-08, 1.74572996e-08, 1.74178130e-08,\n",
      "       1.26871091e-08, 1.72316081e-08, 1.62917662e-08, 1.53694124e-08,\n",
      "       1.83006108e-08, 1.70891763e-08, 1.85090432e-08, 1.86942302e-08,\n",
      "       1.81157045e-08, 1.66747540e-08, 1.89039167e-08, 1.75905441e-08,\n",
      "       1.81934645e-08, 1.78347932e-08, 1.87999163e-08, 1.72344201e-08,\n",
      "       1.70667320e-08, 1.65019109e-08, 1.90568965e-08, 1.73855170e-08,\n",
      "       1.88232665e-08, 1.84762960e-08, 1.85321252e-08, 1.41761429e-08,\n",
      "       1.69983458e-08, 1.63073945e-08, 1.84702973e-08, 1.51643551e-08,\n",
      "       1.51560933e-08, 1.77912227e-08, 1.90754488e-08, 1.88782359e-08,\n",
      "       1.83568396e-08, 1.85639184e-08, 1.86094997e-08, 1.67262488e-08,\n",
      "       1.80339903e-08, 1.36066225e-08, 1.71798522e-08, 1.82230160e-08,\n",
      "       1.70547505e-08, 1.76037762e-08, 1.61258011e-08, 1.66806959e-08,\n",
      "       1.72516632e-08, 1.80853608e-08, 1.69977810e-08, 1.44963641e-08,\n",
      "       1.62486167e-08, 1.71235630e-08, 1.54808628e-08, 1.70238952e-08,\n",
      "       1.88268512e-08, 1.67602039e-08, 1.84926154e-08, 1.78647319e-08,\n",
      "       1.68673520e-08, 1.80691639e-08, 1.46619294e-08, 1.89462064e-08,\n",
      "       1.42597854e-08, 1.82433215e-08, 1.71767258e-08, 1.88259381e-08,\n",
      "       1.78496045e-08, 1.74191630e-08, 1.86984526e-08, 1.66678849e-08,\n",
      "       1.72684498e-08, 1.84283042e-08, 1.18284502e-08, 1.82967153e-08,\n",
      "       1.88412344e-08, 1.86778824e-08, 1.88716509e-08, 1.89403249e-08,\n",
      "       1.90551397e-08, 1.37100287e-08, 1.74360615e-08, 1.73947061e-08,\n",
      "       1.72764043e-08, 1.86549869e-08, 1.84651103e-08, 1.78940311e-08,\n",
      "       1.57075117e-08, 1.58786033e-08, 1.87353297e-08, 1.71503576e-08,\n",
      "       1.68052381e-08, 1.84258226e-08, 1.71790422e-08, 1.77055401e-08,\n",
      "       1.84304874e-08, 1.68568963e-08, 1.85345943e-08, 1.79210815e-08,\n",
      "       1.57233053e-08, 1.61926668e-08, 1.64791238e-08, 1.80827637e-08,\n",
      "       1.58590154e-08, 1.82283841e-08, 1.34619551e-08, 1.82858368e-08,\n",
      "       1.52461457e-08, 1.91182501e-08, 1.86833660e-08, 1.48789816e-08,\n",
      "       1.68694623e-08, 1.81895032e-08, 1.66981575e-08, 1.67016534e-08,\n",
      "       1.27871269e-08, 1.81448243e-08, 1.68957399e-08, 1.54399888e-08,\n",
      "       1.69516667e-08, 1.59672560e-08, 1.37451224e-08, 1.85153226e-08,\n",
      "       1.45932306e-08, 1.79400974e-08, 1.67775998e-08, 1.68756227e-08,\n",
      "       1.61880287e-08, 1.88463414e-08, 1.46161536e-08, 1.65461085e-08,\n",
      "       1.72407582e-08, 1.73448562e-08, 1.83283149e-08, 1.76054922e-08,\n",
      "       1.45890802e-08, 1.72428560e-08, 1.83643021e-08, 1.75798984e-08,\n",
      "       1.85605966e-08, 1.73527628e-08, 1.70935568e-08, 1.62808345e-08,\n",
      "       1.82926563e-08, 1.78402164e-08, 1.84350277e-08, 1.78300343e-08,\n",
      "       1.87327167e-08, 1.82686399e-08, 1.67927539e-08, 1.74810442e-08,\n",
      "       1.44253880e-08, 1.61859877e-08, 1.86685654e-08, 1.69016818e-08,\n",
      "       1.18150192e-08, 1.85340916e-08, 1.03928262e-08, 1.85823072e-08,\n",
      "       1.80689526e-08, 1.88457339e-08, 1.78382589e-08, 1.34256464e-08,\n",
      "       1.61266485e-08, 1.77764434e-08, 1.79587403e-08, 1.40852690e-08,\n",
      "       1.84574578e-08, 1.74246786e-08, 1.37085197e-08, 1.75646591e-08,\n",
      "       1.84231794e-08, 1.82836590e-08, 1.66548215e-08, 1.78785378e-08,\n",
      "       1.67026535e-08, 1.79171646e-08, 1.74232326e-08, 1.39030929e-08,\n",
      "       1.59838969e-08, 1.46757904e-08, 1.71351360e-08, 1.89087626e-08,\n",
      "       1.60777365e-08, 1.86067908e-08, 1.69332726e-08, 1.79984454e-08,\n",
      "       1.26564990e-08, 1.69740169e-08, 1.84661300e-08, 1.54289843e-08,\n",
      "       1.56831668e-08, 1.75443784e-08, 1.80433499e-08, 1.73835097e-08,\n",
      "       1.29101672e-08, 1.40700411e-08, 1.23136505e-08, 1.75504589e-08,\n",
      "       1.85413516e-08, 1.63556191e-08, 1.62330824e-08, 1.54318212e-08,\n",
      "       1.29499487e-08, 1.82104625e-08, 1.53237245e-08, 1.53327306e-08,\n",
      "       1.71880146e-08, 1.34004061e-08, 1.26862369e-08, 1.88812130e-08,\n",
      "       1.81671620e-08, 1.78214208e-08, 1.28849704e-08, 1.84018329e-08,\n",
      "       1.61031704e-08, 1.78335444e-08, 1.10229559e-08, 1.88134752e-08,\n",
      "       1.44704178e-08, 1.51352602e-08, 1.72886363e-08, 1.75612307e-08,\n",
      "       1.85081923e-08, 1.86389340e-08, 1.64670837e-08, 1.51800972e-08,\n",
      "       1.41751801e-08, 1.67241296e-08, 1.49025450e-08, 1.79700290e-08,\n",
      "       1.86456877e-08, 1.68227157e-08, 1.90017317e-08, 1.54644955e-08,\n",
      "       1.83020674e-08, 1.42935273e-08, 1.74440640e-08, 1.82650215e-08,\n",
      "       1.50313859e-08, 1.84845881e-08, 1.73212076e-08, 1.80248207e-08,\n",
      "       1.84388558e-08, 1.37920289e-08, 1.79510167e-08, 1.74258155e-08,\n",
      "       1.86659612e-08, 1.55721231e-08, 1.69349121e-08, 1.72000174e-08,\n",
      "       1.87783940e-08, 1.53798183e-08, 1.50199835e-08, 1.45927448e-08,\n",
      "       1.91304235e-08, 1.75853891e-08, 1.47172114e-08, 1.50002144e-08,\n",
      "       1.72003798e-08, 1.40564760e-08, 1.77902795e-08, 1.55197473e-08,\n",
      "       1.70120575e-08, 1.73479382e-08, 1.84932212e-08, 1.87061850e-08,\n",
      "       1.83524662e-08, 1.86634441e-08, 7.82876519e-09, 1.52338764e-08,\n",
      "       1.51745585e-08, 1.73452968e-08, 1.92614937e-08, 1.72248029e-08,\n",
      "       1.72454424e-08, 1.84426749e-08, 1.79856965e-08, 1.88239344e-08,\n",
      "       1.76414190e-08, 1.38309488e-08, 1.67049450e-08, 1.86069435e-08,\n",
      "       1.67414171e-08, 1.54836375e-08, 1.84502653e-08, 1.83980955e-08,\n",
      "       1.84097146e-08, 1.85062206e-08, 1.63436376e-08, 1.85516580e-08,\n",
      "       1.68679506e-08, 1.79166726e-08, 1.82808790e-08, 1.62697269e-08,\n",
      "       1.82144753e-08, 1.88643803e-08, 1.69637513e-08, 1.50430779e-08,\n",
      "       1.29845539e-08, 1.89680627e-08, 1.19797372e-08, 1.81250961e-08,\n",
      "       1.80789943e-08, 1.79391986e-08, 1.70265100e-08, 1.79058883e-08,\n",
      "       1.87219786e-08, 1.51819819e-08, 1.90676115e-08, 1.71162657e-08,\n",
      "       1.82290076e-08, 1.93528340e-08, 1.82429591e-08, 1.53671085e-08,\n",
      "       1.76154380e-08, 1.84550988e-08, 1.33908591e-08, 1.53397064e-08,\n",
      "       1.77139530e-08, 1.77915034e-08, 1.76592820e-08, 1.59065685e-08,\n",
      "       1.51387152e-08, 1.74343011e-08, 1.81016802e-08, 1.82720026e-08,\n",
      "       1.46496912e-08, 1.86988789e-08, 1.89996108e-08, 1.77726189e-08,\n",
      "       1.77635524e-08, 1.88249931e-08, 1.60521907e-08, 1.80137327e-08,\n",
      "       1.87787652e-08, 1.83732016e-08, 1.79048616e-08, 1.67375411e-08,\n",
      "       1.85346369e-08, 1.68332424e-08, 1.41838639e-08, 1.73398185e-08,\n",
      "       1.61423372e-08, 1.67800618e-08, 1.88800620e-08, 1.66209020e-08,\n",
      "       1.78209572e-08, 1.70307146e-08, 1.80119617e-08, 1.88435276e-08,\n",
      "       1.43617331e-08, 1.73270642e-08, 1.36109719e-08, 1.42402206e-08,\n",
      "       1.81324964e-08, 1.87393674e-08, 1.75696524e-08, 1.47160231e-08,\n",
      "       1.58009463e-08, 1.79397439e-08, 1.87638012e-08, 1.64287801e-08,\n",
      "       1.79922868e-08, 1.66183742e-08, 1.78933472e-08, 1.82801845e-08,\n",
      "       1.71843748e-08, 1.56026498e-08, 1.60512155e-08, 1.64459717e-08,\n",
      "       1.85609412e-08, 1.52456217e-08, 1.16067103e-08, 1.88352516e-08,\n",
      "       1.89284197e-08, 1.75026731e-08, 1.74381078e-08, 1.65641172e-08,\n",
      "       1.85006694e-08, 1.63092491e-08, 1.71517449e-08, 1.49476609e-08,\n",
      "       1.84420781e-08, 1.47276067e-08, 1.61756954e-08, 1.73821704e-08,\n",
      "       1.90679774e-08, 1.73117822e-08, 1.38102054e-08, 1.78483681e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/Conv2D\n",
      "index : 88\n",
      "shape : [120   1   1 480]\n",
      "shape_signature : [120   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078844, 0.00078243, 0.00078643, 0.00078709, 0.00078907,\n",
      "       0.00078698, 0.00078724, 0.0007871 , 0.00078637, 0.00078033,\n",
      "       0.00078709, 0.00078527, 0.00078411, 0.00079123, 0.00078548,\n",
      "       0.00079167, 0.00078775, 0.00078918, 0.00079265, 0.00079   ,\n",
      "       0.00078211, 0.00078906, 0.00078639, 0.00078465, 0.00078509,\n",
      "       0.00078237, 0.00078766, 0.0007856 , 0.00078753, 0.00078653,\n",
      "       0.00078746, 0.00078753, 0.00078638, 0.00078842, 0.00078624,\n",
      "       0.00078978, 0.00078918, 0.00078041, 0.00078951, 0.00078662,\n",
      "       0.00078914, 0.00078694, 0.00078626, 0.0007884 , 0.00078719,\n",
      "       0.00078726, 0.00078427, 0.00078719, 0.00078541, 0.00078519,\n",
      "       0.00078979, 0.00079091, 0.00078742, 0.0007879 , 0.00078272,\n",
      "       0.00078728, 0.00078486, 0.00078696, 0.0007864 , 0.00078468,\n",
      "       0.00078684, 0.00078953, 0.0007886 , 0.00078431, 0.00078556,\n",
      "       0.00078885, 0.00079303, 0.00078718, 0.00079203, 0.0007871 ,\n",
      "       0.0007865 , 0.00078755, 0.00078877, 0.00078499, 0.00078414,\n",
      "       0.0007823 , 0.00078826, 0.00078669, 0.00078863, 0.00078139,\n",
      "       0.00078978, 0.00078731, 0.00078269, 0.0007829 , 0.00078413,\n",
      "       0.00078818, 0.00078484, 0.00078625, 0.00079158, 0.00078698,\n",
      "       0.00079002, 0.00079033, 0.00078725, 0.00078706, 0.0007883 ,\n",
      "       0.00078531, 0.00078886, 0.00078613, 0.000783  , 0.00078666,\n",
      "       0.00078865, 0.00078662, 0.0007917 , 0.00078444, 0.00079006,\n",
      "       0.00078949, 0.00078763, 0.00078813, 0.00078418, 0.00078771,\n",
      "       0.000787  , 0.00079039, 0.00078813, 0.00078731, 0.00078862,\n",
      "       0.00077992, 0.00078807, 0.00078423, 0.00078663, 0.00078678],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/BiasAdd/ReadVariableOp/resource\n",
      "index : 89\n",
      "shape : [120]\n",
      "shape_signature : [120]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.6612275e-08, 2.6409474e-08, 2.6544246e-08, 2.6566571e-08,\n",
      "       2.6633558e-08, 2.6562919e-08, 2.6571801e-08, 2.6566990e-08,\n",
      "       2.6542418e-08, 2.6338475e-08, 2.6566548e-08, 2.6505285e-08,\n",
      "       2.6466063e-08, 2.6706331e-08, 2.6512369e-08, 2.6721212e-08,\n",
      "       2.6589019e-08, 2.6637220e-08, 2.6754382e-08, 2.6664804e-08,\n",
      "       2.6398510e-08, 2.6633323e-08, 2.6543130e-08, 2.6484257e-08,\n",
      "       2.6499194e-08, 2.6407378e-08, 2.6585788e-08, 2.6516298e-08,\n",
      "       2.6581672e-08, 2.6547820e-08, 2.6579141e-08, 2.6581532e-08,\n",
      "       2.6542606e-08, 2.6611584e-08, 2.6538055e-08, 2.6657343e-08,\n",
      "       2.6637379e-08, 2.6341162e-08, 2.6648216e-08, 2.6550671e-08,\n",
      "       2.6635735e-08, 2.6561469e-08, 2.6538714e-08, 2.6611009e-08,\n",
      "       2.6570017e-08, 2.6572339e-08, 2.6471316e-08, 2.6570023e-08,\n",
      "       2.6509907e-08, 2.6502626e-08, 2.6657768e-08, 2.6695480e-08,\n",
      "       2.6577945e-08, 2.6594087e-08, 2.6419256e-08, 2.6573042e-08,\n",
      "       2.6491406e-08, 2.6562260e-08, 2.6543272e-08, 2.6485324e-08,\n",
      "       2.6558327e-08, 2.6649047e-08, 2.6617762e-08, 2.6472939e-08,\n",
      "       2.6514897e-08, 2.6626042e-08, 2.6767186e-08, 2.6569650e-08,\n",
      "       2.6733510e-08, 2.6567093e-08, 2.6546902e-08, 2.6582105e-08,\n",
      "       2.6623312e-08, 2.6495794e-08, 2.6467250e-08, 2.6404841e-08,\n",
      "       2.6606243e-08, 2.6553300e-08, 2.6618805e-08, 2.6374151e-08,\n",
      "       2.6657487e-08, 2.6574066e-08, 2.6418128e-08, 2.6425120e-08,\n",
      "       2.6466667e-08, 2.6603338e-08, 2.6490847e-08, 2.6538173e-08,\n",
      "       2.6718274e-08, 2.6563017e-08, 2.6665653e-08, 2.6675908e-08,\n",
      "       2.6572183e-08, 2.6565745e-08, 2.6607426e-08, 2.6506600e-08,\n",
      "       2.6626255e-08, 2.6534176e-08, 2.6428472e-08, 2.6552044e-08,\n",
      "       2.6619441e-08, 2.6550886e-08, 2.6722391e-08, 2.6477311e-08,\n",
      "       2.6666974e-08, 2.6647694e-08, 2.6584946e-08, 2.6601841e-08,\n",
      "       2.6468436e-08, 2.6587678e-08, 2.6563677e-08, 2.6677974e-08,\n",
      "       2.6601835e-08, 2.6574138e-08, 2.6618425e-08, 2.6324518e-08,\n",
      "       2.6599754e-08, 2.6469991e-08, 2.6551037e-08, 2.6556254e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/Conv2D\n",
      "index : 90\n",
      "shape : [480   1   1 120]\n",
      "shape_signature : [480   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078919, 0.00079052, 0.00078723, 0.00077925, 0.00078817,\n",
      "       0.00078466, 0.0007861 , 0.00078455, 0.0007773 , 0.00078751,\n",
      "       0.00078371, 0.00077426, 0.00076875, 0.00077515, 0.00079016,\n",
      "       0.00077231, 0.00078779, 0.00078408, 0.0007886 , 0.0007779 ,\n",
      "       0.00078646, 0.00078557, 0.00076714, 0.00077645, 0.00077714,\n",
      "       0.00078207, 0.00079079, 0.00076279, 0.00077745, 0.00077904,\n",
      "       0.00077809, 0.00078542, 0.00078207, 0.00078047, 0.00078114,\n",
      "       0.00077983, 0.00078975, 0.00078404, 0.0007824 , 0.00077551,\n",
      "       0.00077311, 0.00077875, 0.00077867, 0.00078861, 0.00078258,\n",
      "       0.00078291, 0.00078651, 0.00078275, 0.00077849, 0.00078636,\n",
      "       0.000781  , 0.0007823 , 0.00077803, 0.00078669, 0.00078103,\n",
      "       0.00077851, 0.00078421, 0.00079062, 0.00078282, 0.00078203,\n",
      "       0.00078328, 0.00078319, 0.00078005, 0.00077335, 0.00078365,\n",
      "       0.00077275, 0.00078912, 0.00078794, 0.00078872, 0.00078729,\n",
      "       0.00077977, 0.00076092, 0.00079119, 0.00077204, 0.00078578,\n",
      "       0.00078702, 0.00078669, 0.00079106, 0.00077942, 0.00077739,\n",
      "       0.00077135, 0.0007911 , 0.00078845, 0.00077258, 0.00077759,\n",
      "       0.00076977, 0.00078076, 0.00077493, 0.00077007, 0.00076182,\n",
      "       0.00077879, 0.00078519, 0.00078398, 0.00078167, 0.00078706,\n",
      "       0.0007723 , 0.00077866, 0.00075972, 0.00077452, 0.00078184,\n",
      "       0.00078767, 0.00077648, 0.00078889, 0.00078624, 0.00077375,\n",
      "       0.00078757, 0.00077992, 0.00076665, 0.00078727, 0.00078324,\n",
      "       0.00077526, 0.00077554, 0.00078535, 0.0007782 , 0.00078551,\n",
      "       0.00078141, 0.00078481, 0.00078005, 0.00077427, 0.00078588,\n",
      "       0.00079196, 0.00078941, 0.00076138, 0.00075051, 0.0007848 ,\n",
      "       0.00076743, 0.00076838, 0.00078118, 0.00078454, 0.00078394,\n",
      "       0.00078545, 0.00076997, 0.00078661, 0.00077539, 0.00078125,\n",
      "       0.00077544, 0.00078571, 0.00078645, 0.00078417, 0.00076832,\n",
      "       0.00078006, 0.00078594, 0.00076089, 0.0007835 , 0.00077985,\n",
      "       0.00078538, 0.0007774 , 0.00078821, 0.00078137, 0.00078241,\n",
      "       0.0007821 , 0.00078369, 0.00078688, 0.0007848 , 0.00078813,\n",
      "       0.0007765 , 0.00079196, 0.00077173, 0.00079017, 0.0007828 ,\n",
      "       0.00078683, 0.00074856, 0.00078401, 0.00078025, 0.00078595,\n",
      "       0.00078478, 0.00075583, 0.00078401, 0.0007814 , 0.00078788,\n",
      "       0.00077994, 0.00076703, 0.00076915, 0.00078505, 0.00078404,\n",
      "       0.00079038, 0.00078201, 0.00078108, 0.00077859, 0.00078274,\n",
      "       0.00076587, 0.00078609, 0.00078036, 0.00078429, 0.00077594,\n",
      "       0.00077507, 0.00078079, 0.00078182, 0.00077749, 0.00078633,\n",
      "       0.00078708, 0.00078752, 0.00079086, 0.00077689, 0.0007818 ,\n",
      "       0.00077509, 0.00076944, 0.00075656, 0.00077696, 0.00078922,\n",
      "       0.00077973, 0.00078538, 0.00078029, 0.00078875, 0.00076089,\n",
      "       0.00077998, 0.00077754, 0.00078502, 0.00078015, 0.00077141,\n",
      "       0.0007797 , 0.00078599, 0.00078744, 0.00078923, 0.00077868,\n",
      "       0.00079002, 0.00078467, 0.00078134, 0.00077954, 0.00077979,\n",
      "       0.00078613, 0.00076528, 0.00078008, 0.00078874, 0.00078704,\n",
      "       0.00077498, 0.00078675, 0.00078307, 0.00078715, 0.00078681,\n",
      "       0.00077849, 0.00078307, 0.00078407, 0.00078459, 0.00078675,\n",
      "       0.0007789 , 0.00078024, 0.00078991, 0.00078776, 0.0007831 ,\n",
      "       0.000788  , 0.00078487, 0.0007635 , 0.00077587, 0.00078678,\n",
      "       0.00078877, 0.00077625, 0.00078039, 0.00077685, 0.00078283,\n",
      "       0.00077063, 0.00078332, 0.00078603, 0.00078459, 0.0007885 ,\n",
      "       0.00078484, 0.00077845, 0.00078264, 0.00078877, 0.00078584,\n",
      "       0.00076814, 0.00076421, 0.00078648, 0.00077922, 0.00077865,\n",
      "       0.00077992, 0.00076868, 0.00077995, 0.00078134, 0.00079089,\n",
      "       0.00078902, 0.00078985, 0.00079139, 0.00078811, 0.00078457,\n",
      "       0.00077702, 0.00078965, 0.00078362, 0.00077058, 0.00077326,\n",
      "       0.0007876 , 0.00078791, 0.00078321, 0.00078044, 0.00078367,\n",
      "       0.00077752, 0.00078357, 0.00077733, 0.00078227, 0.000772  ,\n",
      "       0.00077608, 0.00079309, 0.0007885 , 0.00078677, 0.00078478,\n",
      "       0.00078466, 0.00078762, 0.00078485, 0.00078134, 0.00077624,\n",
      "       0.00076527, 0.00077321, 0.0007795 , 0.00078191, 0.00078115,\n",
      "       0.00078248, 0.00078859, 0.00078558, 0.00078101, 0.00077143,\n",
      "       0.00078415, 0.00078415, 0.00078604, 0.00077852, 0.00078285,\n",
      "       0.00078492, 0.00077983, 0.00078563, 0.00077303, 0.00078984,\n",
      "       0.00077724, 0.00078525, 0.00078084, 0.00078427, 0.00078273,\n",
      "       0.00078035, 0.0007788 , 0.00079022, 0.00078141, 0.00078751,\n",
      "       0.0007838 , 0.00078312, 0.00077146, 0.00077957, 0.00078083,\n",
      "       0.00078673, 0.00078597, 0.00078624, 0.00077857, 0.00078352,\n",
      "       0.00078565, 0.00078108, 0.00079094, 0.00078568, 0.00079081,\n",
      "       0.00076683, 0.00078144, 0.00078243, 0.00078292, 0.00078603,\n",
      "       0.00078773, 0.00078699, 0.00077864, 0.00078353, 0.0007825 ,\n",
      "       0.0007919 , 0.00078767, 0.00078469, 0.00077844, 0.00076319,\n",
      "       0.00079024, 0.00077335, 0.00078377, 0.0007688 , 0.00076676,\n",
      "       0.00078016, 0.00076291, 0.0007826 , 0.0007862 , 0.00077827,\n",
      "       0.00077665, 0.00077887, 0.00075848, 0.00078779, 0.00078477,\n",
      "       0.00077837, 0.00078271, 0.00078733, 0.00078135, 0.00078894,\n",
      "       0.00078113, 0.0007548 , 0.00078113, 0.00077016, 0.00078605,\n",
      "       0.00076892, 0.00077657, 0.00078205, 0.00077859, 0.00078394,\n",
      "       0.00078133, 0.00078619, 0.00077566, 0.0007585 , 0.00078145,\n",
      "       0.00078414, 0.00078039, 0.00078587, 0.00078278, 0.00078478,\n",
      "       0.00078999, 0.00078774, 0.0007731 , 0.00078199, 0.00076285,\n",
      "       0.00077498, 0.00077349, 0.00077496, 0.00078445, 0.00077563,\n",
      "       0.00078436, 0.00077741, 0.0007872 , 0.00078202, 0.00074955,\n",
      "       0.00078924, 0.00078873, 0.00078436, 0.0007897 , 0.00078235,\n",
      "       0.00078084, 0.00077803, 0.00077605, 0.00078092, 0.00078785,\n",
      "       0.00078175, 0.00077996, 0.00076185, 0.00078107, 0.00078034,\n",
      "       0.00077009, 0.00078563, 0.00078794, 0.00078327, 0.00078529,\n",
      "       0.00078479, 0.00078485, 0.00078409, 0.00077885, 0.00078468,\n",
      "       0.00077107, 0.00078013, 0.00077121, 0.00078192, 0.00075779,\n",
      "       0.00078913, 0.00078683, 0.00078145, 0.00077275, 0.00077677,\n",
      "       0.00078388, 0.00078353, 0.00078215, 0.00076861, 0.000779  ,\n",
      "       0.00078257, 0.00078629, 0.00078278, 0.00077476, 0.00077998,\n",
      "       0.00077865, 0.00077897, 0.00076144, 0.00078354, 0.00078766,\n",
      "       0.00078213, 0.00078806, 0.00078366, 0.0007802 , 0.00079023,\n",
      "       0.00077577, 0.00077667, 0.0007779 , 0.00078888, 0.00078941,\n",
      "       0.0007814 , 0.00077906, 0.00078538, 0.0007855 , 0.00078309],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/BiasAdd/ReadVariableOp/resource\n",
      "index : 91\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8089960e-08, 1.8120316e-08, 1.8045034e-08, 1.7862126e-08,\n",
      "       1.8066594e-08, 1.7986146e-08, 1.8019113e-08, 1.7983442e-08,\n",
      "       1.7817358e-08, 1.8051352e-08, 1.7964201e-08, 1.7747627e-08,\n",
      "       1.7621289e-08, 1.7767945e-08, 1.8112209e-08, 1.7702945e-08,\n",
      "       1.8057696e-08, 1.7972706e-08, 1.8076459e-08, 1.7831148e-08,\n",
      "       1.8027356e-08, 1.8006887e-08, 1.7584529e-08, 1.7797834e-08,\n",
      "       1.7813772e-08, 1.7926665e-08, 1.8126554e-08, 1.7484677e-08,\n",
      "       1.7820712e-08, 1.7857115e-08, 1.7835442e-08, 1.8003462e-08,\n",
      "       1.7926789e-08, 1.7889906e-08, 1.7905432e-08, 1.7875442e-08,\n",
      "       1.8102753e-08, 1.7971772e-08, 1.7934235e-08, 1.7776244e-08,\n",
      "       1.7721376e-08, 1.7850571e-08, 1.7848727e-08, 1.8076653e-08,\n",
      "       1.7938369e-08, 1.7945997e-08, 1.8028372e-08, 1.7942304e-08,\n",
      "       1.7844611e-08, 1.8024982e-08, 1.7902192e-08, 1.7931910e-08,\n",
      "       1.7834017e-08, 1.8032472e-08, 1.7902849e-08, 1.7844984e-08,\n",
      "       1.7975701e-08, 1.8122602e-08, 1.7943927e-08, 1.7925773e-08,\n",
      "       1.7954441e-08, 1.7952244e-08, 1.7880431e-08, 1.7726837e-08,\n",
      "       1.7962904e-08, 1.7713093e-08, 1.8088299e-08, 1.8061323e-08,\n",
      "       1.8079147e-08, 1.8046375e-08, 1.7873869e-08, 1.7441796e-08,\n",
      "       1.8135770e-08, 1.7696726e-08, 1.8011713e-08, 1.8040202e-08,\n",
      "       1.8032676e-08, 1.8132839e-08, 1.7865990e-08, 1.7819357e-08,\n",
      "       1.7680964e-08, 1.8133745e-08, 1.8072910e-08, 1.7709047e-08,\n",
      "       1.7823966e-08, 1.7644680e-08, 1.7896728e-08, 1.7763105e-08,\n",
      "       1.7651580e-08, 1.7462568e-08, 1.7851413e-08, 1.7998138e-08,\n",
      "       1.7970507e-08, 1.7917417e-08, 1.8040975e-08, 1.7702735e-08,\n",
      "       1.7848439e-08, 1.7414326e-08, 1.7753578e-08, 1.7921316e-08,\n",
      "       1.8054999e-08, 1.7798531e-08, 1.8083062e-08, 1.8022346e-08,\n",
      "       1.7735898e-08, 1.8052720e-08, 1.7877500e-08, 1.7573296e-08,\n",
      "       1.8045775e-08, 1.7953408e-08, 1.7770507e-08, 1.7776992e-08,\n",
      "       1.8001760e-08, 1.7837994e-08, 1.8005597e-08, 1.7911534e-08,\n",
      "       1.7989404e-08, 1.7880453e-08, 1.7747919e-08, 1.8014020e-08,\n",
      "       1.8153349e-08, 1.8094813e-08, 1.7452358e-08, 1.7203272e-08,\n",
      "       1.7989274e-08, 1.7590995e-08, 1.7612777e-08, 1.7906173e-08,\n",
      "       1.7983378e-08, 1.7969516e-08, 1.8004128e-08, 1.7649391e-08,\n",
      "       1.8030681e-08, 1.7773489e-08, 1.7907904e-08, 1.7774719e-08,\n",
      "       1.8010168e-08, 1.8026972e-08, 1.7974713e-08, 1.7611544e-08,\n",
      "       1.7880655e-08, 1.8015294e-08, 1.7441277e-08, 1.7959536e-08,\n",
      "       1.7875680e-08, 1.8002613e-08, 1.7819536e-08, 1.8067464e-08,\n",
      "       1.7910645e-08, 1.7934493e-08, 1.7927301e-08, 1.7963727e-08,\n",
      "       1.8036987e-08, 1.7989333e-08, 1.8065593e-08, 1.7799010e-08,\n",
      "       1.8153466e-08, 1.7689633e-08, 1.8112406e-08, 1.7943382e-08,\n",
      "       1.8035815e-08, 1.7158541e-08, 1.7971185e-08, 1.7884970e-08,\n",
      "       1.8015609e-08, 1.7988723e-08, 1.7325243e-08, 1.7971194e-08,\n",
      "       1.7911329e-08, 1.8059902e-08, 1.7877820e-08, 1.7581906e-08,\n",
      "       1.7630507e-08, 1.7995038e-08, 1.7971772e-08, 1.8117152e-08,\n",
      "       1.7925252e-08, 1.7903902e-08, 1.7847011e-08, 1.7941920e-08,\n",
      "       1.7555315e-08, 1.8018845e-08, 1.7887380e-08, 1.7977637e-08,\n",
      "       1.7786148e-08, 1.7766242e-08, 1.7897369e-08, 1.7920893e-08,\n",
      "       1.7821634e-08, 1.8024368e-08, 1.8041405e-08, 1.8051713e-08,\n",
      "       1.8128084e-08, 1.7807841e-08, 1.7920524e-08, 1.7766649e-08,\n",
      "       1.7637255e-08, 1.7341963e-08, 1.7809644e-08, 1.8090642e-08,\n",
      "       1.7873134e-08, 1.8002462e-08, 1.7885846e-08, 1.8079890e-08,\n",
      "       1.7441238e-08, 1.7878659e-08, 1.7822746e-08, 1.7994337e-08,\n",
      "       1.7882686e-08, 1.7682337e-08, 1.7872255e-08, 1.8016546e-08,\n",
      "       1.8049738e-08, 1.8090734e-08, 1.7848933e-08, 1.8108977e-08,\n",
      "       1.7986306e-08, 1.7909985e-08, 1.7868647e-08, 1.7874386e-08,\n",
      "       1.8019843e-08, 1.7541780e-08, 1.7880998e-08, 1.8079536e-08,\n",
      "       1.8040593e-08, 1.7764110e-08, 1.8033839e-08, 1.7949695e-08,\n",
      "       1.8043011e-08, 1.8035308e-08, 1.7844723e-08, 1.7949707e-08,\n",
      "       1.7972445e-08, 1.7984325e-08, 1.8034033e-08, 1.7853925e-08,\n",
      "       1.7884833e-08, 1.8106272e-08, 1.8057072e-08, 1.7950335e-08,\n",
      "       1.8062581e-08, 1.7990775e-08, 1.7501108e-08, 1.7784664e-08,\n",
      "       1.8034719e-08, 1.8080151e-08, 1.7793214e-08, 1.7888272e-08,\n",
      "       1.7807022e-08, 1.7944171e-08, 1.7664345e-08, 1.7955257e-08,\n",
      "       1.8017420e-08, 1.7984368e-08, 1.8074122e-08, 1.7990219e-08,\n",
      "       1.7843751e-08, 1.7939835e-08, 1.8080236e-08, 1.8013051e-08,\n",
      "       1.7607476e-08, 1.7517333e-08, 1.8027681e-08, 1.7861401e-08,\n",
      "       1.7848302e-08, 1.7877278e-08, 1.7619636e-08, 1.7878060e-08,\n",
      "       1.7909894e-08, 1.8128892e-08, 1.8086027e-08, 1.8105061e-08,\n",
      "       1.8140332e-08, 1.8065032e-08, 1.7983874e-08, 1.7811010e-08,\n",
      "       1.8100362e-08, 1.7962146e-08, 1.7663334e-08, 1.7724799e-08,\n",
      "       1.8053505e-08, 1.8060593e-08, 1.7952763e-08, 1.7889352e-08,\n",
      "       1.7963334e-08, 1.7822426e-08, 1.7961161e-08, 1.7818115e-08,\n",
      "       1.7931265e-08, 1.7695870e-08, 1.7789320e-08, 1.8179364e-08,\n",
      "       1.8074122e-08, 1.8034372e-08, 1.7988734e-08, 1.7985975e-08,\n",
      "       1.8053809e-08, 1.7990354e-08, 1.7909963e-08, 1.7793059e-08,\n",
      "       1.7541474e-08, 1.7723480e-08, 1.7867876e-08, 1.7923046e-08,\n",
      "       1.7905579e-08, 1.7936022e-08, 1.8076017e-08, 1.8007171e-08,\n",
      "       1.7902305e-08, 1.7682796e-08, 1.7974260e-08, 1.7974294e-08,\n",
      "       1.8017726e-08, 1.7845210e-08, 1.7944490e-08, 1.7991983e-08,\n",
      "       1.7875248e-08, 1.8008189e-08, 1.7719382e-08, 1.8104812e-08,\n",
      "       1.7816060e-08, 1.7999557e-08, 1.7898419e-08, 1.7977204e-08,\n",
      "       1.7941751e-08, 1.7887174e-08, 1.7851637e-08, 1.8113582e-08,\n",
      "       1.7911576e-08, 1.8051349e-08, 1.7966416e-08, 1.7950683e-08,\n",
      "       1.7683373e-08, 1.7869448e-08, 1.7898362e-08, 1.8033507e-08,\n",
      "       1.8016021e-08, 1.8022181e-08, 1.7846453e-08, 1.7959879e-08,\n",
      "       1.8008720e-08, 1.7903881e-08, 1.8130011e-08, 1.8009532e-08,\n",
      "       1.8126954e-08, 1.7577362e-08, 1.7912335e-08, 1.7934939e-08,\n",
      "       1.7946046e-08, 1.8017552e-08, 1.8056408e-08, 1.8039533e-08,\n",
      "       1.7848036e-08, 1.7960202e-08, 1.7936587e-08, 1.8152020e-08,\n",
      "       1.8054962e-08, 1.7986750e-08, 1.7843448e-08, 1.7493891e-08,\n",
      "       1.8113901e-08, 1.7726700e-08, 1.7965636e-08, 1.7622609e-08,\n",
      "       1.7575809e-08, 1.7882925e-08, 1.7487569e-08, 1.7938724e-08,\n",
      "       1.8021309e-08, 1.7839495e-08, 1.7802479e-08, 1.7853282e-08,\n",
      "       1.7386030e-08, 1.8057888e-08, 1.7988677e-08, 1.7841820e-08,\n",
      "       1.7941392e-08, 1.8047217e-08, 1.7910082e-08, 1.8084204e-08,\n",
      "       1.7905075e-08, 1.7301545e-08, 1.7905084e-08, 1.7653678e-08,\n",
      "       1.8018019e-08, 1.7625219e-08, 1.7800696e-08, 1.7926283e-08,\n",
      "       1.7847007e-08, 1.7969596e-08, 1.7909745e-08, 1.8021204e-08,\n",
      "       1.7779698e-08, 1.7386466e-08, 1.7912559e-08, 1.7974088e-08,\n",
      "       1.7888173e-08, 1.8013850e-08, 1.7942922e-08, 1.7988702e-08,\n",
      "       1.8108107e-08, 1.8056575e-08, 1.7721119e-08, 1.7924888e-08,\n",
      "       1.7486107e-08, 1.7764261e-08, 1.7729953e-08, 1.7763787e-08,\n",
      "       1.7981282e-08, 1.7779117e-08, 1.7979209e-08, 1.7819790e-08,\n",
      "       1.8044235e-08, 1.7925553e-08, 1.7181181e-08, 1.8091093e-08,\n",
      "       1.8079417e-08, 1.7979206e-08, 1.8101490e-08, 1.7933132e-08,\n",
      "       1.7898545e-08, 1.7834139e-08, 1.7788638e-08, 1.7900341e-08,\n",
      "       1.8059087e-08, 1.7919342e-08, 1.7878238e-08, 1.7463206e-08,\n",
      "       1.7903790e-08, 1.7886975e-08, 1.7652026e-08, 1.8008194e-08,\n",
      "       1.8061312e-08, 1.7954077e-08, 1.8000586e-08, 1.7988940e-08,\n",
      "       1.7990423e-08, 1.7972985e-08, 1.7852836e-08, 1.7986395e-08,\n",
      "       1.7674616e-08, 1.7882300e-08, 1.7677845e-08, 1.7923337e-08,\n",
      "       1.7370143e-08, 1.8088494e-08, 1.8035799e-08, 1.7912370e-08,\n",
      "       1.7713068e-08, 1.7805238e-08, 1.7968254e-08, 1.7960117e-08,\n",
      "       1.7928430e-08, 1.7618227e-08, 1.7856369e-08, 1.7938151e-08,\n",
      "       1.8023298e-08, 1.7942996e-08, 1.7759103e-08, 1.7878705e-08,\n",
      "       1.7848230e-08, 1.7855633e-08, 1.7453736e-08, 1.7960391e-08,\n",
      "       1.8054752e-08, 1.7928125e-08, 1.8064009e-08, 1.7963227e-08,\n",
      "       1.7883902e-08, 1.8113790e-08, 1.7782190e-08, 1.7802874e-08,\n",
      "       1.7831121e-08, 1.8082664e-08, 1.8094992e-08, 1.7911423e-08,\n",
      "       1.7857763e-08, 1.8002495e-08, 1.8005384e-08, 1.7950127e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D\n",
      "index : 92\n",
      "shape : [ 80   1   1 480]\n",
      "shape_signature : [ 80   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00088159, 0.00087897, 0.00088491, 0.00087324, 0.00088062,\n",
      "       0.00088024, 0.00088232, 0.00088423, 0.00088761, 0.00087638,\n",
      "       0.00087426, 0.00088441, 0.00088701, 0.00088205, 0.00087158,\n",
      "       0.00087938, 0.00088227, 0.00088344, 0.00088031, 0.00087494,\n",
      "       0.0008736 , 0.00088684, 0.00088045, 0.00088106, 0.00088435,\n",
      "       0.00087991, 0.00088312, 0.00088309, 0.00087884, 0.00088033,\n",
      "       0.00088782, 0.00088436, 0.00087998, 0.0008888 , 0.00088494,\n",
      "       0.00088046, 0.00087402, 0.00088561, 0.00088612, 0.00088079,\n",
      "       0.00088385, 0.0008829 , 0.00087851, 0.0008813 , 0.00087514,\n",
      "       0.00088139, 0.00088596, 0.00088308, 0.00088243, 0.00088361,\n",
      "       0.00088515, 0.00087674, 0.0008846 , 0.00087991, 0.00087656,\n",
      "       0.00087445, 0.00088501, 0.00087894, 0.00087247, 0.00087654,\n",
      "       0.00087931, 0.00088299, 0.00088474, 0.00087879, 0.00087677,\n",
      "       0.00088342, 0.00087754, 0.00088108, 0.00087969, 0.00088071,\n",
      "       0.00088289, 0.00088543, 0.00088782, 0.00087893, 0.00087868,\n",
      "       0.00088348, 0.00088443, 0.00087998, 0.00088265, 0.00088492],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_24/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D\n",
      "index : 93\n",
      "shape : [80]\n",
      "shape_signature : [80]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.5685040e-09, 7.5459816e-09, 7.5970075e-09, 7.4968129e-09,\n",
      "       7.5601978e-09, 7.5568964e-09, 7.5748083e-09, 7.5911757e-09,\n",
      "       7.6202120e-09, 7.5238011e-09, 7.5055633e-09, 7.5927620e-09,\n",
      "       7.6150073e-09, 7.5724333e-09, 7.4825435e-09, 7.5495379e-09,\n",
      "       7.5743083e-09, 7.5844007e-09, 7.5575146e-09, 7.5113835e-09,\n",
      "       7.4999011e-09, 7.6135951e-09, 7.5587403e-09, 7.5639743e-09,\n",
      "       7.5922229e-09, 7.5540658e-09, 7.5816811e-09, 7.5813578e-09,\n",
      "       7.5449318e-09, 7.5576940e-09, 7.6220275e-09, 7.5923126e-09,\n",
      "       7.5546867e-09, 7.6303994e-09, 7.5972553e-09, 7.5588176e-09,\n",
      "       7.5035613e-09, 7.6030044e-09, 7.6074000e-09, 7.5616073e-09,\n",
      "       7.5879028e-09, 7.5797173e-09, 7.5420550e-09, 7.5659825e-09,\n",
      "       7.5131386e-09, 7.5667623e-09, 7.6059914e-09, 7.5813054e-09,\n",
      "       7.5757267e-09, 7.5858875e-09, 7.5990947e-09, 7.5268494e-09,\n",
      "       7.5943412e-09, 7.5540942e-09, 7.5253039e-09, 7.5072233e-09,\n",
      "       7.5978965e-09, 7.5457800e-09, 7.4902156e-09, 7.5251831e-09,\n",
      "       7.5489179e-09, 7.5805371e-09, 7.5955660e-09, 7.5445010e-09,\n",
      "       7.5271060e-09, 7.5842399e-09, 7.5336999e-09, 7.5641715e-09,\n",
      "       7.5521784e-09, 7.5609945e-09, 7.5796338e-09, 7.6014617e-09,\n",
      "       7.6219839e-09, 7.5456672e-09, 7.5435267e-09, 7.5847639e-09,\n",
      "       7.5928934e-09, 7.5546795e-09, 7.5775812e-09, 7.5970714e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_1/conv2d_66/Conv2D\n",
      "index : 94\n",
      "shape : [64  1  1 80]\n",
      "shape_signature : [64  1  1 80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00128686, 0.00133042, 0.00136213, 0.00132638, 0.00124348,\n",
      "       0.00128981, 0.00130344, 0.00128544, 0.00128138, 0.0012889 ,\n",
      "       0.00130985, 0.0013194 , 0.00129609, 0.0012983 , 0.00135153,\n",
      "       0.00127615, 0.00136337, 0.00134451, 0.00118586, 0.00138265,\n",
      "       0.00140868, 0.00128302, 0.00127529, 0.00118723, 0.00136494,\n",
      "       0.00132217, 0.00130487, 0.00135247, 0.00131329, 0.00133124,\n",
      "       0.00133748, 0.00132863, 0.00137326, 0.0013601 , 0.00135702,\n",
      "       0.00134366, 0.00133693, 0.00123014, 0.00134128, 0.00142611,\n",
      "       0.00133291, 0.00138223, 0.00120449, 0.00136505, 0.00137106,\n",
      "       0.00127335, 0.00132808, 0.00127739, 0.00135845, 0.0013545 ,\n",
      "       0.00128444, 0.00128038, 0.00123907, 0.00127799, 0.00123419,\n",
      "       0.00135019, 0.00126401, 0.00136133, 0.0013275 , 0.00140569,\n",
      "       0.00133402, 0.00136853, 0.00131271, 0.00129496], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_1/batch_normalization_50/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_1/conv2d_66/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_1/conv2d_66/BiasAdd\n",
      "index : 95\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.1158598e-07, 3.2213296e-07, 3.2981029e-07, 3.2115369e-07,\n",
      "       3.0108257e-07, 3.1230104e-07, 3.1559946e-07, 3.1124273e-07,\n",
      "       3.1025996e-07, 3.1207983e-07, 3.1715288e-07, 3.1946527e-07,\n",
      "       3.1382007e-07, 3.1435533e-07, 3.2724344e-07, 3.0899338e-07,\n",
      "       3.3011099e-07, 3.2554354e-07, 2.8713083e-07, 3.3477846e-07,\n",
      "       3.4108075e-07, 3.1065704e-07, 3.0878428e-07, 2.8746260e-07,\n",
      "       3.3049207e-07, 3.2013577e-07, 3.1594530e-07, 3.2747204e-07,\n",
      "       3.1798402e-07, 3.2233123e-07, 3.2384165e-07, 3.2169814e-07,\n",
      "       3.3250436e-07, 3.2932033e-07, 3.2857395e-07, 3.2533811e-07,\n",
      "       3.2370954e-07, 2.9785249e-07, 3.2476112e-07, 3.4530228e-07,\n",
      "       3.2273678e-07, 3.3467720e-07, 2.9164201e-07, 3.3051859e-07,\n",
      "       3.3197202e-07, 3.0831453e-07, 3.2156564e-07, 3.0929257e-07,\n",
      "       3.2891862e-07, 3.2796214e-07, 3.1099859e-07, 3.1001619e-07,\n",
      "       3.0001445e-07, 3.0943838e-07, 2.9883338e-07, 3.2692051e-07,\n",
      "       3.0605287e-07, 3.2961719e-07, 3.2142577e-07, 3.4035719e-07,\n",
      "       3.2300528e-07, 3.3136035e-07, 3.1784359e-07, 3.1354577e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/strided_slice\n",
      "index : 96\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001958615379408002, -128)\n",
      "quantization_parameters : {'scales': array([0.00195862], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/strided_slice\n",
      "index : 97\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013093743473291397, -128)\n",
      "quantization_parameters : {'scales': array([0.00130937], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/conv2d_33/Conv2D\n",
      "index : 98\n",
      "shape : [480   1   1  80]\n",
      "shape_signature : [480   1   1  80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00079731, 0.00081798, 0.00080235, 0.00080494, 0.00080521,\n",
      "       0.00082272, 0.00082454, 0.00081173, 0.00082266, 0.00078789,\n",
      "       0.00080938, 0.00080678, 0.00079873, 0.00080521, 0.00081209,\n",
      "       0.00082239, 0.0008029 , 0.00079935, 0.00082134, 0.00080434,\n",
      "       0.00076406, 0.00081898, 0.00082207, 0.00079922, 0.00081375,\n",
      "       0.000812  , 0.00080648, 0.00080771, 0.00082089, 0.00082037,\n",
      "       0.0007759 , 0.00080718, 0.00079453, 0.0007986 , 0.00079551,\n",
      "       0.00080384, 0.00080653, 0.00081621, 0.00082024, 0.00082157,\n",
      "       0.00082186, 0.00076029, 0.00078811, 0.00080566, 0.00080983,\n",
      "       0.0007905 , 0.00082538, 0.00081106, 0.0008383 , 0.00079274,\n",
      "       0.00079098, 0.00081383, 0.00079577, 0.00079539, 0.00080071,\n",
      "       0.00081604, 0.00080065, 0.00080522, 0.00079412, 0.00080955,\n",
      "       0.00081324, 0.00080387, 0.00080122, 0.00079779, 0.00079989,\n",
      "       0.00081636, 0.00081901, 0.00079915, 0.00082501, 0.00080819,\n",
      "       0.00080979, 0.0008072 , 0.00079576, 0.00077499, 0.00080705,\n",
      "       0.0008181 , 0.0007666 , 0.00081957, 0.00082236, 0.00081672,\n",
      "       0.00081254, 0.00080585, 0.00080709, 0.00081776, 0.00078842,\n",
      "       0.00078165, 0.00081435, 0.00081796, 0.0008237 , 0.00080128,\n",
      "       0.00080238, 0.00081015, 0.00080773, 0.00081323, 0.00081575,\n",
      "       0.0008057 , 0.00080264, 0.00081754, 0.00077962, 0.00080488,\n",
      "       0.00082912, 0.00081775, 0.00080835, 0.00076251, 0.00080676,\n",
      "       0.00080039, 0.00077953, 0.0008115 , 0.00080605, 0.00083477,\n",
      "       0.00080739, 0.00080523, 0.00083087, 0.00076542, 0.00082507,\n",
      "       0.00080362, 0.00077867, 0.00080527, 0.00082281, 0.00080838,\n",
      "       0.00077147, 0.00080767, 0.0008176 , 0.00078352, 0.00078591,\n",
      "       0.00080144, 0.000799  , 0.00081671, 0.00080865, 0.0008087 ,\n",
      "       0.00081183, 0.00082904, 0.00079662, 0.00081891, 0.00082738,\n",
      "       0.00081863, 0.0007914 , 0.00081419, 0.00081403, 0.00079174,\n",
      "       0.00079447, 0.00080574, 0.00080243, 0.00081384, 0.00081043,\n",
      "       0.00082161, 0.00082651, 0.0008271 , 0.00081989, 0.00083676,\n",
      "       0.00080855, 0.00080464, 0.00080664, 0.00079519, 0.00079578,\n",
      "       0.00080886, 0.00080167, 0.00079939, 0.000807  , 0.00081084,\n",
      "       0.00079331, 0.00080093, 0.00081533, 0.00080256, 0.00082254,\n",
      "       0.00080116, 0.00080381, 0.0008028 , 0.0007997 , 0.00079328,\n",
      "       0.0008084 , 0.00081156, 0.00081445, 0.000804  , 0.00081969,\n",
      "       0.00078369, 0.00080963, 0.00080558, 0.0008017 , 0.00080908,\n",
      "       0.00081498, 0.0007933 , 0.000805  , 0.00082254, 0.00080555,\n",
      "       0.00077725, 0.00079335, 0.00079767, 0.00079897, 0.00076692,\n",
      "       0.00080231, 0.00081766, 0.00079101, 0.00081547, 0.00079878,\n",
      "       0.00080614, 0.0008094 , 0.00080854, 0.00081877, 0.00082393,\n",
      "       0.00077757, 0.00079589, 0.00079892, 0.00081429, 0.00080628,\n",
      "       0.00081947, 0.00080627, 0.00079559, 0.00082516, 0.00081106,\n",
      "       0.00078636, 0.00081179, 0.00080743, 0.0008265 , 0.00082046,\n",
      "       0.00079074, 0.00080154, 0.00078144, 0.0008114 , 0.00082356,\n",
      "       0.00081537, 0.0008073 , 0.00083344, 0.00081181, 0.00081289,\n",
      "       0.00081889, 0.00080633, 0.00080219, 0.00080652, 0.00076709,\n",
      "       0.00082519, 0.00080884, 0.00082079, 0.00080978, 0.00081658,\n",
      "       0.00080369, 0.00081582, 0.00080698, 0.000806  , 0.00078685,\n",
      "       0.00078977, 0.00078595, 0.00081625, 0.00081917, 0.000794  ,\n",
      "       0.00077827, 0.0008084 , 0.00077919, 0.00082372, 0.00080176,\n",
      "       0.0008376 , 0.00079798, 0.00081545, 0.00079707, 0.00082725,\n",
      "       0.00080522, 0.00082878, 0.00080878, 0.00081463, 0.00082441,\n",
      "       0.00081119, 0.0008216 , 0.00079762, 0.00080975, 0.00077527,\n",
      "       0.00081469, 0.00079737, 0.00080459, 0.00081306, 0.00080297,\n",
      "       0.00081741, 0.00080769, 0.00080951, 0.00082507, 0.00082106,\n",
      "       0.00077053, 0.00082227, 0.00080502, 0.00081278, 0.00082185,\n",
      "       0.00082172, 0.00078952, 0.00078035, 0.00082056, 0.0008212 ,\n",
      "       0.00081586, 0.00082111, 0.0008084 , 0.0008127 , 0.00079654,\n",
      "       0.00081012, 0.00080403, 0.00080524, 0.00081518, 0.00083208,\n",
      "       0.00081716, 0.00080284, 0.00081909, 0.00079681, 0.00081668,\n",
      "       0.00081022, 0.00080326, 0.00081172, 0.00081287, 0.00080108,\n",
      "       0.00078538, 0.00081078, 0.00081642, 0.00080926, 0.00083698,\n",
      "       0.00082048, 0.00082015, 0.00079585, 0.00078543, 0.00080995,\n",
      "       0.00079661, 0.00080557, 0.00081406, 0.00082627, 0.00079341,\n",
      "       0.00080382, 0.00081547, 0.00081425, 0.000784  , 0.000807  ,\n",
      "       0.00081182, 0.00079993, 0.0008019 , 0.00081108, 0.00082191,\n",
      "       0.00080757, 0.00080604, 0.00079668, 0.00081673, 0.00079991,\n",
      "       0.00079086, 0.0008122 , 0.00082115, 0.00081208, 0.00082506,\n",
      "       0.0008006 , 0.00080228, 0.0008288 , 0.00079306, 0.00077045,\n",
      "       0.00076335, 0.00078285, 0.00080532, 0.00080507, 0.00081194,\n",
      "       0.00079022, 0.00081072, 0.0008316 , 0.00083074, 0.00081133,\n",
      "       0.0008023 , 0.00080341, 0.00081456, 0.00081825, 0.00081642,\n",
      "       0.00080987, 0.00080461, 0.00078465, 0.0008204 , 0.00080205,\n",
      "       0.00080741, 0.00078612, 0.00082642, 0.00080755, 0.0008154 ,\n",
      "       0.00082551, 0.000797  , 0.00082027, 0.00080511, 0.0008098 ,\n",
      "       0.00081527, 0.00078328, 0.00081759, 0.00081935, 0.00081255,\n",
      "       0.00080275, 0.00080202, 0.00081348, 0.00080371, 0.00081132,\n",
      "       0.00078856, 0.00081224, 0.00081544, 0.00081394, 0.00080502,\n",
      "       0.00081822, 0.0007989 , 0.00081803, 0.00076914, 0.00082157,\n",
      "       0.00081314, 0.00081257, 0.0008004 , 0.00080902, 0.00077374,\n",
      "       0.00080139, 0.00081397, 0.00080652, 0.00081345, 0.00081308,\n",
      "       0.0008293 , 0.00081895, 0.00079684, 0.00081088, 0.00079424,\n",
      "       0.00078905, 0.00080139, 0.00081149, 0.00081099, 0.00082603,\n",
      "       0.0008199 , 0.00081127, 0.00081819, 0.00079425, 0.00079026,\n",
      "       0.00080932, 0.00080936, 0.00080188, 0.00081676, 0.00080119,\n",
      "       0.00078813, 0.00081975, 0.00080695, 0.00082783, 0.00079691,\n",
      "       0.00081206, 0.00080145, 0.00081484, 0.00081968, 0.00081091,\n",
      "       0.00082018, 0.00078017, 0.00081989, 0.00081   , 0.00082455,\n",
      "       0.00081699, 0.00081062, 0.00081887, 0.00081802, 0.0007956 ,\n",
      "       0.00080575, 0.00080437, 0.00081844, 0.00080644, 0.00079886,\n",
      "       0.00080985, 0.00080776, 0.00081411, 0.00082519, 0.00082639,\n",
      "       0.00079526, 0.00080186, 0.00081382, 0.00082207, 0.00081673,\n",
      "       0.00081193, 0.00078764, 0.00080627, 0.0008237 , 0.00080339,\n",
      "       0.00082036, 0.00081563, 0.00081406, 0.00080769, 0.00081576,\n",
      "       0.00080472, 0.00081873, 0.00082041, 0.00081829, 0.00079316,\n",
      "       0.00076434, 0.00082029, 0.00081352, 0.00080594, 0.00080204],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_25/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/conv2d_33/Conv2D\n",
      "index : 99\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.9305206e-07, 1.9805674e-07, 1.9427301e-07, 1.9489916e-07,\n",
      "       1.9496488e-07, 1.9920290e-07, 1.9964500e-07, 1.9654257e-07,\n",
      "       1.9919051e-07, 1.9077137e-07, 1.9597408e-07, 1.9534491e-07,\n",
      "       1.9339519e-07, 1.9496343e-07, 1.9663064e-07, 1.9912302e-07,\n",
      "       1.9440516e-07, 1.9354644e-07, 1.9886909e-07, 1.9475269e-07,\n",
      "       1.8500009e-07, 1.9829935e-07, 1.9904671e-07, 1.9351413e-07,\n",
      "       1.9703313e-07, 1.9660752e-07, 1.9527205e-07, 1.9556902e-07,\n",
      "       1.9876217e-07, 1.9863590e-07, 1.8786682e-07, 1.9544019e-07,\n",
      "       1.9237737e-07, 1.9336349e-07, 1.9261465e-07, 1.9463239e-07,\n",
      "       1.9528433e-07, 1.9762891e-07, 1.9860245e-07, 1.9892620e-07,\n",
      "       1.9899636e-07, 1.8408684e-07, 1.9082441e-07, 1.9507289e-07,\n",
      "       1.9608338e-07, 1.9140357e-07, 1.9984783e-07, 1.9638138e-07,\n",
      "       2.0297642e-07, 1.9194603e-07, 1.9151815e-07, 1.9705227e-07,\n",
      "       1.9267803e-07, 1.9258567e-07, 1.9387576e-07, 1.9758656e-07,\n",
      "       1.9385971e-07, 1.9496726e-07, 1.9227829e-07, 1.9601468e-07,\n",
      "       1.9690913e-07, 1.9463938e-07, 1.9399796e-07, 1.9316737e-07,\n",
      "       1.9367543e-07, 1.9766331e-07, 1.9830675e-07, 1.9349712e-07,\n",
      "       1.9975845e-07, 1.9568635e-07, 1.9607329e-07, 1.9544531e-07,\n",
      "       1.9267513e-07, 1.8764841e-07, 1.9540981e-07, 1.9808527e-07,\n",
      "       1.8561538e-07, 1.9844103e-07, 1.9911612e-07, 1.9775221e-07,\n",
      "       1.9673934e-07, 1.9511954e-07, 1.9541905e-07, 1.9800311e-07,\n",
      "       1.9089991e-07, 1.8925910e-07, 1.9717760e-07, 1.9805209e-07,\n",
      "       1.9944078e-07, 1.9401175e-07, 1.9428018e-07, 1.9616083e-07,\n",
      "       1.9557532e-07, 1.9690603e-07, 1.9751651e-07, 1.9508279e-07,\n",
      "       1.9434221e-07, 1.9795070e-07, 1.8876898e-07, 1.9488539e-07,\n",
      "       2.0075420e-07, 1.9800082e-07, 1.9572414e-07, 1.8462612e-07,\n",
      "       1.9534015e-07, 1.9379775e-07, 1.8874745e-07, 1.9648692e-07,\n",
      "       1.9516781e-07, 2.0212177e-07, 1.9549199e-07, 1.9496996e-07,\n",
      "       2.0117812e-07, 1.8532918e-07, 1.9977317e-07, 1.9457961e-07,\n",
      "       1.8853761e-07, 1.9497993e-07, 1.9922642e-07, 1.9573177e-07,\n",
      "       1.8679592e-07, 1.9555910e-07, 1.9796420e-07, 1.8971295e-07,\n",
      "       1.9029224e-07, 1.9405161e-07, 1.9345994e-07, 1.9775004e-07,\n",
      "       1.9579848e-07, 1.9580870e-07, 1.9656839e-07, 2.0073453e-07,\n",
      "       1.9288390e-07, 1.9828103e-07, 2.0033244e-07, 1.9821321e-07,\n",
      "       1.9162100e-07, 1.9713791e-07, 1.9709950e-07, 1.9170294e-07,\n",
      "       1.9236359e-07, 1.9509187e-07, 1.9429088e-07, 1.9705378e-07,\n",
      "       1.9622786e-07, 1.9893552e-07, 2.0012062e-07, 2.0026468e-07,\n",
      "       1.9851905e-07, 2.0260245e-07, 1.9577396e-07, 1.9482673e-07,\n",
      "       1.9531065e-07, 1.9253922e-07, 1.9268141e-07, 1.9584749e-07,\n",
      "       1.9410764e-07, 1.9355519e-07, 1.9539733e-07, 1.9632751e-07,\n",
      "       1.9208294e-07, 1.9392829e-07, 1.9741533e-07, 1.9432193e-07,\n",
      "       1.9915930e-07, 1.9398333e-07, 1.9462614e-07, 1.9438184e-07,\n",
      "       1.9362960e-07, 1.9207482e-07, 1.9573713e-07, 1.9650085e-07,\n",
      "       1.9720275e-07, 1.9467080e-07, 1.9846972e-07, 1.8975398e-07,\n",
      "       1.9603354e-07, 1.9505443e-07, 1.9411497e-07, 1.9590237e-07,\n",
      "       1.9732919e-07, 1.9208079e-07, 1.9491327e-07, 1.9916102e-07,\n",
      "       1.9504753e-07, 1.8819520e-07, 1.9209249e-07, 1.9313944e-07,\n",
      "       1.9345380e-07, 1.8569322e-07, 1.9426267e-07, 1.9797893e-07,\n",
      "       1.9152719e-07, 1.9744766e-07, 1.9340726e-07, 1.9518957e-07,\n",
      "       1.9597772e-07, 1.9577094e-07, 1.9824788e-07, 1.9949697e-07,\n",
      "       1.8827075e-07, 1.9270659e-07, 1.9344240e-07, 1.9716235e-07,\n",
      "       1.9522231e-07, 1.9841622e-07, 1.9522075e-07, 1.9263618e-07,\n",
      "       1.9979522e-07, 1.9638195e-07, 1.9039994e-07, 1.9655640e-07,\n",
      "       1.9550257e-07, 2.0011980e-07, 1.9865568e-07, 1.9146066e-07,\n",
      "       1.9407460e-07, 1.8920962e-07, 1.9646269e-07, 1.9940762e-07,\n",
      "       1.9742539e-07, 1.9546989e-07, 2.0180052e-07, 1.9656258e-07,\n",
      "       1.9682453e-07, 1.9827603e-07, 1.9523560e-07, 1.9423383e-07,\n",
      "       1.9528136e-07, 1.8573392e-07, 1.9980310e-07, 1.9584363e-07,\n",
      "       1.9873639e-07, 1.9607059e-07, 1.9771711e-07, 1.9459578e-07,\n",
      "       1.9753338e-07, 1.9539387e-07, 1.9515684e-07, 1.9051804e-07,\n",
      "       1.9122641e-07, 1.9030128e-07, 1.9763743e-07, 1.9834539e-07,\n",
      "       1.9224895e-07, 1.8844246e-07, 1.9573589e-07, 1.8866537e-07,\n",
      "       1.9944706e-07, 1.9412924e-07, 2.0280646e-07, 1.9321348e-07,\n",
      "       1.9744465e-07, 1.9299370e-07, 2.0030085e-07, 1.9496598e-07,\n",
      "       2.0067202e-07, 1.9582880e-07, 1.9724583e-07, 1.9961348e-07,\n",
      "       1.9641152e-07, 1.9893329e-07, 1.9312651e-07, 1.9606382e-07,\n",
      "       1.8771594e-07, 1.9726075e-07, 1.9306719e-07, 1.9481452e-07,\n",
      "       1.9686578e-07, 1.9442190e-07, 1.9791952e-07, 1.9556551e-07,\n",
      "       1.9600617e-07, 1.9977232e-07, 1.9880252e-07, 1.8656857e-07,\n",
      "       1.9909628e-07, 1.9491875e-07, 1.9679648e-07, 1.9899410e-07,\n",
      "       1.9896237e-07, 1.9116652e-07, 1.8894460e-07, 1.9868224e-07,\n",
      "       1.9883701e-07, 1.9754248e-07, 1.9881544e-07, 1.9573682e-07,\n",
      "       1.9677888e-07, 1.9286536e-07, 1.9615216e-07, 1.9467871e-07,\n",
      "       1.9497092e-07, 1.9737790e-07, 2.0147010e-07, 1.9785895e-07,\n",
      "       1.9439099e-07, 1.9832400e-07, 1.9293127e-07, 1.9774124e-07,\n",
      "       1.9617681e-07, 1.9449230e-07, 1.9654063e-07, 1.9681902e-07,\n",
      "       1.9396424e-07, 1.9016197e-07, 1.9631423e-07, 1.9767917e-07,\n",
      "       1.9594518e-07, 2.0265753e-07, 1.9866246e-07, 1.9858282e-07,\n",
      "       1.9269731e-07, 1.9017517e-07, 1.9611275e-07, 1.9288153e-07,\n",
      "       1.9505239e-07, 1.9710843e-07, 2.0006452e-07, 1.9210833e-07,\n",
      "       1.9462836e-07, 1.9744957e-07, 1.9715435e-07, 1.8982904e-07,\n",
      "       1.9539900e-07, 1.9656459e-07, 1.9368521e-07, 1.9416187e-07,\n",
      "       1.9638610e-07, 1.9900871e-07, 1.9553558e-07, 1.9516635e-07,\n",
      "       1.9289928e-07, 1.9775347e-07, 1.9368044e-07, 1.9149101e-07,\n",
      "       1.9665752e-07, 1.9882496e-07, 1.9662900e-07, 1.9976986e-07,\n",
      "       1.9384879e-07, 1.9425389e-07, 2.0067702e-07, 1.9202260e-07,\n",
      "       1.8654885e-07, 1.8482865e-07, 1.8955083e-07, 1.9499181e-07,\n",
      "       1.9492990e-07, 1.9659345e-07, 1.9133606e-07, 1.9629914e-07,\n",
      "       2.0135437e-07, 2.0114614e-07, 1.9644651e-07, 1.9425997e-07,\n",
      "       1.9452766e-07, 1.9722863e-07, 1.9812188e-07, 1.9767792e-07,\n",
      "       1.9609280e-07, 1.9481905e-07, 1.8998669e-07, 1.9864352e-07,\n",
      "       1.9419889e-07, 1.9549680e-07, 1.9034222e-07, 2.0009972e-07,\n",
      "       1.9553123e-07, 1.9743175e-07, 1.9987935e-07, 1.9297697e-07,\n",
      "       1.9861066e-07, 1.9493966e-07, 1.9607515e-07, 1.9740055e-07,\n",
      "       1.8965353e-07, 1.9796174e-07, 1.9838872e-07, 1.9674268e-07,\n",
      "       1.9436841e-07, 1.9419284e-07, 1.9696564e-07, 1.9460018e-07,\n",
      "       1.9644327e-07, 1.9093228e-07, 1.9666719e-07, 1.9744149e-07,\n",
      "       1.9707718e-07, 1.9491863e-07, 1.9811361e-07, 1.9343662e-07,\n",
      "       1.9806959e-07, 1.8623105e-07, 1.9892627e-07, 1.9688483e-07,\n",
      "       1.9674633e-07, 1.9379910e-07, 1.9588795e-07, 1.8734417e-07,\n",
      "       1.9403898e-07, 1.9708531e-07, 1.9528245e-07, 1.9696003e-07,\n",
      "       1.9686888e-07, 2.0079641e-07, 1.9829125e-07, 1.9293833e-07,\n",
      "       1.9633769e-07, 1.9230843e-07, 1.9105138e-07, 1.9403856e-07,\n",
      "       1.9648472e-07, 1.9636313e-07, 2.0000593e-07, 1.9852244e-07,\n",
      "       1.9643177e-07, 1.9810676e-07, 1.9230991e-07, 1.9134437e-07,\n",
      "       1.9595933e-07, 1.9596990e-07, 1.9415916e-07, 1.9776047e-07,\n",
      "       1.9399090e-07, 1.9082840e-07, 1.9848490e-07, 1.9538545e-07,\n",
      "       2.0044078e-07, 1.9295423e-07, 1.9662245e-07, 1.9405439e-07,\n",
      "       1.9729721e-07, 1.9846848e-07, 1.9634331e-07, 1.9858925e-07,\n",
      "       1.8890051e-07, 1.9851917e-07, 1.9612335e-07, 1.9964781e-07,\n",
      "       1.9781629e-07, 1.9627485e-07, 1.9827215e-07, 1.9806620e-07,\n",
      "       1.9263827e-07, 1.9509601e-07, 1.9476099e-07, 1.9816770e-07,\n",
      "       1.9526213e-07, 1.9342750e-07, 1.9608905e-07, 1.9558297e-07,\n",
      "       1.9711923e-07, 1.9980131e-07, 2.0009189e-07, 1.9255546e-07,\n",
      "       1.9415418e-07, 1.9704903e-07, 1.9904704e-07, 1.9775457e-07,\n",
      "       1.9659105e-07, 1.9071136e-07, 1.9522152e-07, 1.9944142e-07,\n",
      "       1.9452472e-07, 1.9863315e-07, 1.9748784e-07, 1.9710610e-07,\n",
      "       1.9556514e-07, 1.9751849e-07, 1.9484585e-07, 1.9823717e-07,\n",
      "       1.9864405e-07, 1.9813027e-07, 1.9204657e-07, 1.8506763e-07,\n",
      "       1.9861653e-07, 1.9697744e-07, 1.9514140e-07, 1.9419605e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_26/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/depthwise_conv2d_8/depthwise;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D\n",
      "index : 100\n",
      "shape : [  1   5   5 480]\n",
      "shape_signature : [  1   5   5 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00018884, 0.00018736, 0.00018313, 0.0001877 , 0.00018295,\n",
      "       0.00018199, 0.00018727, 0.00019053, 0.00018808, 0.0001869 ,\n",
      "       0.00019114, 0.00019481, 0.00018076, 0.00018364, 0.0001745 ,\n",
      "       0.00018069, 0.00017546, 0.00019603, 0.00019043, 0.00018904,\n",
      "       0.00019224, 0.00018577, 0.00018591, 0.00019417, 0.00017204,\n",
      "       0.00018502, 0.00018282, 0.00018859, 0.00018857, 0.00018874,\n",
      "       0.00016331, 0.0001885 , 0.0001766 , 0.00016177, 0.0001788 ,\n",
      "       0.00019332, 0.00018209, 0.00019493, 0.00018473, 0.00018532,\n",
      "       0.00018276, 0.00018528, 0.00019138, 0.00018376, 0.00018208,\n",
      "       0.00019348, 0.00018881, 0.00019492, 0.00019377, 0.00018895,\n",
      "       0.000186  , 0.00018914, 0.00018757, 0.00019557, 0.00018689,\n",
      "       0.0001737 , 0.00018432, 0.00018752, 0.00019593, 0.00018021,\n",
      "       0.00018455, 0.00019219, 0.00014424, 0.00016689, 0.00018231,\n",
      "       0.00018442, 0.00018479, 0.00018833, 0.00018268, 0.00015266,\n",
      "       0.0001917 , 0.00018638, 0.00017881, 0.00019383, 0.00019167,\n",
      "       0.0001893 , 0.00018506, 0.00017936, 0.00018587, 0.00016873,\n",
      "       0.00019155, 0.00017743, 0.0001913 , 0.00019508, 0.00016721,\n",
      "       0.00018814, 0.0001941 , 0.0001874 , 0.00019406, 0.00018563,\n",
      "       0.00017568, 0.00019202, 0.0001813 , 0.00018823, 0.0001875 ,\n",
      "       0.00018583, 0.00019298, 0.00018757, 0.0001952 , 0.00018775,\n",
      "       0.00018965, 0.00018911, 0.00018775, 0.00018611, 0.00019311,\n",
      "       0.00017657, 0.0001902 , 0.00018544, 0.00019118, 0.00018733,\n",
      "       0.00019606, 0.00019895, 0.00018215, 0.00019115, 0.00019237,\n",
      "       0.00018344, 0.00017777, 0.00019032, 0.00018428, 0.00019233,\n",
      "       0.00018309, 0.00017885, 0.00018881, 0.0001669 , 0.00019184,\n",
      "       0.00018698, 0.00017775, 0.00017659, 0.00016045, 0.00017276,\n",
      "       0.00018355, 0.0001876 , 0.00018327, 0.00015436, 0.00019465,\n",
      "       0.00018613, 0.00018515, 0.00019626, 0.00017606, 0.00016047,\n",
      "       0.00019448, 0.00017809, 0.00019639, 0.00018365, 0.00017669,\n",
      "       0.00017268, 0.00019309, 0.00019087, 0.00019428, 0.00018477,\n",
      "       0.00019369, 0.00019327, 0.00018808, 0.00019483, 0.00019128,\n",
      "       0.0001852 , 0.00019306, 0.00018753, 0.00019387, 0.00019293,\n",
      "       0.00018323, 0.00016357, 0.00018424, 0.00019166, 0.00018292,\n",
      "       0.00018668, 0.00018966, 0.00018278, 0.00017809, 0.00019032,\n",
      "       0.00019231, 0.00017336, 0.00018331, 0.00019258, 0.00017922,\n",
      "       0.00018582, 0.00018605, 0.00018303, 0.00018962, 0.00019197,\n",
      "       0.000189  , 0.00017943, 0.00018398, 0.00018325, 0.00018004,\n",
      "       0.00018952, 0.00015424, 0.00018917, 0.00018658, 0.00018694,\n",
      "       0.00018353, 0.0001749 , 0.00018689, 0.00018739, 0.00018801,\n",
      "       0.00018558, 0.00019116, 0.00017776, 0.00017921, 0.00018036,\n",
      "       0.00019276, 0.00017385, 0.00019222, 0.00019204, 0.00019047,\n",
      "       0.00019204, 0.00018728, 0.00017687, 0.00019062, 0.00018639,\n",
      "       0.00018885, 0.00017764, 0.00018833, 0.0001868 , 0.00017845,\n",
      "       0.00017366, 0.00018771, 0.00019233, 0.00019094, 0.00017446,\n",
      "       0.00018597, 0.00018728, 0.0001898 , 0.0001953 , 0.00018852,\n",
      "       0.00019156, 0.00018481, 0.00019509, 0.00018113, 0.00018318,\n",
      "       0.00018408, 0.00017653, 0.00019442, 0.00018116, 0.00018613,\n",
      "       0.0001895 , 0.0001932 , 0.00018622, 0.00018453, 0.0001851 ,\n",
      "       0.00018247, 0.00017043, 0.00018876, 0.00019569, 0.00019273,\n",
      "       0.00019067, 0.0001968 , 0.00018719, 0.00019679, 0.00018028,\n",
      "       0.00017164, 0.00018525, 0.00019471, 0.00017876, 0.00019654,\n",
      "       0.00019181, 0.00018751, 0.00018013, 0.00017133, 0.00019   ,\n",
      "       0.00018658, 0.00019406, 0.00019023, 0.00018233, 0.00017733,\n",
      "       0.00018557, 0.0001944 , 0.00018982, 0.00019085, 0.00019029,\n",
      "       0.00019106, 0.00018537, 0.00019386, 0.0001898 , 0.0001891 ,\n",
      "       0.00019698, 0.00019573, 0.00018034, 0.00018957, 0.00019327,\n",
      "       0.00018297, 0.00017629, 0.00018556, 0.00018759, 0.00018775,\n",
      "       0.00019466, 0.00019022, 0.00019165, 0.00018672, 0.0001728 ,\n",
      "       0.00017672, 0.00018765, 0.00016035, 0.00018989, 0.00018141,\n",
      "       0.00018297, 0.00018698, 0.0001905 , 0.00018895, 0.00018383,\n",
      "       0.00019007, 0.00019676, 0.00017001, 0.0001881 , 0.00017837,\n",
      "       0.00018541, 0.00018451, 0.00018707, 0.00018944, 0.00017875,\n",
      "       0.00019267, 0.00016838, 0.00019303, 0.00019211, 0.00019358,\n",
      "       0.00018279, 0.00018887, 0.00017869, 0.00017873, 0.00018617,\n",
      "       0.00019092, 0.00018492, 0.00019223, 0.00019288, 0.00018322,\n",
      "       0.00017427, 0.00018566, 0.00018221, 0.00019135, 0.00019525,\n",
      "       0.00019336, 0.00018297, 0.0001853 , 0.00018869, 0.00018812,\n",
      "       0.00018889, 0.00017956, 0.00017103, 0.00017378, 0.00018123,\n",
      "       0.00019124, 0.00019103, 0.00018708, 0.00017867, 0.00019043,\n",
      "       0.00018867, 0.00018542, 0.00019807, 0.00017379, 0.00018536,\n",
      "       0.00018775, 0.00018902, 0.00018403, 0.00018088, 0.00017797,\n",
      "       0.0001913 , 0.00018472, 0.00017464, 0.00018967, 0.00018595,\n",
      "       0.00018544, 0.00018824, 0.00018724, 0.00018934, 0.00018385,\n",
      "       0.00018662, 0.00018904, 0.00018347, 0.00019028, 0.0001885 ,\n",
      "       0.00018121, 0.00019335, 0.00019384, 0.00018019, 0.00018206,\n",
      "       0.00018951, 0.00018768, 0.00018826, 0.00019458, 0.00017599,\n",
      "       0.00018295, 0.00019338, 0.00018765, 0.00017378, 0.00018494,\n",
      "       0.0001808 , 0.00019592, 0.00017714, 0.00018613, 0.00018596,\n",
      "       0.00018945, 0.0001842 , 0.00018815, 0.00017028, 0.00018653,\n",
      "       0.00018807, 0.00018941, 0.00018452, 0.00017983, 0.00017822,\n",
      "       0.00019229, 0.00018464, 0.00018834, 0.00019486, 0.00017967,\n",
      "       0.00018843, 0.00018276, 0.00019661, 0.00018203, 0.00019078,\n",
      "       0.00019784, 0.0001885 , 0.00017808, 0.00018679, 0.00018792,\n",
      "       0.00018743, 0.00018344, 0.0001919 , 0.0001865 , 0.00018082,\n",
      "       0.00018306, 0.00019112, 0.00019328, 0.00019128, 0.00016762,\n",
      "       0.00019261, 0.00018372, 0.0001904 , 0.0001703 , 0.00017997,\n",
      "       0.00018484, 0.00019314, 0.00017763, 0.00018149, 0.00018635,\n",
      "       0.00019187, 0.00019066, 0.0001717 , 0.00015884, 0.00019484,\n",
      "       0.0001885 , 0.00018762, 0.00018502, 0.00017901, 0.00018225,\n",
      "       0.00019486, 0.00018559, 0.00018557, 0.00017514, 0.00018853,\n",
      "       0.00018671, 0.00019113, 0.00017391, 0.00018357, 0.00016781,\n",
      "       0.00017664, 0.00018341, 0.00019233, 0.00018425, 0.00018418,\n",
      "       0.00018528, 0.00019103, 0.00018524, 0.00018683, 0.00018348,\n",
      "       0.00017609, 0.00019446, 0.00018149, 0.00017589, 0.00018603,\n",
      "       0.00017881, 0.00018642, 0.00017566, 0.00018645, 0.00018174,\n",
      "       0.00019269, 0.00018899, 0.0001921 , 0.0001924 , 0.0001798 ],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_26/FusedBatchNormV3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 101\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.31785551e-08, 1.30754243e-08, 1.27802569e-08, 1.30990880e-08,\n",
      "       1.27673196e-08, 1.27006441e-08, 1.30692523e-08, 1.32966367e-08,\n",
      "       1.31258666e-08, 1.30431976e-08, 1.33393767e-08, 1.35954119e-08,\n",
      "       1.26151205e-08, 1.28159146e-08, 1.21781101e-08, 1.26097630e-08,\n",
      "       1.22447084e-08, 1.36802054e-08, 1.32894327e-08, 1.31928575e-08,\n",
      "       1.34159794e-08, 1.29646063e-08, 1.29745050e-08, 1.35505624e-08,\n",
      "       1.20061117e-08, 1.29119568e-08, 1.27589157e-08, 1.31612801e-08,\n",
      "       1.31600082e-08, 1.31720466e-08, 1.13969456e-08, 1.31550904e-08,\n",
      "       1.23247830e-08, 1.12897833e-08, 1.24779636e-08, 1.34915306e-08,\n",
      "       1.27077211e-08, 1.36040406e-08, 1.28917161e-08, 1.29329960e-08,\n",
      "       1.27543824e-08, 1.29299256e-08, 1.33563107e-08, 1.28244046e-08,\n",
      "       1.27071749e-08, 1.35022500e-08, 1.31768143e-08, 1.36029188e-08,\n",
      "       1.35228113e-08, 1.31860896e-08, 1.29803599e-08, 1.31994753e-08,\n",
      "       1.30903546e-08, 1.36484486e-08, 1.30427980e-08, 1.21222410e-08,\n",
      "       1.28631452e-08, 1.30867504e-08, 1.36736711e-08, 1.25765647e-08,\n",
      "       1.28792461e-08, 1.34126710e-08, 1.00658823e-08, 1.16467440e-08,\n",
      "       1.27229800e-08, 1.28700650e-08, 1.28961020e-08, 1.31433859e-08,\n",
      "       1.27490427e-08, 1.06540998e-08, 1.33782319e-08, 1.30067512e-08,\n",
      "       1.24790702e-08, 1.35266980e-08, 1.33760034e-08, 1.32104798e-08,\n",
      "       1.29146880e-08, 1.25170470e-08, 1.29712783e-08, 1.17750671e-08,\n",
      "       1.33678331e-08, 1.23823138e-08, 1.33500428e-08, 1.36143097e-08,\n",
      "       1.16690515e-08, 1.31298403e-08, 1.35457601e-08, 1.30780577e-08,\n",
      "       1.35430618e-08, 1.29545050e-08, 1.22604451e-08, 1.34004168e-08,\n",
      "       1.26521824e-08, 1.31362849e-08, 1.30850104e-08, 1.29686955e-08,\n",
      "       1.34673375e-08, 1.30902515e-08, 1.36228495e-08, 1.31025306e-08,\n",
      "       1.32353941e-08, 1.31975666e-08, 1.31026923e-08, 1.29880693e-08,\n",
      "       1.34769111e-08, 1.23227029e-08, 1.32733069e-08, 1.29411415e-08,\n",
      "       1.33421869e-08, 1.30735582e-08, 1.36823610e-08, 1.38845264e-08,\n",
      "       1.27118058e-08, 1.33397631e-08, 1.34252369e-08, 1.28015865e-08,\n",
      "       1.24064785e-08, 1.32821327e-08, 1.28608075e-08, 1.34219151e-08,\n",
      "       1.27773880e-08, 1.24814674e-08, 1.31764430e-08, 1.16476828e-08,\n",
      "       1.33877469e-08, 1.30485756e-08, 1.24049739e-08, 1.23238344e-08,\n",
      "       1.11971401e-08, 1.20565975e-08, 1.28095223e-08, 1.30923947e-08,\n",
      "       1.27902409e-08, 1.07723190e-08, 1.35840663e-08, 1.29898394e-08,\n",
      "       1.29208679e-08, 1.36966758e-08, 1.22865398e-08, 1.11986171e-08,\n",
      "       1.35721905e-08, 1.24286910e-08, 1.37055896e-08, 1.28162352e-08,\n",
      "       1.23307924e-08, 1.20509913e-08, 1.34755940e-08, 1.33204301e-08,\n",
      "       1.35582807e-08, 1.28945601e-08, 1.35170843e-08, 1.34880791e-08,\n",
      "       1.31254412e-08, 1.35966589e-08, 1.33491680e-08, 1.29244286e-08,\n",
      "       1.34731524e-08, 1.30874751e-08, 1.35299327e-08, 1.34641223e-08,\n",
      "       1.27875426e-08, 1.14152456e-08, 1.28578090e-08, 1.33757032e-08,\n",
      "       1.27657023e-08, 1.30282904e-08, 1.32359119e-08, 1.27554785e-08,\n",
      "       1.24287025e-08, 1.32818663e-08, 1.34210394e-08, 1.20986492e-08,\n",
      "       1.27926914e-08, 1.34395144e-08, 1.25073658e-08, 1.29682185e-08,\n",
      "       1.29841649e-08, 1.27731816e-08, 1.32334224e-08, 1.33972984e-08,\n",
      "       1.31896432e-08, 1.25217854e-08, 1.28397399e-08, 1.27888713e-08,\n",
      "       1.25646418e-08, 1.32260896e-08, 1.07638423e-08, 1.32014897e-08,\n",
      "       1.30208715e-08, 1.30464350e-08, 1.28081670e-08, 1.22055619e-08,\n",
      "       1.30425910e-08, 1.30778561e-08, 1.31205873e-08, 1.29508502e-08,\n",
      "       1.33403191e-08, 1.24053736e-08, 1.25066224e-08, 1.25865993e-08,\n",
      "       1.34524614e-08, 1.21326069e-08, 1.34148825e-08, 1.34019933e-08,\n",
      "       1.32924294e-08, 1.34018672e-08, 1.30698083e-08, 1.23433006e-08,\n",
      "       1.33031017e-08, 1.30077789e-08, 1.31791014e-08, 1.23972175e-08,\n",
      "       1.31433566e-08, 1.30364555e-08, 1.24538539e-08, 1.21192878e-08,\n",
      "       1.30996911e-08, 1.34220342e-08, 1.33254474e-08, 1.21753372e-08,\n",
      "       1.29786262e-08, 1.30696360e-08, 1.32454554e-08, 1.36293776e-08,\n",
      "       1.31565541e-08, 1.33686049e-08, 1.28974413e-08, 1.36151375e-08,\n",
      "       1.26407356e-08, 1.27835582e-08, 1.28467716e-08, 1.23194495e-08,\n",
      "       1.35684237e-08, 1.26429640e-08, 1.29897817e-08, 1.32244375e-08,\n",
      "       1.34828246e-08, 1.29959830e-08, 1.28781670e-08, 1.29179236e-08,\n",
      "       1.27343665e-08, 1.18941239e-08, 1.31732687e-08, 1.36566110e-08,\n",
      "       1.34502711e-08, 1.33064502e-08, 1.37340104e-08, 1.30635529e-08,\n",
      "       1.37334570e-08, 1.25812427e-08, 1.19783783e-08, 1.29282753e-08,\n",
      "       1.35880978e-08, 1.24752457e-08, 1.37161651e-08, 1.33856837e-08,\n",
      "       1.30856685e-08, 1.25706920e-08, 1.19565913e-08, 1.32593749e-08,\n",
      "       1.30208351e-08, 1.35430289e-08, 1.32754403e-08, 1.27243105e-08,\n",
      "       1.23751223e-08, 1.29503572e-08, 1.35665266e-08, 1.32469724e-08,\n",
      "       1.33192346e-08, 1.32796556e-08, 1.33335627e-08, 1.29363569e-08,\n",
      "       1.35288287e-08, 1.32459084e-08, 1.31968942e-08, 1.37467886e-08,\n",
      "       1.36593892e-08, 1.25854944e-08, 1.32297489e-08, 1.34879681e-08,\n",
      "       1.27691555e-08, 1.23030173e-08, 1.29499060e-08, 1.30913635e-08,\n",
      "       1.31027296e-08, 1.35847715e-08, 1.32752067e-08, 1.33749847e-08,\n",
      "       1.30310580e-08, 1.20593411e-08, 1.23326300e-08, 1.30957440e-08,\n",
      "       1.11905694e-08, 1.32522899e-08, 1.26601059e-08, 1.27690338e-08,\n",
      "       1.30488482e-08, 1.32948177e-08, 1.31865434e-08, 1.28294104e-08,\n",
      "       1.32646418e-08, 1.37312588e-08, 1.18643326e-08, 1.31272042e-08,\n",
      "       1.24480275e-08, 1.29394850e-08, 1.28767050e-08, 1.30553737e-08,\n",
      "       1.32207933e-08, 1.24742447e-08, 1.34459475e-08, 1.17510028e-08,\n",
      "       1.34708715e-08, 1.34070195e-08, 1.35096672e-08, 1.27566402e-08,\n",
      "       1.31806601e-08, 1.24705730e-08, 1.24731843e-08, 1.29925262e-08,\n",
      "       1.33237679e-08, 1.29053461e-08, 1.34154705e-08, 1.34609373e-08,\n",
      "       1.27862432e-08, 1.21616006e-08, 1.29566047e-08, 1.27163036e-08,\n",
      "       1.33541400e-08, 1.36259226e-08, 1.34942200e-08, 1.27692230e-08,\n",
      "       1.29318867e-08, 1.31682532e-08, 1.31287115e-08, 1.31823708e-08,\n",
      "       1.25313342e-08, 1.19355787e-08, 1.21278356e-08, 1.26474884e-08,\n",
      "       1.33460887e-08, 1.33313476e-08, 1.30555442e-08, 1.24686625e-08,\n",
      "       1.32899087e-08, 1.31665354e-08, 1.29401014e-08, 1.38227279e-08,\n",
      "       1.21281465e-08, 1.29359048e-08, 1.31026363e-08, 1.31909639e-08,\n",
      "       1.28429383e-08, 1.26230431e-08, 1.24204353e-08, 1.33506237e-08,\n",
      "       1.28914186e-08, 1.21880115e-08, 1.32364644e-08, 1.29771163e-08,\n",
      "       1.29411353e-08, 1.31371047e-08, 1.30673223e-08, 1.32138442e-08,\n",
      "       1.28303315e-08, 1.30236062e-08, 1.31925626e-08, 1.28040600e-08,\n",
      "       1.32789397e-08, 1.31548514e-08, 1.26461428e-08, 1.34935201e-08,\n",
      "       1.35274814e-08, 1.25749349e-08, 1.27054056e-08, 1.32251259e-08,\n",
      "       1.30976998e-08, 1.31382141e-08, 1.35795135e-08, 1.22821282e-08,\n",
      "       1.27673809e-08, 1.34957965e-08, 1.30959776e-08, 1.21280284e-08,\n",
      "       1.29063507e-08, 1.26177024e-08, 1.36727838e-08, 1.23621895e-08,\n",
      "       1.29896831e-08, 1.29776261e-08, 1.32213440e-08, 1.28550814e-08,\n",
      "       1.31306246e-08, 1.18833050e-08, 1.30175062e-08, 1.31253017e-08,\n",
      "       1.32184734e-08, 1.28775639e-08, 1.25495729e-08, 1.24375008e-08,\n",
      "       1.34191396e-08, 1.28858533e-08, 1.31435955e-08, 1.35987595e-08,\n",
      "       1.25390356e-08, 1.31498847e-08, 1.27544855e-08, 1.37211620e-08,\n",
      "       1.27031434e-08, 1.33143692e-08, 1.38065905e-08, 1.31552103e-08,\n",
      "       1.24281074e-08, 1.30355904e-08, 1.31147377e-08, 1.30801299e-08,\n",
      "       1.28017392e-08, 1.33923548e-08, 1.30156099e-08, 1.26187505e-08,\n",
      "       1.27754927e-08, 1.33376989e-08, 1.34883145e-08, 1.33489690e-08,\n",
      "       1.16979848e-08, 1.34415510e-08, 1.28211610e-08, 1.32874378e-08,\n",
      "       1.18850192e-08, 1.25596538e-08, 1.28994007e-08, 1.34789468e-08,\n",
      "       1.23961801e-08, 1.26659829e-08, 1.30047493e-08, 1.33898128e-08,\n",
      "       1.33055735e-08, 1.19824364e-08, 1.10851923e-08, 1.35972984e-08,\n",
      "       1.31546560e-08, 1.30934303e-08, 1.29121913e-08, 1.24924258e-08,\n",
      "       1.27187043e-08, 1.35987532e-08, 1.29520776e-08, 1.29505091e-08,\n",
      "       1.22222703e-08, 1.31572850e-08, 1.30302862e-08, 1.33385454e-08,\n",
      "       1.21368311e-08, 1.28111255e-08, 1.17110401e-08, 1.23270780e-08,\n",
      "       1.27996556e-08, 1.34225706e-08, 1.28580684e-08, 1.28537083e-08,\n",
      "       1.29302586e-08, 1.33315661e-08, 1.29274209e-08, 1.30381528e-08,\n",
      "       1.28045441e-08, 1.22887380e-08, 1.35707365e-08, 1.26658355e-08,\n",
      "       1.22749624e-08, 1.29827580e-08, 1.24788251e-08, 1.30101672e-08,\n",
      "       1.22589663e-08, 1.30119941e-08, 1.26829764e-08, 1.34470914e-08,\n",
      "       1.31891786e-08, 1.34059182e-08, 1.34271998e-08, 1.25480852e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D\n",
      "index : 102\n",
      "shape : [120   1   1 480]\n",
      "shape_signature : [120   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078341, 0.00079093, 0.00078559, 0.00078748, 0.00078353,\n",
      "       0.00078735, 0.00078404, 0.00078846, 0.00078805, 0.000788  ,\n",
      "       0.00078554, 0.00078773, 0.00078594, 0.0007901 , 0.00078952,\n",
      "       0.00078739, 0.0007892 , 0.00078449, 0.0007891 , 0.0007909 ,\n",
      "       0.00078493, 0.00078722, 0.0007888 , 0.0007933 , 0.00078238,\n",
      "       0.00078151, 0.00078949, 0.00078876, 0.00078708, 0.00079051,\n",
      "       0.00077806, 0.00078956, 0.00079257, 0.00078492, 0.00079021,\n",
      "       0.00078703, 0.00078559, 0.00079049, 0.00078808, 0.00078375,\n",
      "       0.000785  , 0.000785  , 0.00078915, 0.00078436, 0.00078736,\n",
      "       0.00078708, 0.00078806, 0.00079101, 0.00078497, 0.00079279,\n",
      "       0.00078269, 0.00078762, 0.00078829, 0.00078577, 0.00078866,\n",
      "       0.00078609, 0.00078779, 0.00078586, 0.00078986, 0.00078889,\n",
      "       0.00078759, 0.0007863 , 0.00078548, 0.00079193, 0.00078605,\n",
      "       0.00078511, 0.00078862, 0.00079067, 0.00078328, 0.000789  ,\n",
      "       0.00078734, 0.00078733, 0.00079069, 0.00078669, 0.00078553,\n",
      "       0.00078814, 0.00078261, 0.00078911, 0.00078383, 0.00078249,\n",
      "       0.00078871, 0.00078703, 0.00079082, 0.0007868 , 0.0007846 ,\n",
      "       0.00079208, 0.0007807 , 0.00078967, 0.00078292, 0.00078895,\n",
      "       0.00078941, 0.00079248, 0.0007895 , 0.000779  , 0.00078924,\n",
      "       0.00078609, 0.00078507, 0.00078785, 0.00079036, 0.00078586,\n",
      "       0.00079039, 0.00078787, 0.00078602, 0.00077925, 0.0007919 ,\n",
      "       0.0007914 , 0.00078828, 0.00078972, 0.00078744, 0.00078645,\n",
      "       0.00078318, 0.00078562, 0.00078739, 0.00079105, 0.00078629,\n",
      "       0.00078625, 0.00078984, 0.00079203, 0.00079101, 0.00078657],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/BiasAdd/ReadVariableOp/resource\n",
      "index : 103\n",
      "shape : [120]\n",
      "shape_signature : [120]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.1255603e-08, 3.1555597e-08, 3.1342577e-08, 3.1417891e-08,\n",
      "       3.1260495e-08, 3.1412842e-08, 3.1280592e-08, 3.1457159e-08,\n",
      "       3.1440610e-08, 3.1438638e-08, 3.1340573e-08, 3.1428083e-08,\n",
      "       3.1356656e-08, 3.1522287e-08, 3.1499205e-08, 3.1414505e-08,\n",
      "       3.1486433e-08, 3.1298683e-08, 3.1482482e-08, 3.1554393e-08,\n",
      "       3.1316258e-08, 3.1407524e-08, 3.1470638e-08, 3.1650099e-08,\n",
      "       3.1214640e-08, 3.1179638e-08, 3.1497976e-08, 3.1468872e-08,\n",
      "       3.1401996e-08, 3.1538825e-08, 3.1042127e-08, 3.1500790e-08,\n",
      "       3.1620839e-08, 3.1315814e-08, 3.1527023e-08, 3.1400141e-08,\n",
      "       3.1342420e-08, 3.1537922e-08, 3.1441790e-08, 3.1269291e-08,\n",
      "       3.1319114e-08, 3.1319040e-08, 3.1484515e-08, 3.1293357e-08,\n",
      "       3.1413279e-08, 3.1402035e-08, 3.1440937e-08, 3.1558660e-08,\n",
      "       3.1317988e-08, 3.1629675e-08, 3.1226982e-08, 3.1423710e-08,\n",
      "       3.1450199e-08, 3.1349789e-08, 3.1464850e-08, 3.1362593e-08,\n",
      "       3.1430261e-08, 3.1353338e-08, 3.1512805e-08, 3.1474357e-08,\n",
      "       3.1422466e-08, 3.1370874e-08, 3.1338157e-08, 3.1595430e-08,\n",
      "       3.1360823e-08, 3.1323289e-08, 3.1463507e-08, 3.1545294e-08,\n",
      "       3.1250249e-08, 3.1478429e-08, 3.1412480e-08, 3.1411798e-08,\n",
      "       3.1545969e-08, 3.1386424e-08, 3.1340281e-08, 3.1444426e-08,\n",
      "       3.1223674e-08, 3.1482784e-08, 3.1272158e-08, 3.1218864e-08,\n",
      "       3.1466833e-08, 3.1399818e-08, 3.1551330e-08, 3.1390709e-08,\n",
      "       3.1303120e-08, 3.1601257e-08, 3.1147252e-08, 3.1505405e-08,\n",
      "       3.1236059e-08, 3.1476691e-08, 3.1494935e-08, 3.1617407e-08,\n",
      "       3.1498519e-08, 3.1079555e-08, 3.1488277e-08, 3.1362475e-08,\n",
      "       3.1321918e-08, 3.1432858e-08, 3.1533034e-08, 3.1353334e-08,\n",
      "       3.1533997e-08, 3.1433689e-08, 3.1359775e-08, 3.1089630e-08,\n",
      "       3.1594347e-08, 3.1574324e-08, 3.1449904e-08, 3.1507174e-08,\n",
      "       3.1416327e-08, 3.1376658e-08, 3.1246227e-08, 3.1343870e-08,\n",
      "       3.1414178e-08, 3.1560440e-08, 3.1370512e-08, 3.1368842e-08,\n",
      "       3.1511970e-08, 3.1599509e-08, 3.1558958e-08, 3.1381457e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D\n",
      "index : 104\n",
      "shape : [480   1   1 120]\n",
      "shape_signature : [480   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0007889 , 0.00077189, 0.00078999, 0.000791  , 0.00076649,\n",
      "       0.00078543, 0.00078849, 0.00077573, 0.00077937, 0.00078705,\n",
      "       0.00078132, 0.00078742, 0.00077382, 0.00078672, 0.00077575,\n",
      "       0.00078071, 0.00077579, 0.00077653, 0.00078669, 0.00077442,\n",
      "       0.00078957, 0.00078681, 0.00077981, 0.00077023, 0.00077462,\n",
      "       0.00077885, 0.00079237, 0.0007842 , 0.00078805, 0.00078366,\n",
      "       0.00078221, 0.00078077, 0.00076779, 0.00078648, 0.00078368,\n",
      "       0.00078909, 0.00078293, 0.00078853, 0.00077704, 0.00077666,\n",
      "       0.0007906 , 0.00078616, 0.00078699, 0.00078025, 0.00078036,\n",
      "       0.00078353, 0.00077107, 0.0007758 , 0.00078771, 0.00078439,\n",
      "       0.00078373, 0.00078681, 0.00078141, 0.00078751, 0.00078502,\n",
      "       0.00077858, 0.00078326, 0.00078985, 0.00078086, 0.00078819,\n",
      "       0.00077854, 0.00078574, 0.00078528, 0.00078836, 0.00077265,\n",
      "       0.00078516, 0.00077662, 0.0007836 , 0.00078393, 0.00078747,\n",
      "       0.0007855 , 0.00076403, 0.00076366, 0.0007879 , 0.0007845 ,\n",
      "       0.00078211, 0.00078754, 0.00077993, 0.00076976, 0.00078429,\n",
      "       0.00079017, 0.00078232, 0.00078624, 0.00078668, 0.00078428,\n",
      "       0.00078818, 0.0007872 , 0.00078421, 0.00078434, 0.00077029,\n",
      "       0.00077768, 0.00078399, 0.00078508, 0.00077044, 0.00078949,\n",
      "       0.00078687, 0.00078213, 0.00077821, 0.00078726, 0.0007826 ,\n",
      "       0.00078267, 0.00076005, 0.00078554, 0.00078505, 0.0007863 ,\n",
      "       0.00078574, 0.00078428, 0.00077901, 0.00075965, 0.00078263,\n",
      "       0.00078327, 0.00078569, 0.00077691, 0.00078975, 0.00078069,\n",
      "       0.00077597, 0.00078472, 0.00078709, 0.00077916, 0.00078   ,\n",
      "       0.00077761, 0.00077848, 0.00077781, 0.00076968, 0.00077194,\n",
      "       0.00076744, 0.00077982, 0.0007802 , 0.00078731, 0.00078444,\n",
      "       0.00077498, 0.00078731, 0.00078629, 0.00078098, 0.00077667,\n",
      "       0.0007873 , 0.0007891 , 0.00077493, 0.00078613, 0.00077786,\n",
      "       0.00078869, 0.00078773, 0.00078319, 0.00078819, 0.00078459,\n",
      "       0.00077737, 0.00078844, 0.00078599, 0.00079032, 0.00077878,\n",
      "       0.00078117, 0.00077212, 0.00075346, 0.00078442, 0.00077688,\n",
      "       0.00078673, 0.00078359, 0.00077955, 0.00078226, 0.00078559,\n",
      "       0.00077362, 0.00078675, 0.00077356, 0.00078679, 0.00079087,\n",
      "       0.00078739, 0.00078858, 0.00078306, 0.00077809, 0.00077803,\n",
      "       0.00078267, 0.00077545, 0.00076141, 0.00078598, 0.00079127,\n",
      "       0.00077952, 0.00078139, 0.00078474, 0.00078672, 0.00078942,\n",
      "       0.00078799, 0.00078349, 0.00077441, 0.00078827, 0.00078081,\n",
      "       0.00078474, 0.00078581, 0.00078548, 0.00078554, 0.00077277,\n",
      "       0.0007822 , 0.00078814, 0.00078046, 0.00078572, 0.00078316,\n",
      "       0.0007856 , 0.0007793 , 0.00076608, 0.0007837 , 0.00079066,\n",
      "       0.00079233, 0.00078388, 0.00078299, 0.00078506, 0.00078193,\n",
      "       0.0007795 , 0.00077858, 0.00078499, 0.00078745, 0.00077835,\n",
      "       0.00079263, 0.00078446, 0.00077019, 0.00078529, 0.00078687,\n",
      "       0.00077897, 0.00078389, 0.00078291, 0.00078659, 0.00078316,\n",
      "       0.00077624, 0.00079053, 0.00076903, 0.00078244, 0.00078747,\n",
      "       0.00078121, 0.00079007, 0.00076866, 0.00074821, 0.00077829,\n",
      "       0.00076712, 0.00078477, 0.00077705, 0.00078188, 0.00077679,\n",
      "       0.00078678, 0.00078435, 0.00078856, 0.00078871, 0.00078669,\n",
      "       0.0007886 , 0.00078367, 0.00078427, 0.00077849, 0.00077246,\n",
      "       0.0007849 , 0.00076202, 0.00078514, 0.00078649, 0.00077444,\n",
      "       0.00078256, 0.00077839, 0.00077772, 0.0007819 , 0.00077785,\n",
      "       0.00078271, 0.00078487, 0.00078908, 0.00078426, 0.00077355,\n",
      "       0.00078458, 0.00078308, 0.00077707, 0.00079193, 0.00078662,\n",
      "       0.00078661, 0.00078246, 0.00078979, 0.00077361, 0.00078632,\n",
      "       0.00077598, 0.00078282, 0.00079226, 0.00078413, 0.00078685,\n",
      "       0.0007853 , 0.00076906, 0.00077911, 0.00078568, 0.00077226,\n",
      "       0.00078161, 0.00078251, 0.0007836 , 0.00078569, 0.00078585,\n",
      "       0.0007868 , 0.0007823 , 0.00079044, 0.00078651, 0.00077613,\n",
      "       0.00078547, 0.00078041, 0.00078631, 0.00076877, 0.00078628,\n",
      "       0.00078372, 0.0007803 , 0.00077567, 0.00078337, 0.00077698,\n",
      "       0.00077518, 0.0007869 , 0.00077676, 0.00078422, 0.00078041,\n",
      "       0.00078846, 0.00077612, 0.00077946, 0.00077988, 0.00077737,\n",
      "       0.00078754, 0.00078265, 0.00078614, 0.00077801, 0.00077642,\n",
      "       0.00078111, 0.00077806, 0.00078879, 0.00075714, 0.00078579,\n",
      "       0.00078375, 0.00078511, 0.00078536, 0.00079125, 0.00077094,\n",
      "       0.00078409, 0.00079075, 0.0007784 , 0.00078521, 0.0007711 ,\n",
      "       0.0007588 , 0.00077542, 0.00077414, 0.00078648, 0.00078629,\n",
      "       0.00077866, 0.00077852, 0.00078736, 0.00077133, 0.00078888,\n",
      "       0.00078812, 0.00076662, 0.00077606, 0.00078651, 0.00077916,\n",
      "       0.00078579, 0.00077928, 0.00078604, 0.0007849 , 0.00078771,\n",
      "       0.00078496, 0.0007793 , 0.00077298, 0.00078678, 0.00078406,\n",
      "       0.00077475, 0.00077476, 0.00078091, 0.00078116, 0.00078705,\n",
      "       0.00078979, 0.00078569, 0.0007868 , 0.00077975, 0.00077707,\n",
      "       0.0007855 , 0.00078536, 0.00078903, 0.00078857, 0.00076149,\n",
      "       0.00077533, 0.00078171, 0.00078451, 0.0007701 , 0.000789  ,\n",
      "       0.00078118, 0.00077754, 0.00078084, 0.00078231, 0.00078028,\n",
      "       0.00078632, 0.00078412, 0.00077233, 0.00078355, 0.00078718,\n",
      "       0.00077536, 0.00077886, 0.0007895 , 0.00078546, 0.00078417,\n",
      "       0.00078199, 0.00078068, 0.00077992, 0.00078292, 0.00078478,\n",
      "       0.00076987, 0.00078655, 0.00078152, 0.00077488, 0.00078733,\n",
      "       0.00079198, 0.00077778, 0.00078346, 0.00078995, 0.00077101,\n",
      "       0.00077778, 0.00077   , 0.00077988, 0.0007654 , 0.00077744,\n",
      "       0.00078525, 0.00076665, 0.00078062, 0.00078938, 0.00077129,\n",
      "       0.000779  , 0.00078706, 0.0007866 , 0.00078528, 0.00077249,\n",
      "       0.00078449, 0.0007845 , 0.00078797, 0.00077995, 0.00078237,\n",
      "       0.00078532, 0.00078942, 0.00076636, 0.00077083, 0.00078431,\n",
      "       0.00077895, 0.00078706, 0.00078208, 0.00078372, 0.00078047,\n",
      "       0.00079234, 0.00078535, 0.00077885, 0.00075278, 0.00078314,\n",
      "       0.00078489, 0.0007839 , 0.00078593, 0.00077811, 0.00077787,\n",
      "       0.00078672, 0.0007842 , 0.00077711, 0.00078934, 0.00078629,\n",
      "       0.00078961, 0.00079118, 0.00078682, 0.00078   , 0.00078966,\n",
      "       0.00078122, 0.00077925, 0.00078139, 0.00078938, 0.00078604,\n",
      "       0.00077901, 0.00077514, 0.00077551, 0.00078943, 0.0007863 ,\n",
      "       0.00077694, 0.00076477, 0.00078598, 0.00077978, 0.00078697,\n",
      "       0.00078199, 0.00077336, 0.00078588, 0.00078394, 0.00075346,\n",
      "       0.00077726, 0.00078571, 0.00078409, 0.00076885, 0.00075903],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/BiasAdd/ReadVariableOp/resource\n",
      "index : 105\n",
      "shape : [480]\n",
      "shape_signature : [480]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8564322e-08, 1.8163941e-08, 1.8589896e-08, 1.8613614e-08,\n",
      "       1.8036953e-08, 1.8482531e-08, 1.8554561e-08, 1.8254436e-08,\n",
      "       1.8339938e-08, 1.8520653e-08, 1.8385895e-08, 1.8529505e-08,\n",
      "       1.8209322e-08, 1.8513017e-08, 1.8254870e-08, 1.8371463e-08,\n",
      "       1.8255667e-08, 1.8273065e-08, 1.8512234e-08, 1.8223503e-08,\n",
      "       1.8580053e-08, 1.8514989e-08, 1.8350441e-08, 1.8124968e-08,\n",
      "       1.8228304e-08, 1.8327759e-08, 1.8645808e-08, 1.8453743e-08,\n",
      "       1.8544350e-08, 1.8441051e-08, 1.8406880e-08, 1.8372949e-08,\n",
      "       1.8067469e-08, 1.8507333e-08, 1.8441328e-08, 1.8568741e-08,\n",
      "       1.8423863e-08, 1.8555562e-08, 1.8285260e-08, 1.8276173e-08,\n",
      "       1.8604311e-08, 1.8499852e-08, 1.8519239e-08, 1.8360732e-08,\n",
      "       1.8363203e-08, 1.8438017e-08, 1.8144728e-08, 1.8255943e-08,\n",
      "       1.8536378e-08, 1.8458190e-08, 1.8442506e-08, 1.8515081e-08,\n",
      "       1.8387935e-08, 1.8531443e-08, 1.8472907e-08, 1.8321385e-08,\n",
      "       1.8431473e-08, 1.8586695e-08, 1.8374976e-08, 1.8547611e-08,\n",
      "       1.8320574e-08, 1.8489814e-08, 1.8479154e-08, 1.8551562e-08,\n",
      "       1.8181805e-08, 1.8476193e-08, 1.8275397e-08, 1.8439573e-08,\n",
      "       1.8447285e-08, 1.8530706e-08, 1.8484265e-08, 1.7979094e-08,\n",
      "       1.7970274e-08, 1.8540794e-08, 1.8460740e-08, 1.8404378e-08,\n",
      "       1.8532290e-08, 1.8353193e-08, 1.8113758e-08, 1.8455806e-08,\n",
      "       1.8594179e-08, 1.8409350e-08, 1.8501785e-08, 1.8512072e-08,\n",
      "       1.8455603e-08, 1.8547244e-08, 1.8524219e-08, 1.8454001e-08,\n",
      "       1.8457044e-08, 1.8126350e-08, 1.8300179e-08, 1.8448691e-08,\n",
      "       1.8474465e-08, 1.8129766e-08, 1.8578074e-08, 1.8516596e-08,\n",
      "       1.8405071e-08, 1.8312733e-08, 1.8525602e-08, 1.8415907e-08,\n",
      "       1.8417600e-08, 1.7885448e-08, 1.8485144e-08, 1.8473722e-08,\n",
      "       1.8503178e-08, 1.8489974e-08, 1.8455637e-08, 1.8331548e-08,\n",
      "       1.7875868e-08, 1.8416626e-08, 1.8431763e-08, 1.8488690e-08,\n",
      "       1.8282165e-08, 1.8584251e-08, 1.8371153e-08, 1.8260083e-08,\n",
      "       1.8465789e-08, 1.8521751e-08, 1.8335051e-08, 1.8354800e-08,\n",
      "       1.8298566e-08, 1.8319087e-08, 1.8303206e-08, 1.8111914e-08,\n",
      "       1.8165256e-08, 1.8059270e-08, 1.8350663e-08, 1.8359588e-08,\n",
      "       1.8526947e-08, 1.8459261e-08, 1.8236694e-08, 1.8526778e-08,\n",
      "       1.8502806e-08, 1.8377857e-08, 1.8276586e-08, 1.8526675e-08,\n",
      "       1.8568988e-08, 1.8235605e-08, 1.8498985e-08, 1.8304437e-08,\n",
      "       1.8559325e-08, 1.8536785e-08, 1.8429800e-08, 1.8547478e-08,\n",
      "       1.8462865e-08, 1.8292967e-08, 1.8553473e-08, 1.8495712e-08,\n",
      "       1.8597758e-08, 1.8326039e-08, 1.8382316e-08, 1.8169493e-08,\n",
      "       1.7730393e-08, 1.8458920e-08, 1.8281318e-08, 1.8513173e-08,\n",
      "       1.8439309e-08, 1.8344338e-08, 1.8408061e-08, 1.8486487e-08,\n",
      "       1.8204583e-08, 1.8513637e-08, 1.8203203e-08, 1.8514568e-08,\n",
      "       1.8610642e-08, 1.8528850e-08, 1.8556841e-08, 1.8426935e-08,\n",
      "       1.8310002e-08, 1.8308571e-08, 1.8417721e-08, 1.8247764e-08,\n",
      "       1.7917388e-08, 1.8495497e-08, 1.8620108e-08, 1.8343508e-08,\n",
      "       1.8387521e-08, 1.8466471e-08, 1.8513058e-08, 1.8576452e-08,\n",
      "       1.8542954e-08, 1.8436852e-08, 1.8223195e-08, 1.8549519e-08,\n",
      "       1.8373814e-08, 1.8466288e-08, 1.8491555e-08, 1.8483775e-08,\n",
      "       1.8485236e-08, 1.8184677e-08, 1.8406590e-08, 1.8546434e-08,\n",
      "       1.8365743e-08, 1.8489418e-08, 1.8429304e-08, 1.8486556e-08,\n",
      "       1.8338325e-08, 1.8027363e-08, 1.8441922e-08, 1.8605711e-08,\n",
      "       1.8644972e-08, 1.8446029e-08, 1.8425238e-08, 1.8473967e-08,\n",
      "       1.8400206e-08, 1.8343091e-08, 1.8321469e-08, 1.8472294e-08,\n",
      "       1.8530125e-08, 1.8315918e-08, 1.8651980e-08, 1.8459714e-08,\n",
      "       1.8124007e-08, 1.8479227e-08, 1.8516495e-08, 1.8330507e-08,\n",
      "       1.8446347e-08, 1.8423252e-08, 1.8509795e-08, 1.8429263e-08,\n",
      "       1.8266405e-08, 1.8602670e-08, 1.8096658e-08, 1.8412273e-08,\n",
      "       1.8530638e-08, 1.8383323e-08, 1.8591795e-08, 1.8088032e-08,\n",
      "       1.7606844e-08, 1.8314546e-08, 1.8051722e-08, 1.8467002e-08,\n",
      "       1.8285405e-08, 1.8399176e-08, 1.8279225e-08, 1.8514362e-08,\n",
      "       1.8457250e-08, 1.8556268e-08, 1.8559810e-08, 1.8512235e-08,\n",
      "       1.8557301e-08, 1.8441305e-08, 1.8455353e-08, 1.8319346e-08,\n",
      "       1.8177412e-08, 1.8470061e-08, 1.7931750e-08, 1.8475685e-08,\n",
      "       1.8507576e-08, 1.8223957e-08, 1.8415102e-08, 1.8316832e-08,\n",
      "       1.8301229e-08, 1.8399447e-08, 1.8304274e-08, 1.8418490e-08,\n",
      "       1.8469420e-08, 1.8568434e-08, 1.8455063e-08, 1.8203005e-08,\n",
      "       1.8462497e-08, 1.8427402e-08, 1.8285862e-08, 1.8635614e-08,\n",
      "       1.8510564e-08, 1.8510431e-08, 1.8412802e-08, 1.8585324e-08,\n",
      "       1.8204540e-08, 1.8503563e-08, 1.8260236e-08, 1.8421172e-08,\n",
      "       1.8643433e-08, 1.8451958e-08, 1.8515985e-08, 1.8479486e-08,\n",
      "       1.8097412e-08, 1.8333985e-08, 1.8488466e-08, 1.8172768e-08,\n",
      "       1.8392743e-08, 1.8413811e-08, 1.8439545e-08, 1.8488684e-08,\n",
      "       1.8492569e-08, 1.8514818e-08, 1.8408931e-08, 1.8600517e-08,\n",
      "       1.8508107e-08, 1.8263648e-08, 1.8483494e-08, 1.8364531e-08,\n",
      "       1.8503343e-08, 1.8090653e-08, 1.8502652e-08, 1.8442288e-08,\n",
      "       1.8361987e-08, 1.8252885e-08, 1.8434072e-08, 1.8283686e-08,\n",
      "       1.8241366e-08, 1.8517104e-08, 1.8278609e-08, 1.8454029e-08,\n",
      "       1.8364435e-08, 1.8553907e-08, 1.8263448e-08, 1.8342050e-08,\n",
      "       1.8351923e-08, 1.8293013e-08, 1.8532250e-08, 1.8417305e-08,\n",
      "       1.8499209e-08, 1.8307942e-08, 1.8270578e-08, 1.8380918e-08,\n",
      "       1.8309221e-08, 1.8561751e-08, 1.7816994e-08, 1.8491168e-08,\n",
      "       1.8443055e-08, 1.8474973e-08, 1.8480875e-08, 1.8619543e-08,\n",
      "       1.8141680e-08, 1.8451088e-08, 1.8607764e-08, 1.8317111e-08,\n",
      "       1.8477497e-08, 1.8145496e-08, 1.7855989e-08, 1.8247027e-08,\n",
      "       1.8216834e-08, 1.8507322e-08, 1.8502755e-08, 1.8323407e-08,\n",
      "       1.8319943e-08, 1.8528079e-08, 1.8150770e-08, 1.8563703e-08,\n",
      "       1.8545959e-08, 1.8040069e-08, 1.8262149e-08, 1.8507937e-08,\n",
      "       1.8334966e-08, 1.8491003e-08, 1.8337778e-08, 1.8496896e-08,\n",
      "       1.8470072e-08, 1.8536163e-08, 1.8471495e-08, 1.8338435e-08,\n",
      "       1.8189677e-08, 1.8514289e-08, 1.8450358e-08, 1.8231194e-08,\n",
      "       1.8231621e-08, 1.8376296e-08, 1.8382048e-08, 1.8520762e-08,\n",
      "       1.8585263e-08, 1.8488647e-08, 1.8514926e-08, 1.8348977e-08,\n",
      "       1.8285785e-08, 1.8484283e-08, 1.8480989e-08, 1.8567427e-08,\n",
      "       1.8556458e-08, 1.7919316e-08, 1.8244990e-08, 1.8395189e-08,\n",
      "       1.8460909e-08, 1.8121968e-08, 1.8566585e-08, 1.8382595e-08,\n",
      "       1.8296998e-08, 1.8374680e-08, 1.8409088e-08, 1.8361456e-08,\n",
      "       1.8503554e-08, 1.8451827e-08, 1.8174404e-08, 1.8438454e-08,\n",
      "       1.8523817e-08, 1.8245663e-08, 1.8328084e-08, 1.8578408e-08,\n",
      "       1.8483316e-08, 1.8452875e-08, 1.8401579e-08, 1.8370910e-08,\n",
      "       1.8353006e-08, 1.8423448e-08, 1.8467404e-08, 1.8116548e-08,\n",
      "       1.8508906e-08, 1.8390494e-08, 1.8234392e-08, 1.8527402e-08,\n",
      "       1.8636859e-08, 1.8302588e-08, 1.8436175e-08, 1.8588938e-08,\n",
      "       1.8143208e-08, 1.8302693e-08, 1.8119602e-08, 1.8352083e-08,\n",
      "       1.8011310e-08, 1.8294575e-08, 1.8478431e-08, 1.8040661e-08,\n",
      "       1.8369434e-08, 1.8575571e-08, 1.8149839e-08, 1.8331257e-08,\n",
      "       1.8520970e-08, 1.8510152e-08, 1.8479009e-08, 1.8178156e-08,\n",
      "       1.8460588e-08, 1.8460648e-08, 1.8542444e-08, 1.8353665e-08,\n",
      "       1.8410514e-08, 1.8479927e-08, 1.8576559e-08, 1.8033875e-08,\n",
      "       1.8139062e-08, 1.8456365e-08, 1.8330232e-08, 1.8521076e-08,\n",
      "       1.8403792e-08, 1.8442481e-08, 1.8365906e-08, 1.8645146e-08,\n",
      "       1.8480710e-08, 1.8327716e-08, 1.7714298e-08, 1.8428690e-08,\n",
      "       1.8469990e-08, 1.8446688e-08, 1.8494420e-08, 1.8310343e-08,\n",
      "       1.8304672e-08, 1.8512980e-08, 1.8453594e-08, 1.8286762e-08,\n",
      "       1.8574530e-08, 1.8502792e-08, 1.8580941e-08, 1.8617865e-08,\n",
      "       1.8515339e-08, 1.8354882e-08, 1.8582238e-08, 1.8383647e-08,\n",
      "       1.8337071e-08, 1.8387599e-08, 1.8575562e-08, 1.8496879e-08,\n",
      "       1.8331420e-08, 1.8240538e-08, 1.8249278e-08, 1.8576774e-08,\n",
      "       1.8503060e-08, 1.8282787e-08, 1.7996477e-08, 1.8495516e-08,\n",
      "       1.8349716e-08, 1.8518744e-08, 1.8401684e-08, 1.8198666e-08,\n",
      "       1.8493312e-08, 1.8447597e-08, 1.7730253e-08, 1.8290278e-08,\n",
      "       1.8489146e-08, 1.8451187e-08, 1.8092473e-08, 1.7861296e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/conv2d_36/Conv2D\n",
      "index : 106\n",
      "shape : [112   1   1 480]\n",
      "shape_signature : [112   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00085654, 0.00085848, 0.0008605 , 0.00085555, 0.00085981,\n",
      "       0.00085065, 0.00085485, 0.00086068, 0.00086158, 0.00086004,\n",
      "       0.00085724, 0.0008586 , 0.00085907, 0.00086184, 0.00085787,\n",
      "       0.00085411, 0.00086431, 0.00085983, 0.00085389, 0.00085991,\n",
      "       0.00085699, 0.00085831, 0.00085528, 0.00085482, 0.00085564,\n",
      "       0.00085829, 0.00085746, 0.00085443, 0.00085904, 0.00085905,\n",
      "       0.00085471, 0.00085759, 0.00085422, 0.00086182, 0.00085965,\n",
      "       0.00085897, 0.00085313, 0.00085638, 0.00086226, 0.00085685,\n",
      "       0.00086002, 0.00085864, 0.00086372, 0.00086113, 0.00085872,\n",
      "       0.00085932, 0.00086101, 0.00085459, 0.00085622, 0.00086093,\n",
      "       0.00086075, 0.00085963, 0.00085861, 0.00085378, 0.00086214,\n",
      "       0.00086026, 0.00086015, 0.00085889, 0.00085079, 0.00085928,\n",
      "       0.00086037, 0.00086386, 0.00086262, 0.00085974, 0.00086363,\n",
      "       0.00085444, 0.00085344, 0.00086049, 0.00085357, 0.00086072,\n",
      "       0.00085029, 0.00086186, 0.00086063, 0.00086229, 0.00085415,\n",
      "       0.00085672, 0.00086108, 0.00086184, 0.00086052, 0.00086143,\n",
      "       0.00086161, 0.0008543 , 0.00085853, 0.00085973, 0.000859  ,\n",
      "       0.00085401, 0.000861  , 0.00085692, 0.00085397, 0.00085972,\n",
      "       0.00085617, 0.00085876, 0.00086007, 0.00086087, 0.00085234,\n",
      "       0.00085515, 0.00085753, 0.0008589 , 0.00086081, 0.00085465,\n",
      "       0.00086097, 0.00085616, 0.00085998, 0.00085273, 0.00085944,\n",
      "       0.0008559 , 0.00085686, 0.00086241, 0.00085896, 0.00086129,\n",
      "       0.00086224, 0.00085911], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_27/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/conv2d_36/Conv2D\n",
      "index : 107\n",
      "shape : [112]\n",
      "shape_signature : [112]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([8.7273770e-09, 8.7471417e-09, 8.7677892e-09, 8.7173104e-09,\n",
      "       8.7607592e-09, 8.6674303e-09, 8.7101437e-09, 8.7695353e-09,\n",
      "       8.7787244e-09, 8.7630125e-09, 8.7344816e-09, 8.7484162e-09,\n",
      "       8.7531733e-09, 8.7814218e-09, 8.7409093e-09, 8.7026102e-09,\n",
      "       8.8066097e-09, 8.7609626e-09, 8.7003755e-09, 8.7617407e-09,\n",
      "       8.7320045e-09, 8.7454435e-09, 8.7145420e-09, 8.7098941e-09,\n",
      "       8.7182386e-09, 8.7452614e-09, 8.7368157e-09, 8.7059426e-09,\n",
      "       8.7528909e-09, 8.7529681e-09, 8.7087875e-09, 8.7380752e-09,\n",
      "       8.7037284e-09, 8.7811456e-09, 8.7590593e-09, 8.7521990e-09,\n",
      "       8.6926164e-09, 8.7257419e-09, 8.7856789e-09, 8.7305034e-09,\n",
      "       8.7628234e-09, 8.7487821e-09, 8.8005541e-09, 8.7741547e-09,\n",
      "       8.7495700e-09, 8.7557401e-09, 8.7729815e-09, 8.7075378e-09,\n",
      "       8.7241343e-09, 8.7721395e-09, 8.7703249e-09, 8.7588585e-09,\n",
      "       8.7485281e-09, 8.6992786e-09, 8.7844070e-09, 8.7652507e-09,\n",
      "       8.7642045e-09, 8.7513188e-09, 8.6688212e-09, 8.7552969e-09,\n",
      "       8.7664489e-09, 8.8019361e-09, 8.7893017e-09, 8.7600425e-09,\n",
      "       8.7995939e-09, 8.7059933e-09, 8.6957925e-09, 8.7676462e-09,\n",
      "       8.6971408e-09, 8.7699608e-09, 8.6636920e-09, 8.7816003e-09,\n",
      "       8.7690264e-09, 8.7859924e-09, 8.7030720e-09, 8.7292724e-09,\n",
      "       8.7736787e-09, 8.7813685e-09, 8.7679499e-09, 8.7771825e-09,\n",
      "       8.7790859e-09, 8.7045349e-09, 8.7476950e-09, 8.7599084e-09,\n",
      "       8.7524636e-09, 8.7016003e-09, 8.7728687e-09, 8.7312770e-09,\n",
      "       8.7012095e-09, 8.7598107e-09, 8.7236156e-09, 8.7500416e-09,\n",
      "       8.7633953e-09, 8.7715408e-09, 8.6846512e-09, 8.7132470e-09,\n",
      "       8.7374330e-09, 8.7514200e-09, 8.7709502e-09, 8.7081258e-09,\n",
      "       8.7725676e-09, 8.7235712e-09, 8.7624192e-09, 8.6885992e-09,\n",
      "       8.7569720e-09, 8.7208507e-09, 8.7307059e-09, 8.7871594e-09,\n",
      "       8.7520728e-09, 8.7757446e-09, 8.7854950e-09, 8.7536138e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/conv2d_37/Conv2D\n",
      "index : 108\n",
      "shape : [672   1   1 112]\n",
      "shape_signature : [672   1   1 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00070741, 0.00073488, 0.00071547, 0.00073605, 0.00072993,\n",
      "       0.00072286, 0.0007265 , 0.00072469, 0.00070267, 0.00072958,\n",
      "       0.00072234, 0.00072616, 0.00072983, 0.00072321, 0.0007241 ,\n",
      "       0.00073569, 0.00071792, 0.00073285, 0.00073165, 0.00071567,\n",
      "       0.00071208, 0.00072365, 0.00073386, 0.00071209, 0.00072542,\n",
      "       0.00072773, 0.00073236, 0.00071575, 0.00072918, 0.00072181,\n",
      "       0.00073124, 0.0007294 , 0.00072597, 0.00073021, 0.00072614,\n",
      "       0.00072888, 0.00073052, 0.0007252 , 0.00072237, 0.00072994,\n",
      "       0.00073296, 0.0007297 , 0.00073108, 0.00071458, 0.00073677,\n",
      "       0.00072035, 0.00073095, 0.00072235, 0.00072534, 0.00072457,\n",
      "       0.0007159 , 0.00072097, 0.00072906, 0.00071074, 0.00072758,\n",
      "       0.00073246, 0.00071752, 0.00072297, 0.00073434, 0.00073356,\n",
      "       0.00071931, 0.00071985, 0.00072864, 0.00072827, 0.00072774,\n",
      "       0.0007269 , 0.00072544, 0.000728  , 0.00071715, 0.00073677,\n",
      "       0.00072974, 0.00073673, 0.00072002, 0.00072649, 0.00071866,\n",
      "       0.00072719, 0.0007311 , 0.00072835, 0.00073556, 0.00072109,\n",
      "       0.00071948, 0.00072168, 0.00073309, 0.0007273 , 0.00072437,\n",
      "       0.00073016, 0.00072393, 0.00073029, 0.00073673, 0.00070011,\n",
      "       0.00072837, 0.00073684, 0.00072945, 0.00071637, 0.00073546,\n",
      "       0.00072007, 0.00072471, 0.00072256, 0.00071351, 0.00072245,\n",
      "       0.00071971, 0.00073143, 0.00073153, 0.00073321, 0.00072493,\n",
      "       0.00070529, 0.00072097, 0.0007199 , 0.00071436, 0.00072606,\n",
      "       0.00072604, 0.0007346 , 0.00072652, 0.00073815, 0.00072809,\n",
      "       0.00072799, 0.00073062, 0.00072829, 0.00071872, 0.00071446,\n",
      "       0.00072485, 0.00071704, 0.0007295 , 0.00073223, 0.00072964,\n",
      "       0.00073054, 0.00072044, 0.00073039, 0.00073553, 0.00071667,\n",
      "       0.00072528, 0.0007389 , 0.00073312, 0.00071585, 0.00073191,\n",
      "       0.00072434, 0.00072408, 0.00073263, 0.00072253, 0.00073069,\n",
      "       0.00073494, 0.00073141, 0.00069628, 0.00073229, 0.00072206,\n",
      "       0.00073541, 0.00072712, 0.00072258, 0.00071885, 0.0007356 ,\n",
      "       0.00073005, 0.00072259, 0.00071901, 0.00073091, 0.00072145,\n",
      "       0.00072534, 0.000724  , 0.00071622, 0.00070582, 0.000729  ,\n",
      "       0.00071564, 0.00073231, 0.00073335, 0.00071363, 0.000732  ,\n",
      "       0.0007241 , 0.00072756, 0.00071806, 0.00072271, 0.00072142,\n",
      "       0.00072626, 0.00072377, 0.00072244, 0.00072285, 0.00072782,\n",
      "       0.00072708, 0.00072961, 0.00072101, 0.00071237, 0.00072896,\n",
      "       0.00072052, 0.00072367, 0.00073217, 0.00071315, 0.00073366,\n",
      "       0.00072468, 0.00072642, 0.00072726, 0.00072917, 0.00069885,\n",
      "       0.0007227 , 0.00072051, 0.0007111 , 0.00073267, 0.00072306,\n",
      "       0.00071753, 0.00072386, 0.00070029, 0.00073159, 0.00072   ,\n",
      "       0.00073001, 0.00071719, 0.00070025, 0.00073765, 0.0007291 ,\n",
      "       0.00072592, 0.00072035, 0.0007348 , 0.00072377, 0.00073378,\n",
      "       0.00072733, 0.00072526, 0.00072836, 0.00072254, 0.00071838,\n",
      "       0.00072135, 0.0007262 , 0.00071156, 0.00073001, 0.00072514,\n",
      "       0.00072405, 0.00072541, 0.00073474, 0.00072892, 0.00071978,\n",
      "       0.0007239 , 0.00072712, 0.00073241, 0.00072377, 0.00071216,\n",
      "       0.00073779, 0.0007243 , 0.00072476, 0.00072462, 0.00072173,\n",
      "       0.00072611, 0.00071123, 0.00073235, 0.00071603, 0.00072405,\n",
      "       0.00072443, 0.00072793, 0.00073023, 0.00072104, 0.00072865,\n",
      "       0.00071374, 0.0007328 , 0.00072024, 0.00071877, 0.00072056,\n",
      "       0.00073637, 0.00073245, 0.00071789, 0.00070809, 0.00072383,\n",
      "       0.0007177 , 0.00073205, 0.00073063, 0.00071944, 0.00069738,\n",
      "       0.00072304, 0.00072569, 0.0007342 , 0.00072953, 0.00073139,\n",
      "       0.00073529, 0.00072492, 0.00072862, 0.00073203, 0.00073654,\n",
      "       0.00072506, 0.00072915, 0.00072967, 0.00070968, 0.00073063,\n",
      "       0.00073185, 0.00073   , 0.00073182, 0.00072696, 0.0007283 ,\n",
      "       0.00070448, 0.00071526, 0.00073714, 0.00071372, 0.0007301 ,\n",
      "       0.00073021, 0.00073451, 0.00073282, 0.00073139, 0.00073507,\n",
      "       0.0007352 , 0.00072961, 0.00073304, 0.00069356, 0.00072684,\n",
      "       0.0007262 , 0.00071973, 0.00072048, 0.00072353, 0.00072383,\n",
      "       0.00072576, 0.0007242 , 0.00072489, 0.00072867, 0.00070754,\n",
      "       0.00071892, 0.00072996, 0.0007173 , 0.00070475, 0.00072064,\n",
      "       0.00072658, 0.00071684, 0.00072753, 0.00071288, 0.00071443,\n",
      "       0.00072148, 0.00071157, 0.0007242 , 0.00072521, 0.00072664,\n",
      "       0.00072356, 0.00073493, 0.00073641, 0.00072816, 0.00073678,\n",
      "       0.00072585, 0.00071423, 0.0007202 , 0.00072199, 0.00073138,\n",
      "       0.00072204, 0.00073594, 0.00072264, 0.00070969, 0.00071207,\n",
      "       0.00071972, 0.00072464, 0.00072773, 0.00073296, 0.0007279 ,\n",
      "       0.00072069, 0.00072948, 0.0007206 , 0.00073741, 0.00073209,\n",
      "       0.00071044, 0.0007204 , 0.00073339, 0.00071857, 0.00072431,\n",
      "       0.00070944, 0.00073048, 0.000729  , 0.00072909, 0.0007274 ,\n",
      "       0.00073135, 0.00071652, 0.00072996, 0.0007284 , 0.00070519,\n",
      "       0.00073153, 0.00072592, 0.00073186, 0.00072213, 0.00072999,\n",
      "       0.0007327 , 0.00073232, 0.00072525, 0.00072861, 0.00072741,\n",
      "       0.0007327 , 0.00072985, 0.0007275 , 0.00073318, 0.00072743,\n",
      "       0.00073315, 0.0007292 , 0.00073174, 0.00072403, 0.00073   ,\n",
      "       0.00072661, 0.00073339, 0.00071485, 0.0007289 , 0.00072433,\n",
      "       0.00071872, 0.00072508, 0.00073154, 0.00072812, 0.00072686,\n",
      "       0.00072459, 0.00073534, 0.00071829, 0.00072921, 0.00072547,\n",
      "       0.00073729, 0.00072119, 0.00073597, 0.00071864, 0.00072025,\n",
      "       0.00072724, 0.00073463, 0.00069828, 0.00072355, 0.00073469,\n",
      "       0.00072875, 0.00073349, 0.00073177, 0.00072721, 0.00072727,\n",
      "       0.0007247 , 0.00072434, 0.00073421, 0.00072493, 0.00072861,\n",
      "       0.00072141, 0.00072032, 0.00072228, 0.00073143, 0.00073051,\n",
      "       0.00072593, 0.00072966, 0.00072702, 0.0007279 , 0.00072427,\n",
      "       0.00072592, 0.00072833, 0.00071561, 0.00072921, 0.00072015,\n",
      "       0.00073642, 0.00072914, 0.0007326 , 0.00070633, 0.00072292,\n",
      "       0.00072902, 0.00072753, 0.00072379, 0.00071847, 0.00071033,\n",
      "       0.00072888, 0.00073483, 0.00073199, 0.0007278 , 0.00073103,\n",
      "       0.0007337 , 0.00072961, 0.00070998, 0.00072564, 0.00070663,\n",
      "       0.00072321, 0.00072271, 0.00072188, 0.00072513, 0.00073497,\n",
      "       0.00073301, 0.00072657, 0.00073703, 0.00072703, 0.00072716,\n",
      "       0.00072706, 0.00072429, 0.00071062, 0.00070869, 0.00073119,\n",
      "       0.00072626, 0.00073016, 0.00072396, 0.00073189, 0.0007277 ,\n",
      "       0.00073463, 0.00072366, 0.00071793, 0.0007262 , 0.00072253,\n",
      "       0.00071669, 0.00072623, 0.00073552, 0.00073745, 0.00073502,\n",
      "       0.00071019, 0.00071224, 0.00071688, 0.00072568, 0.00072813,\n",
      "       0.00072896, 0.00073161, 0.00072969, 0.00072441, 0.00073189,\n",
      "       0.00073135, 0.00073313, 0.00073162, 0.00071834, 0.00073385,\n",
      "       0.00072344, 0.0007162 , 0.00071206, 0.00073086, 0.00071873,\n",
      "       0.00070491, 0.00071796, 0.00073543, 0.00072509, 0.00072805,\n",
      "       0.0007221 , 0.00072723, 0.00073389, 0.00073125, 0.00072695,\n",
      "       0.00073084, 0.00071393, 0.00069653, 0.00073117, 0.00072658,\n",
      "       0.00073408, 0.00072656, 0.00072935, 0.00071194, 0.00072653,\n",
      "       0.00073266, 0.00072299, 0.00073244, 0.00071171, 0.00073523,\n",
      "       0.00073142, 0.00073548, 0.00071623, 0.0007261 , 0.00073693,\n",
      "       0.0007283 , 0.00072658, 0.00071993, 0.00072736, 0.00071981,\n",
      "       0.00073072, 0.00072572, 0.0007191 , 0.00073226, 0.00073237,\n",
      "       0.00073384, 0.00072202, 0.000723  , 0.00073158, 0.00072978,\n",
      "       0.00073085, 0.00073401, 0.00071871, 0.00073325, 0.00073469,\n",
      "       0.00070396, 0.00072991, 0.00073103, 0.00072362, 0.00072148,\n",
      "       0.00073111, 0.00072474, 0.00072604, 0.00073455, 0.00072751,\n",
      "       0.00072368, 0.00072802, 0.00072086, 0.00073009, 0.00071417,\n",
      "       0.00073409, 0.00073156, 0.00073527, 0.00071938, 0.0007062 ,\n",
      "       0.0007325 , 0.00071848, 0.00073249, 0.00073753, 0.00072527,\n",
      "       0.0007221 , 0.00072108, 0.00073134, 0.00069364, 0.00072402,\n",
      "       0.00073083, 0.00069858, 0.00072375, 0.00072577, 0.00072931,\n",
      "       0.00073568, 0.00072702, 0.00072712, 0.00072638, 0.00072543,\n",
      "       0.00072978, 0.0007226 , 0.00072898, 0.00071594, 0.0007171 ,\n",
      "       0.0007234 , 0.00073076, 0.00073154, 0.00072199, 0.00073321,\n",
      "       0.00072799, 0.00071919, 0.00073012, 0.0007213 , 0.00072305,\n",
      "       0.00072237, 0.00072881, 0.00072933, 0.00072232, 0.00072238,\n",
      "       0.00070988, 0.00073188, 0.00071887, 0.00073038, 0.00072813,\n",
      "       0.0007279 , 0.00072741, 0.00073097, 0.00072229, 0.00072363,\n",
      "       0.00072794, 0.00072832, 0.00072322, 0.00072732, 0.00072703,\n",
      "       0.00072837, 0.00073504, 0.00072152, 0.00073352, 0.00072685,\n",
      "       0.0007289 , 0.00073558, 0.00072761, 0.00072604, 0.00072341,\n",
      "       0.00073372, 0.00073347, 0.00073537, 0.00071895, 0.000721  ,\n",
      "       0.00071461, 0.00071229, 0.00072154, 0.00073133, 0.00072659,\n",
      "       0.00073213, 0.00072848, 0.00073225, 0.0007342 , 0.00073213,\n",
      "       0.00073576, 0.00072508, 0.00072333, 0.00072415, 0.00072093,\n",
      "       0.00072775, 0.00072493, 0.00073744, 0.00072828, 0.00073866,\n",
      "       0.00072774, 0.00072196, 0.0007379 , 0.00072855, 0.00072231,\n",
      "       0.00072847, 0.00072945, 0.00073058, 0.00072427, 0.00072989,\n",
      "       0.00072947, 0.00073012], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_28/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/conv2d_37/Conv2D\n",
      "index : 109\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.01298760e-07, 1.05231791e-07, 1.02453036e-07, 1.05399494e-07,\n",
      "       1.04522840e-07, 1.03510267e-07, 1.04031891e-07, 1.03773424e-07,\n",
      "       1.00619467e-07, 1.04473038e-07, 1.03436236e-07, 1.03982750e-07,\n",
      "       1.04508473e-07, 1.03560424e-07, 1.03688436e-07, 1.05348313e-07,\n",
      "       1.02803227e-07, 1.04941321e-07, 1.04768958e-07, 1.02481252e-07,\n",
      "       1.01966641e-07, 1.03623506e-07, 1.05086180e-07, 1.01968070e-07,\n",
      "       1.03877355e-07, 1.04208830e-07, 1.04871368e-07, 1.02492137e-07,\n",
      "       1.04416500e-07, 1.03360094e-07, 1.04710480e-07, 1.04448041e-07,\n",
      "       1.03956147e-07, 1.04563021e-07, 1.03980788e-07, 1.04372866e-07,\n",
      "       1.04608027e-07, 1.03846332e-07, 1.03441423e-07, 1.04524638e-07,\n",
      "       1.04956960e-07, 1.04490454e-07, 1.04687778e-07, 1.02325671e-07,\n",
      "       1.05503133e-07, 1.03151869e-07, 1.04668970e-07, 1.03437273e-07,\n",
      "       1.03866164e-07, 1.03755092e-07, 1.02514591e-07, 1.03240012e-07,\n",
      "       1.04399405e-07, 1.01775832e-07, 1.04187038e-07, 1.04885061e-07,\n",
      "       1.02746796e-07, 1.03527235e-07, 1.05155479e-07, 1.05043100e-07,\n",
      "       1.03002172e-07, 1.03079508e-07, 1.04338753e-07, 1.04285249e-07,\n",
      "       1.04209207e-07, 1.04089615e-07, 1.03880417e-07, 1.04246801e-07,\n",
      "       1.02692880e-07, 1.05502146e-07, 1.04496387e-07, 1.05497676e-07,\n",
      "       1.03104242e-07, 1.04030953e-07, 1.02909162e-07, 1.04131509e-07,\n",
      "       1.04691495e-07, 1.04297328e-07, 1.05330095e-07, 1.03257271e-07,\n",
      "       1.03026387e-07, 1.03342067e-07, 1.04976124e-07, 1.04146935e-07,\n",
      "       1.03727785e-07, 1.04555888e-07, 1.03664213e-07, 1.04574163e-07,\n",
      "       1.05496383e-07, 1.00252834e-07, 1.04299502e-07, 1.05512669e-07,\n",
      "       1.04454053e-07, 1.02580856e-07, 1.05314847e-07, 1.03112008e-07,\n",
      "       1.03776429e-07, 1.03467627e-07, 1.02172528e-07, 1.03452514e-07,\n",
      "       1.03060415e-07, 1.04737545e-07, 1.04751841e-07, 1.04992957e-07,\n",
      "       1.03806784e-07, 1.00994825e-07, 1.03240851e-07, 1.03087530e-07,\n",
      "       1.02293335e-07, 1.03968439e-07, 1.03966485e-07, 1.05192704e-07,\n",
      "       1.04035003e-07, 1.05701083e-07, 1.04259861e-07, 1.04245515e-07,\n",
      "       1.04621492e-07, 1.04288475e-07, 1.02917497e-07, 1.02308114e-07,\n",
      "       1.03795287e-07, 1.02677035e-07, 1.04461918e-07, 1.04851985e-07,\n",
      "       1.04481721e-07, 1.04610073e-07, 1.03164489e-07, 1.04589695e-07,\n",
      "       1.05325739e-07, 1.02624284e-07, 1.03857516e-07, 1.05808212e-07,\n",
      "       1.04979925e-07, 1.02506888e-07, 1.04806276e-07, 1.03722847e-07,\n",
      "       1.03686077e-07, 1.04910221e-07, 1.03463378e-07, 1.04631745e-07,\n",
      "       1.05240517e-07, 1.04735719e-07, 9.97045362e-08, 1.04861307e-07,\n",
      "       1.03396388e-07, 1.05308544e-07, 1.04120559e-07, 1.03470917e-07,\n",
      "       1.02935978e-07, 1.05334721e-07, 1.04540511e-07, 1.03472573e-07,\n",
      "       1.02960072e-07, 1.04663272e-07, 1.03309290e-07, 1.03866483e-07,\n",
      "       1.03674431e-07, 1.02560399e-07, 1.01070924e-07, 1.04389578e-07,\n",
      "       1.02477202e-07, 1.04864192e-07, 1.05012553e-07, 1.02189723e-07,\n",
      "       1.04819037e-07, 1.03689096e-07, 1.04183371e-07, 1.02823648e-07,\n",
      "       1.03488709e-07, 1.03305332e-07, 1.03997394e-07, 1.03641135e-07,\n",
      "       1.03450951e-07, 1.03508967e-07, 1.04221115e-07, 1.04115003e-07,\n",
      "       1.04476797e-07, 1.03246556e-07, 1.02009309e-07, 1.04383716e-07,\n",
      "       1.03175907e-07, 1.03626505e-07, 1.04843998e-07, 1.02119969e-07,\n",
      "       1.05057282e-07, 1.03771875e-07, 1.04021019e-07, 1.04141314e-07,\n",
      "       1.04414781e-07, 1.00072505e-07, 1.03487778e-07, 1.03174671e-07,\n",
      "       1.01827339e-07, 1.04915500e-07, 1.03540145e-07, 1.02746995e-07,\n",
      "       1.03654266e-07, 1.00278264e-07, 1.04761206e-07, 1.03101719e-07,\n",
      "       1.04534507e-07, 1.02698692e-07, 1.00273944e-07, 1.05629354e-07,\n",
      "       1.04405139e-07, 1.03948445e-07, 1.03151862e-07, 1.05220430e-07,\n",
      "       1.03641121e-07, 1.05074619e-07, 1.04150438e-07, 1.03854539e-07,\n",
      "       1.04298969e-07, 1.03464409e-07, 1.02869983e-07, 1.03295157e-07,\n",
      "       1.03989692e-07, 1.01893114e-07, 1.04534458e-07, 1.03838005e-07,\n",
      "       1.03681494e-07, 1.03875820e-07, 1.05211591e-07, 1.04378159e-07,\n",
      "       1.03069681e-07, 1.03659538e-07, 1.04121405e-07, 1.04878467e-07,\n",
      "       1.03641511e-07, 1.01978067e-07, 1.05648326e-07, 1.03716829e-07,\n",
      "       1.03783421e-07, 1.03762972e-07, 1.03349755e-07, 1.03976134e-07,\n",
      "       1.01846140e-07, 1.04869571e-07, 1.02532944e-07, 1.03680676e-07,\n",
      "       1.03736006e-07, 1.04236221e-07, 1.04565594e-07, 1.03250841e-07,\n",
      "       1.04339342e-07, 1.02205050e-07, 1.04933640e-07, 1.03135143e-07,\n",
      "       1.02925753e-07, 1.03182110e-07, 1.05445729e-07, 1.04883654e-07,\n",
      "       1.02799362e-07, 1.01396552e-07, 1.03650287e-07, 1.02772518e-07,\n",
      "       1.04827521e-07, 1.04622970e-07, 1.03021371e-07, 9.98629304e-08,\n",
      "       1.03536969e-07, 1.03916484e-07, 1.05134788e-07, 1.04465620e-07,\n",
      "       1.04732159e-07, 1.05290809e-07, 1.03805739e-07, 1.04336237e-07,\n",
      "       1.04823563e-07, 1.05470505e-07, 1.03826601e-07, 1.04412145e-07,\n",
      "       1.04485579e-07, 1.01623890e-07, 1.04623020e-07, 1.04798318e-07,\n",
      "       1.04532717e-07, 1.04794189e-07, 1.04098440e-07, 1.04290557e-07,\n",
      "       1.00879227e-07, 1.02422476e-07, 1.05555706e-07, 1.02201859e-07,\n",
      "       1.04548278e-07, 1.04562680e-07, 1.05179758e-07, 1.04937349e-07,\n",
      "       1.04732344e-07, 1.05259801e-07, 1.05277969e-07, 1.04477529e-07,\n",
      "       1.04969160e-07, 9.93153719e-08, 1.04080918e-07, 1.03989173e-07,\n",
      "       1.03062305e-07, 1.03170457e-07, 1.03607114e-07, 1.03649853e-07,\n",
      "       1.03926453e-07, 1.03703350e-07, 1.03802201e-07, 1.04343044e-07,\n",
      "       1.01317319e-07, 1.02946814e-07, 1.04527992e-07, 1.02714885e-07,\n",
      "       1.00917219e-07, 1.03192413e-07, 1.04042954e-07, 1.02648499e-07,\n",
      "       1.04178923e-07, 1.02082097e-07, 1.02304213e-07, 1.03312651e-07,\n",
      "       1.01894059e-07, 1.03702696e-07, 1.03847697e-07, 1.04052276e-07,\n",
      "       1.03611029e-07, 1.05239572e-07, 1.05451441e-07, 1.04269340e-07,\n",
      "       1.05504633e-07, 1.03939215e-07, 1.02275173e-07, 1.03129992e-07,\n",
      "       1.03386682e-07, 1.04730262e-07, 1.03393099e-07, 1.05383990e-07,\n",
      "       1.03479550e-07, 1.01624437e-07, 1.01965448e-07, 1.03060955e-07,\n",
      "       1.03765302e-07, 1.04208581e-07, 1.04957124e-07, 1.04232313e-07,\n",
      "       1.03199710e-07, 1.04458863e-07, 1.03187084e-07, 1.05594204e-07,\n",
      "       1.04832075e-07, 1.01732397e-07, 1.03159188e-07, 1.05018891e-07,\n",
      "       1.02896060e-07, 1.03717916e-07, 1.01589031e-07, 1.04601597e-07,\n",
      "       1.04389990e-07, 1.04402773e-07, 1.04161174e-07, 1.04726446e-07,\n",
      "       1.02603146e-07, 1.04526983e-07, 1.04303695e-07, 1.00981111e-07,\n",
      "       1.04751813e-07, 1.03948494e-07, 1.04800279e-07, 1.03405988e-07,\n",
      "       1.04531217e-07, 1.04920169e-07, 1.04865912e-07, 1.03853090e-07,\n",
      "       1.04334553e-07, 1.04162652e-07, 1.04919593e-07, 1.04511670e-07,\n",
      "       1.04174958e-07, 1.04988494e-07, 1.04164819e-07, 1.04984956e-07,\n",
      "       1.04419478e-07, 1.04783005e-07, 1.03677777e-07, 1.04533754e-07,\n",
      "       1.04048183e-07, 1.05019403e-07, 1.02363529e-07, 1.04375140e-07,\n",
      "       1.03721220e-07, 1.02917618e-07, 1.03829095e-07, 1.04753973e-07,\n",
      "       1.04263663e-07, 1.04084073e-07, 1.03759263e-07, 1.05297531e-07,\n",
      "       1.02856923e-07, 1.04419911e-07, 1.03884922e-07, 1.05577072e-07,\n",
      "       1.03271390e-07, 1.05388018e-07, 1.02906007e-07, 1.03137829e-07,\n",
      "       1.04138607e-07, 1.05195745e-07, 9.99913041e-08, 1.03609736e-07,\n",
      "       1.05204329e-07, 1.04354598e-07, 1.05032676e-07, 1.04786679e-07,\n",
      "       1.04133150e-07, 1.04142245e-07, 1.03774020e-07, 1.03722329e-07,\n",
      "       1.05136536e-07, 1.03807395e-07, 1.04333900e-07, 1.03302860e-07,\n",
      "       1.03147286e-07, 1.03428320e-07, 1.04738120e-07, 1.04605896e-07,\n",
      "       1.03950732e-07, 1.04484130e-07, 1.04106199e-07, 1.04232988e-07,\n",
      "       1.03713127e-07, 1.03948437e-07, 1.04293711e-07, 1.02472804e-07,\n",
      "       1.04420359e-07, 1.03122268e-07, 1.05452216e-07, 1.04409956e-07,\n",
      "       1.04906093e-07, 1.01144309e-07, 1.03519582e-07, 1.04392896e-07,\n",
      "       1.04180167e-07, 1.03644609e-07, 1.02881636e-07, 1.01716530e-07,\n",
      "       1.04372731e-07, 1.05224409e-07, 1.04818199e-07, 1.04218607e-07,\n",
      "       1.04680645e-07, 1.05063037e-07, 1.04477436e-07, 1.01667204e-07,\n",
      "       1.03909350e-07, 1.01187055e-07, 1.03561227e-07, 1.03489164e-07,\n",
      "       1.03370191e-07, 1.03835532e-07, 1.05245135e-07, 1.04964769e-07,\n",
      "       1.04042073e-07, 1.05540146e-07, 1.04108295e-07, 1.04126933e-07,\n",
      "       1.04112381e-07, 1.03716083e-07, 1.01757848e-07, 1.01481739e-07,\n",
      "       1.04704398e-07, 1.03998019e-07, 1.04556591e-07, 1.03668860e-07,\n",
      "       1.04803298e-07, 1.04203920e-07, 1.05196953e-07, 1.03625233e-07,\n",
      "       1.02804691e-07, 1.03988718e-07, 1.03463186e-07, 1.02627894e-07,\n",
      "       1.03993976e-07, 1.05323906e-07, 1.05599732e-07, 1.05252830e-07,\n",
      "       1.01697189e-07, 1.01990423e-07, 1.02654887e-07, 1.03914715e-07,\n",
      "       1.04265546e-07, 1.04384078e-07, 1.04764332e-07, 1.04489501e-07,\n",
      "       1.03733171e-07, 1.04803959e-07, 1.04727057e-07, 1.04981446e-07,\n",
      "       1.04765412e-07, 1.02863218e-07, 1.05084645e-07, 1.03594516e-07,\n",
      "       1.02557543e-07, 1.01964027e-07, 1.04656571e-07, 1.02919856e-07,\n",
      "       1.00941229e-07, 1.02808563e-07, 1.05311500e-07, 1.03830672e-07,\n",
      "       1.04253694e-07, 1.03401369e-07, 1.04136468e-07, 1.05090088e-07,\n",
      "       1.04712768e-07, 1.04096394e-07, 1.04653857e-07, 1.02232050e-07,\n",
      "       9.97405394e-08, 1.04700632e-07, 1.04043387e-07, 1.05117870e-07,\n",
      "       1.04040154e-07, 1.04440758e-07, 1.01947244e-07, 1.04036609e-07,\n",
      "       1.04914925e-07, 1.03529253e-07, 1.04882908e-07, 1.01914331e-07,\n",
      "       1.05282460e-07, 1.04736472e-07, 1.05318009e-07, 1.02561785e-07,\n",
      "       1.03975360e-07, 1.05525437e-07, 1.04290493e-07, 1.04043664e-07,\n",
      "       1.03091622e-07, 1.04155973e-07, 1.03073802e-07, 1.04636818e-07,\n",
      "       1.03920890e-07, 1.02972933e-07, 1.04856809e-07, 1.04872001e-07,\n",
      "       1.05083011e-07, 1.03390633e-07, 1.03530880e-07, 1.04759103e-07,\n",
      "       1.04501368e-07, 1.04655626e-07, 1.05108242e-07, 1.02916204e-07,\n",
      "       1.04999359e-07, 1.05204947e-07, 1.00803895e-07, 1.04520268e-07,\n",
      "       1.04680382e-07, 1.03619563e-07, 1.03313234e-07, 1.04692212e-07,\n",
      "       1.03779499e-07, 1.03966869e-07, 1.05184355e-07, 1.04177374e-07,\n",
      "       1.03628643e-07, 1.04249757e-07, 1.03224430e-07, 1.04546849e-07,\n",
      "       1.02266362e-07, 1.05118524e-07, 1.04756715e-07, 1.05287725e-07,\n",
      "       1.03012468e-07, 1.01124691e-07, 1.04891868e-07, 1.02884158e-07,\n",
      "       1.04890276e-07, 1.05612081e-07, 1.03856294e-07, 1.03401590e-07,\n",
      "       1.03256220e-07, 1.04724542e-07, 9.93273517e-08, 1.03676825e-07,\n",
      "       1.04651519e-07, 1.00034761e-07, 1.03638037e-07, 1.03928031e-07,\n",
      "       1.04435138e-07, 1.05346182e-07, 1.04106846e-07, 1.04121177e-07,\n",
      "       1.04015612e-07, 1.03878229e-07, 1.04501822e-07, 1.03474108e-07,\n",
      "       1.04386622e-07, 1.02520218e-07, 1.02686514e-07, 1.03588718e-07,\n",
      "       1.04641515e-07, 1.04753809e-07, 1.03385872e-07, 1.04993369e-07,\n",
      "       1.04245053e-07, 1.02986036e-07, 1.04551013e-07, 1.03287007e-07,\n",
      "       1.03538099e-07, 1.03440655e-07, 1.04363515e-07, 1.04437319e-07,\n",
      "       1.03433926e-07, 1.03441977e-07, 1.01651814e-07, 1.04802325e-07,\n",
      "       1.02938870e-07, 1.04587230e-07, 1.04265567e-07, 1.04233315e-07,\n",
      "       1.04162538e-07, 1.04671649e-07, 1.03429038e-07, 1.03621325e-07,\n",
      "       1.04238431e-07, 1.04292603e-07, 1.03561810e-07, 1.04149201e-07,\n",
      "       1.04108437e-07, 1.04299268e-07, 1.05255438e-07, 1.03318740e-07,\n",
      "       1.05036790e-07, 1.04081622e-07, 1.04376412e-07, 1.05331686e-07,\n",
      "       1.04191734e-07, 1.03966720e-07, 1.03589279e-07, 1.05065439e-07,\n",
      "       1.05029528e-07, 1.05302277e-07, 1.02951027e-07, 1.03245100e-07,\n",
      "       1.02330233e-07, 1.01996946e-07, 1.03322492e-07, 1.04723924e-07,\n",
      "       1.04044503e-07, 1.04838236e-07, 1.04315063e-07, 1.04855580e-07,\n",
      "       1.05135420e-07, 1.04838641e-07, 1.05358076e-07, 1.03828889e-07,\n",
      "       1.03577605e-07, 1.03696145e-07, 1.03234683e-07, 1.04211189e-07,\n",
      "       1.03807899e-07, 1.05598616e-07, 1.04287366e-07, 1.05772848e-07,\n",
      "       1.04209647e-07, 1.03381929e-07, 1.05663943e-07, 1.04325281e-07,\n",
      "       1.03432050e-07, 1.04314857e-07, 1.04454628e-07, 1.04616603e-07,\n",
      "       1.03713454e-07, 1.04517333e-07, 1.04457300e-07, 1.04550274e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_29/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_9/depthwise_conv2d_9/depthwise;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D\n",
      "index : 110\n",
      "shape : [  1   5   5 672]\n",
      "shape_signature : [  1   5   5 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00016413, 0.00015784, 0.00015779, 0.00015312, 0.00015849,\n",
      "       0.00016042, 0.00015119, 0.0001532 , 0.00015524, 0.00015232,\n",
      "       0.00014727, 0.00015696, 0.00015914, 0.00015538, 0.00014294,\n",
      "       0.00016003, 0.00016444, 0.00014834, 0.00014504, 0.00015797,\n",
      "       0.00016477, 0.00016089, 0.00016119, 0.00015882, 0.00015823,\n",
      "       0.00016187, 0.00016405, 0.00014627, 0.00015089, 0.00014508,\n",
      "       0.00014962, 0.00016497, 0.00015572, 0.00016014, 0.0001535 ,\n",
      "       0.00015777, 0.00015742, 0.00016077, 0.00015194, 0.00015005,\n",
      "       0.00015884, 0.00015991, 0.00015943, 0.00016426, 0.00015525,\n",
      "       0.00016351, 0.00015761, 0.00014069, 0.00015222, 0.00016386,\n",
      "       0.00016553, 0.00015263, 0.00016625, 0.0001563 , 0.00015585,\n",
      "       0.00016572, 0.00016155, 0.00015879, 0.00015071, 0.00015886,\n",
      "       0.00014874, 0.00016384, 0.00015924, 0.00015559, 0.00013991,\n",
      "       0.00016274, 0.00015961, 0.00016169, 0.00015845, 0.00015164,\n",
      "       0.0001497 , 0.00014655, 0.00015423, 0.0001602 , 0.00015173,\n",
      "       0.00015166, 0.00014988, 0.0001575 , 0.00016046, 0.00016451,\n",
      "       0.0001656 , 0.00016515, 0.00016094, 0.00016403, 0.000157  ,\n",
      "       0.00016189, 0.00015699, 0.00015177, 0.00015914, 0.00015076,\n",
      "       0.0001552 , 0.00014551, 0.00015931, 0.0001476 , 0.00015117,\n",
      "       0.00016113, 0.00015678, 0.00015612, 0.00015804, 0.00015027,\n",
      "       0.00016072, 0.00016372, 0.00015705, 0.00014526, 0.00016042,\n",
      "       0.00014937, 0.00015215, 0.0001606 , 0.00014732, 0.00015212,\n",
      "       0.00016344, 0.0001632 , 0.00015878, 0.00015732, 0.00016281,\n",
      "       0.00015543, 0.00015617, 0.00016023, 0.00015213, 0.00014498,\n",
      "       0.00015465, 0.00013728, 0.0001587 , 0.00015872, 0.00015066,\n",
      "       0.0001602 , 0.00015661, 0.00015487, 0.00015729, 0.0001591 ,\n",
      "       0.00016649, 0.00015985, 0.00015785, 0.00016383, 0.00016173,\n",
      "       0.00015888, 0.00015835, 0.00014833, 0.00015706, 0.00014989,\n",
      "       0.00015221, 0.00016247, 0.00015323, 0.00016044, 0.00016258,\n",
      "       0.00015717, 0.00013509, 0.00016092, 0.00014791, 0.00015799,\n",
      "       0.0001567 , 0.00015437, 0.00015823, 0.00015538, 0.00015649,\n",
      "       0.00015994, 0.00016219, 0.00014631, 0.00016248, 0.00015567,\n",
      "       0.00015574, 0.00015636, 0.00013944, 0.00015274, 0.00016068,\n",
      "       0.00016818, 0.00016153, 0.00014552, 0.00016141, 0.00014625,\n",
      "       0.00014287, 0.00015878, 0.00015805, 0.00013802, 0.00015775,\n",
      "       0.00016453, 0.00016341, 0.00014548, 0.00015398, 0.00016256,\n",
      "       0.00015964, 0.00016682, 0.00014732, 0.00015482, 0.00015935,\n",
      "       0.00016442, 0.00015975, 0.00016283, 0.00015436, 0.00015239,\n",
      "       0.00014658, 0.00014782, 0.00015774, 0.00015649, 0.0001603 ,\n",
      "       0.00015032, 0.00015607, 0.00015797, 0.00015655, 0.00015425,\n",
      "       0.00015221, 0.0001654 , 0.00014628, 0.00015152, 0.00014253,\n",
      "       0.00015962, 0.00014197, 0.00016545, 0.00015147, 0.00015663,\n",
      "       0.00015512, 0.00016075, 0.00014043, 0.00016151, 0.00015962,\n",
      "       0.00016128, 0.00013375, 0.00015848, 0.00016261, 0.00016086,\n",
      "       0.00016207, 0.00016387, 0.00015909, 0.00015476, 0.00016466,\n",
      "       0.00015791, 0.00015338, 0.00014858, 0.00016403, 0.00012859,\n",
      "       0.00015573, 0.00015884, 0.00015476, 0.00015642, 0.00015993,\n",
      "       0.00015674, 0.00015501, 0.00015452, 0.00015905, 0.00014949,\n",
      "       0.00014894, 0.00015848, 0.00015525, 0.0001619 , 0.00016141,\n",
      "       0.00016378, 0.00016153, 0.00015851, 0.00015474, 0.00015851,\n",
      "       0.00014984, 0.00016335, 0.00016112, 0.00015753, 0.00016298,\n",
      "       0.00015173, 0.00016488, 0.00016135, 0.00014122, 0.00015507,\n",
      "       0.00015852, 0.00015532, 0.00016347, 0.00015806, 0.00014793,\n",
      "       0.00015296, 0.00016215, 0.00015975, 0.00015852, 0.00015018,\n",
      "       0.00013991, 0.00015867, 0.00016075, 0.00014758, 0.00015849,\n",
      "       0.0001685 , 0.00016123, 0.00016398, 0.0001575 , 0.00015541,\n",
      "       0.00015524, 0.00015535, 0.00015976, 0.00015237, 0.00015774,\n",
      "       0.00016308, 0.00015743, 0.0001566 , 0.00015865, 0.00014493,\n",
      "       0.00014912, 0.00016179, 0.00015527, 0.00015131, 0.00015819,\n",
      "       0.00015175, 0.00016473, 0.00014542, 0.00014214, 0.00016313,\n",
      "       0.00016191, 0.00014842, 0.00015684, 0.00015406, 0.00016313,\n",
      "       0.00014844, 0.00015836, 0.00015494, 0.00015536, 0.00015352,\n",
      "       0.00015845, 0.0001564 , 0.0001491 , 0.00015519, 0.00016194,\n",
      "       0.00016085, 0.00016455, 0.00015413, 0.0001639 , 0.00016428,\n",
      "       0.0001489 , 0.00015601, 0.00016102, 0.00015114, 0.00015057,\n",
      "       0.00015945, 0.00015338, 0.00016306, 0.00015924, 0.00016212,\n",
      "       0.00016449, 0.00014222, 0.00015799, 0.00015499, 0.0001603 ,\n",
      "       0.00015748, 0.00016119, 0.00015928, 0.00015611, 0.00014694,\n",
      "       0.00016618, 0.00012367, 0.00015491, 0.0001693 , 0.00016953,\n",
      "       0.00014745, 0.00015117, 0.0001572 , 0.00013986, 0.00014992,\n",
      "       0.00015097, 0.00015539, 0.00016507, 0.00016289, 0.00015963,\n",
      "       0.00016425, 0.00016308, 0.00015507, 0.00015525, 0.00016627,\n",
      "       0.00014866, 0.00014955, 0.00015854, 0.00016436, 0.00016281,\n",
      "       0.00016135, 0.00015541, 0.0001626 , 0.00015613, 0.00015779,\n",
      "       0.00014824, 0.00016347, 0.00016888, 0.00016555, 0.00015391,\n",
      "       0.0001523 , 0.00015931, 0.00015554, 0.0001641 , 0.00015752,\n",
      "       0.00016084, 0.00014716, 0.00014692, 0.00015734, 0.00015196,\n",
      "       0.00015974, 0.00015865, 0.00016213, 0.00016076, 0.00015299,\n",
      "       0.00015929, 0.00015402, 0.0001491 , 0.00015626, 0.0001583 ,\n",
      "       0.00015657, 0.00015183, 0.00016187, 0.00015137, 0.00016264,\n",
      "       0.00016372, 0.00016247, 0.00015795, 0.00016428, 0.00014177,\n",
      "       0.00016241, 0.00016594, 0.00016846, 0.00014684, 0.0001551 ,\n",
      "       0.00015808, 0.00015267, 0.00013332, 0.00014102, 0.00015863,\n",
      "       0.00015118, 0.00016303, 0.00015742, 0.00016345, 0.00016581,\n",
      "       0.00016032, 0.00015664, 0.00015876, 0.00014811, 0.00015891,\n",
      "       0.00015961, 0.0001626 , 0.00015863, 0.00015719, 0.00016631,\n",
      "       0.00016165, 0.00015799, 0.00015385, 0.0001679 , 0.00015959,\n",
      "       0.00016059, 0.0001508 , 0.00016599, 0.00015607, 0.00016247,\n",
      "       0.00015522, 0.00016304, 0.00014773, 0.00016164, 0.00016105,\n",
      "       0.00014529, 0.00014491, 0.00016275, 0.00016166, 0.00016807,\n",
      "       0.00016207, 0.00016101, 0.00015971, 0.0001621 , 0.00014034,\n",
      "       0.00016123, 0.0001594 , 0.00016331, 0.00014756, 0.00015969,\n",
      "       0.00016293, 0.00016007, 0.00015791, 0.00015529, 0.00015223,\n",
      "       0.00016297, 0.00014812, 0.00015043, 0.00016225, 0.00015445,\n",
      "       0.00016537, 0.00016026, 0.00015279, 0.00015252, 0.00014859,\n",
      "       0.00015532, 0.00016156, 0.00015484, 0.00015738, 0.00015179,\n",
      "       0.00016143, 0.00015604, 0.00016592, 0.0001544 , 0.00015254,\n",
      "       0.0001673 , 0.0001574 , 0.00015609, 0.00015129, 0.00014494,\n",
      "       0.0001563 , 0.00015749, 0.00016483, 0.00016427, 0.00016636,\n",
      "       0.00014937, 0.00015804, 0.0001558 , 0.00015743, 0.00014882,\n",
      "       0.00016015, 0.00016118, 0.00016215, 0.0001537 , 0.0001543 ,\n",
      "       0.00015782, 0.00016384, 0.00014761, 0.00015347, 0.00016564,\n",
      "       0.00016393, 0.00016202, 0.00015251, 0.00015815, 0.00016162,\n",
      "       0.00015678, 0.0001661 , 0.00014489, 0.00015439, 0.00015946,\n",
      "       0.00015789, 0.00016324, 0.00014136, 0.00016283, 0.00015052,\n",
      "       0.00016911, 0.00015915, 0.00015783, 0.00015535, 0.0001604 ,\n",
      "       0.00015413, 0.00016649, 0.00016425, 0.0001613 , 0.00014612,\n",
      "       0.00016402, 0.00015809, 0.00016595, 0.00015845, 0.00013689,\n",
      "       0.00015846, 0.00016336, 0.00015981, 0.00016019, 0.00015977,\n",
      "       0.00016244, 0.00016026, 0.00016397, 0.00016045, 0.00015609,\n",
      "       0.00015168, 0.00016468, 0.00015501, 0.00015449, 0.00015466,\n",
      "       0.0001568 , 0.00016131, 0.00016627, 0.0001669 , 0.00016215,\n",
      "       0.00016522, 0.00014962, 0.00015516, 0.00016032, 0.00015694,\n",
      "       0.00013248, 0.00014858, 0.00015756, 0.00016102, 0.00016503,\n",
      "       0.00016239, 0.00016171, 0.00015476, 0.00016298, 0.00015518,\n",
      "       0.0001573 , 0.00016488, 0.00016448, 0.00015871, 0.0001488 ,\n",
      "       0.00016278, 0.00014941, 0.00015237, 0.00016715, 0.0001524 ,\n",
      "       0.00015782, 0.00015164, 0.0001564 , 0.00015639, 0.00015322,\n",
      "       0.00015952, 0.00015993, 0.00015469, 0.00016336, 0.00015931,\n",
      "       0.00016072, 0.00015933, 0.00016181, 0.00016328, 0.00015093,\n",
      "       0.00016032, 0.00016724, 0.00016497, 0.00016052, 0.00015791,\n",
      "       0.00015958, 0.00016053, 0.00012041, 0.00015984, 0.0001605 ,\n",
      "       0.00015941, 0.00015623, 0.00016469, 0.00016443, 0.00016596,\n",
      "       0.00015899, 0.0001652 , 0.00016216, 0.00016229, 0.00016246,\n",
      "       0.00016179, 0.00014856, 0.00015219, 0.00014038, 0.00016131,\n",
      "       0.00016338, 0.00016282, 0.00016449, 0.00015393, 0.00016497,\n",
      "       0.0001359 , 0.00016291, 0.00015261, 0.00016389, 0.00015779,\n",
      "       0.0001503 , 0.00015863, 0.00016194, 0.00016635, 0.00015085,\n",
      "       0.00015336, 0.00014987, 0.0001406 , 0.00015371, 0.00015599,\n",
      "       0.00015965, 0.00015528, 0.00016215, 0.00015647, 0.00015604,\n",
      "       0.00016515, 0.00015885, 0.00015873, 0.00014934, 0.00015884,\n",
      "       0.00016349, 0.00016518, 0.0001552 , 0.00015669, 0.00016216,\n",
      "       0.00014859, 0.00016564, 0.00015383, 0.00015643, 0.00015967,\n",
      "       0.00015232, 0.00015298, 0.00014901, 0.00016706, 0.00016513,\n",
      "       0.00014374, 0.00016807], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_29/FusedBatchNormV3\n",
      "index : 111\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([8.1659079e-09, 7.8528393e-09, 7.8505158e-09, 7.6183886e-09,\n",
      "       7.8851992e-09, 7.9811295e-09, 7.5221918e-09, 7.6223676e-09,\n",
      "       7.7237488e-09, 7.5784126e-09, 7.3270892e-09, 7.8091524e-09,\n",
      "       7.9175058e-09, 7.7304012e-09, 7.1114821e-09, 7.9617513e-09,\n",
      "       8.1813702e-09, 7.3804372e-09, 7.2160082e-09, 7.8595050e-09,\n",
      "       8.1979454e-09, 8.0047844e-09, 8.0196472e-09, 7.9016562e-09,\n",
      "       7.8721856e-09, 8.0533917e-09, 8.1620390e-09, 7.2771438e-09,\n",
      "       7.5072144e-09, 7.2183854e-09, 7.4441107e-09, 8.2077829e-09,\n",
      "       7.7475013e-09, 7.9672082e-09, 7.6368929e-09, 7.8494518e-09,\n",
      "       7.8320337e-09, 7.9985973e-09, 7.5595903e-09, 7.4654007e-09,\n",
      "       7.9026954e-09, 7.9557472e-09, 7.9321332e-09, 8.1723730e-09,\n",
      "       7.7243785e-09, 8.1349336e-09, 7.8414653e-09, 6.9998651e-09,\n",
      "       7.5735045e-09, 8.1527247e-09, 8.2356246e-09, 7.5939495e-09,\n",
      "       8.2712068e-09, 7.7765199e-09, 7.7539175e-09, 8.2450970e-09,\n",
      "       8.0374134e-09, 7.9004554e-09, 7.4982749e-09, 7.9038251e-09,\n",
      "       7.4004549e-09, 8.1514147e-09, 7.9225613e-09, 7.7409315e-09,\n",
      "       6.9608634e-09, 8.0966620e-09, 7.9412850e-09, 8.0444860e-09,\n",
      "       7.8833926e-09, 7.5443580e-09, 7.4478885e-09, 7.2912401e-09,\n",
      "       7.6733482e-09, 7.9702485e-09, 7.5492110e-09, 7.5453190e-09,\n",
      "       7.4568591e-09, 7.8359026e-09, 7.9835152e-09, 8.1850091e-09,\n",
      "       8.2392093e-09, 8.2169027e-09, 8.0070937e-09, 8.1611695e-09,\n",
      "       7.8110505e-09, 8.0543137e-09, 7.8105780e-09, 7.5510558e-09,\n",
      "       7.9178211e-09, 7.5008879e-09, 7.7218960e-09, 7.2394197e-09,\n",
      "       7.9262694e-09, 7.3433224e-09, 7.5210531e-09, 8.0166016e-09,\n",
      "       7.8002484e-09, 7.7674756e-09, 7.8629112e-09, 7.4764888e-09,\n",
      "       7.9963387e-09, 8.1455056e-09, 7.8135942e-09, 7.2271531e-09,\n",
      "       7.9811810e-09, 7.4314848e-09, 7.5699518e-09, 7.9905593e-09,\n",
      "       7.3297208e-09, 7.5684756e-09, 8.1317797e-09, 8.1196090e-09,\n",
      "       7.8997804e-09, 7.8271549e-09, 8.1001996e-09, 7.7330231e-09,\n",
      "       7.7699909e-09, 7.9720310e-09, 7.5688655e-09, 7.2129711e-09,\n",
      "       7.6942746e-09, 6.8298749e-09, 7.8956957e-09, 7.8966691e-09,\n",
      "       7.4958555e-09, 7.9705700e-09, 7.7920275e-09, 7.7052871e-09,\n",
      "       7.8257951e-09, 7.9158262e-09, 8.2836111e-09, 7.9528695e-09,\n",
      "       7.8532842e-09, 8.1508711e-09, 8.0465137e-09, 7.9049700e-09,\n",
      "       7.8782909e-09, 7.3797448e-09, 7.8143181e-09, 7.4575235e-09,\n",
      "       7.5726927e-09, 8.0833864e-09, 7.6237958e-09, 7.9825533e-09,\n",
      "       8.0886640e-09, 7.8196667e-09, 6.7210943e-09, 8.0061362e-09,\n",
      "       7.3591910e-09, 7.8603239e-09, 7.7962090e-09, 7.6803621e-09,\n",
      "       7.8722149e-09, 7.7305833e-09, 7.7859301e-09, 7.9573939e-09,\n",
      "       8.0693949e-09, 7.2791893e-09, 8.0837488e-09, 7.7448101e-09,\n",
      "       7.7485494e-09, 7.7791649e-09, 6.9376607e-09, 7.5990965e-09,\n",
      "       7.9940747e-09, 8.3672287e-09, 8.0365563e-09, 7.2400943e-09,\n",
      "       8.0306437e-09, 7.2762432e-09, 7.1081852e-09, 7.8999713e-09,\n",
      "       7.8633615e-09, 6.8667143e-09, 7.8484339e-09, 8.1856255e-09,\n",
      "       8.1299500e-09, 7.2380262e-09, 7.6611260e-09, 8.0880058e-09,\n",
      "       7.9426092e-09, 8.2996063e-09, 7.3294628e-09, 7.7026483e-09,\n",
      "       7.9282918e-09, 8.1802476e-09, 7.9480902e-09, 8.1013836e-09,\n",
      "       7.6799731e-09, 7.5817583e-09, 7.2925452e-09, 7.3544046e-09,\n",
      "       7.8478175e-09, 7.7856237e-09, 7.9754674e-09, 7.4786470e-09,\n",
      "       7.7649958e-09, 7.8594127e-09, 7.7889180e-09, 7.6745259e-09,\n",
      "       7.5731235e-09, 8.2291711e-09, 7.2780924e-09, 7.5384614e-09,\n",
      "       7.0913733e-09, 7.9413187e-09, 7.0634232e-09, 8.2318632e-09,\n",
      "       7.5363094e-09, 7.7927540e-09, 7.7174489e-09, 7.9976807e-09,\n",
      "       6.9869759e-09, 8.0354035e-09, 7.9414431e-09, 8.0240934e-09,\n",
      "       6.6543002e-09, 7.8846325e-09, 8.0904350e-09, 8.0032994e-09,\n",
      "       8.0632585e-09, 8.1531928e-09, 7.9154443e-09, 7.6999624e-09,\n",
      "       8.1924965e-09, 7.8565741e-09, 7.6310682e-09, 7.3921673e-09,\n",
      "       8.1611145e-09, 6.3977939e-09, 7.7479365e-09, 7.9025302e-09,\n",
      "       7.6998532e-09, 7.7822921e-09, 7.9570439e-09, 7.7984934e-09,\n",
      "       7.7119982e-09, 7.6880022e-09, 7.9129805e-09, 7.4373454e-09,\n",
      "       7.4104474e-09, 7.8850810e-09, 7.7241937e-09, 8.0547586e-09,\n",
      "       8.0304154e-09, 8.1483540e-09, 8.0364115e-09, 7.8865190e-09,\n",
      "       7.6990103e-09, 7.8864710e-09, 7.4547746e-09, 8.1273619e-09,\n",
      "       8.0159710e-09, 7.8376052e-09, 8.1087475e-09, 7.5488797e-09,\n",
      "       8.2031271e-09, 8.0277722e-09, 7.0259421e-09, 7.7153182e-09,\n",
      "       7.8867197e-09, 7.7278512e-09, 8.1332390e-09, 7.8639362e-09,\n",
      "       7.3597204e-09, 7.6100966e-09, 8.0673468e-09, 7.9479650e-09,\n",
      "       7.8865954e-09, 7.4718498e-09, 6.9610575e-09, 7.8943492e-09,\n",
      "       7.9977784e-09, 7.3424204e-09, 7.8851397e-09, 8.3832825e-09,\n",
      "       8.0218934e-09, 8.1583567e-09, 7.8358440e-09, 7.7319369e-09,\n",
      "       7.7237674e-09, 7.7293558e-09, 7.9485547e-09, 7.5806650e-09,\n",
      "       7.8482456e-09, 8.1136067e-09, 7.8323694e-09, 7.7911091e-09,\n",
      "       7.8930755e-09, 7.2107897e-09, 7.4193673e-09, 8.0494793e-09,\n",
      "       7.7253057e-09, 7.5283406e-09, 7.8706481e-09, 7.5499607e-09,\n",
      "       8.1956975e-09, 7.2351756e-09, 7.0720430e-09, 8.1160518e-09,\n",
      "       8.0553519e-09, 7.3841844e-09, 7.8033962e-09, 7.6648625e-09,\n",
      "       8.1164400e-09, 7.3851272e-09, 7.8788744e-09, 7.7088869e-09,\n",
      "       7.7297200e-09, 7.6381754e-09, 7.8833180e-09, 7.7815070e-09,\n",
      "       7.4181545e-09, 7.7209767e-09, 8.0571461e-09, 8.0029672e-09,\n",
      "       8.1867846e-09, 7.6684090e-09, 8.1547569e-09, 8.1734060e-09,\n",
      "       7.4084059e-09, 7.7619982e-09, 8.0110327e-09, 7.5197581e-09,\n",
      "       7.4914146e-09, 7.9329867e-09, 7.6310203e-09, 8.1129059e-09,\n",
      "       7.9226590e-09, 8.0659683e-09, 8.1836555e-09, 7.0756347e-09,\n",
      "       7.8603879e-09, 7.7113560e-09, 7.9755145e-09, 7.8352427e-09,\n",
      "       8.0194384e-09, 7.9245543e-09, 7.7671638e-09, 7.3108359e-09,\n",
      "       8.2680920e-09, 6.1531202e-09, 7.7074667e-09, 8.4229983e-09,\n",
      "       8.4346485e-09, 7.3363076e-09, 7.5209998e-09, 7.8210567e-09,\n",
      "       6.9582060e-09, 7.4589206e-09, 7.5110682e-09, 7.7308790e-09,\n",
      "       8.2125649e-09, 8.1042852e-09, 7.9419396e-09, 8.1720879e-09,\n",
      "       8.1136697e-09, 7.7150455e-09, 7.7241253e-09, 8.2723224e-09,\n",
      "       7.3963489e-09, 7.4404709e-09, 7.8876035e-09, 8.1772340e-09,\n",
      "       8.1000522e-09, 8.0276985e-09, 7.7321305e-09, 8.0900220e-09,\n",
      "       7.7679090e-09, 7.8504927e-09, 7.3753812e-09, 8.1331581e-09,\n",
      "       8.4021936e-09, 8.2363751e-09, 7.6573894e-09, 7.5772171e-09,\n",
      "       7.9261655e-09, 7.7383406e-09, 8.1645712e-09, 7.8368938e-09,\n",
      "       8.0023250e-09, 7.3218485e-09, 7.3094970e-09, 7.8283140e-09,\n",
      "       7.5606339e-09, 7.9475893e-09, 7.8931004e-09, 8.0665190e-09,\n",
      "       7.9982101e-09, 7.6115239e-09, 7.9253066e-09, 7.6627042e-09,\n",
      "       7.4180417e-09, 7.7744238e-09, 7.8759488e-09, 7.7896409e-09,\n",
      "       7.5541280e-09, 8.0533145e-09, 7.5310487e-09, 8.0919440e-09,\n",
      "       8.1453440e-09, 8.0831732e-09, 7.8587208e-09, 8.1733234e-09,\n",
      "       7.0534716e-09, 8.0805718e-09, 8.2562357e-09, 8.3815488e-09,\n",
      "       7.3056006e-09, 7.7166806e-09, 7.8650508e-09, 7.5956557e-09,\n",
      "       6.6331318e-09, 7.0163781e-09, 7.8925053e-09, 7.5216926e-09,\n",
      "       8.1110452e-09, 7.8322389e-09, 8.1321554e-09, 8.2494873e-09,\n",
      "       7.9763280e-09, 7.7933731e-09, 7.8989233e-09, 7.3688500e-09,\n",
      "       7.9063032e-09, 7.9408231e-09, 8.0896925e-09, 7.8923481e-09,\n",
      "       7.8207405e-09, 8.2745837e-09, 8.0425266e-09, 7.8605655e-09,\n",
      "       7.6543802e-09, 8.3532825e-09, 7.9401028e-09, 7.9900326e-09,\n",
      "       7.5026021e-09, 8.2583176e-09, 7.7651539e-09, 8.0833003e-09,\n",
      "       7.7225053e-09, 8.1118063e-09, 7.3499336e-09, 8.0421048e-09,\n",
      "       8.0125284e-09, 7.2286364e-09, 7.2097377e-09, 8.0973095e-09,\n",
      "       8.0430480e-09, 8.3621519e-09, 8.0633340e-09, 8.0109652e-09,\n",
      "       7.9461664e-09, 8.0648546e-09, 6.9822192e-09, 8.0215106e-09,\n",
      "       7.9305593e-09, 8.1251335e-09, 7.3415256e-09, 7.9452613e-09,\n",
      "       8.1060838e-09, 7.9640543e-09, 7.8564026e-09, 7.7261770e-09,\n",
      "       7.5739361e-09, 8.1081026e-09, 7.3693829e-09, 7.4842745e-09,\n",
      "       8.0725338e-09, 7.6845543e-09, 8.2274703e-09, 7.9735267e-09,\n",
      "       7.6015532e-09, 7.5883477e-09, 7.3928375e-09, 7.7277065e-09,\n",
      "       8.0380254e-09, 7.7036466e-09, 7.8299589e-09, 7.5517663e-09,\n",
      "       8.0314697e-09, 7.7634805e-09, 8.2548119e-09, 7.6820017e-09,\n",
      "       7.5892004e-09, 8.3236342e-09, 7.8312805e-09, 7.7659550e-09,\n",
      "       7.5273512e-09, 7.2112045e-09, 7.7763733e-09, 7.8356157e-09,\n",
      "       8.2009128e-09, 8.1729228e-09, 8.2769240e-09, 7.4315905e-09,\n",
      "       7.8628544e-09, 7.7514306e-09, 7.8324343e-09, 7.4043855e-09,\n",
      "       7.9679792e-09, 8.0192946e-09, 8.0672029e-09, 7.6471425e-09,\n",
      "       7.6766753e-09, 7.8519209e-09, 8.1515408e-09, 7.3439654e-09,\n",
      "       7.6353706e-09, 8.2410256e-09, 8.1558511e-09, 8.0608631e-09,\n",
      "       7.5876976e-09, 7.8685618e-09, 8.0410372e-09, 7.8000753e-09,\n",
      "       8.2637888e-09, 7.2087483e-09, 7.6811828e-09, 7.9336138e-09,\n",
      "       7.8556335e-09, 8.1218037e-09, 7.0330195e-09, 8.1014386e-09,\n",
      "       7.4885875e-09, 8.4137524e-09, 7.9180875e-09, 7.8525124e-09,\n",
      "       7.7292848e-09, 7.9804234e-09, 7.6686257e-09, 8.2832248e-09,\n",
      "       8.1721359e-09, 8.0252258e-09, 7.2699349e-09, 8.1605265e-09,\n",
      "       7.8652906e-09, 8.2563281e-09, 7.8833891e-09, 6.8106996e-09,\n",
      "       7.8840641e-09, 8.1274552e-09, 7.9509492e-09, 7.9698133e-09,\n",
      "       7.9489242e-09, 8.0816402e-09, 7.9733722e-09, 8.1578149e-09,\n",
      "       7.9826163e-09, 7.7657001e-09, 7.5466273e-09, 8.1935285e-09,\n",
      "       7.7122708e-09, 7.6864417e-09, 7.6948945e-09, 7.8013986e-09,\n",
      "       8.0255615e-09, 8.2725480e-09, 8.3035872e-09, 8.0675981e-09,\n",
      "       8.2201792e-09, 7.4442723e-09, 7.7196303e-09, 7.9764240e-09,\n",
      "       7.8081834e-09, 6.5913874e-09, 7.3923649e-09, 7.8392626e-09,\n",
      "       8.0114049e-09, 8.2107743e-09, 8.0792812e-09, 8.0453910e-09,\n",
      "       7.6997395e-09, 8.1087768e-09, 7.7207858e-09, 7.8263689e-09,\n",
      "       8.2033162e-09, 8.1834051e-09, 7.8965172e-09, 7.4034059e-09,\n",
      "       8.0988363e-09, 7.4334627e-09, 7.5806481e-09, 8.3163245e-09,\n",
      "       7.5825675e-09, 7.8518205e-09, 7.5446138e-09, 7.7812361e-09,\n",
      "       7.7809643e-09, 7.6232265e-09, 7.9364222e-09, 7.9567730e-09,\n",
      "       7.6962632e-09, 8.1275546e-09, 7.9259523e-09, 7.9963653e-09,\n",
      "       7.9269142e-09, 8.0503222e-09, 8.1236795e-09, 7.5091799e-09,\n",
      "       7.9763183e-09, 8.3205425e-09, 8.2077936e-09, 7.9861175e-09,\n",
      "       7.8565598e-09, 7.9397422e-09, 7.9866638e-09, 5.9907377e-09,\n",
      "       7.9527487e-09, 7.9855766e-09, 7.9312708e-09, 7.7727007e-09,\n",
      "       8.1936973e-09, 8.1810603e-09, 8.2570226e-09, 7.9100611e-09,\n",
      "       8.2191587e-09, 8.0679898e-09, 8.0742346e-09, 8.0826581e-09,\n",
      "       8.0494003e-09, 7.3911841e-09, 7.5719573e-09, 6.9844064e-09,\n",
      "       8.0254745e-09, 8.1285068e-09, 8.1007174e-09, 8.1840783e-09,\n",
      "       7.6586497e-09, 8.2077305e-09, 6.7615402e-09, 8.1054425e-09,\n",
      "       7.5926527e-09, 8.1541893e-09, 7.8505478e-09, 7.4779276e-09,\n",
      "       7.8920968e-09, 8.0571985e-09, 8.2761975e-09, 7.5052098e-09,\n",
      "       7.6299624e-09, 7.4566859e-09, 6.9950348e-09, 7.6474374e-09,\n",
      "       7.7608959e-09, 7.9428464e-09, 7.7257871e-09, 8.0676861e-09,\n",
      "       7.7846716e-09, 7.7636679e-09, 8.2167944e-09, 7.9032860e-09,\n",
      "       7.8972233e-09, 7.4302715e-09, 7.9027256e-09, 8.1340596e-09,\n",
      "       8.2179668e-09, 7.7216464e-09, 7.7959736e-09, 8.0680600e-09,\n",
      "       7.3927935e-09, 8.2412157e-09, 7.6535116e-09, 7.7827362e-09,\n",
      "       7.9441564e-09, 7.5785227e-09, 7.6109758e-09, 7.4134765e-09,\n",
      "       8.3116376e-09, 8.2154719e-09, 7.1512711e-09, 8.3618232e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/Conv2D\n",
      "index : 112\n",
      "shape : [168   1   1 672]\n",
      "shape_signature : [168   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00066669, 0.00066613, 0.00066589, 0.00066425, 0.00066527,\n",
      "       0.00066605, 0.00066295, 0.000669  , 0.00066434, 0.00066682,\n",
      "       0.00066643, 0.00066458, 0.00066546, 0.00066376, 0.00066552,\n",
      "       0.00066638, 0.00066966, 0.00066494, 0.00066464, 0.00066472,\n",
      "       0.0006664 , 0.00066543, 0.0006688 , 0.00066536, 0.00066678,\n",
      "       0.00066812, 0.00066425, 0.00066525, 0.00066514, 0.00066507,\n",
      "       0.0006682 , 0.00066521, 0.00066595, 0.00066223, 0.00066528,\n",
      "       0.00066181, 0.00066665, 0.00066472, 0.00066358, 0.00066733,\n",
      "       0.00066639, 0.00066533, 0.00066755, 0.00066422, 0.00066625,\n",
      "       0.00066602, 0.00066576, 0.0006672 , 0.00066854, 0.00066853,\n",
      "       0.00066308, 0.00066911, 0.00066329, 0.00066636, 0.00067137,\n",
      "       0.00066852, 0.00066978, 0.00066571, 0.00066998, 0.00066823,\n",
      "       0.00066651, 0.00066503, 0.00066689, 0.00066352, 0.00066781,\n",
      "       0.00067097, 0.00067077, 0.00066489, 0.00066704, 0.00066919,\n",
      "       0.00066442, 0.00066862, 0.00066525, 0.0006675 , 0.00067015,\n",
      "       0.00066624, 0.00066381, 0.00066136, 0.00066517, 0.00066802,\n",
      "       0.00066716, 0.00066501, 0.00066422, 0.00066613, 0.00066554,\n",
      "       0.00066678, 0.00066755, 0.00066648, 0.00066835, 0.00066229,\n",
      "       0.00066568, 0.00066547, 0.00066906, 0.00066678, 0.00066947,\n",
      "       0.00066485, 0.00066578, 0.00066647, 0.00066674, 0.00066876,\n",
      "       0.00066572, 0.00066651, 0.00066371, 0.00066323, 0.00066798,\n",
      "       0.00066515, 0.00066504, 0.00066346, 0.00066906, 0.00066825,\n",
      "       0.00066464, 0.00066599, 0.00066829, 0.00066708, 0.00066522,\n",
      "       0.00066718, 0.00066631, 0.00066538, 0.00066821, 0.00066683,\n",
      "       0.0006668 , 0.0006658 , 0.00066425, 0.00066414, 0.0006683 ,\n",
      "       0.00066798, 0.00067169, 0.0006683 , 0.00066362, 0.00066679,\n",
      "       0.00066933, 0.0006662 , 0.00067017, 0.00066731, 0.000666  ,\n",
      "       0.0006677 , 0.00066473, 0.00066604, 0.00066764, 0.00066426,\n",
      "       0.00066367, 0.0006678 , 0.00066637, 0.00066545, 0.0006664 ,\n",
      "       0.00066681, 0.00066516, 0.00066537, 0.00066642, 0.00066992,\n",
      "       0.00066425, 0.00066705, 0.00066536, 0.00066889, 0.00066353,\n",
      "       0.00066808, 0.00066782, 0.00066505, 0.00066351, 0.00066707,\n",
      "       0.00066549, 0.00066495, 0.00066777, 0.00066553, 0.00066538,\n",
      "       0.00066529, 0.00066537, 0.00067071], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/BiasAdd/ReadVariableOp/resource\n",
      "index : 113\n",
      "shape : [168]\n",
      "shape_signature : [168]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.4859162e-08, 2.4838577e-08, 2.4829374e-08, 2.4768228e-08,\n",
      "       2.4806329e-08, 2.4835522e-08, 2.4719769e-08, 2.4945308e-08,\n",
      "       2.4771559e-08, 2.4864033e-08, 2.4849630e-08, 2.4780629e-08,\n",
      "       2.4813623e-08, 2.4750024e-08, 2.4815575e-08, 2.4847751e-08,\n",
      "       2.4970181e-08, 2.4794168e-08, 2.4783041e-08, 2.4785802e-08,\n",
      "       2.4848356e-08, 2.4812142e-08, 2.4938107e-08, 2.4809852e-08,\n",
      "       2.4862757e-08, 2.4912564e-08, 2.4768198e-08, 2.4805455e-08,\n",
      "       2.4801437e-08, 2.4799013e-08, 2.4915515e-08, 2.4804070e-08,\n",
      "       2.4831582e-08, 2.4693138e-08, 2.4806701e-08, 2.4677258e-08,\n",
      "       2.4857973e-08, 2.4785948e-08, 2.4743382e-08, 2.4883136e-08,\n",
      "       2.4847960e-08, 2.4808719e-08, 2.4891508e-08, 2.4767056e-08,\n",
      "       2.4842782e-08, 2.4834321e-08, 2.4824704e-08, 2.4878503e-08,\n",
      "       2.4928406e-08, 2.4927907e-08, 2.4724839e-08, 2.4949584e-08,\n",
      "       2.4732383e-08, 2.4846861e-08, 2.5033808e-08, 2.4927505e-08,\n",
      "       2.4974550e-08, 2.4822794e-08, 2.4982025e-08, 2.4916728e-08,\n",
      "       2.4852554e-08, 2.4797339e-08, 2.4866813e-08, 2.4741247e-08,\n",
      "       2.4901253e-08, 2.5018837e-08, 2.5011422e-08, 2.4792325e-08,\n",
      "       2.4872364e-08, 2.4952474e-08, 2.4774762e-08, 2.4931188e-08,\n",
      "       2.4805514e-08, 2.4889442e-08, 2.4988278e-08, 2.4842400e-08,\n",
      "       2.4752012e-08, 2.4660551e-08, 2.4802484e-08, 2.4908783e-08,\n",
      "       2.4876829e-08, 2.4796741e-08, 2.4767157e-08, 2.4838542e-08,\n",
      "       2.4816506e-08, 2.4862683e-08, 2.4891532e-08, 2.4851527e-08,\n",
      "       2.4921277e-08, 2.4695384e-08, 2.4821590e-08, 2.4813783e-08,\n",
      "       2.4947568e-08, 2.4862681e-08, 2.4962958e-08, 2.4790555e-08,\n",
      "       2.4825541e-08, 2.4850925e-08, 2.4861025e-08, 2.4936400e-08,\n",
      "       2.4822999e-08, 2.4852598e-08, 2.4748308e-08, 2.4730140e-08,\n",
      "       2.4907484e-08, 2.4801992e-08, 2.4797924e-08, 2.4738808e-08,\n",
      "       2.4947752e-08, 2.4917398e-08, 2.4782743e-08, 2.4833190e-08,\n",
      "       2.4918851e-08, 2.4873779e-08, 2.4804516e-08, 2.4877478e-08,\n",
      "       2.4845143e-08, 2.4810493e-08, 2.4916142e-08, 2.4864669e-08,\n",
      "       2.4863580e-08, 2.4826079e-08, 2.4768285e-08, 2.4764402e-08,\n",
      "       2.4919322e-08, 2.4907548e-08, 2.5045763e-08, 2.4919181e-08,\n",
      "       2.4744679e-08, 2.4863184e-08, 2.4957691e-08, 2.4840894e-08,\n",
      "       2.4989083e-08, 2.4882251e-08, 2.4833506e-08, 2.4897014e-08,\n",
      "       2.4786113e-08, 2.4835034e-08, 2.4894693e-08, 2.4768562e-08,\n",
      "       2.4746710e-08, 2.4900546e-08, 2.4847353e-08, 2.4813193e-08,\n",
      "       2.4848577e-08, 2.4863642e-08, 2.4802139e-08, 2.4810264e-08,\n",
      "       2.4849173e-08, 2.4979700e-08, 2.4768434e-08, 2.4872778e-08,\n",
      "       2.4809852e-08, 2.4941359e-08, 2.4741599e-08, 2.4910980e-08,\n",
      "       2.4901533e-08, 2.4798096e-08, 2.4740856e-08, 2.4873476e-08,\n",
      "       2.4814664e-08, 2.4794574e-08, 2.4899686e-08, 2.4816012e-08,\n",
      "       2.4810577e-08, 2.4807040e-08, 2.4809925e-08, 2.5009111e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/Conv2D\n",
      "index : 114\n",
      "shape : [672   1   1 168]\n",
      "shape_signature : [672   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.000671  , 0.00066252, 0.00066153, 0.00066598, 0.00065197,\n",
      "       0.00066951, 0.00066697, 0.00065808, 0.00066154, 0.00066858,\n",
      "       0.00066304, 0.00066328, 0.00066044, 0.00066361, 0.00066289,\n",
      "       0.0006597 , 0.0006595 , 0.00066097, 0.00066787, 0.00066542,\n",
      "       0.00066659, 0.00065885, 0.00066329, 0.00066155, 0.00066382,\n",
      "       0.00066187, 0.00066432, 0.00066631, 0.00065484, 0.00066485,\n",
      "       0.0006591 , 0.00065664, 0.00066504, 0.00066415, 0.00066614,\n",
      "       0.0006638 , 0.00066101, 0.00066183, 0.00065981, 0.00066116,\n",
      "       0.00066093, 0.00066623, 0.00065256, 0.00066325, 0.00066037,\n",
      "       0.00065752, 0.00066559, 0.00065356, 0.00065913, 0.00066291,\n",
      "       0.00066834, 0.00066263, 0.00066779, 0.00065777, 0.0006587 ,\n",
      "       0.000662  , 0.00066468, 0.00066035, 0.00066219, 0.00066448,\n",
      "       0.00065508, 0.00066113, 0.00065798, 0.00065704, 0.00066294,\n",
      "       0.00065227, 0.00066278, 0.00065864, 0.00066575, 0.00066548,\n",
      "       0.00066218, 0.00066178, 0.00065805, 0.00065798, 0.00066298,\n",
      "       0.00066162, 0.00066779, 0.00065726, 0.00065956, 0.00066038,\n",
      "       0.00066669, 0.00066121, 0.00066354, 0.00066381, 0.00066329,\n",
      "       0.00065539, 0.00066031, 0.00066238, 0.00065461, 0.00066   ,\n",
      "       0.00064901, 0.00066086, 0.00066821, 0.00066039, 0.00065749,\n",
      "       0.000662  , 0.00066512, 0.00066173, 0.00065873, 0.00066555,\n",
      "       0.00066286, 0.00066539, 0.00066243, 0.0006663 , 0.00065758,\n",
      "       0.00066736, 0.00066401, 0.0006609 , 0.00066795, 0.00065466,\n",
      "       0.00065562, 0.00066352, 0.00065515, 0.00066316, 0.00066013,\n",
      "       0.00066465, 0.00066281, 0.0006645 , 0.00065489, 0.00066406,\n",
      "       0.00066285, 0.00066772, 0.00066033, 0.00066096, 0.00066327,\n",
      "       0.00065963, 0.00066468, 0.00065853, 0.00065131, 0.00066125,\n",
      "       0.00066729, 0.00066315, 0.00066346, 0.00066315, 0.00066822,\n",
      "       0.00066582, 0.00066484, 0.00066253, 0.00065751, 0.00066627,\n",
      "       0.00066465, 0.00066035, 0.00066355, 0.00066979, 0.00066992,\n",
      "       0.00066144, 0.00066073, 0.00066089, 0.0006568 , 0.00066016,\n",
      "       0.00066584, 0.00065581, 0.00066676, 0.00066317, 0.00066298,\n",
      "       0.00066302, 0.00065217, 0.0006591 , 0.00065737, 0.00066498,\n",
      "       0.00065911, 0.00065916, 0.00065639, 0.00066377, 0.00066987,\n",
      "       0.00066421, 0.00066248, 0.00066078, 0.00066641, 0.00066304,\n",
      "       0.00066639, 0.00066777, 0.0006607 , 0.00066679, 0.00066609,\n",
      "       0.00066822, 0.00066511, 0.00066054, 0.00065814, 0.00065991,\n",
      "       0.0006571 , 0.00066213, 0.0006524 , 0.00066094, 0.00066687,\n",
      "       0.00066127, 0.00066937, 0.00066878, 0.00066481, 0.00066526,\n",
      "       0.00065537, 0.00066802, 0.00066732, 0.00066225, 0.00065429,\n",
      "       0.00066404, 0.00066012, 0.0006648 , 0.00066187, 0.00066406,\n",
      "       0.00066947, 0.00066716, 0.00066809, 0.00066174, 0.00066522,\n",
      "       0.00066827, 0.00065979, 0.00066435, 0.00066484, 0.00066605,\n",
      "       0.00066862, 0.0006613 , 0.00066739, 0.00066382, 0.00066822,\n",
      "       0.00066653, 0.00066837, 0.00066072, 0.00066864, 0.00066256,\n",
      "       0.00066511, 0.00065407, 0.00066388, 0.00066357, 0.00066445,\n",
      "       0.00065572, 0.00065894, 0.00066391, 0.00066552, 0.00066252,\n",
      "       0.00065836, 0.00065424, 0.00066349, 0.00065223, 0.00066155,\n",
      "       0.00066207, 0.00066146, 0.00066471, 0.00066338, 0.0006621 ,\n",
      "       0.00066447, 0.00066433, 0.00066511, 0.00066158, 0.000663  ,\n",
      "       0.00065122, 0.00066573, 0.00066295, 0.00066275, 0.00065925,\n",
      "       0.00066473, 0.00065966, 0.00066439, 0.00066611, 0.00066609,\n",
      "       0.00065933, 0.00066663, 0.00065258, 0.00066508, 0.00067022,\n",
      "       0.00066362, 0.00066273, 0.00066818, 0.00066583, 0.00066262,\n",
      "       0.00065881, 0.00065191, 0.00066541, 0.00065353, 0.00065589,\n",
      "       0.00066264, 0.00066514, 0.00066103, 0.00065044, 0.00066433,\n",
      "       0.00066304, 0.00066511, 0.00066453, 0.00065896, 0.00065897,\n",
      "       0.00066554, 0.00065663, 0.00065867, 0.00066705, 0.00066537,\n",
      "       0.00065772, 0.00066437, 0.00066489, 0.00066173, 0.00064467,\n",
      "       0.00065596, 0.00066512, 0.00066734, 0.00066681, 0.00067049,\n",
      "       0.0006657 , 0.00066373, 0.00066393, 0.00066749, 0.00065846,\n",
      "       0.00066286, 0.00064973, 0.0006619 , 0.0006559 , 0.00066443,\n",
      "       0.0006511 , 0.00066315, 0.00065835, 0.00065869, 0.00066412,\n",
      "       0.00066457, 0.0006614 , 0.00066766, 0.00065305, 0.00066096,\n",
      "       0.00066524, 0.00066385, 0.00066279, 0.00066568, 0.00066197,\n",
      "       0.00066272, 0.00066024, 0.00066439, 0.00066739, 0.00066501,\n",
      "       0.00066399, 0.00065352, 0.00066614, 0.00066715, 0.00066645,\n",
      "       0.00066316, 0.00065743, 0.00065783, 0.00066258, 0.00066586,\n",
      "       0.00066656, 0.000666  , 0.00065284, 0.00065988, 0.00066259,\n",
      "       0.00065636, 0.00066616, 0.00066182, 0.0006636 , 0.0006592 ,\n",
      "       0.00066132, 0.00066434, 0.00066336, 0.0006682 , 0.00066601,\n",
      "       0.00064178, 0.00066495, 0.00065052, 0.00066294, 0.00066852,\n",
      "       0.00066138, 0.00066178, 0.00065955, 0.00066688, 0.0006636 ,\n",
      "       0.00065333, 0.00066499, 0.00066439, 0.00066988, 0.00066363,\n",
      "       0.0006629 , 0.00066392, 0.00066732, 0.00066544, 0.00066481,\n",
      "       0.00066376, 0.00065204, 0.00066574, 0.00066216, 0.00066029,\n",
      "       0.0006628 , 0.00066517, 0.00066032, 0.00066283, 0.00066703,\n",
      "       0.00065594, 0.00066157, 0.00065838, 0.00066402, 0.00065875,\n",
      "       0.00066015, 0.00066168, 0.00066297, 0.00065919, 0.0006675 ,\n",
      "       0.00066418, 0.00066061, 0.00066405, 0.00066457, 0.00065604,\n",
      "       0.00066325, 0.00066446, 0.00066826, 0.00065877, 0.00065985,\n",
      "       0.00066216, 0.00066288, 0.00066669, 0.0006619 , 0.00066232,\n",
      "       0.00066033, 0.00066195, 0.00066722, 0.00065555, 0.00063958,\n",
      "       0.00066973, 0.00066389, 0.00065797, 0.00066756, 0.00066088,\n",
      "       0.00065922, 0.00066386, 0.00066489, 0.00066852, 0.00066485,\n",
      "       0.00066066, 0.00066326, 0.00066896, 0.00065567, 0.00065072,\n",
      "       0.00066678, 0.00066334, 0.00066996, 0.00066082, 0.00066058,\n",
      "       0.00066028, 0.00066638, 0.00066218, 0.00066804, 0.00066371,\n",
      "       0.00066523, 0.00066296, 0.00066594, 0.00065935, 0.00066054,\n",
      "       0.00066413, 0.00066709, 0.00066828, 0.00066955, 0.00066844,\n",
      "       0.00065848, 0.00066294, 0.00066042, 0.00066468, 0.00067075,\n",
      "       0.00066961, 0.00066054, 0.00066678, 0.00066325, 0.00066187,\n",
      "       0.00065591, 0.00066314, 0.00066541, 0.00064914, 0.0006654 ,\n",
      "       0.00066741, 0.00065059, 0.00066696, 0.00066037, 0.00066397,\n",
      "       0.00066071, 0.00066075, 0.00066675, 0.00066594, 0.0006591 ,\n",
      "       0.00065559, 0.00066703, 0.00066296, 0.00065775, 0.00066627,\n",
      "       0.00066508, 0.00066457, 0.00066041, 0.00066271, 0.00066833,\n",
      "       0.00066366, 0.00066596, 0.00066204, 0.00066208, 0.00066152,\n",
      "       0.00066107, 0.00065115, 0.00066739, 0.00066504, 0.00066285,\n",
      "       0.00066813, 0.00066899, 0.00065352, 0.0006625 , 0.0006706 ,\n",
      "       0.00066488, 0.00066354, 0.00065986, 0.00065866, 0.00065367,\n",
      "       0.00065908, 0.00066211, 0.00066519, 0.00066447, 0.00065794,\n",
      "       0.00066499, 0.00066482, 0.0006612 , 0.00065495, 0.00066206,\n",
      "       0.00066569, 0.00064969, 0.00066179, 0.00066138, 0.00066429,\n",
      "       0.00066583, 0.00066577, 0.00066687, 0.00066443, 0.00064804,\n",
      "       0.00065043, 0.00066172, 0.00065244, 0.00066082, 0.00066105,\n",
      "       0.00066097, 0.00066062, 0.00067059, 0.00066389, 0.00066254,\n",
      "       0.00064578, 0.00066477, 0.00066515, 0.00065783, 0.00066112,\n",
      "       0.0006608 , 0.00065822, 0.00066623, 0.00065932, 0.00066163,\n",
      "       0.00064945, 0.00065978, 0.00066469, 0.00064861, 0.00065965,\n",
      "       0.00065921, 0.00065998, 0.00065796, 0.00066597, 0.00066224,\n",
      "       0.00066462, 0.00066623, 0.00066608, 0.00066446, 0.00066029,\n",
      "       0.00065997, 0.00065737, 0.00066589, 0.00064587, 0.00066545,\n",
      "       0.00066947, 0.00065368, 0.00066161, 0.0006634 , 0.00066583,\n",
      "       0.0006681 , 0.00065728, 0.00065929, 0.00066168, 0.00065851,\n",
      "       0.00066202, 0.00065377, 0.00065361, 0.00066482, 0.00066248,\n",
      "       0.00066337, 0.00066278, 0.00066932, 0.00066224, 0.00066176,\n",
      "       0.00066252, 0.00066628, 0.00066177, 0.00065914, 0.00066588,\n",
      "       0.0006477 , 0.00066238, 0.00066531, 0.00066747, 0.00066107,\n",
      "       0.00065239, 0.00066428, 0.00066239, 0.00066736, 0.00065871,\n",
      "       0.00066282, 0.00066276, 0.00065338, 0.00066814, 0.00066963,\n",
      "       0.00066799, 0.00066097, 0.00066083, 0.0006603 , 0.00066018,\n",
      "       0.0006591 , 0.00066581, 0.00066533, 0.00066393, 0.00065903,\n",
      "       0.00066226, 0.00065937, 0.00064655, 0.00066004, 0.00065566,\n",
      "       0.00066928, 0.00066366, 0.00065148, 0.00066712, 0.00066453,\n",
      "       0.00066603, 0.00066174, 0.00066704, 0.00066616, 0.00065485,\n",
      "       0.00066557, 0.00066401, 0.00066153, 0.00065868, 0.00066176,\n",
      "       0.00066094, 0.00066453, 0.00066486, 0.00066331, 0.00065947,\n",
      "       0.00065866, 0.00066368, 0.00066427, 0.00065869, 0.00065991,\n",
      "       0.00065214, 0.00066246, 0.00066486, 0.00066514, 0.00066449,\n",
      "       0.00066605, 0.00065693, 0.00066233, 0.0006643 , 0.00065999,\n",
      "       0.00065345, 0.00066322, 0.00065421, 0.00066541, 0.00066437,\n",
      "       0.00066339, 0.00066693, 0.00065961, 0.00066031, 0.00065884,\n",
      "       0.00066605, 0.00066166, 0.00065671, 0.00065581, 0.00066511,\n",
      "       0.00066286, 0.00065465, 0.00065523, 0.00066408, 0.00066346,\n",
      "       0.00064691, 0.00066163], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/BiasAdd/ReadVariableOp/resource\n",
      "index : 115\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.47946251e-08, 1.46077310e-08, 1.45859307e-08, 1.46839660e-08,\n",
      "       1.43750887e-08, 1.47618318e-08, 1.47057468e-08, 1.45097392e-08,\n",
      "       1.45861456e-08, 1.47412367e-08, 1.46190997e-08, 1.46243959e-08,\n",
      "       1.45618388e-08, 1.46317847e-08, 1.46158463e-08, 1.45455248e-08,\n",
      "       1.45412322e-08, 1.45735068e-08, 1.47256056e-08, 1.46717074e-08,\n",
      "       1.46975410e-08, 1.45268775e-08, 1.46247583e-08, 1.45863748e-08,\n",
      "       1.46363330e-08, 1.45934411e-08, 1.46474868e-08, 1.46911905e-08,\n",
      "       1.44384247e-08, 1.46590837e-08, 1.45323025e-08, 1.44779726e-08,\n",
      "       1.46632564e-08, 1.46435486e-08, 1.46874495e-08, 1.46359449e-08,\n",
      "       1.45743266e-08, 1.45925929e-08, 1.45479024e-08, 1.45777914e-08,\n",
      "       1.45725743e-08, 1.46895296e-08, 1.43881600e-08, 1.46237173e-08,\n",
      "       1.45602126e-08, 1.44974956e-08, 1.46755150e-08, 1.44102614e-08,\n",
      "       1.45329420e-08, 1.46163659e-08, 1.47361341e-08, 1.46102108e-08,\n",
      "       1.47239936e-08, 1.45029500e-08, 1.45234678e-08, 1.45962815e-08,\n",
      "       1.46552930e-08, 1.45599728e-08, 1.46003369e-08, 1.46508725e-08,\n",
      "       1.44435681e-08, 1.45771599e-08, 1.45077141e-08, 1.44870000e-08,\n",
      "       1.46169556e-08, 1.43818104e-08, 1.46134731e-08, 1.45220929e-08,\n",
      "       1.46790180e-08, 1.46730033e-08, 1.46003138e-08, 1.45913397e-08,\n",
      "       1.45090642e-08, 1.45075649e-08, 1.46177515e-08, 1.45879202e-08,\n",
      "       1.47238106e-08, 1.44918451e-08, 1.45424393e-08, 1.45606016e-08,\n",
      "       1.46996699e-08, 1.45789123e-08, 1.46303005e-08, 1.46361625e-08,\n",
      "       1.46247183e-08, 1.44504781e-08, 1.45589105e-08, 1.46047228e-08,\n",
      "       1.44332519e-08, 1.45521648e-08, 1.43099301e-08, 1.45712127e-08,\n",
      "       1.47331090e-08, 1.45608290e-08, 1.44967549e-08, 1.45962584e-08,\n",
      "       1.46651136e-08, 1.45902019e-08, 1.45240451e-08, 1.46746260e-08,\n",
      "       1.46153223e-08, 1.46709658e-08, 1.46058357e-08, 1.46910679e-08,\n",
      "       1.44987702e-08, 1.47144945e-08, 1.46406682e-08, 1.45719454e-08,\n",
      "       1.47275241e-08, 1.44343240e-08, 1.44555985e-08, 1.46297721e-08,\n",
      "       1.44453214e-08, 1.46219250e-08, 1.45549981e-08, 1.46546624e-08,\n",
      "       1.46141446e-08, 1.46514454e-08, 1.44394212e-08, 1.46416959e-08,\n",
      "       1.46149333e-08, 1.47222723e-08, 1.45593697e-08, 1.45734278e-08,\n",
      "       1.46241614e-08, 1.45439545e-08, 1.46554315e-08, 1.45198058e-08,\n",
      "       1.43605616e-08, 1.45796539e-08, 1.47128238e-08, 1.46215342e-08,\n",
      "       1.46283474e-08, 1.46215955e-08, 1.47334509e-08, 1.46804542e-08,\n",
      "       1.46588173e-08, 1.46079158e-08, 1.44971795e-08, 1.46904862e-08,\n",
      "       1.46545984e-08, 1.45598023e-08, 1.46304728e-08, 1.47679105e-08,\n",
      "       1.47707846e-08, 1.45838293e-08, 1.45682879e-08, 1.45718868e-08,\n",
      "       1.44816124e-08, 1.45557681e-08, 1.46808654e-08, 1.44596761e-08,\n",
      "       1.47012980e-08, 1.46220707e-08, 1.46178349e-08, 1.46187578e-08,\n",
      "       1.43794159e-08, 1.45322092e-08, 1.44940691e-08, 1.46619969e-08,\n",
      "       1.45325263e-08, 1.45336889e-08, 1.44725680e-08, 1.46352690e-08,\n",
      "       1.47698138e-08, 1.46449262e-08, 1.46068571e-08, 1.45692800e-08,\n",
      "       1.46934047e-08, 1.46192036e-08, 1.46930477e-08, 1.47234642e-08,\n",
      "       1.45674894e-08, 1.47019366e-08, 1.46864965e-08, 1.47332964e-08,\n",
      "       1.46649288e-08, 1.45640513e-08, 1.45110723e-08, 1.45502330e-08,\n",
      "       1.44882204e-08, 1.45990722e-08, 1.43845531e-08, 1.45729420e-08,\n",
      "       1.47035193e-08, 1.45801611e-08, 1.47587080e-08, 1.47458339e-08,\n",
      "       1.46581138e-08, 1.46681201e-08, 1.44500145e-08, 1.47289860e-08,\n",
      "       1.47134669e-08, 1.46017154e-08, 1.44262655e-08, 1.46413264e-08,\n",
      "       1.45548009e-08, 1.46579335e-08, 1.45933621e-08, 1.46416577e-08,\n",
      "       1.47609986e-08, 1.47099453e-08, 1.47304959e-08, 1.45905874e-08,\n",
      "       1.46672461e-08, 1.47344528e-08, 1.45474814e-08, 1.46481751e-08,\n",
      "       1.46588333e-08, 1.46855852e-08, 1.47422936e-08, 1.45807615e-08,\n",
      "       1.47151074e-08, 1.46363570e-08, 1.47334926e-08, 1.46961714e-08,\n",
      "       1.47367647e-08, 1.45679904e-08, 1.47425885e-08, 1.46086450e-08,\n",
      "       1.46648755e-08, 1.44213379e-08, 1.46376244e-08, 1.46307606e-08,\n",
      "       1.46503210e-08, 1.44577728e-08, 1.45288217e-08, 1.46384656e-08,\n",
      "       1.46737733e-08, 1.46077088e-08, 1.45159538e-08, 1.44250842e-08,\n",
      "       1.46291237e-08, 1.43807979e-08, 1.45864121e-08, 1.45978305e-08,\n",
      "       1.45844004e-08, 1.46560470e-08, 1.46266279e-08, 1.45985632e-08,\n",
      "       1.46506132e-08, 1.46475880e-08, 1.46647574e-08, 1.45870409e-08,\n",
      "       1.46182115e-08, 1.43585375e-08, 1.46784371e-08, 1.46171164e-08,\n",
      "       1.46127519e-08, 1.45355550e-08, 1.46564165e-08, 1.45445531e-08,\n",
      "       1.46489256e-08, 1.46867745e-08, 1.46864503e-08, 1.45374797e-08,\n",
      "       1.46982932e-08, 1.43886432e-08, 1.46642058e-08, 1.47775152e-08,\n",
      "       1.46319401e-08, 1.46122874e-08, 1.47325911e-08, 1.46806682e-08,\n",
      "       1.46099000e-08, 1.45258872e-08, 1.43738470e-08, 1.46714276e-08,\n",
      "       1.44094434e-08, 1.44615457e-08, 1.46103734e-08, 1.46654440e-08,\n",
      "       1.45748169e-08, 1.43412864e-08, 1.46476244e-08, 1.46191574e-08,\n",
      "       1.46649093e-08, 1.46520875e-08, 1.45291814e-08, 1.45295509e-08,\n",
      "       1.46743835e-08, 1.44779362e-08, 1.45229118e-08, 1.47076085e-08,\n",
      "       1.46705732e-08, 1.45018619e-08, 1.46485535e-08, 1.46599479e-08,\n",
      "       1.45902126e-08, 1.42141428e-08, 1.44631489e-08, 1.46649937e-08,\n",
      "       1.47140495e-08, 1.47023336e-08, 1.47834829e-08, 1.46779264e-08,\n",
      "       1.46344350e-08, 1.46387569e-08, 1.47174042e-08, 1.45182888e-08,\n",
      "       1.46151828e-08, 1.43256722e-08, 1.45941534e-08, 1.44618051e-08,\n",
      "       1.46497614e-08, 1.43558312e-08, 1.46215724e-08, 1.45157184e-08,\n",
      "       1.45232431e-08, 1.46430024e-08, 1.46529340e-08, 1.45829739e-08,\n",
      "       1.47211043e-08, 1.43988350e-08, 1.45733985e-08, 1.46677417e-08,\n",
      "       1.46369707e-08, 1.46136410e-08, 1.46773314e-08, 1.45956092e-08,\n",
      "       1.46121728e-08, 1.45573544e-08, 1.46490065e-08, 1.47151225e-08,\n",
      "       1.46626711e-08, 1.46400705e-08, 1.44093626e-08, 1.46875356e-08,\n",
      "       1.47097285e-08, 1.46942591e-08, 1.46217829e-08, 1.44955257e-08,\n",
      "       1.45043053e-08, 1.46089834e-08, 1.46814232e-08, 1.46967167e-08,\n",
      "       1.46845558e-08, 1.43943462e-08, 1.45495411e-08, 1.46092018e-08,\n",
      "       1.44719712e-08, 1.46879371e-08, 1.45922687e-08, 1.46314729e-08,\n",
      "       1.45345975e-08, 1.45811940e-08, 1.46479247e-08, 1.46261554e-08,\n",
      "       1.47329429e-08, 1.46845940e-08, 1.41504053e-08, 1.46613095e-08,\n",
      "       1.43431356e-08, 1.46169095e-08, 1.47399168e-08, 1.45824952e-08,\n",
      "       1.45913495e-08, 1.45421533e-08, 1.47037742e-08, 1.46316284e-08,\n",
      "       1.44051056e-08, 1.46622359e-08, 1.46489567e-08, 1.47700749e-08,\n",
      "       1.46322030e-08, 1.46160088e-08, 1.46385029e-08, 1.47135220e-08,\n",
      "       1.46721382e-08, 1.46582986e-08, 1.46350416e-08, 1.43765950e-08,\n",
      "       1.46786157e-08, 1.45997570e-08, 1.45586494e-08, 1.46139811e-08,\n",
      "       1.46660382e-08, 1.45591441e-08, 1.46145789e-08, 1.47072541e-08,\n",
      "       1.44626027e-08, 1.45866883e-08, 1.45164307e-08, 1.46406922e-08,\n",
      "       1.45245931e-08, 1.45553605e-08, 1.45891894e-08, 1.46175552e-08,\n",
      "       1.45341872e-08, 1.47174593e-08, 1.46443897e-08, 1.45656021e-08,\n",
      "       1.46414045e-08, 1.46528363e-08, 1.44648444e-08, 1.46237360e-08,\n",
      "       1.46505252e-08, 1.47343808e-08, 1.45251127e-08, 1.45489372e-08,\n",
      "       1.45997250e-08, 1.46157575e-08, 1.46995935e-08, 1.45939767e-08,\n",
      "       1.46032004e-08, 1.45594727e-08, 1.45952219e-08, 1.47112384e-08,\n",
      "       1.44540397e-08, 1.41018184e-08, 1.47666661e-08, 1.46378909e-08,\n",
      "       1.45074761e-08, 1.47188119e-08, 1.45715582e-08, 1.45349608e-08,\n",
      "       1.46372034e-08, 1.46600563e-08, 1.47400909e-08, 1.46591432e-08,\n",
      "       1.45667700e-08, 1.46240904e-08, 1.47497294e-08, 1.44567114e-08,\n",
      "       1.43476351e-08, 1.47017003e-08, 1.46258756e-08, 1.47716630e-08,\n",
      "       1.45701362e-08, 1.45649013e-08, 1.45582426e-08, 1.46928603e-08,\n",
      "       1.46002987e-08, 1.47295145e-08, 1.46340255e-08, 1.46674326e-08,\n",
      "       1.46173305e-08, 1.46831480e-08, 1.45379166e-08, 1.45640442e-08,\n",
      "       1.46431400e-08, 1.47084114e-08, 1.47348089e-08, 1.47627164e-08,\n",
      "       1.47382266e-08, 1.45187498e-08, 1.46170560e-08, 1.45614205e-08,\n",
      "       1.46552877e-08, 1.47891042e-08, 1.47641153e-08, 1.45640353e-08,\n",
      "       1.47017003e-08, 1.46239074e-08, 1.45933683e-08, 1.44619543e-08,\n",
      "       1.46212837e-08, 1.46714543e-08, 1.43127021e-08, 1.46711718e-08,\n",
      "       1.47156225e-08, 1.43445931e-08, 1.47055150e-08, 1.45603813e-08,\n",
      "       1.46396246e-08, 1.45678367e-08, 1.45686068e-08, 1.47009178e-08,\n",
      "       1.46831578e-08, 1.45322963e-08, 1.44549279e-08, 1.47072550e-08,\n",
      "       1.46174708e-08, 1.45024570e-08, 1.46903627e-08, 1.46642138e-08,\n",
      "       1.46530059e-08, 1.45611230e-08, 1.46118806e-08, 1.47357300e-08,\n",
      "       1.46327652e-08, 1.46836214e-08, 1.45972354e-08, 1.45979850e-08,\n",
      "       1.45857451e-08, 1.45758001e-08, 1.43569254e-08, 1.47149839e-08,\n",
      "       1.46633523e-08, 1.46150461e-08, 1.47313894e-08, 1.47504302e-08,\n",
      "       1.44093217e-08, 1.46072203e-08, 1.47859174e-08, 1.46596921e-08,\n",
      "       1.46303059e-08, 1.45489807e-08, 1.45225538e-08, 1.44126560e-08,\n",
      "       1.45318717e-08, 1.45985677e-08, 1.46666448e-08, 1.46507722e-08,\n",
      "       1.45066368e-08, 1.46622821e-08, 1.46583190e-08, 1.45785402e-08,\n",
      "       1.44407331e-08, 1.45975116e-08, 1.46775614e-08, 1.43248684e-08,\n",
      "       1.45915244e-08, 1.45825032e-08, 1.46467887e-08, 1.46807224e-08,\n",
      "       1.46794052e-08, 1.47036445e-08, 1.46498316e-08, 1.42885108e-08,\n",
      "       1.43411949e-08, 1.45899852e-08, 1.43854697e-08, 1.45702783e-08,\n",
      "       1.45754075e-08, 1.45735575e-08, 1.45658268e-08, 1.47857300e-08,\n",
      "       1.46380179e-08, 1.46081982e-08, 1.42385792e-08, 1.46574042e-08,\n",
      "       1.46656589e-08, 1.45043693e-08, 1.45767531e-08, 1.45697996e-08,\n",
      "       1.45127972e-08, 1.46896113e-08, 1.45371795e-08, 1.45880215e-08,\n",
      "       1.43196388e-08, 1.45473598e-08, 1.46556633e-08, 1.43010741e-08,\n",
      "       1.45445425e-08, 1.45346659e-08, 1.45516079e-08, 1.45070800e-08,\n",
      "       1.46837378e-08, 1.46014587e-08, 1.46539092e-08, 1.46894878e-08,\n",
      "       1.46861003e-08, 1.46505004e-08, 1.45584469e-08, 1.45514258e-08,\n",
      "       1.44940673e-08, 1.46819552e-08, 1.42406282e-08, 1.46723469e-08,\n",
      "       1.47609196e-08, 1.44128425e-08, 1.45877070e-08, 1.46271413e-08,\n",
      "       1.46806114e-08, 1.47307873e-08, 1.44920902e-08, 1.45364343e-08,\n",
      "       1.45891592e-08, 1.45192711e-08, 1.45966066e-08, 1.44147556e-08,\n",
      "       1.44112953e-08, 1.46584487e-08, 1.46067647e-08, 1.46264805e-08,\n",
      "       1.46135362e-08, 1.47575854e-08, 1.46014578e-08, 1.45908912e-08,\n",
      "       1.46077603e-08, 1.46905590e-08, 1.45911390e-08, 1.45332226e-08,\n",
      "       1.46818921e-08, 1.42809249e-08, 1.46045940e-08, 1.46691761e-08,\n",
      "       1.47169512e-08, 1.45757815e-08, 1.43843675e-08, 1.46464911e-08,\n",
      "       1.46049430e-08, 1.47144297e-08, 1.45237617e-08, 1.46144110e-08,\n",
      "       1.46129207e-08, 1.44060861e-08, 1.47315484e-08, 1.47645336e-08,\n",
      "       1.47283696e-08, 1.45735859e-08, 1.45703938e-08, 1.45588679e-08,\n",
      "       1.45560959e-08, 1.45322758e-08, 1.46801646e-08, 1.46695651e-08,\n",
      "       1.46389141e-08, 1.45308654e-08, 1.46019046e-08, 1.45382755e-08,\n",
      "       1.42556820e-08, 1.45530121e-08, 1.44564165e-08, 1.47566714e-08,\n",
      "       1.46329189e-08, 1.43644003e-08, 1.47090926e-08, 1.46520458e-08,\n",
      "       1.46850896e-08, 1.45904240e-08, 1.47074859e-08, 1.46879620e-08,\n",
      "       1.44386076e-08, 1.46750310e-08, 1.46406167e-08, 1.45859929e-08,\n",
      "       1.45230850e-08, 1.45910377e-08, 1.45728176e-08, 1.46520645e-08,\n",
      "       1.46592862e-08, 1.46251136e-08, 1.45405767e-08, 1.45226737e-08,\n",
      "       1.46332164e-08, 1.46463215e-08, 1.45233443e-08, 1.45500625e-08,\n",
      "       1.43789567e-08, 1.46064414e-08, 1.46592969e-08, 1.46654999e-08,\n",
      "       1.46511665e-08, 1.46855363e-08, 1.44844039e-08, 1.46035752e-08,\n",
      "       1.46470622e-08, 1.45518966e-08, 1.44078447e-08, 1.46231294e-08,\n",
      "       1.44245567e-08, 1.46715200e-08, 1.46486112e-08, 1.46269921e-08,\n",
      "       1.47049537e-08, 1.45435424e-08, 1.45589754e-08, 1.45266110e-08,\n",
      "       1.46855479e-08, 1.45886530e-08, 1.44795962e-08, 1.44596699e-08,\n",
      "       1.46647201e-08, 1.46151145e-08, 1.44341517e-08, 1.44469050e-08,\n",
      "       1.46420778e-08, 1.46284602e-08, 1.42636321e-08, 1.45880321e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/conv2d_40/Conv2D\n",
      "index : 116\n",
      "shape : [112   1   1 672]\n",
      "shape_signature : [112   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00074569, 0.00074595, 0.00074755, 0.00074777, 0.00074836,\n",
      "       0.00074905, 0.00074618, 0.00074819, 0.00075262, 0.0007526 ,\n",
      "       0.00074812, 0.00075299, 0.00075401, 0.00074994, 0.00074426,\n",
      "       0.00074812, 0.00074939, 0.00074685, 0.00074702, 0.00074793,\n",
      "       0.00074725, 0.00074996, 0.00074683, 0.00074742, 0.00074351,\n",
      "       0.00075077, 0.00074495, 0.00074454, 0.00074904, 0.00074436,\n",
      "       0.00075333, 0.0007514 , 0.00074965, 0.00074786, 0.00074825,\n",
      "       0.00074948, 0.00074792, 0.00074728, 0.00074247, 0.00075217,\n",
      "       0.00075149, 0.00075034, 0.00074887, 0.0007514 , 0.00074844,\n",
      "       0.0007457 , 0.00074615, 0.00074319, 0.00074757, 0.00074493,\n",
      "       0.00075091, 0.00074988, 0.00074642, 0.0007494 , 0.00075153,\n",
      "       0.00075266, 0.00074835, 0.00074778, 0.00074824, 0.00074863,\n",
      "       0.00074654, 0.00075329, 0.00075133, 0.00075326, 0.00075031,\n",
      "       0.0007483 , 0.00074347, 0.00075171, 0.0007489 , 0.00074769,\n",
      "       0.00074952, 0.00074537, 0.00075145, 0.00074654, 0.00074821,\n",
      "       0.00074891, 0.00074974, 0.00074854, 0.00075061, 0.00074553,\n",
      "       0.00074602, 0.00074797, 0.00074677, 0.00074434, 0.00074948,\n",
      "       0.00074887, 0.00075058, 0.0007504 , 0.00074684, 0.00074989,\n",
      "       0.00074816, 0.00075215, 0.00074833, 0.00074788, 0.00074354,\n",
      "       0.00074951, 0.00074672, 0.00074559, 0.00075094, 0.00074404,\n",
      "       0.00075133, 0.00074958, 0.00074795, 0.00075213, 0.00074699,\n",
      "       0.00074681, 0.00074982, 0.00074896, 0.00074913, 0.00075217,\n",
      "       0.00074325, 0.00075203], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_30/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/conv2d_40/Conv2D\n",
      "index : 117\n",
      "shape : [112]\n",
      "shape_signature : [112]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.0916584e-09, 7.0941861e-09, 7.1093753e-09, 7.1114599e-09,\n",
      "       7.1171047e-09, 7.1236310e-09, 7.0963893e-09, 7.1154855e-09,\n",
      "       7.1575710e-09, 7.1574213e-09, 7.1147572e-09, 7.1611361e-09,\n",
      "       7.1707862e-09, 7.1320798e-09, 7.0780524e-09, 7.1148207e-09,\n",
      "       7.1269084e-09, 7.1026989e-09, 7.1043589e-09, 7.1130302e-09,\n",
      "       7.1065642e-09, 7.1322743e-09, 7.1025417e-09, 7.1081083e-09,\n",
      "       7.0709865e-09, 7.1399593e-09, 7.0846635e-09, 7.0806987e-09,\n",
      "       7.1235595e-09, 7.0790254e-09, 7.1643780e-09, 7.1460118e-09,\n",
      "       7.1293424e-09, 7.1123556e-09, 7.1160495e-09, 7.1277664e-09,\n",
      "       7.1128690e-09, 7.1067676e-09, 7.0610509e-09, 7.1532726e-09,\n",
      "       7.1468360e-09, 7.1359278e-09, 7.1219493e-09, 7.1459794e-09,\n",
      "       7.1178747e-09, 7.0918111e-09, 7.0960691e-09, 7.0678872e-09,\n",
      "       7.1095587e-09, 7.0844197e-09, 7.1412840e-09, 7.1315114e-09,\n",
      "       7.0986572e-09, 7.1270088e-09, 7.1472224e-09, 7.1580004e-09,\n",
      "       7.1169541e-09, 7.1115491e-09, 7.1159492e-09, 7.1196049e-09,\n",
      "       7.0997599e-09, 7.1639681e-09, 7.1453012e-09, 7.1636599e-09,\n",
      "       7.1355797e-09, 7.1165092e-09, 7.0705943e-09, 7.1489068e-09,\n",
      "       7.1222015e-09, 7.1106685e-09, 7.1281403e-09, 7.0886315e-09,\n",
      "       7.1464816e-09, 7.0997355e-09, 7.1156068e-09, 7.1223365e-09,\n",
      "       7.1302266e-09, 7.1188291e-09, 7.1384676e-09, 7.0902031e-09,\n",
      "       7.0948567e-09, 7.1133277e-09, 7.1019493e-09, 7.0788055e-09,\n",
      "       7.1277118e-09, 7.1219257e-09, 7.1382349e-09, 7.1364958e-09,\n",
      "       7.1026425e-09, 7.1316002e-09, 7.1151760e-09, 7.1530928e-09,\n",
      "       7.1167925e-09, 7.1125150e-09, 7.0712134e-09, 7.1279929e-09,\n",
      "       7.1014621e-09, 7.0907711e-09, 7.1416562e-09, 7.0760091e-09,\n",
      "       7.1452768e-09, 7.1286848e-09, 7.1131967e-09, 7.1529032e-09,\n",
      "       7.1040351e-09, 7.1023214e-09, 7.1309323e-09, 7.1227531e-09,\n",
      "       7.1244002e-09, 7.1533157e-09, 7.0684414e-09, 7.1519812e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_41/Conv2D\n",
      "index : 118\n",
      "shape : [672   1   1 112]\n",
      "shape_signature : [672   1   1 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00070416, 0.00071021, 0.0007052 , 0.00069235, 0.00071983,\n",
      "       0.00070808, 0.000707  , 0.00071473, 0.00069986, 0.00071644,\n",
      "       0.00068442, 0.00069326, 0.00070658, 0.00070692, 0.00071521,\n",
      "       0.00070483, 0.00070798, 0.00070267, 0.00070057, 0.00069988,\n",
      "       0.00070205, 0.00070958, 0.00070685, 0.00070382, 0.00070872,\n",
      "       0.00071172, 0.00071244, 0.00070856, 0.00070825, 0.00070593,\n",
      "       0.00070684, 0.00070343, 0.00070258, 0.00071402, 0.00071661,\n",
      "       0.00071195, 0.00070431, 0.00069854, 0.00070909, 0.00071185,\n",
      "       0.00071521, 0.00070977, 0.00069133, 0.00071048, 0.00069942,\n",
      "       0.00071705, 0.00069884, 0.00068723, 0.00069842, 0.00071163,\n",
      "       0.00071327, 0.00071802, 0.00071726, 0.00070546, 0.0007061 ,\n",
      "       0.00071206, 0.00071079, 0.00071278, 0.0006998 , 0.000701  ,\n",
      "       0.00070527, 0.00070849, 0.00068679, 0.00070714, 0.00071661,\n",
      "       0.00070456, 0.00068793, 0.00070723, 0.0007011 , 0.00070584,\n",
      "       0.00070088, 0.0007033 , 0.00071425, 0.00069722, 0.00070659,\n",
      "       0.00070264, 0.0007057 , 0.000709  , 0.00070104, 0.00070321,\n",
      "       0.00069467, 0.00071004, 0.00070126, 0.0007108 , 0.00070692,\n",
      "       0.0007068 , 0.00069627, 0.00071078, 0.00069624, 0.00070681,\n",
      "       0.00069416, 0.00071037, 0.00070735, 0.00070174, 0.00070435,\n",
      "       0.00070682, 0.00070084, 0.0006933 , 0.00070378, 0.00071981,\n",
      "       0.00071546, 0.00072499, 0.00070995, 0.00070954, 0.00071873,\n",
      "       0.00070369, 0.00070461, 0.00068697, 0.00067559, 0.0007016 ,\n",
      "       0.00071173, 0.00070513, 0.00071477, 0.00070701, 0.00070709,\n",
      "       0.00069188, 0.00069269, 0.00070977, 0.00070019, 0.00070398,\n",
      "       0.00069511, 0.00071082, 0.00071112, 0.00071202, 0.00069144,\n",
      "       0.00070417, 0.00071418, 0.00070686, 0.00070081, 0.00070129,\n",
      "       0.00070777, 0.00070335, 0.0007093 , 0.00070688, 0.00070674,\n",
      "       0.00070803, 0.00069911, 0.00069114, 0.0007074 , 0.00069453,\n",
      "       0.00070083, 0.0007025 , 0.00071026, 0.00070921, 0.00070056,\n",
      "       0.00070968, 0.00069925, 0.00070754, 0.00071241, 0.00071436,\n",
      "       0.00069955, 0.00071164, 0.00070523, 0.00069831, 0.00071421,\n",
      "       0.00071024, 0.00071639, 0.00070202, 0.00070765, 0.00071539,\n",
      "       0.00069954, 0.00070504, 0.00070156, 0.00071451, 0.00070128,\n",
      "       0.00069484, 0.00068484, 0.00070788, 0.00069043, 0.00070845,\n",
      "       0.00070422, 0.00067367, 0.00069133, 0.0007107 , 0.00070001,\n",
      "       0.00071248, 0.00071274, 0.00071038, 0.00071023, 0.00069532,\n",
      "       0.00070728, 0.00070977, 0.00070341, 0.00070733, 0.00070942,\n",
      "       0.00070966, 0.00070948, 0.00070958, 0.00070335, 0.00070694,\n",
      "       0.00067002, 0.00071153, 0.00070464, 0.00068433, 0.000692  ,\n",
      "       0.00070993, 0.00070354, 0.00070142, 0.00069484, 0.00070857,\n",
      "       0.00070739, 0.00071095, 0.00071563, 0.00070018, 0.0007032 ,\n",
      "       0.00070695, 0.00072145, 0.00068822, 0.0007054 , 0.00070699,\n",
      "       0.0006889 , 0.00070146, 0.00070015, 0.00070334, 0.00070439,\n",
      "       0.0006997 , 0.00070846, 0.00070794, 0.00071702, 0.00070274,\n",
      "       0.0007133 , 0.0007095 , 0.00070133, 0.00069505, 0.00070301,\n",
      "       0.00070902, 0.00069089, 0.00070022, 0.0007039 , 0.00071332,\n",
      "       0.00070391, 0.00071099, 0.00069272, 0.00070901, 0.00070127,\n",
      "       0.00070004, 0.00070382, 0.00069557, 0.00071091, 0.00069071,\n",
      "       0.00070793, 0.00070729, 0.00069803, 0.00071165, 0.00070384,\n",
      "       0.00069436, 0.00070502, 0.00071337, 0.00069537, 0.00069012,\n",
      "       0.00070929, 0.00070593, 0.00069905, 0.00071143, 0.00070347,\n",
      "       0.0006942 , 0.0007067 , 0.0006993 , 0.00071064, 0.0007026 ,\n",
      "       0.00070304, 0.00069882, 0.00071752, 0.00070981, 0.00068653,\n",
      "       0.00068843, 0.00069094, 0.00069407, 0.00071814, 0.00068554,\n",
      "       0.00071119, 0.00070796, 0.00071227, 0.00068962, 0.00070444,\n",
      "       0.00070263, 0.00070772, 0.00071778, 0.00070575, 0.00070869,\n",
      "       0.00070908, 0.00070772, 0.00069739, 0.00070556, 0.00072234,\n",
      "       0.00070478, 0.00070908, 0.0006598 , 0.00070095, 0.00071326,\n",
      "       0.00071389, 0.00070005, 0.00070014, 0.00069851, 0.00070684,\n",
      "       0.00071031, 0.00070291, 0.00068385, 0.000694  , 0.00070668,\n",
      "       0.0007011 , 0.00070425, 0.00069635, 0.00069819, 0.00071463,\n",
      "       0.00069375, 0.00072036, 0.0007071 , 0.00071406, 0.00070393,\n",
      "       0.00070896, 0.00071382, 0.0006936 , 0.0007173 , 0.00069605,\n",
      "       0.00069974, 0.00070456, 0.00069182, 0.00071537, 0.0007046 ,\n",
      "       0.00070543, 0.00071343, 0.00071076, 0.0006995 , 0.00070889,\n",
      "       0.00071995, 0.00069755, 0.00068414, 0.00071003, 0.00070731,\n",
      "       0.0007069 , 0.00070329, 0.00072192, 0.00070858, 0.0007086 ,\n",
      "       0.00071327, 0.00070787, 0.00071866, 0.00070901, 0.00071365,\n",
      "       0.00069782, 0.00070588, 0.00070833, 0.00070847, 0.0006957 ,\n",
      "       0.00069475, 0.00069437, 0.0007014 , 0.00068383, 0.00070148,\n",
      "       0.00070749, 0.00072302, 0.00069333, 0.00068958, 0.00069214,\n",
      "       0.0007163 , 0.00070694, 0.00070868, 0.00070499, 0.00070131,\n",
      "       0.00069602, 0.00071339, 0.00070597, 0.00070819, 0.00069543,\n",
      "       0.0007091 , 0.00071753, 0.00070811, 0.00069274, 0.00071072,\n",
      "       0.00069648, 0.00069745, 0.00070282, 0.00068274, 0.00070931,\n",
      "       0.00069867, 0.0007095 , 0.00069629, 0.00070714, 0.00070965,\n",
      "       0.00070597, 0.00070496, 0.00071268, 0.00068595, 0.00071145,\n",
      "       0.00070985, 0.00069623, 0.00069438, 0.00070026, 0.00070887,\n",
      "       0.00070644, 0.00070726, 0.00069043, 0.00071205, 0.00070508,\n",
      "       0.00069297, 0.00069806, 0.00068962, 0.00070227, 0.00070479,\n",
      "       0.0006977 , 0.00071089, 0.00071329, 0.00069732, 0.00071191,\n",
      "       0.00070424, 0.00070703, 0.00070312, 0.00071742, 0.00071636,\n",
      "       0.00069845, 0.00071627, 0.00070536, 0.0006976 , 0.00071185,\n",
      "       0.00071058, 0.00071772, 0.00069992, 0.00069123, 0.00069636,\n",
      "       0.00070808, 0.00070852, 0.00070177, 0.00070145, 0.00070903,\n",
      "       0.00071888, 0.00069895, 0.00071527, 0.00070486, 0.00070784,\n",
      "       0.00067436, 0.00070433, 0.00071465, 0.00070211, 0.00071099,\n",
      "       0.00070847, 0.0007152 , 0.00071984, 0.00071535, 0.00070903,\n",
      "       0.00071754, 0.00071248, 0.00070645, 0.00071037, 0.00070029,\n",
      "       0.00070781, 0.00070904, 0.00070577, 0.00070061, 0.00072035,\n",
      "       0.00070761, 0.00070266, 0.00070744, 0.0006867 , 0.00070454,\n",
      "       0.00068949, 0.00070989, 0.00070787, 0.00070167, 0.00069787,\n",
      "       0.00071068, 0.00070033, 0.00071384, 0.00071421, 0.00068105,\n",
      "       0.00072007, 0.00070917, 0.00071317, 0.00071222, 0.0007072 ,\n",
      "       0.00071247, 0.00071035, 0.00069533, 0.00071788, 0.00069132,\n",
      "       0.00070869, 0.00069422, 0.00070045, 0.000699  , 0.00069482,\n",
      "       0.0007037 , 0.00070683, 0.00070717, 0.00069944, 0.00069805,\n",
      "       0.00071486, 0.00070543, 0.0007053 , 0.00070322, 0.00071327,\n",
      "       0.00070545, 0.00070477, 0.00070037, 0.00070334, 0.000709  ,\n",
      "       0.0006954 , 0.0007128 , 0.0007024 , 0.0007096 , 0.00068433,\n",
      "       0.00068906, 0.00069375, 0.0007161 , 0.00070269, 0.00070434,\n",
      "       0.00068758, 0.00071034, 0.00071368, 0.00069808, 0.00070373,\n",
      "       0.00071435, 0.00070493, 0.00070459, 0.00071416, 0.00070201,\n",
      "       0.00068618, 0.00069876, 0.00071115, 0.00068856, 0.0007057 ,\n",
      "       0.00071715, 0.00070608, 0.00069962, 0.00069528, 0.00070075,\n",
      "       0.000707  , 0.00068914, 0.00070657, 0.00068777, 0.00070697,\n",
      "       0.00069147, 0.00069817, 0.00069662, 0.00071539, 0.00069343,\n",
      "       0.00069195, 0.00072453, 0.00070833, 0.00071034, 0.00071018,\n",
      "       0.00069778, 0.00069363, 0.00070846, 0.00070938, 0.00070674,\n",
      "       0.00070524, 0.0006921 , 0.000702  , 0.00071389, 0.00070332,\n",
      "       0.00069716, 0.00070008, 0.00071326, 0.0007101 , 0.00069855,\n",
      "       0.00070872, 0.00071387, 0.00069307, 0.00070612, 0.00070781,\n",
      "       0.00070955, 0.00068262, 0.00071363, 0.00071158, 0.00071182,\n",
      "       0.00070442, 0.00069823, 0.00069479, 0.0007144 , 0.00070204,\n",
      "       0.00071108, 0.00069133, 0.00068927, 0.00070981, 0.00071021,\n",
      "       0.00069398, 0.00069848, 0.00069435, 0.00070888, 0.00070369,\n",
      "       0.00070514, 0.00068911, 0.00071397, 0.00069777, 0.00071646,\n",
      "       0.00070794, 0.00071155, 0.00070278, 0.00071009, 0.00070389,\n",
      "       0.00071519, 0.00070202, 0.00069015, 0.00070538, 0.00070092,\n",
      "       0.00070891, 0.00071285, 0.00071542, 0.00070572, 0.00070058,\n",
      "       0.0007033 , 0.00071829, 0.00070616, 0.00070389, 0.00069373,\n",
      "       0.00070935, 0.00070742, 0.00070909, 0.00071428, 0.00069277,\n",
      "       0.00070757, 0.00068555, 0.00068442, 0.00070354, 0.00070863,\n",
      "       0.00071242, 0.00070268, 0.0007073 , 0.00070144, 0.00070462,\n",
      "       0.00070053, 0.00070291, 0.0007087 , 0.00071257, 0.00070945,\n",
      "       0.00070314, 0.00070824, 0.00070203, 0.00070197, 0.00070888,\n",
      "       0.00070448, 0.0007029 , 0.00071134, 0.00071975, 0.00069753,\n",
      "       0.000707  , 0.00070606, 0.00069601, 0.00069786, 0.00071939,\n",
      "       0.00069715, 0.00070711, 0.00070742, 0.00070301, 0.00069141,\n",
      "       0.00070202, 0.00069181, 0.0006918 , 0.00070127, 0.00070232,\n",
      "       0.0006905 , 0.00071387, 0.00070749, 0.00069547, 0.00070169,\n",
      "       0.0007133 , 0.00071694, 0.00070649, 0.00071134, 0.00070422,\n",
      "       0.00072075, 0.00070622, 0.00070482, 0.00069772, 0.00071148,\n",
      "       0.00070074, 0.00070406, 0.00068565, 0.00071041, 0.00071486,\n",
      "       0.00071081, 0.00069146], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_31/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_41/Conv2D\n",
      "index : 119\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.06854394e-07, 1.07771989e-07, 1.07012355e-07, 1.05062554e-07,\n",
      "       1.09231991e-07, 1.07448507e-07, 1.07285679e-07, 1.08458920e-07,\n",
      "       1.06201227e-07, 1.08718403e-07, 1.03858248e-07, 1.05200684e-07,\n",
      "       1.07222135e-07, 1.07272825e-07, 1.08530678e-07, 1.06956740e-07,\n",
      "       1.07434509e-07, 1.06628598e-07, 1.06308960e-07, 1.06204986e-07,\n",
      "       1.06534436e-07, 1.07677302e-07, 1.07262451e-07, 1.06802716e-07,\n",
      "       1.07546533e-07, 1.08002148e-07, 1.08111152e-07, 1.07522283e-07,\n",
      "       1.07475103e-07, 1.07123434e-07, 1.07261293e-07, 1.06743954e-07,\n",
      "       1.06614664e-07, 1.08350463e-07, 1.08743755e-07, 1.08036218e-07,\n",
      "       1.06877856e-07, 1.06002091e-07, 1.07601842e-07, 1.08020664e-07,\n",
      "       1.08531495e-07, 1.07705688e-07, 1.04907919e-07, 1.07813342e-07,\n",
      "       1.06135431e-07, 1.08810859e-07, 1.06047779e-07, 1.04285625e-07,\n",
      "       1.05983162e-07, 1.07988299e-07, 1.08236918e-07, 1.08957927e-07,\n",
      "       1.08842912e-07, 1.07051846e-07, 1.07148786e-07, 1.08053406e-07,\n",
      "       1.07860679e-07, 1.08162993e-07, 1.06192331e-07, 1.06375289e-07,\n",
      "       1.07022466e-07, 1.07511596e-07, 1.04217911e-07, 1.07306867e-07,\n",
      "       1.08744167e-07, 1.06914754e-07, 1.04391191e-07, 1.07320346e-07,\n",
      "       1.06389791e-07, 1.07109251e-07, 1.06356403e-07, 1.06724094e-07,\n",
      "       1.08385208e-07, 1.05801767e-07, 1.07223478e-07, 1.06623865e-07,\n",
      "       1.07088319e-07, 1.07588193e-07, 1.06380703e-07, 1.06710004e-07,\n",
      "       1.05413910e-07, 1.07745961e-07, 1.06414568e-07, 1.07862640e-07,\n",
      "       1.07272918e-07, 1.07255083e-07, 1.05656689e-07, 1.07859542e-07,\n",
      "       1.05653235e-07, 1.07256554e-07, 1.05336667e-07, 1.07797455e-07,\n",
      "       1.07337968e-07, 1.06487583e-07, 1.06882830e-07, 1.07258053e-07,\n",
      "       1.06350889e-07, 1.05205757e-07, 1.06796293e-07, 1.09229731e-07,\n",
      "       1.08569374e-07, 1.10014653e-07, 1.07732248e-07, 1.07671319e-07,\n",
      "       1.09065070e-07, 1.06783666e-07, 1.06921959e-07, 1.04245323e-07,\n",
      "       1.02519664e-07, 1.06465983e-07, 1.08002709e-07, 1.07000837e-07,\n",
      "       1.08464462e-07, 1.07286318e-07, 1.07299115e-07, 1.04990946e-07,\n",
      "       1.05114296e-07, 1.07705603e-07, 1.06251292e-07, 1.06827081e-07,\n",
      "       1.05481725e-07, 1.07864281e-07, 1.07910715e-07, 1.08046358e-07,\n",
      "       1.04923899e-07, 1.06855900e-07, 1.08375268e-07, 1.07264846e-07,\n",
      "       1.06345432e-07, 1.06419265e-07, 1.07402670e-07, 1.06731903e-07,\n",
      "       1.07634101e-07, 1.07267340e-07, 1.07245619e-07, 1.07441267e-07,\n",
      "       1.06088379e-07, 1.04877898e-07, 1.07345961e-07, 1.05392360e-07,\n",
      "       1.06349795e-07, 1.06601938e-07, 1.07780622e-07, 1.07621219e-07,\n",
      "       1.06308278e-07, 1.07692706e-07, 1.06110029e-07, 1.07366979e-07,\n",
      "       1.08106832e-07, 1.08401466e-07, 1.06155014e-07, 1.07989784e-07,\n",
      "       1.07016348e-07, 1.05966862e-07, 1.08380064e-07, 1.07777446e-07,\n",
      "       1.08709479e-07, 1.06530194e-07, 1.07383400e-07, 1.08558567e-07,\n",
      "       1.06153962e-07, 1.06987869e-07, 1.06459858e-07, 1.08425660e-07,\n",
      "       1.06417183e-07, 1.05440776e-07, 1.03922730e-07, 1.07419567e-07,\n",
      "       1.04771239e-07, 1.07505095e-07, 1.06863141e-07, 1.02227304e-07,\n",
      "       1.04906789e-07, 1.07846716e-07, 1.06224114e-07, 1.08117163e-07,\n",
      "       1.08157032e-07, 1.07798243e-07, 1.07775918e-07, 1.05512207e-07,\n",
      "       1.07328106e-07, 1.07705127e-07, 1.06739812e-07, 1.07336135e-07,\n",
      "       1.07652212e-07, 1.07688820e-07, 1.07662125e-07, 1.07677018e-07,\n",
      "       1.06730930e-07, 1.07276669e-07, 1.01674281e-07, 1.07972177e-07,\n",
      "       1.06927452e-07, 1.03844997e-07, 1.05008773e-07, 1.07729669e-07,\n",
      "       1.06759771e-07, 1.06438513e-07, 1.05440535e-07, 1.07523825e-07,\n",
      "       1.07344398e-07, 1.07885384e-07, 1.08594755e-07, 1.06250219e-07,\n",
      "       1.06708541e-07, 1.07278311e-07, 1.09478769e-07, 1.04434910e-07,\n",
      "       1.07042716e-07, 1.07284457e-07, 1.04538778e-07, 1.06444126e-07,\n",
      "       1.06245302e-07, 1.06729679e-07, 1.06888720e-07, 1.06177758e-07,\n",
      "       1.07506494e-07, 1.07428271e-07, 1.08806283e-07, 1.06638645e-07,\n",
      "       1.08241800e-07, 1.07664263e-07, 1.06424636e-07, 1.05471315e-07,\n",
      "       1.06679735e-07, 1.07592513e-07, 1.04840410e-07, 1.06257104e-07,\n",
      "       1.06815406e-07, 1.08244784e-07, 1.06816181e-07, 1.07890088e-07,\n",
      "       1.05118787e-07, 1.07590132e-07, 1.06415634e-07, 1.06229727e-07,\n",
      "       1.06802688e-07, 1.05550264e-07, 1.07877923e-07, 1.04812685e-07,\n",
      "       1.07426310e-07, 1.07328923e-07, 1.05923817e-07, 1.07991688e-07,\n",
      "       1.06805956e-07, 1.05366688e-07, 1.06985034e-07, 1.08251214e-07,\n",
      "       1.05520179e-07, 1.04724307e-07, 1.07632573e-07, 1.07122219e-07,\n",
      "       1.06078318e-07, 1.07957739e-07, 1.06750186e-07, 1.05343602e-07,\n",
      "       1.07239586e-07, 1.06116374e-07, 1.07838410e-07, 1.06617193e-07,\n",
      "       1.06683949e-07, 1.06044091e-07, 1.08881537e-07, 1.07711919e-07,\n",
      "       1.04178959e-07, 1.04467546e-07, 1.04848617e-07, 1.05322883e-07,\n",
      "       1.08975712e-07, 1.04028786e-07, 1.07921032e-07, 1.07431084e-07,\n",
      "       1.08084599e-07, 1.04648102e-07, 1.06897481e-07, 1.06622764e-07,\n",
      "       1.07394101e-07, 1.08921306e-07, 1.07095723e-07, 1.07542519e-07,\n",
      "       1.07601672e-07, 1.07394520e-07, 1.05827411e-07, 1.07066619e-07,\n",
      "       1.09613381e-07, 1.06947716e-07, 1.07600748e-07, 1.00122612e-07,\n",
      "       1.06367359e-07, 1.08236023e-07, 1.08331278e-07, 1.06230345e-07,\n",
      "       1.06244883e-07, 1.05996797e-07, 1.07261776e-07, 1.07787749e-07,\n",
      "       1.06664245e-07, 1.03772742e-07, 1.05313156e-07, 1.07236943e-07,\n",
      "       1.06389869e-07, 1.06868171e-07, 1.05669393e-07, 1.05948246e-07,\n",
      "       1.08442421e-07, 1.05275099e-07, 1.09313170e-07, 1.07300728e-07,\n",
      "       1.08356900e-07, 1.06818767e-07, 1.07582956e-07, 1.08319732e-07,\n",
      "       1.05251758e-07, 1.08848994e-07, 1.05623847e-07, 1.06183727e-07,\n",
      "       1.06914662e-07, 1.04982334e-07, 1.08554957e-07, 1.06921846e-07,\n",
      "       1.07046937e-07, 1.08261375e-07, 1.07855215e-07, 1.06147660e-07,\n",
      "       1.07572262e-07, 1.09250017e-07, 1.05851022e-07, 1.03816653e-07,\n",
      "       1.07745350e-07, 1.07332660e-07, 1.07270630e-07, 1.06722645e-07,\n",
      "       1.09549347e-07, 1.07525189e-07, 1.07528329e-07, 1.08236193e-07,\n",
      "       1.07417719e-07, 1.09054852e-07, 1.07589756e-07, 1.08294778e-07,\n",
      "       1.05891722e-07, 1.07115568e-07, 1.07486699e-07, 1.07508143e-07,\n",
      "       1.05570990e-07, 1.05426523e-07, 1.05368350e-07, 1.06435166e-07,\n",
      "       1.03769203e-07, 1.06447359e-07, 1.07360002e-07, 1.09716872e-07,\n",
      "       1.05211072e-07, 1.04641558e-07, 1.05030090e-07, 1.08695986e-07,\n",
      "       1.07275973e-07, 1.07539599e-07, 1.06980728e-07, 1.06421638e-07,\n",
      "       1.05618398e-07, 1.08254255e-07, 1.07129331e-07, 1.07465404e-07,\n",
      "       1.05529828e-07, 1.07604684e-07, 1.08882872e-07, 1.07453268e-07,\n",
      "       1.05120819e-07, 1.07850020e-07, 1.05689303e-07, 1.05836257e-07,\n",
      "       1.06650305e-07, 1.03603234e-07, 1.07635863e-07, 1.06020870e-07,\n",
      "       1.07664917e-07, 1.05659510e-07, 1.07306377e-07, 1.07687271e-07,\n",
      "       1.07128336e-07, 1.06975229e-07, 1.08147944e-07, 1.04091583e-07,\n",
      "       1.07961299e-07, 1.07717170e-07, 1.05651232e-07, 1.05369665e-07,\n",
      "       1.06262142e-07, 1.07569790e-07, 1.07200975e-07, 1.07324581e-07,\n",
      "       1.04770415e-07, 1.08052205e-07, 1.06994428e-07, 1.05156282e-07,\n",
      "       1.05928088e-07, 1.04648031e-07, 1.06567796e-07, 1.06949379e-07,\n",
      "       1.05873958e-07, 1.07875245e-07, 1.08240300e-07, 1.05816234e-07,\n",
      "       1.08030846e-07, 1.06867013e-07, 1.07290425e-07, 1.06697058e-07,\n",
      "       1.08865976e-07, 1.08706331e-07, 1.05987894e-07, 1.08691346e-07,\n",
      "       1.07036257e-07, 1.05859037e-07, 1.08021368e-07, 1.07828058e-07,\n",
      "       1.08912786e-07, 1.06211552e-07, 1.04892408e-07, 1.05670907e-07,\n",
      "       1.07449686e-07, 1.07515909e-07, 1.06491534e-07, 1.06442812e-07,\n",
      "       1.07593600e-07, 1.09087388e-07, 1.06064164e-07, 1.08539801e-07,\n",
      "       1.06961245e-07, 1.07412710e-07, 1.02331541e-07, 1.06879774e-07,\n",
      "       1.08446770e-07, 1.06542942e-07, 1.07890763e-07, 1.07509130e-07,\n",
      "       1.08530173e-07, 1.09233262e-07, 1.08552655e-07, 1.07593131e-07,\n",
      "       1.08885324e-07, 1.08117298e-07, 1.07201686e-07, 1.07796993e-07,\n",
      "       1.06266938e-07, 1.07407750e-07, 1.07595518e-07, 1.07098316e-07,\n",
      "       1.06315682e-07, 1.09310825e-07, 1.07377929e-07, 1.06626274e-07,\n",
      "       1.07351845e-07, 1.04205121e-07, 1.06912481e-07, 1.04628768e-07,\n",
      "       1.07723650e-07, 1.07417634e-07, 1.06476641e-07, 1.05900078e-07,\n",
      "       1.07844293e-07, 1.06273028e-07, 1.08323356e-07, 1.08379560e-07,\n",
      "       1.03347418e-07, 1.09269394e-07, 1.07614234e-07, 1.08222174e-07,\n",
      "       1.08076982e-07, 1.07315188e-07, 1.08115650e-07, 1.07794243e-07,\n",
      "       1.05514026e-07, 1.08936128e-07, 1.04905745e-07, 1.07541467e-07,\n",
      "       1.05345528e-07, 1.06291999e-07, 1.06071504e-07, 1.05437266e-07,\n",
      "       1.06785180e-07, 1.07259915e-07, 1.07310541e-07, 1.06138415e-07,\n",
      "       1.05926738e-07, 1.08477508e-07, 1.07046979e-07, 1.07027574e-07,\n",
      "       1.06712115e-07, 1.08237046e-07, 1.07049402e-07, 1.06947340e-07,\n",
      "       1.06279131e-07, 1.06730518e-07, 1.07588619e-07, 1.05524954e-07,\n",
      "       1.08166162e-07, 1.06587926e-07, 1.07679703e-07, 1.03844755e-07,\n",
      "       1.04563028e-07, 1.05275092e-07, 1.08666931e-07, 1.06631383e-07,\n",
      "       1.06881380e-07, 1.04338554e-07, 1.07791955e-07, 1.08298806e-07,\n",
      "       1.05931292e-07, 1.06788804e-07, 1.08401018e-07, 1.06970866e-07,\n",
      "       1.06919586e-07, 1.08371935e-07, 1.06527565e-07, 1.04125405e-07,\n",
      "       1.06035692e-07, 1.07914772e-07, 1.04487803e-07, 1.07088184e-07,\n",
      "       1.08826249e-07, 1.07145958e-07, 1.06165629e-07, 1.05506700e-07,\n",
      "       1.06336238e-07, 1.07285615e-07, 1.04574617e-07, 1.07219527e-07,\n",
      "       1.04366976e-07, 1.07281146e-07, 1.04928532e-07, 1.05945098e-07,\n",
      "       1.05710896e-07, 1.08559163e-07, 1.05225965e-07, 1.05001632e-07,\n",
      "       1.09945063e-07, 1.07487537e-07, 1.07792147e-07, 1.07768436e-07,\n",
      "       1.05886954e-07, 1.05257222e-07, 1.07507134e-07, 1.07646954e-07,\n",
      "       1.07246187e-07, 1.07017733e-07, 1.05024647e-07, 1.06526883e-07,\n",
      "       1.08330916e-07, 1.06726809e-07, 1.05791528e-07, 1.06234793e-07,\n",
      "       1.08235547e-07, 1.07756257e-07, 1.06002453e-07, 1.07546299e-07,\n",
      "       1.08328273e-07, 1.05170841e-07, 1.07151138e-07, 1.07407907e-07,\n",
      "       1.07672427e-07, 1.03585741e-07, 1.08291985e-07, 1.07979744e-07,\n",
      "       1.08016458e-07, 1.06893232e-07, 1.05954243e-07, 1.05432328e-07,\n",
      "       1.08409012e-07, 1.06531992e-07, 1.07904611e-07, 1.04906711e-07,\n",
      "       1.04594548e-07, 1.07710996e-07, 1.07771847e-07, 1.05310214e-07,\n",
      "       1.05992612e-07, 1.05365373e-07, 1.07570628e-07, 1.06783702e-07,\n",
      "       1.07003771e-07, 1.04569821e-07, 1.08342917e-07, 1.05885121e-07,\n",
      "       1.08720762e-07, 1.07427631e-07, 1.07975460e-07, 1.06645217e-07,\n",
      "       1.07753699e-07, 1.06813978e-07, 1.08527409e-07, 1.06529612e-07,\n",
      "       1.04727718e-07, 1.07039867e-07, 1.06362009e-07, 1.07574529e-07,\n",
      "       1.08172436e-07, 1.08562915e-07, 1.07090358e-07, 1.06311688e-07,\n",
      "       1.06723682e-07, 1.08998428e-07, 1.07157909e-07, 1.06812998e-07,\n",
      "       1.05272122e-07, 1.07641306e-07, 1.07348527e-07, 1.07602276e-07,\n",
      "       1.08389713e-07, 1.05126702e-07, 1.07371505e-07, 1.04029809e-07,\n",
      "       1.03859577e-07, 1.06760062e-07, 1.07532948e-07, 1.08107578e-07,\n",
      "       1.06629145e-07, 1.07330848e-07, 1.06442364e-07, 1.06923984e-07,\n",
      "       1.06304263e-07, 1.06664864e-07, 1.07543094e-07, 1.08130742e-07,\n",
      "       1.07657371e-07, 1.06700149e-07, 1.07473220e-07, 1.06530429e-07,\n",
      "       1.06522194e-07, 1.07571054e-07, 1.06902341e-07, 1.06663286e-07,\n",
      "       1.07944139e-07, 1.09220068e-07, 1.05847917e-07, 1.07284578e-07,\n",
      "       1.07142199e-07, 1.05617957e-07, 1.05898671e-07, 1.09164965e-07,\n",
      "       1.05790825e-07, 1.07301723e-07, 1.07349088e-07, 1.06679359e-07,\n",
      "       1.04919678e-07, 1.06530180e-07, 1.04979542e-07, 1.04979136e-07,\n",
      "       1.06416188e-07, 1.06574561e-07, 1.04782252e-07, 1.08327100e-07,\n",
      "       1.07360172e-07, 1.05535385e-07, 1.06479796e-07, 1.08241252e-07,\n",
      "       1.08794083e-07, 1.07208059e-07, 1.07944054e-07, 1.06862984e-07,\n",
      "       1.09372529e-07, 1.07166393e-07, 1.06954467e-07, 1.05877795e-07,\n",
      "       1.07964908e-07, 1.06335854e-07, 1.06839515e-07, 1.04045291e-07,\n",
      "       1.07802386e-07, 1.08477415e-07, 1.07863400e-07, 1.04926471e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_32/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/depthwise_conv2d_10/depthwise;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D\n",
      "index : 120\n",
      "shape : [  1   5   5 672]\n",
      "shape_signature : [  1   5   5 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00014109, 0.00016375, 0.00015938, 0.00016314, 0.00015856,\n",
      "       0.00014871, 0.00015225, 0.00015799, 0.00015782, 0.00014293,\n",
      "       0.0001565 , 0.00015285, 0.00015524, 0.00016251, 0.00015109,\n",
      "       0.00015718, 0.00015372, 0.0001646 , 0.00015328, 0.00016025,\n",
      "       0.00016363, 0.00014344, 0.00015903, 0.00015717, 0.00015562,\n",
      "       0.00016758, 0.00015257, 0.00016166, 0.00015584, 0.00015808,\n",
      "       0.00016069, 0.00015816, 0.00016757, 0.00014726, 0.00016428,\n",
      "       0.00015078, 0.00016503, 0.0001502 , 0.00016079, 0.00016539,\n",
      "       0.00016398, 0.00015462, 0.00015644, 0.00016165, 0.00014717,\n",
      "       0.00013786, 0.00015943, 0.00014815, 0.00016492, 0.00014975,\n",
      "       0.00016049, 0.0001619 , 0.00015262, 0.00015673, 0.00016561,\n",
      "       0.00015313, 0.00016487, 0.00016473, 0.00015611, 0.00015376,\n",
      "       0.00015414, 0.0001384 , 0.00016118, 0.00015513, 0.00015274,\n",
      "       0.00016152, 0.00012807, 0.00015297, 0.00015936, 0.00015591,\n",
      "       0.00015727, 0.00015627, 0.00015097, 0.00016045, 0.0001597 ,\n",
      "       0.00015408, 0.00015747, 0.00015339, 0.00015649, 0.00016347,\n",
      "       0.00015556, 0.00015629, 0.0001367 , 0.00015085, 0.00014593,\n",
      "       0.00015124, 0.00014974, 0.00016011, 0.00016192, 0.00015548,\n",
      "       0.00014587, 0.00015884, 0.00016619, 0.00015525, 0.00016399,\n",
      "       0.00015284, 0.00016314, 0.00016105, 0.00015756, 0.00015096,\n",
      "       0.00016429, 0.0001598 , 0.00016393, 0.00015739, 0.00015428,\n",
      "       0.00013114, 0.00014743, 0.0001533 , 0.00015709, 0.00016201,\n",
      "       0.00014747, 0.00016542, 0.00013216, 0.00016794, 0.00015358,\n",
      "       0.00016292, 0.00016262, 0.00015377, 0.00016261, 0.00016508,\n",
      "       0.00016447, 0.00016419, 0.00015598, 0.00015016, 0.00015784,\n",
      "       0.00014961, 0.00015444, 0.00014847, 0.0001591 , 0.00015542,\n",
      "       0.00015418, 0.00016036, 0.0001656 , 0.0001605 , 0.00015302,\n",
      "       0.00013522, 0.0001574 , 0.00013843, 0.0001585 , 0.00014945,\n",
      "       0.00015315, 0.00015925, 0.00016289, 0.00016196, 0.00014894,\n",
      "       0.00015746, 0.00016613, 0.00016741, 0.0001503 , 0.00015481,\n",
      "       0.00015241, 0.00015957, 0.00015162, 0.00014817, 0.00015765,\n",
      "       0.00014655, 0.00015048, 0.00015774, 0.00015509, 0.00016071,\n",
      "       0.00014697, 0.00015466, 0.00015077, 0.00016314, 0.00016026,\n",
      "       0.00014742, 0.00015066, 0.00014392, 0.00015182, 0.0001662 ,\n",
      "       0.00015531, 0.00015273, 0.00015203, 0.00014889, 0.00016773,\n",
      "       0.00016396, 0.00015796, 0.00014846, 0.00016126, 0.00016261,\n",
      "       0.00015156, 0.00016014, 0.00014597, 0.00015329, 0.0001557 ,\n",
      "       0.00015842, 0.00014855, 0.00016746, 0.00015998, 0.00015882,\n",
      "       0.0001602 , 0.00015579, 0.00015588, 0.0001578 , 0.00016433,\n",
      "       0.00015922, 0.00016228, 0.00016613, 0.00015108, 0.00016079,\n",
      "       0.00016112, 0.00015212, 0.00015365, 0.00016008, 0.00015562,\n",
      "       0.00015471, 0.00013748, 0.00016262, 0.00015994, 0.00015843,\n",
      "       0.00015818, 0.00016016, 0.0001558 , 0.00013199, 0.00015495,\n",
      "       0.00015795, 0.00014563, 0.00016126, 0.00016228, 0.00016366,\n",
      "       0.00015447, 0.00016546, 0.00015546, 0.00016189, 0.00015757,\n",
      "       0.00016621, 0.00016493, 0.00015709, 0.0001434 , 0.00015612,\n",
      "       0.00014566, 0.00015203, 0.00015847, 0.00015893, 0.00016084,\n",
      "       0.00014883, 0.00015166, 0.00015515, 0.00015948, 0.00014696,\n",
      "       0.00014725, 0.00016216, 0.00014014, 0.00015517, 0.00015058,\n",
      "       0.00016341, 0.00016212, 0.00015207, 0.00015873, 0.00016317,\n",
      "       0.00015574, 0.00015457, 0.00014629, 0.00016036, 0.00014783,\n",
      "       0.00015821, 0.00015302, 0.0001502 , 0.00015488, 0.00015244,\n",
      "       0.00016635, 0.00016256, 0.00015574, 0.00016411, 0.0001605 ,\n",
      "       0.00015139, 0.00015961, 0.00015345, 0.00015576, 0.00016318,\n",
      "       0.0001421 , 0.00013392, 0.00015059, 0.00015918, 0.00015845,\n",
      "       0.00015917, 0.00014684, 0.00014673, 0.00014892, 0.00015539,\n",
      "       0.00016407, 0.00015084, 0.00016486, 0.00016445, 0.00016748,\n",
      "       0.00016392, 0.00016434, 0.00014668, 0.0001546 , 0.00016561,\n",
      "       0.00016452, 0.0001544 , 0.00014496, 0.00016398, 0.00015925,\n",
      "       0.00015022, 0.00016095, 0.00015522, 0.00016017, 0.00015932,\n",
      "       0.0001396 , 0.00016411, 0.00015998, 0.00015263, 0.00016046,\n",
      "       0.00015536, 0.00016065, 0.00015335, 0.00016154, 0.00015431,\n",
      "       0.00016217, 0.00015253, 0.00014841, 0.00016345, 0.00014333,\n",
      "       0.00015858, 0.00014893, 0.00015291, 0.00016109, 0.00015138,\n",
      "       0.00016131, 0.00016484, 0.00015907, 0.00014486, 0.00015527,\n",
      "       0.00016488, 0.00016108, 0.00016203, 0.00016076, 0.00015259,\n",
      "       0.00016116, 0.00015177, 0.00014833, 0.00015223, 0.00015279,\n",
      "       0.00016454, 0.00016058, 0.00015904, 0.00016141, 0.00014814,\n",
      "       0.00014105, 0.00015877, 0.0001519 , 0.00015705, 0.00016567,\n",
      "       0.00016518, 0.00015427, 0.00015845, 0.00016593, 0.00015731,\n",
      "       0.00015631, 0.00015888, 0.00016405, 0.00015402, 0.00013892,\n",
      "       0.00015135, 0.00014621, 0.00016452, 0.00015541, 0.00012265,\n",
      "       0.00016478, 0.00016045, 0.0001393 , 0.0001549 , 0.00016281,\n",
      "       0.00013909, 0.00015048, 0.00015294, 0.00015913, 0.00016121,\n",
      "       0.00015504, 0.00015439, 0.00016418, 0.00016489, 0.00014804,\n",
      "       0.0001659 , 0.00015755, 0.00015749, 0.00016246, 0.00015224,\n",
      "       0.00015397, 0.0001562 , 0.00015813, 0.00016825, 0.00015155,\n",
      "       0.00015105, 0.00015895, 0.00014036, 0.00016382, 0.00015475,\n",
      "       0.00014431, 0.00015888, 0.00015578, 0.00016094, 0.00015374,\n",
      "       0.00015601, 0.00015809, 0.00015823, 0.00016826, 0.00015809,\n",
      "       0.00016396, 0.000162  , 0.00015861, 0.00015824, 0.00015579,\n",
      "       0.00014191, 0.00016305, 0.00015925, 0.00015539, 0.00015658,\n",
      "       0.00016226, 0.00015672, 0.00015931, 0.00016285, 0.00016407,\n",
      "       0.00015425, 0.00016498, 0.00013341, 0.00016293, 0.00016485,\n",
      "       0.00016094, 0.0001665 , 0.0001581 , 0.00015383, 0.00015359,\n",
      "       0.00014157, 0.0001548 , 0.00015754, 0.00016892, 0.00016   ,\n",
      "       0.00015606, 0.00015739, 0.00016233, 0.00016549, 0.00015227,\n",
      "       0.00015327, 0.00016011, 0.00014825, 0.00016312, 0.0001627 ,\n",
      "       0.00016134, 0.00016151, 0.0001583 , 0.00016373, 0.00016324,\n",
      "       0.00015066, 0.00014561, 0.0001549 , 0.00015815, 0.00015312,\n",
      "       0.00015161, 0.0001585 , 0.00015109, 0.00016463, 0.00015601,\n",
      "       0.00015943, 0.00015907, 0.00016161, 0.00016363, 0.00015512,\n",
      "       0.00015611, 0.00015981, 0.00015324, 0.00016368, 0.0001614 ,\n",
      "       0.00016453, 0.00016225, 0.00015866, 0.00016096, 0.00015615,\n",
      "       0.00015262, 0.00015861, 0.00015591, 0.00016402, 0.00014815,\n",
      "       0.00016199, 0.00015026, 0.0001501 , 0.00015156, 0.00015558,\n",
      "       0.00015254, 0.00014895, 0.00016821, 0.00015246, 0.00015273,\n",
      "       0.00014817, 0.00016753, 0.00015274, 0.00016393, 0.00015965,\n",
      "       0.00016472, 0.00016194, 0.00015794, 0.00016442, 0.00015684,\n",
      "       0.00014956, 0.00016407, 0.00015781, 0.00016368, 0.00014937,\n",
      "       0.00016368, 0.00016122, 0.0001581 , 0.00014422, 0.00014108,\n",
      "       0.00014179, 0.00016163, 0.00016887, 0.00015728, 0.00017045,\n",
      "       0.00015657, 0.00015322, 0.00015511, 0.00016398, 0.00015692,\n",
      "       0.00015435, 0.00014775, 0.00015245, 0.0001655 , 0.00014864,\n",
      "       0.0001215 , 0.00016506, 0.00016821, 0.00015943, 0.00015979,\n",
      "       0.00016269, 0.00016306, 0.00015571, 0.00016105, 0.00016115,\n",
      "       0.00016329, 0.0001544 , 0.00014426, 0.00014734, 0.00016172,\n",
      "       0.00016218, 0.00015323, 0.00015155, 0.00015678, 0.0001573 ,\n",
      "       0.00016233, 0.00016012, 0.00015093, 0.00015937, 0.00016446,\n",
      "       0.0001474 , 0.00015862, 0.00015816, 0.00015397, 0.00016604,\n",
      "       0.00014856, 0.00016192, 0.00016012, 0.00014248, 0.00016927,\n",
      "       0.00016095, 0.00014821, 0.00014749, 0.00015718, 0.00014986,\n",
      "       0.00014448, 0.00015066, 0.00014698, 0.0001625 , 0.00015694,\n",
      "       0.00015101, 0.00015607, 0.00015198, 0.00015933, 0.00016112,\n",
      "       0.00015385, 0.00013985, 0.00015707, 0.00016049, 0.00016382,\n",
      "       0.00016266, 0.00015986, 0.00016101, 0.00015853, 0.00015121,\n",
      "       0.00016415, 0.00015965, 0.00015425, 0.00014897, 0.00015629,\n",
      "       0.00016291, 0.00016831, 0.00016764, 0.00015958, 0.00014969,\n",
      "       0.00016061, 0.00016099, 0.00016392, 0.00015745, 0.00014649,\n",
      "       0.00013832, 0.00016109, 0.00015742, 0.00016063, 0.00015626,\n",
      "       0.0001554 , 0.0001605 , 0.0001474 , 0.00015268, 0.00015523,\n",
      "       0.000161  , 0.00016054, 0.00015053, 0.00015913, 0.00015768,\n",
      "       0.00016223, 0.00016342, 0.0001413 , 0.00015653, 0.00015648,\n",
      "       0.00014947, 0.00015978, 0.00015808, 0.0001491 , 0.00015634,\n",
      "       0.00014918, 0.0001432 , 0.00016909, 0.00016538, 0.00016173,\n",
      "       0.00016218, 0.0001471 , 0.00014855, 0.00015613, 0.00015137,\n",
      "       0.00016484, 0.00015908, 0.00015305, 0.00015624, 0.00016178,\n",
      "       0.00015436, 0.00016176, 0.0001633 , 0.000154  , 0.00013806,\n",
      "       0.00016026, 0.00015748, 0.00016009, 0.00015695, 0.00016725,\n",
      "       0.00016314, 0.00016255, 0.00015443, 0.00014852, 0.00015249,\n",
      "       0.00015397, 0.00014632, 0.00015288, 0.00016615, 0.00016027,\n",
      "       0.0001507 , 0.00015703, 0.00016754, 0.00015437, 0.00016032,\n",
      "       0.00016338, 0.00016138, 0.00015948, 0.00016086, 0.00015527,\n",
      "       0.00014674, 0.00016048, 0.00015475, 0.00015929, 0.00016436,\n",
      "       0.00015962, 0.00015975], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_32/FusedBatchNormV3\n",
      "index : 121\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([8.1596010e-09, 9.4696198e-09, 9.2172225e-09, 9.4348325e-09,\n",
      "       9.1696535e-09, 8.6002050e-09, 8.8046841e-09, 9.1368548e-09,\n",
      "       9.1268051e-09, 8.2660980e-09, 9.0507122e-09, 8.8396588e-09,\n",
      "       8.9776462e-09, 9.3982235e-09, 8.7377945e-09, 9.0900425e-09,\n",
      "       8.8898870e-09, 9.5187707e-09, 8.8645251e-09, 9.2672394e-09,\n",
      "       9.4627906e-09, 8.2953271e-09, 9.1969703e-09, 9.0896064e-09,\n",
      "       8.9998995e-09, 9.6912220e-09, 8.8230943e-09, 9.3490922e-09,\n",
      "       9.0122310e-09, 9.1420675e-09, 9.2931121e-09, 9.1468557e-09,\n",
      "       9.6910044e-09, 8.5163574e-09, 9.5004093e-09, 8.7201002e-09,\n",
      "       9.5439088e-09, 8.6863743e-09, 9.2984678e-09, 9.5645580e-09,\n",
      "       9.4830019e-09, 8.9421182e-09, 9.0471524e-09, 9.3485850e-09,\n",
      "       8.5112593e-09, 7.9725799e-09, 9.2200905e-09, 8.5678398e-09,\n",
      "       9.5375849e-09, 8.6601375e-09, 9.2813650e-09, 9.3629069e-09,\n",
      "       8.8260235e-09, 9.0637302e-09, 9.5774428e-09, 8.8559196e-09,\n",
      "       9.5347019e-09, 9.5268273e-09, 9.0279109e-09, 8.8919645e-09,\n",
      "       8.9142480e-09, 8.0039078e-09, 9.3213819e-09, 8.9711820e-09,\n",
      "       8.8333678e-09, 9.3409760e-09, 7.4061979e-09, 8.8467340e-09,\n",
      "       9.2159560e-09, 9.0166283e-09, 9.0953023e-09, 9.0375885e-09,\n",
      "       8.7307601e-09, 9.2788373e-09, 9.2357038e-09, 8.9105496e-09,\n",
      "       9.1069765e-09, 8.8706029e-09, 9.0498355e-09, 9.4536947e-09,\n",
      "       8.9959666e-09, 9.0383496e-09, 7.9057196e-09, 8.7238927e-09,\n",
      "       8.4392422e-09, 8.7464116e-09, 8.6594758e-09, 9.2594075e-09,\n",
      "       9.3641717e-09, 8.9916616e-09, 8.4357312e-09, 9.1859036e-09,\n",
      "       9.6109192e-09, 8.9782946e-09, 9.4838439e-09, 8.8387129e-09,\n",
      "       9.4345234e-09, 9.3136681e-09, 9.1121759e-09, 8.7301508e-09,\n",
      "       9.5010186e-09, 9.2412593e-09, 9.4805142e-09, 9.1021279e-09,\n",
      "       8.9220515e-09, 7.5841760e-09, 8.5262437e-09, 8.8658254e-09,\n",
      "       9.0848804e-09, 9.3691703e-09, 8.5281613e-09, 9.5663157e-09,\n",
      "       7.6429334e-09, 9.7121067e-09, 8.8817247e-09, 9.4220773e-09,\n",
      "       9.4045216e-09, 8.8924992e-09, 9.4041255e-09, 9.5469872e-09,\n",
      "       9.5112807e-09, 9.4952863e-09, 9.0204466e-09, 8.6839869e-09,\n",
      "       9.1283141e-09, 8.6518739e-09, 8.9315746e-09, 8.5860146e-09,\n",
      "       9.2012051e-09, 8.9881409e-09, 8.9161976e-09, 9.2739709e-09,\n",
      "       9.5766541e-09, 9.2818642e-09, 8.8492200e-09, 7.8197839e-09,\n",
      "       9.1023917e-09, 8.0054985e-09, 9.1664809e-09, 8.6431573e-09,\n",
      "       8.8568370e-09, 9.2097050e-09, 9.4201047e-09, 9.3664854e-09,\n",
      "       8.6133856e-09, 9.1060075e-09, 9.6073371e-09, 9.6815906e-09,\n",
      "       8.6918241e-09, 8.9530738e-09, 8.8143119e-09, 9.2280237e-09,\n",
      "       8.7683327e-09, 8.5685947e-09, 9.1168451e-09, 8.4753315e-09,\n",
      "       8.7021768e-09, 9.1224894e-09, 8.9689758e-09, 9.2943289e-09,\n",
      "       8.4993061e-09, 8.9443812e-09, 8.7192449e-09, 9.4345660e-09,\n",
      "       9.2679446e-09, 8.5255349e-09, 8.7128216e-09, 8.3230161e-09,\n",
      "       8.7801206e-09, 9.6113304e-09, 8.9819059e-09, 8.8327026e-09,\n",
      "       8.7919192e-09, 8.6107974e-09, 9.7001900e-09, 9.4817834e-09,\n",
      "       9.1350811e-09, 8.5853795e-09, 9.3258148e-09, 9.4042250e-09,\n",
      "       8.7652090e-09, 9.2609804e-09, 8.4417264e-09, 8.8652303e-09,\n",
      "       9.0043581e-09, 9.1616110e-09, 8.5909777e-09, 9.6843076e-09,\n",
      "       9.2517363e-09, 9.1848484e-09, 9.2647614e-09, 9.0098338e-09,\n",
      "       9.0145491e-09, 9.1259533e-09, 9.5035837e-09, 9.2080565e-09,\n",
      "       9.3850012e-09, 9.6077342e-09, 8.7369889e-09, 9.2989616e-09,\n",
      "       9.3175521e-09, 8.7970493e-09, 8.8856460e-09, 9.2576000e-09,\n",
      "       8.9995185e-09, 8.9472385e-09, 7.9507334e-09, 9.4044186e-09,\n",
      "       9.2493186e-09, 9.1619414e-09, 9.1480370e-09, 9.2624886e-09,\n",
      "       9.0100363e-09, 7.6330604e-09, 8.9610088e-09, 9.1342161e-09,\n",
      "       8.4221679e-09, 9.3259356e-09, 9.3850003e-09, 9.4645030e-09,\n",
      "       8.9334122e-09, 9.5687041e-09, 8.9903276e-09, 9.3623944e-09,\n",
      "       9.1123882e-09, 9.6118971e-09, 9.5379900e-09, 9.0845180e-09,\n",
      "       8.2931040e-09, 9.0288639e-09, 8.4234584e-09, 8.7918881e-09,\n",
      "       9.1644754e-09, 9.1911749e-09, 9.3018500e-09, 8.6068646e-09,\n",
      "       8.7707397e-09, 8.9724068e-09, 9.2228696e-09, 8.4987901e-09,\n",
      "       8.5155882e-09, 9.3778283e-09, 8.1042923e-09, 8.9737728e-09,\n",
      "       8.7081435e-09, 9.4501766e-09, 9.3758414e-09, 8.7945997e-09,\n",
      "       9.1794377e-09, 9.4363468e-09, 9.0068593e-09, 8.9390753e-09,\n",
      "       8.4602165e-09, 9.2737436e-09, 8.5493870e-09, 9.1492307e-09,\n",
      "       8.8491205e-09, 8.6863627e-09, 8.9571630e-09, 8.8159666e-09,\n",
      "       9.6202601e-09, 9.4013570e-09, 9.0064951e-09, 9.4909103e-09,\n",
      "       9.2821493e-09, 8.7551397e-09, 9.2306065e-09, 8.8742276e-09,\n",
      "       9.0075805e-09, 9.4369144e-09, 8.2181106e-09, 7.7446050e-09,\n",
      "       8.7088008e-09, 9.2057793e-09, 9.1632719e-09, 9.2047774e-09,\n",
      "       8.4921901e-09, 8.4855172e-09, 8.6124361e-09, 8.9863184e-09,\n",
      "       9.4881942e-09, 8.7231493e-09, 9.5339470e-09, 9.5104733e-09,\n",
      "       9.6853796e-09, 9.4799839e-09, 9.5038724e-09, 8.4826484e-09,\n",
      "       8.9408196e-09, 9.5776800e-09, 9.5142978e-09, 8.9294314e-09,\n",
      "       8.3833234e-09, 9.4830677e-09, 9.2097467e-09, 8.6876550e-09,\n",
      "       9.3077883e-09, 8.9764587e-09, 9.2625871e-09, 9.2138830e-09,\n",
      "       8.0732478e-09, 9.4908570e-09, 9.2516794e-09, 8.8269934e-09,\n",
      "       9.2797761e-09, 8.9844274e-09, 9.2903738e-09, 8.8687262e-09,\n",
      "       9.3419743e-09, 8.9239833e-09, 9.3787502e-09, 8.8209493e-09,\n",
      "       8.5826883e-09, 9.4526298e-09, 8.2892564e-09, 9.1709120e-09,\n",
      "       8.6129077e-09, 8.8428376e-09, 9.3163051e-09, 8.7544816e-09,\n",
      "       9.3286872e-09, 9.5328945e-09, 9.1993186e-09, 8.3776337e-09,\n",
      "       8.9793959e-09, 9.5349941e-09, 9.3156931e-09, 9.3705301e-09,\n",
      "       9.2970183e-09, 8.8246299e-09, 9.3200265e-09, 8.7768939e-09,\n",
      "       8.5779988e-09, 8.8038794e-09, 8.8363183e-09, 9.5157935e-09,\n",
      "       9.2863575e-09, 9.1975885e-09, 9.3347836e-09, 8.5670218e-09,\n",
      "       8.1572820e-09, 9.1816661e-09, 8.7846965e-09, 9.0822940e-09,\n",
      "       9.5808357e-09, 9.5526067e-09, 8.9217780e-09, 9.1636174e-09,\n",
      "       9.5960271e-09, 9.0972527e-09, 9.0397023e-09, 9.1881480e-09,\n",
      "       9.4870183e-09, 8.9074561e-09, 8.0339646e-09, 8.7529539e-09,\n",
      "       8.4554479e-09, 9.5141344e-09, 8.9874641e-09, 7.0932300e-09,\n",
      "       9.5292316e-09, 9.2788568e-09, 8.0556664e-09, 8.9579046e-09,\n",
      "       9.4153663e-09, 8.0436466e-09, 8.7022283e-09, 8.8445038e-09,\n",
      "       9.2029815e-09, 9.3231662e-09, 8.9663335e-09, 8.9284775e-09,\n",
      "       9.4945758e-09, 9.5359489e-09, 8.5610949e-09, 9.5945003e-09,\n",
      "       9.1115480e-09, 9.1080228e-09, 9.3952970e-09, 8.8042009e-09,\n",
      "       8.9041290e-09, 9.0332133e-09, 9.1449239e-09, 9.7300745e-09,\n",
      "       8.7645127e-09, 8.7355474e-09, 9.1923384e-09, 8.1173424e-09,\n",
      "       9.4740580e-09, 8.9492405e-09, 8.3454434e-09, 9.1882262e-09,\n",
      "       9.0088754e-09, 9.3071471e-09, 8.8910586e-09, 9.0225347e-09,\n",
      "       9.1423829e-09, 9.1506518e-09, 9.7309716e-09, 9.1426484e-09,\n",
      "       9.4820756e-09, 9.3685451e-09, 9.1726822e-09, 9.1514849e-09,\n",
      "       9.0093089e-09, 8.2068450e-09, 9.4295407e-09, 9.2094901e-09,\n",
      "       8.9867029e-09, 9.0552188e-09, 9.3838803e-09, 9.0634087e-09,\n",
      "       9.2130765e-09, 9.4179633e-09, 9.4882688e-09, 8.9206846e-09,\n",
      "       9.5410595e-09, 7.7150073e-09, 9.4222559e-09, 9.5336228e-09,\n",
      "       9.3072101e-09, 9.6291393e-09, 9.1434060e-09, 8.8960510e-09,\n",
      "       8.8823269e-09, 8.1872447e-09, 8.9524468e-09, 9.1106029e-09,\n",
      "       9.7689874e-09, 9.2529868e-09, 9.0249319e-09, 9.1020800e-09,\n",
      "       9.3880104e-09, 9.5707344e-09, 8.8057144e-09, 8.8636627e-09,\n",
      "       9.2596668e-09, 8.5734557e-09, 9.4335046e-09, 9.4092956e-09,\n",
      "       9.3303667e-09, 9.3403774e-09, 9.1549541e-09, 9.4689128e-09,\n",
      "       9.4405177e-09, 8.7131573e-09, 8.4206500e-09, 8.9579686e-09,\n",
      "       9.1462562e-09, 8.8553787e-09, 8.7677803e-09, 9.1662580e-09,\n",
      "       8.7375369e-09, 9.5209431e-09, 9.0223757e-09, 9.2200425e-09,\n",
      "       9.1991614e-09, 9.3459391e-09, 9.4632098e-09, 8.9709253e-09,\n",
      "       9.0281578e-09, 9.2418375e-09, 8.8621395e-09, 9.4655910e-09,\n",
      "       9.3339558e-09, 9.5151087e-09, 9.3833048e-09, 9.1756256e-09,\n",
      "       9.3083186e-09, 9.0303756e-09, 8.8261398e-09, 9.1728776e-09,\n",
      "       9.0162260e-09, 9.4855928e-09, 8.5677856e-09, 9.3678816e-09,\n",
      "       8.6895673e-09, 8.6802530e-09, 8.7649852e-09, 8.9974286e-09,\n",
      "       8.8217131e-09, 8.6140766e-09, 9.7277102e-09, 8.8170307e-09,\n",
      "       8.8325134e-09, 8.5688550e-09, 9.6885691e-09, 8.8330534e-09,\n",
      "       9.4803614e-09, 9.2326795e-09, 9.5259827e-09, 9.3649968e-09,\n",
      "       9.1337089e-09, 9.5084172e-09, 9.0705532e-09, 8.6494953e-09,\n",
      "       9.4884163e-09, 9.1265857e-09, 9.4658610e-09, 8.6384278e-09,\n",
      "       9.4658530e-09, 9.3236761e-09, 9.1434087e-09, 8.3406926e-09,\n",
      "       8.1591160e-09, 8.2000859e-09, 9.3473247e-09, 9.7658548e-09,\n",
      "       9.0954364e-09, 9.8574491e-09, 9.0548991e-09, 8.8612087e-09,\n",
      "       8.9703924e-09, 9.4831201e-09, 9.0747401e-09, 8.9265573e-09,\n",
      "       8.5444176e-09, 8.8162802e-09, 9.5710773e-09, 8.5963032e-09,\n",
      "       7.0267578e-09, 9.5455563e-09, 9.7276205e-09, 9.2198542e-09,\n",
      "       9.2410204e-09, 9.4084465e-09, 9.4301082e-09, 9.0049141e-09,\n",
      "       9.3134886e-09, 9.3195416e-09, 9.4434958e-09, 8.9291303e-09,\n",
      "       8.3429059e-09, 8.5207033e-09, 9.3522656e-09, 9.3789287e-09,\n",
      "       8.8617629e-09, 8.7641636e-09, 9.0668619e-09, 9.0968504e-09,\n",
      "       9.3875272e-09, 9.2602157e-09, 8.7284073e-09, 9.2167074e-09,\n",
      "       9.5108073e-09, 8.5241405e-09, 9.1734034e-09, 9.1468131e-09,\n",
      "       8.9043271e-09, 9.6021138e-09, 8.5915373e-09, 9.3638421e-09,\n",
      "       9.2599484e-09, 8.2399580e-09, 9.7889474e-09, 9.3080894e-09,\n",
      "       8.5709715e-09, 8.5295744e-09, 9.0899688e-09, 8.6664400e-09,\n",
      "       8.3552401e-09, 8.7129042e-09, 8.5002370e-09, 9.3975521e-09,\n",
      "       9.0761070e-09, 8.7330401e-09, 9.0256567e-09, 8.7889482e-09,\n",
      "       9.2144825e-09, 9.3177173e-09, 8.8975609e-09, 8.0876505e-09,\n",
      "       9.0835028e-09, 9.2812256e-09, 9.4737658e-09, 9.4068859e-09,\n",
      "       9.2449532e-09, 9.3112043e-09, 9.1682688e-09, 8.7444105e-09,\n",
      "       9.4928332e-09, 9.2327372e-09, 8.9206331e-09, 8.6153698e-09,\n",
      "       9.0381835e-09, 9.4214663e-09, 9.7338813e-09, 9.6947810e-09,\n",
      "       9.2284704e-09, 8.6569916e-09, 9.2881018e-09, 9.3101065e-09,\n",
      "       9.4799759e-09, 9.1054080e-09, 8.4718010e-09, 7.9992253e-09,\n",
      "       9.3158530e-09, 9.1036698e-09, 9.2895478e-09, 9.0368371e-09,\n",
      "       8.9869108e-09, 9.2818855e-09, 8.5244221e-09, 8.8295495e-09,\n",
      "       8.9770946e-09, 9.3109787e-09, 9.2842667e-09, 8.7054044e-09,\n",
      "       9.2027808e-09, 9.1188435e-09, 9.3818615e-09, 9.4509565e-09,\n",
      "       8.1718570e-09, 9.0523216e-09, 9.0493497e-09, 8.6437906e-09,\n",
      "       9.2404004e-09, 9.1418739e-09, 8.6229450e-09, 9.0413170e-09,\n",
      "       8.6274703e-09, 8.2817229e-09, 9.7789217e-09, 9.5640731e-09,\n",
      "       9.3531387e-09, 9.3790762e-09, 8.5071408e-09, 8.5908072e-09,\n",
      "       9.0292458e-09, 8.7539824e-09, 9.5328954e-09, 9.1995984e-09,\n",
      "       8.8511838e-09, 9.0358157e-09, 9.3562456e-09, 8.9270316e-09,\n",
      "       9.3547730e-09, 9.4441504e-09, 8.9057570e-09, 7.9840712e-09,\n",
      "       9.2680068e-09, 9.1072367e-09, 9.2582360e-09, 9.0763592e-09,\n",
      "       9.6724717e-09, 9.4348023e-09, 9.4006447e-09, 8.9306642e-09,\n",
      "       8.5891854e-09, 8.8189172e-09, 8.9041752e-09, 8.4619538e-09,\n",
      "       8.8414875e-09, 9.6086490e-09, 9.2685379e-09, 8.7149274e-09,\n",
      "       9.0813188e-09, 9.6889652e-09, 8.9276329e-09, 9.2714796e-09,\n",
      "       9.4486330e-09, 9.3328998e-09, 9.2231884e-09, 9.3028305e-09,\n",
      "       8.9792840e-09, 8.4859444e-09, 9.2805479e-09, 8.9495229e-09,\n",
      "       9.2117975e-09, 9.5051300e-09, 9.2311643e-09, 9.2383399e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/Conv2D\n",
      "index : 122\n",
      "shape : [168   1   1 672]\n",
      "shape_signature : [168   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00066769, 0.00066745, 0.00066429, 0.00066716, 0.00066603,\n",
      "       0.00066646, 0.00066779, 0.00066683, 0.0006636 , 0.00066559,\n",
      "       0.0006671 , 0.00066564, 0.00066389, 0.00066536, 0.00066482,\n",
      "       0.00066477, 0.00066436, 0.00066496, 0.00066584, 0.00066303,\n",
      "       0.00066802, 0.00066605, 0.00066335, 0.00066539, 0.00066422,\n",
      "       0.00066393, 0.00066899, 0.00066626, 0.00066781, 0.00066564,\n",
      "       0.00066718, 0.00066787, 0.00066907, 0.00066477, 0.00066787,\n",
      "       0.00066464, 0.00066138, 0.00066912, 0.00066338, 0.00066982,\n",
      "       0.00066313, 0.00066852, 0.00066175, 0.00066629, 0.00066627,\n",
      "       0.00066781, 0.0006642 , 0.00066362, 0.00066511, 0.00066484,\n",
      "       0.00066508, 0.00066371, 0.00066284, 0.00066516, 0.00066521,\n",
      "       0.00066789, 0.00066859, 0.00065941, 0.00066356, 0.00066675,\n",
      "       0.00066607, 0.00066429, 0.00066486, 0.0006644 , 0.00066503,\n",
      "       0.00066786, 0.00066895, 0.0006674 , 0.00066635, 0.00066278,\n",
      "       0.00066451, 0.00066493, 0.00066398, 0.00066527, 0.00066741,\n",
      "       0.00066501, 0.00066381, 0.00066612, 0.00066337, 0.00066698,\n",
      "       0.00066339, 0.00066511, 0.00066545, 0.00066541, 0.00066837,\n",
      "       0.00066764, 0.00066468, 0.00065851, 0.00065916, 0.00067092,\n",
      "       0.00066536, 0.00066618, 0.00066354, 0.00066626, 0.00066536,\n",
      "       0.00066547, 0.00066822, 0.00066903, 0.00066804, 0.00066563,\n",
      "       0.00066437, 0.00066673, 0.00066294, 0.00066558, 0.000664  ,\n",
      "       0.00066542, 0.00066779, 0.00066628, 0.00066414, 0.00066658,\n",
      "       0.00067019, 0.0006665 , 0.0006648 , 0.00066363, 0.0006635 ,\n",
      "       0.00066417, 0.00066563, 0.00066681, 0.00067055, 0.00066562,\n",
      "       0.00067044, 0.00066056, 0.0006664 , 0.00066721, 0.0006683 ,\n",
      "       0.00066958, 0.00066422, 0.00066773, 0.00066552, 0.00066269,\n",
      "       0.00066793, 0.00066296, 0.00066723, 0.00066265, 0.00066185,\n",
      "       0.00066549, 0.00066874, 0.00066861, 0.00066548, 0.00066874,\n",
      "       0.00066512, 0.00066524, 0.00066728, 0.00066729, 0.00066433,\n",
      "       0.00066912, 0.00066623, 0.00066238, 0.00066923, 0.00066868,\n",
      "       0.00066457, 0.00066818, 0.00066365, 0.00066558, 0.000663  ,\n",
      "       0.00067111, 0.00066576, 0.00066675, 0.00065943, 0.00066354,\n",
      "       0.00066502, 0.00066208, 0.0006651 , 0.00066061, 0.00066799,\n",
      "       0.00066813, 0.00066588, 0.00066716], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/BiasAdd/ReadVariableOp/resource\n",
      "index : 123\n",
      "shape : [168]\n",
      "shape_signature : [168]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.4276980e-08, 2.4268132e-08, 2.4153469e-08, 2.4257719e-08,\n",
      "       2.4216746e-08, 2.4232330e-08, 2.4280494e-08, 2.4245770e-08,\n",
      "       2.4128193e-08, 2.4200661e-08, 2.4255641e-08, 2.4202336e-08,\n",
      "       2.4138689e-08, 2.4192069e-08, 2.4172673e-08, 2.4170889e-08,\n",
      "       2.4155742e-08, 2.4177652e-08, 2.4209610e-08, 2.4107621e-08,\n",
      "       2.4288912e-08, 2.4217405e-08, 2.4119000e-08, 2.4193469e-08,\n",
      "       2.4150879e-08, 2.4140185e-08, 2.4324114e-08, 2.4224946e-08,\n",
      "       2.4281400e-08, 2.4202359e-08, 2.4258236e-08, 2.4283533e-08,\n",
      "       2.4327072e-08, 2.4170845e-08, 2.4283565e-08, 2.4166146e-08,\n",
      "       2.4047345e-08, 2.4329070e-08, 2.4120357e-08, 2.4354517e-08,\n",
      "       2.4111021e-08, 2.4307290e-08, 2.4061077e-08, 2.4226182e-08,\n",
      "       2.4225358e-08, 2.4281368e-08, 2.4149998e-08, 2.4129040e-08,\n",
      "       2.4183169e-08, 2.4173389e-08, 2.4181944e-08, 2.4132371e-08,\n",
      "       2.4100425e-08, 2.4185022e-08, 2.4186829e-08, 2.4284072e-08,\n",
      "       2.4309731e-08, 2.3975852e-08, 2.4126841e-08, 2.4242784e-08,\n",
      "       2.4217963e-08, 2.4153138e-08, 2.4174085e-08, 2.4157231e-08,\n",
      "       2.4180061e-08, 2.4283144e-08, 2.4322658e-08, 2.4266429e-08,\n",
      "       2.4228250e-08, 2.4098567e-08, 2.4161297e-08, 2.4176734e-08,\n",
      "       2.4142206e-08, 2.4188891e-08, 2.4266820e-08, 2.4179618e-08,\n",
      "       2.4135744e-08, 2.4219970e-08, 2.4119890e-08, 2.4250985e-08,\n",
      "       2.4120668e-08, 2.4183127e-08, 2.4195359e-08, 2.4194005e-08,\n",
      "       2.4301567e-08, 2.4275138e-08, 2.4167468e-08, 2.3943194e-08,\n",
      "       2.3966768e-08, 2.4394335e-08, 2.4192351e-08, 2.4221999e-08,\n",
      "       2.4126152e-08, 2.4225036e-08, 2.4192314e-08, 2.4196321e-08,\n",
      "       2.4296071e-08, 2.4325788e-08, 2.4289523e-08, 2.4202084e-08,\n",
      "       2.4156138e-08, 2.4241972e-08, 2.4104338e-08, 2.4200096e-08,\n",
      "       2.4142594e-08, 2.4194478e-08, 2.4280579e-08, 2.4225653e-08,\n",
      "       2.4147713e-08, 2.4236636e-08, 2.4367932e-08, 2.4233708e-08,\n",
      "       2.4171888e-08, 2.4129331e-08, 2.4124486e-08, 2.4148941e-08,\n",
      "       2.4202095e-08, 2.4244828e-08, 2.4380846e-08, 2.4201606e-08,\n",
      "       2.4376872e-08, 2.4017694e-08, 2.4230021e-08, 2.4259572e-08,\n",
      "       2.4299078e-08, 2.4345672e-08, 2.4150932e-08, 2.4278343e-08,\n",
      "       2.4197858e-08, 2.4095282e-08, 2.4285830e-08, 2.4105040e-08,\n",
      "       2.4260274e-08, 2.4093687e-08, 2.4064487e-08, 2.4197062e-08,\n",
      "       2.4315218e-08, 2.4310427e-08, 2.4196693e-08, 2.4315016e-08,\n",
      "       2.4183629e-08, 2.4187761e-08, 2.4262004e-08, 2.4262246e-08,\n",
      "       2.4154865e-08, 2.4328779e-08, 2.4223860e-08, 2.4083899e-08,\n",
      "       2.4332788e-08, 2.4313051e-08, 2.4163608e-08, 2.4294604e-08,\n",
      "       2.4130033e-08, 2.4200171e-08, 2.4106408e-08, 2.4401231e-08,\n",
      "       2.4206594e-08, 2.4242729e-08, 2.3976492e-08, 2.4125976e-08,\n",
      "       2.4180007e-08, 2.4073005e-08, 2.4182725e-08, 2.4019357e-08,\n",
      "       2.4287770e-08, 2.4292898e-08, 2.4211051e-08, 2.4257533e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/Conv2D\n",
      "index : 124\n",
      "shape : [672   1   1 168]\n",
      "shape_signature : [672   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00066667, 0.00066848, 0.00066349, 0.00066722, 0.000664  ,\n",
      "       0.00066307, 0.00066192, 0.00066079, 0.00065768, 0.00066359,\n",
      "       0.00065877, 0.00066686, 0.00066769, 0.00066205, 0.00066063,\n",
      "       0.00066165, 0.00066393, 0.00066013, 0.00065227, 0.00066734,\n",
      "       0.00066553, 0.00065005, 0.00066612, 0.00066307, 0.00066413,\n",
      "       0.00066224, 0.00065829, 0.00065967, 0.000647  , 0.00065834,\n",
      "       0.00065968, 0.00066259, 0.00065094, 0.00066545, 0.00066562,\n",
      "       0.0006629 , 0.00066199, 0.00067026, 0.0006611 , 0.0006612 ,\n",
      "       0.00066995, 0.00066368, 0.00065911, 0.00065307, 0.00066678,\n",
      "       0.00066293, 0.00066463, 0.00063493, 0.0006666 , 0.00066645,\n",
      "       0.00066331, 0.00066392, 0.00066499, 0.00066789, 0.00066332,\n",
      "       0.00066614, 0.00066941, 0.00066092, 0.00065828, 0.00066559,\n",
      "       0.00066216, 0.0006662 , 0.00066464, 0.00066232, 0.00065546,\n",
      "       0.00066309, 0.00066269, 0.00065589, 0.0006612 , 0.00066636,\n",
      "       0.00066336, 0.00066109, 0.00066537, 0.00066623, 0.00065672,\n",
      "       0.00066601, 0.00066504, 0.00066347, 0.00065986, 0.00066648,\n",
      "       0.00066699, 0.00065153, 0.00066631, 0.00066657, 0.00066286,\n",
      "       0.00066895, 0.00066308, 0.00065764, 0.00066132, 0.00066412,\n",
      "       0.00066893, 0.00065682, 0.00066457, 0.00066036, 0.00065825,\n",
      "       0.00066852, 0.00065947, 0.00066181, 0.0006646 , 0.0006603 ,\n",
      "       0.00066514, 0.00066273, 0.00066383, 0.00065651, 0.00066555,\n",
      "       0.00065891, 0.000664  , 0.00065856, 0.00066332, 0.00066513,\n",
      "       0.00064845, 0.00066245, 0.00065842, 0.00066268, 0.00066201,\n",
      "       0.00066652, 0.00065975, 0.00066337, 0.00066365, 0.00065985,\n",
      "       0.00066339, 0.00066708, 0.00066116, 0.00066001, 0.00066017,\n",
      "       0.00065425, 0.00066916, 0.00066294, 0.00065672, 0.00065811,\n",
      "       0.00065929, 0.00066201, 0.00066063, 0.00066586, 0.00065888,\n",
      "       0.00066706, 0.00065874, 0.00065863, 0.00066972, 0.00065828,\n",
      "       0.00066178, 0.00066414, 0.00066431, 0.00065932, 0.0006652 ,\n",
      "       0.00066711, 0.00066247, 0.00066267, 0.0006597 , 0.00066282,\n",
      "       0.00065393, 0.00066569, 0.00066795, 0.00066445, 0.0006581 ,\n",
      "       0.00066308, 0.00066372, 0.00066392, 0.000667  , 0.0006637 ,\n",
      "       0.00066143, 0.0006619 , 0.00066632, 0.0006661 , 0.00065427,\n",
      "       0.00066499, 0.00066697, 0.00066739, 0.0006605 , 0.00065178,\n",
      "       0.00066318, 0.00066335, 0.00066303, 0.00066643, 0.00066421,\n",
      "       0.00065454, 0.00066734, 0.00066143, 0.00065894, 0.00066488,\n",
      "       0.00066184, 0.00066154, 0.00066652, 0.00066375, 0.00066694,\n",
      "       0.00066346, 0.00066202, 0.00066393, 0.00066351, 0.00066825,\n",
      "       0.00066285, 0.00066016, 0.00066314, 0.00066252, 0.00065406,\n",
      "       0.00066703, 0.00065906, 0.00066613, 0.00066008, 0.00066487,\n",
      "       0.0006636 , 0.0006541 , 0.00066454, 0.00065934, 0.00066336,\n",
      "       0.00066738, 0.00065345, 0.00066345, 0.00065883, 0.000666  ,\n",
      "       0.00066257, 0.00066948, 0.00065767, 0.00066051, 0.0006654 ,\n",
      "       0.00067096, 0.00066328, 0.00065659, 0.00066107, 0.00066059,\n",
      "       0.0006613 , 0.00066481, 0.00066116, 0.0006551 , 0.0006648 ,\n",
      "       0.00065166, 0.00065976, 0.00066249, 0.00065762, 0.00066149,\n",
      "       0.00066671, 0.00066122, 0.00066312, 0.00066289, 0.00066895,\n",
      "       0.00066553, 0.00066883, 0.00065997, 0.00066422, 0.0006615 ,\n",
      "       0.00066226, 0.00066598, 0.00066605, 0.00066538, 0.00066545,\n",
      "       0.00066524, 0.00066055, 0.00066289, 0.00066257, 0.00066145,\n",
      "       0.00066277, 0.00066002, 0.00066784, 0.00066866, 0.00066885,\n",
      "       0.00066965, 0.0006671 , 0.00066203, 0.00066662, 0.00066593,\n",
      "       0.00064952, 0.00066098, 0.00066397, 0.00066576, 0.00066636,\n",
      "       0.0006658 , 0.00066529, 0.0006638 , 0.00066258, 0.00066387,\n",
      "       0.00066328, 0.00066459, 0.00065374, 0.00066538, 0.00066588,\n",
      "       0.00064998, 0.00066599, 0.00065814, 0.00066532, 0.00066464,\n",
      "       0.00066088, 0.00066376, 0.00065873, 0.00066058, 0.00065611,\n",
      "       0.00064994, 0.00065783, 0.00065544, 0.00066462, 0.00065822,\n",
      "       0.0006644 , 0.00066647, 0.00066576, 0.00066378, 0.00065795,\n",
      "       0.00066386, 0.00065662, 0.00066143, 0.00066303, 0.0006687 ,\n",
      "       0.00066548, 0.00066215, 0.00066534, 0.00066581, 0.00066127,\n",
      "       0.00066571, 0.00066855, 0.00066116, 0.00066067, 0.00065668,\n",
      "       0.00066707, 0.00066476, 0.00066167, 0.00066015, 0.00066655,\n",
      "       0.00066565, 0.00065892, 0.00066206, 0.00066068, 0.00066263,\n",
      "       0.00066181, 0.00066519, 0.00065947, 0.00066215, 0.00065942,\n",
      "       0.00065894, 0.00065226, 0.0006662 , 0.00065588, 0.00066935,\n",
      "       0.00066348, 0.00066631, 0.00066391, 0.00066544, 0.00066575,\n",
      "       0.00066309, 0.00065852, 0.00066532, 0.00066235, 0.00066528,\n",
      "       0.00066793, 0.00066726, 0.00066707, 0.00066022, 0.00066979,\n",
      "       0.00066439, 0.00065827, 0.00066418, 0.00066674, 0.00066435,\n",
      "       0.00066256, 0.00066669, 0.00066572, 0.00066714, 0.00065315,\n",
      "       0.00066865, 0.00065644, 0.00066126, 0.00065335, 0.00066547,\n",
      "       0.00065896, 0.00066426, 0.000663  , 0.00066594, 0.00066216,\n",
      "       0.00066581, 0.00066483, 0.00066775, 0.00066499, 0.0006664 ,\n",
      "       0.00065915, 0.00065729, 0.00065977, 0.00065797, 0.00066844,\n",
      "       0.00066404, 0.00066561, 0.00066765, 0.00065923, 0.00065542,\n",
      "       0.00066562, 0.00066687, 0.00066267, 0.00066054, 0.00065388,\n",
      "       0.00065977, 0.0006679 , 0.00066666, 0.00066714, 0.00066758,\n",
      "       0.00066361, 0.00066158, 0.0006679 , 0.00066145, 0.00065138,\n",
      "       0.00064979, 0.00066182, 0.00066322, 0.00066384, 0.00066307,\n",
      "       0.00066237, 0.00066626, 0.00066646, 0.00066084, 0.00066193,\n",
      "       0.00066712, 0.00065588, 0.00066465, 0.0006598 , 0.00066351,\n",
      "       0.00066437, 0.00066494, 0.00066611, 0.00065866, 0.00066658,\n",
      "       0.00066196, 0.00066076, 0.00066814, 0.00066305, 0.00066875,\n",
      "       0.00066238, 0.00066192, 0.0006624 , 0.00065851, 0.00066588,\n",
      "       0.00065859, 0.00066151, 0.00066431, 0.00066346, 0.00066232,\n",
      "       0.00066724, 0.00066474, 0.00065517, 0.00066029, 0.0006681 ,\n",
      "       0.00066211, 0.00066178, 0.00066376, 0.00064866, 0.0006675 ,\n",
      "       0.00066681, 0.00065738, 0.0006642 , 0.00066685, 0.00066168,\n",
      "       0.00066446, 0.00066931, 0.00066695, 0.00066602, 0.00066857,\n",
      "       0.00066536, 0.00065981, 0.00065923, 0.00066227, 0.00066733,\n",
      "       0.000663  , 0.00066522, 0.00066269, 0.0006661 , 0.0006626 ,\n",
      "       0.00066215, 0.00066789, 0.00065659, 0.00065742, 0.00066061,\n",
      "       0.00066478, 0.00066046, 0.00066252, 0.00065647, 0.00066525,\n",
      "       0.00066102, 0.00066429, 0.0006581 , 0.00066626, 0.00066297,\n",
      "       0.00066038, 0.0006571 , 0.00065812, 0.00066268, 0.00066162,\n",
      "       0.00066472, 0.0006611 , 0.00066475, 0.00066181, 0.00066767,\n",
      "       0.00064543, 0.00066639, 0.00066644, 0.0006673 , 0.00066284,\n",
      "       0.00066333, 0.00066593, 0.00065872, 0.00066663, 0.00065226,\n",
      "       0.00065613, 0.00065448, 0.00066594, 0.00066357, 0.00066149,\n",
      "       0.00066292, 0.00066061, 0.00066048, 0.00064969, 0.00065956,\n",
      "       0.00065887, 0.0006621 , 0.00066738, 0.00066051, 0.0006658 ,\n",
      "       0.00065922, 0.00065517, 0.00066477, 0.00066433, 0.00066769,\n",
      "       0.0006649 , 0.00065165, 0.00066414, 0.00066473, 0.0006674 ,\n",
      "       0.00066663, 0.00066358, 0.00066311, 0.00066635, 0.00066665,\n",
      "       0.00066682, 0.00066381, 0.00066242, 0.00065935, 0.00066481,\n",
      "       0.0006627 , 0.00066684, 0.00066769, 0.00066496, 0.00065604,\n",
      "       0.0006623 , 0.00066144, 0.00065661, 0.00065906, 0.00066295,\n",
      "       0.00065768, 0.00065829, 0.00065993, 0.00066671, 0.00065851,\n",
      "       0.00066169, 0.00066058, 0.00065609, 0.00066736, 0.00066185,\n",
      "       0.00066117, 0.00066531, 0.00065676, 0.00066167, 0.00066875,\n",
      "       0.00066515, 0.0006655 , 0.00066005, 0.00066504, 0.00065753,\n",
      "       0.0006674 , 0.00066454, 0.00066719, 0.00066609, 0.00066295,\n",
      "       0.00066815, 0.0006637 , 0.00066571, 0.00066094, 0.00066242,\n",
      "       0.0006558 , 0.00065682, 0.00066189, 0.00067036, 0.00065602,\n",
      "       0.0006628 , 0.00065807, 0.00065843, 0.0006539 , 0.00065556,\n",
      "       0.00065029, 0.00066075, 0.00066527, 0.00065003, 0.00066053,\n",
      "       0.00066285, 0.00066104, 0.00066172, 0.00066309, 0.00065829,\n",
      "       0.00066251, 0.00066497, 0.00066704, 0.00066479, 0.0006605 ,\n",
      "       0.00066663, 0.00064351, 0.00066447, 0.00066425, 0.00066674,\n",
      "       0.00065396, 0.00065505, 0.00066235, 0.0006692 , 0.00066174,\n",
      "       0.00066675, 0.0006536 , 0.00066401, 0.00066451, 0.00065856,\n",
      "       0.00066221, 0.00066536, 0.00066587, 0.00066563, 0.0006649 ,\n",
      "       0.00066897, 0.00066652, 0.00065804, 0.00066115, 0.0006611 ,\n",
      "       0.00066212, 0.00066638, 0.0006625 , 0.00066337, 0.00065749,\n",
      "       0.00065924, 0.00066613, 0.00066624, 0.00066314, 0.0006656 ,\n",
      "       0.00066635, 0.00067007, 0.00066269, 0.00066278, 0.00066191,\n",
      "       0.00066495, 0.00066487, 0.00066742, 0.00066517, 0.00066327,\n",
      "       0.00065877, 0.00066328, 0.00066551, 0.0006584 , 0.00066919,\n",
      "       0.00066611, 0.00065322, 0.00065965, 0.00065383, 0.00066211,\n",
      "       0.00065989, 0.0006652 , 0.0006603 , 0.00066023, 0.0006616 ,\n",
      "       0.00067172, 0.00066347, 0.00065765, 0.00066296, 0.00066237,\n",
      "       0.00066386, 0.00064524, 0.00065906, 0.00065852, 0.0006589 ,\n",
      "       0.00065999, 0.00066315, 0.0006654 , 0.00066882, 0.0006558 ,\n",
      "       0.00066473, 0.00067018], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/BiasAdd/ReadVariableOp/resource\n",
      "index : 125\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.6843101e-08, 1.6888920e-08, 1.6762847e-08, 1.6857150e-08,\n",
      "       1.6775690e-08, 1.6752212e-08, 1.6723192e-08, 1.6694537e-08,\n",
      "       1.6616079e-08, 1.6765330e-08, 1.6643549e-08, 1.6847908e-08,\n",
      "       1.6868896e-08, 1.6726592e-08, 1.6690576e-08, 1.6716339e-08,\n",
      "       1.6773926e-08, 1.6677916e-08, 1.6479270e-08, 1.6860104e-08,\n",
      "       1.6814518e-08, 1.6423259e-08, 1.6829347e-08, 1.6752335e-08,\n",
      "       1.6778980e-08, 1.6731340e-08, 1.6631551e-08, 1.6666402e-08,\n",
      "       1.6346309e-08, 1.6632731e-08, 1.6666649e-08, 1.6740112e-08,\n",
      "       1.6445821e-08, 1.6812455e-08, 1.6816793e-08, 1.6747997e-08,\n",
      "       1.6725037e-08, 1.6933978e-08, 1.6702584e-08, 1.6704984e-08,\n",
      "       1.6926027e-08, 1.6767729e-08, 1.6652237e-08, 1.6499696e-08,\n",
      "       1.6845878e-08, 1.6748679e-08, 1.6791693e-08, 1.6041392e-08,\n",
      "       1.6841499e-08, 1.6837619e-08, 1.6758348e-08, 1.6773640e-08,\n",
      "       1.6800826e-08, 1.6873992e-08, 1.6758648e-08, 1.6829922e-08,\n",
      "       1.6912438e-08, 1.6697800e-08, 1.6631319e-08, 1.6815999e-08,\n",
      "       1.6729317e-08, 1.6831226e-08, 1.6791804e-08, 1.6733260e-08,\n",
      "       1.6559884e-08, 1.6752635e-08, 1.6742611e-08, 1.6570743e-08,\n",
      "       1.6705107e-08, 1.6835385e-08, 1.6759474e-08, 1.6702320e-08,\n",
      "       1.6810400e-08, 1.6832095e-08, 1.6591882e-08, 1.6826428e-08,\n",
      "       1.6802082e-08, 1.6762257e-08, 1.6671134e-08, 1.6838301e-08,\n",
      "       1.6851336e-08, 1.6460586e-08, 1.6833974e-08, 1.6840675e-08,\n",
      "       1.6746995e-08, 1.6900787e-08, 1.6752425e-08, 1.6614999e-08,\n",
      "       1.6707997e-08, 1.6778680e-08, 1.6900273e-08, 1.6594239e-08,\n",
      "       1.6790015e-08, 1.6683872e-08, 1.6630494e-08, 1.6889867e-08,\n",
      "       1.6661325e-08, 1.6720376e-08, 1.6790814e-08, 1.6682309e-08,\n",
      "       1.6804467e-08, 1.6743643e-08, 1.6771430e-08, 1.6586398e-08,\n",
      "       1.6814825e-08, 1.6647190e-08, 1.6775662e-08, 1.6638214e-08,\n",
      "       1.6758634e-08, 1.6804380e-08, 1.6382758e-08, 1.6736651e-08,\n",
      "       1.6634887e-08, 1.6742492e-08, 1.6725352e-08, 1.6839433e-08,\n",
      "       1.6668359e-08, 1.6759763e-08, 1.6766972e-08, 1.6670919e-08,\n",
      "       1.6760358e-08, 1.6853454e-08, 1.6703940e-08, 1.6674861e-08,\n",
      "       1.6678955e-08, 1.6529523e-08, 1.6906082e-08, 1.6749043e-08,\n",
      "       1.6591859e-08, 1.6626835e-08, 1.6656781e-08, 1.6725521e-08,\n",
      "       1.6690629e-08, 1.6822698e-08, 1.6646467e-08, 1.6853155e-08,\n",
      "       1.6642835e-08, 1.6640161e-08, 1.6920223e-08, 1.6631317e-08,\n",
      "       1.6719691e-08, 1.6779380e-08, 1.6783527e-08, 1.6657586e-08,\n",
      "       1.6806073e-08, 1.6854347e-08, 1.6737093e-08, 1.6742010e-08,\n",
      "       1.6667199e-08, 1.6745844e-08, 1.6521328e-08, 1.6818401e-08,\n",
      "       1.6875495e-08, 1.6787183e-08, 1.6626784e-08, 1.6752470e-08,\n",
      "       1.6768761e-08, 1.6773727e-08, 1.6851450e-08, 1.6768146e-08,\n",
      "       1.6710747e-08, 1.6722609e-08, 1.6834313e-08, 1.6828709e-08,\n",
      "       1.6529864e-08, 1.6800874e-08, 1.6850658e-08, 1.6861277e-08,\n",
      "       1.6687350e-08, 1.6467071e-08, 1.6754894e-08, 1.6759428e-08,\n",
      "       1.6751256e-08, 1.6837104e-08, 1.6781014e-08, 1.6536742e-08,\n",
      "       1.6860129e-08, 1.6710851e-08, 1.6647833e-08, 1.6798067e-08,\n",
      "       1.6721071e-08, 1.6713601e-08, 1.6839520e-08, 1.6769425e-08,\n",
      "       1.6850029e-08, 1.6762003e-08, 1.6725769e-08, 1.6773953e-08,\n",
      "       1.6763350e-08, 1.6883146e-08, 1.6746727e-08, 1.6678618e-08,\n",
      "       1.6753948e-08, 1.6738303e-08, 1.6524712e-08, 1.6852338e-08,\n",
      "       1.6650976e-08, 1.6829558e-08, 1.6676751e-08, 1.6797710e-08,\n",
      "       1.6765558e-08, 1.6525693e-08, 1.6789329e-08, 1.6657971e-08,\n",
      "       1.6759511e-08, 1.6861222e-08, 1.6509215e-08, 1.6761890e-08,\n",
      "       1.6645231e-08, 1.6826304e-08, 1.6739564e-08, 1.6914198e-08,\n",
      "       1.6615763e-08, 1.6687613e-08, 1.6811226e-08, 1.6951519e-08,\n",
      "       1.6757539e-08, 1.6588594e-08, 1.6701822e-08, 1.6689549e-08,\n",
      "       1.6707496e-08, 1.6796093e-08, 1.6703948e-08, 1.6550828e-08,\n",
      "       1.6796040e-08, 1.6463879e-08, 1.6668501e-08, 1.6737577e-08,\n",
      "       1.6614424e-08, 1.6712249e-08, 1.6844249e-08, 1.6705501e-08,\n",
      "       1.6753587e-08, 1.6747769e-08, 1.6900755e-08, 1.6814306e-08,\n",
      "       1.6897831e-08, 1.6673964e-08, 1.6781318e-08, 1.6712587e-08,\n",
      "       1.6731722e-08, 1.6825851e-08, 1.6827588e-08, 1.6810677e-08,\n",
      "       1.6812420e-08, 1.6807094e-08, 1.6688608e-08, 1.6747812e-08,\n",
      "       1.6739502e-08, 1.6711228e-08, 1.6744545e-08, 1.6675092e-08,\n",
      "       1.6872715e-08, 1.6893356e-08, 1.6898236e-08, 1.6918426e-08,\n",
      "       1.6854150e-08, 1.6726043e-08, 1.6842028e-08, 1.6824552e-08,\n",
      "       1.6409988e-08, 1.6699396e-08, 1.6774861e-08, 1.6820294e-08,\n",
      "       1.6835314e-08, 1.6821254e-08, 1.6808327e-08, 1.6770592e-08,\n",
      "       1.6739870e-08, 1.6772413e-08, 1.6757609e-08, 1.6790722e-08,\n",
      "       1.6516502e-08, 1.6810702e-08, 1.6823206e-08, 1.6421453e-08,\n",
      "       1.6825899e-08, 1.6627576e-08, 1.6809070e-08, 1.6792026e-08,\n",
      "       1.6696790e-08, 1.6769766e-08, 1.6642606e-08, 1.6689443e-08,\n",
      "       1.6576376e-08, 1.6420399e-08, 1.6619889e-08, 1.6559573e-08,\n",
      "       1.6791363e-08, 1.6629629e-08, 1.6785810e-08, 1.6838202e-08,\n",
      "       1.6820247e-08, 1.6770269e-08, 1.6623012e-08, 1.6772223e-08,\n",
      "       1.6589167e-08, 1.6710700e-08, 1.6751205e-08, 1.6894370e-08,\n",
      "       1.6813194e-08, 1.6728922e-08, 1.6809619e-08, 1.6821343e-08,\n",
      "       1.6706812e-08, 1.6818975e-08, 1.6890610e-08, 1.6703948e-08,\n",
      "       1.6691722e-08, 1.6590818e-08, 1.6853217e-08, 1.6794850e-08,\n",
      "       1.6716834e-08, 1.6678566e-08, 1.6840270e-08, 1.6817300e-08,\n",
      "       1.6647361e-08, 1.6726615e-08, 1.6691750e-08, 1.6741046e-08,\n",
      "       1.6720453e-08, 1.6805858e-08, 1.6661316e-08, 1.6728894e-08,\n",
      "       1.6660005e-08, 1.6647823e-08, 1.6479090e-08, 1.6831239e-08,\n",
      "       1.6570525e-08, 1.6910818e-08, 1.6762515e-08, 1.6834090e-08,\n",
      "       1.6773431e-08, 1.6812232e-08, 1.6819829e-08, 1.6752631e-08,\n",
      "       1.6637387e-08, 1.6809025e-08, 1.6734068e-08, 1.6808031e-08,\n",
      "       1.6875072e-08, 1.6858136e-08, 1.6853402e-08, 1.6680294e-08,\n",
      "       1.6921993e-08, 1.6785476e-08, 1.6631027e-08, 1.6780255e-08,\n",
      "       1.6844867e-08, 1.6784515e-08, 1.6739246e-08, 1.6843666e-08,\n",
      "       1.6819282e-08, 1.6854962e-08, 1.6501581e-08, 1.6893292e-08,\n",
      "       1.6584716e-08, 1.6706419e-08, 1.6506652e-08, 1.6812816e-08,\n",
      "       1.6648450e-08, 1.6782314e-08, 1.6750484e-08, 1.6824808e-08,\n",
      "       1.6729247e-08, 1.6821483e-08, 1.6796641e-08, 1.6870413e-08,\n",
      "       1.6800643e-08, 1.6836299e-08, 1.6653116e-08, 1.6606249e-08,\n",
      "       1.6668777e-08, 1.6623391e-08, 1.6887974e-08, 1.6776639e-08,\n",
      "       1.6816461e-08, 1.6868032e-08, 1.6655214e-08, 1.6558980e-08,\n",
      "       1.6816623e-08, 1.6848162e-08, 1.6742199e-08, 1.6688269e-08,\n",
      "       1.6520067e-08, 1.6668928e-08, 1.6874184e-08, 1.6843032e-08,\n",
      "       1.6855019e-08, 1.6866068e-08, 1.6765766e-08, 1.6714669e-08,\n",
      "       1.6874367e-08, 1.6711351e-08, 1.6457014e-08, 1.6416694e-08,\n",
      "       1.6720605e-08, 1.6756140e-08, 1.6771816e-08, 1.6752214e-08,\n",
      "       1.6734527e-08, 1.6832741e-08, 1.6837989e-08, 1.6695910e-08,\n",
      "       1.6723366e-08, 1.6854457e-08, 1.6570660e-08, 1.6792136e-08,\n",
      "       1.6669677e-08, 1.6763456e-08, 1.6785105e-08, 1.6799508e-08,\n",
      "       1.6829137e-08, 1.6640872e-08, 1.6840895e-08, 1.6724233e-08,\n",
      "       1.6694004e-08, 1.6880403e-08, 1.6751741e-08, 1.6895770e-08,\n",
      "       1.6734784e-08, 1.6723265e-08, 1.6735274e-08, 1.6636935e-08,\n",
      "       1.6823110e-08, 1.6639154e-08, 1.6712733e-08, 1.6783492e-08,\n",
      "       1.6762129e-08, 1.6733214e-08, 1.6857623e-08, 1.6794358e-08,\n",
      "       1.6552701e-08, 1.6682023e-08, 1.6879291e-08, 1.6727984e-08,\n",
      "       1.6719744e-08, 1.6769748e-08, 1.6388061e-08, 1.6864050e-08,\n",
      "       1.6846737e-08, 1.6608565e-08, 1.6780834e-08, 1.6847856e-08,\n",
      "       1.6717033e-08, 1.6787315e-08, 1.6909869e-08, 1.6850223e-08,\n",
      "       1.6826888e-08, 1.6891089e-08, 1.6810223e-08, 1.6669862e-08,\n",
      "       1.6655139e-08, 1.6732020e-08, 1.6859955e-08, 1.6750420e-08,\n",
      "       1.6806556e-08, 1.6742636e-08, 1.6828858e-08, 1.6740396e-08,\n",
      "       1.6728899e-08, 1.6873900e-08, 1.6588407e-08, 1.6609379e-08,\n",
      "       1.6690143e-08, 1.6795465e-08, 1.6686297e-08, 1.6738248e-08,\n",
      "       1.6585574e-08, 1.6807332e-08, 1.6700531e-08, 1.6783069e-08,\n",
      "       1.6626663e-08, 1.6832720e-08, 1.6749659e-08, 1.6684332e-08,\n",
      "       1.6601327e-08, 1.6627279e-08, 1.6742309e-08, 1.6715694e-08,\n",
      "       1.6793933e-08, 1.6702552e-08, 1.6794701e-08, 1.6720325e-08,\n",
      "       1.6868444e-08, 1.6306696e-08, 1.6836117e-08, 1.6837337e-08,\n",
      "       1.6858992e-08, 1.6746320e-08, 1.6758928e-08, 1.6824496e-08,\n",
      "       1.6642240e-08, 1.6842291e-08, 1.6479211e-08, 1.6576973e-08,\n",
      "       1.6535134e-08, 1.6824876e-08, 1.6764986e-08, 1.6712377e-08,\n",
      "       1.6748398e-08, 1.6690120e-08, 1.6686810e-08, 1.6414180e-08,\n",
      "       1.6663460e-08, 1.6646046e-08, 1.6727689e-08, 1.6861103e-08,\n",
      "       1.6687547e-08, 1.6821234e-08, 1.6654996e-08, 1.6552534e-08,\n",
      "       1.6795175e-08, 1.6784067e-08, 1.6869022e-08, 1.6798404e-08,\n",
      "       1.6463803e-08, 1.6779293e-08, 1.6794289e-08, 1.6861700e-08,\n",
      "       1.6842112e-08, 1.6765128e-08, 1.6753290e-08, 1.6835232e-08,\n",
      "       1.6842810e-08, 1.6847030e-08, 1.6771017e-08, 1.6735912e-08,\n",
      "       1.6658275e-08, 1.6796220e-08, 1.6742945e-08, 1.6847469e-08,\n",
      "       1.6868928e-08, 1.6799934e-08, 1.6574601e-08, 1.6732701e-08,\n",
      "       1.6710990e-08, 1.6588986e-08, 1.6650848e-08, 1.6749215e-08,\n",
      "       1.6616001e-08, 1.6631432e-08, 1.6672994e-08, 1.6844192e-08,\n",
      "       1.6636990e-08, 1.6717289e-08, 1.6689372e-08, 1.6575941e-08,\n",
      "       1.6860630e-08, 1.6721362e-08, 1.6704272e-08, 1.6808860e-08,\n",
      "       1.6592717e-08, 1.6716772e-08, 1.6895736e-08, 1.6804789e-08,\n",
      "       1.6813528e-08, 1.6675896e-08, 1.6802090e-08, 1.6612182e-08,\n",
      "       1.6861723e-08, 1.6789411e-08, 1.6856250e-08, 1.6828439e-08,\n",
      "       1.6749208e-08, 1.6880580e-08, 1.6768258e-08, 1.6819001e-08,\n",
      "       1.6698515e-08, 1.6735898e-08, 1.6568547e-08, 1.6594441e-08,\n",
      "       1.6722554e-08, 1.6936474e-08, 1.6574054e-08, 1.6745346e-08,\n",
      "       1.6625796e-08, 1.6634951e-08, 1.6520584e-08, 1.6562577e-08,\n",
      "       1.6429322e-08, 1.6693551e-08, 1.6807707e-08, 1.6422819e-08,\n",
      "       1.6688142e-08, 1.6746609e-08, 1.6700879e-08, 1.6718118e-08,\n",
      "       1.6752772e-08, 1.6631516e-08, 1.6737992e-08, 1.6800360e-08,\n",
      "       1.6852422e-08, 1.6795806e-08, 1.6687331e-08, 1.6842304e-08,\n",
      "       1.6258090e-08, 1.6787693e-08, 1.6782039e-08, 1.6844991e-08,\n",
      "       1.6521987e-08, 1.6549620e-08, 1.6734177e-08, 1.6907100e-08,\n",
      "       1.6718641e-08, 1.6845188e-08, 1.6512997e-08, 1.6775928e-08,\n",
      "       1.6788544e-08, 1.6638197e-08, 1.6730505e-08, 1.6810171e-08,\n",
      "       1.6822970e-08, 1.6816953e-08, 1.6798353e-08, 1.6901371e-08,\n",
      "       1.6839381e-08, 1.6625142e-08, 1.6703780e-08, 1.6702378e-08,\n",
      "       1.6728116e-08, 1.6835807e-08, 1.6737944e-08, 1.6759868e-08,\n",
      "       1.6611208e-08, 1.6655500e-08, 1.6829638e-08, 1.6832267e-08,\n",
      "       1.6753974e-08, 1.6816184e-08, 1.6835097e-08, 1.6929151e-08,\n",
      "       1.6742723e-08, 1.6744870e-08, 1.6722911e-08, 1.6799650e-08,\n",
      "       1.6797769e-08, 1.6862208e-08, 1.6805251e-08, 1.6757399e-08,\n",
      "       1.6643597e-08, 1.6757559e-08, 1.6813889e-08, 1.6634310e-08,\n",
      "       1.6906826e-08, 1.6829166e-08, 1.6503462e-08, 1.6665739e-08,\n",
      "       1.6518840e-08, 1.6728048e-08, 1.6671965e-08, 1.6806180e-08,\n",
      "       1.6682193e-08, 1.6680419e-08, 1.6715187e-08, 1.6970715e-08,\n",
      "       1.6762311e-08, 1.6615227e-08, 1.6749487e-08, 1.6734502e-08,\n",
      "       1.6772271e-08, 1.6301650e-08, 1.6651038e-08, 1.6637175e-08,\n",
      "       1.6646990e-08, 1.6674420e-08, 1.6754298e-08, 1.6811230e-08,\n",
      "       1.6897502e-08, 1.6568594e-08, 1.6794090e-08, 1.6931976e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D\n",
      "index : 126\n",
      "shape : [112   1   1 672]\n",
      "shape_signature : [112   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00074503, 0.00074588, 0.00074726, 0.00074687, 0.00074553,\n",
      "       0.00074777, 0.00074754, 0.00074858, 0.00075039, 0.00075006,\n",
      "       0.00075203, 0.00074712, 0.00074352, 0.00074897, 0.00074682,\n",
      "       0.00075098, 0.00075103, 0.00074909, 0.00074702, 0.00075009,\n",
      "       0.0007512 , 0.00074777, 0.00074865, 0.00075077, 0.00074409,\n",
      "       0.00075183, 0.00074686, 0.0007485 , 0.00074311, 0.00074737,\n",
      "       0.00074995, 0.00074694, 0.00075084, 0.00075138, 0.00075085,\n",
      "       0.00074671, 0.00074123, 0.00075221, 0.00074337, 0.00074866,\n",
      "       0.00074147, 0.00074653, 0.0007445 , 0.00074772, 0.00074913,\n",
      "       0.00074032, 0.00074449, 0.00075092, 0.00074588, 0.00074877,\n",
      "       0.00074915, 0.00074738, 0.00075269, 0.00074666, 0.00074815,\n",
      "       0.00074922, 0.00074952, 0.00074922, 0.00074772, 0.00074647,\n",
      "       0.00074482, 0.00074772, 0.00075075, 0.00074579, 0.00074911,\n",
      "       0.00075112, 0.00074288, 0.00074624, 0.00074782, 0.00075118,\n",
      "       0.00075149, 0.00074579, 0.00074623, 0.00075245, 0.00075115,\n",
      "       0.00074828, 0.00074591, 0.00074517, 0.00074977, 0.00075103,\n",
      "       0.00075086, 0.00074514, 0.0007466 , 0.0007469 , 0.00074894,\n",
      "       0.00075253, 0.00075004, 0.00074699, 0.00074473, 0.00074895,\n",
      "       0.00074831, 0.00074864, 0.00074438, 0.0007483 , 0.00075002,\n",
      "       0.0007486 , 0.00074668, 0.00074527, 0.00074512, 0.0007445 ,\n",
      "       0.00074705, 0.00075072, 0.00074537, 0.00074634, 0.00075086,\n",
      "       0.00074941, 0.00074603, 0.00074804, 0.00074911, 0.00074657,\n",
      "       0.00074809, 0.00074977], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_33/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D\n",
      "index : 127\n",
      "shape : [112]\n",
      "shape_signature : [112]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.8028028e-09, 6.8105965e-09, 6.8232247e-09, 6.8196124e-09,\n",
      "       6.8073862e-09, 6.8278294e-09, 6.8257453e-09, 6.8352519e-09,\n",
      "       6.8518187e-09, 6.8487611e-09, 6.8667236e-09, 6.8219275e-09,\n",
      "       6.7890431e-09, 6.8388140e-09, 6.8191568e-09, 6.8571313e-09,\n",
      "       6.8576385e-09, 6.8399011e-09, 6.8210078e-09, 6.8490014e-09,\n",
      "       6.8591581e-09, 6.8279014e-09, 6.8359363e-09, 6.8552644e-09,\n",
      "       6.7942256e-09, 6.8648980e-09, 6.8195751e-09, 6.8345298e-09,\n",
      "       6.7853172e-09, 6.8241772e-09, 6.8477739e-09, 6.8202479e-09,\n",
      "       6.8559154e-09, 6.8607955e-09, 6.8560015e-09, 6.8181425e-09,\n",
      "       6.7681589e-09, 6.8684001e-09, 6.7876718e-09, 6.8359713e-09,\n",
      "       6.7703145e-09, 6.8165278e-09, 6.7979813e-09, 6.8274115e-09,\n",
      "       6.8402799e-09, 6.7598092e-09, 6.7978969e-09, 6.8566219e-09,\n",
      "       6.8106005e-09, 6.8369950e-09, 6.8404216e-09, 6.8243273e-09,\n",
      "       6.8727788e-09, 6.8177028e-09, 6.8313444e-09, 6.8410575e-09,\n",
      "       6.8438375e-09, 6.8410926e-09, 6.8274417e-09, 6.8160158e-09,\n",
      "       6.8009243e-09, 6.8273782e-09, 6.8550485e-09, 6.8098118e-09,\n",
      "       6.8400658e-09, 6.8584787e-09, 6.7831882e-09, 6.8139303e-09,\n",
      "       6.8283303e-09, 6.8589716e-09, 6.8618422e-09, 6.8097501e-09,\n",
      "       6.8137611e-09, 6.8706174e-09, 6.8587314e-09, 6.8325461e-09,\n",
      "       6.8108550e-09, 6.8041044e-09, 6.8461259e-09, 6.8576518e-09,\n",
      "       6.8560886e-09, 6.8038419e-09, 6.8171659e-09, 6.8199411e-09,\n",
      "       6.8385106e-09, 6.8712764e-09, 6.8485986e-09, 6.8206987e-09,\n",
      "       6.8001258e-09, 6.8385870e-09, 6.8328023e-09, 6.8358070e-09,\n",
      "       6.7968613e-09, 6.8327228e-09, 6.8484076e-09, 6.8354300e-09,\n",
      "       6.8178592e-09, 6.8050405e-09, 6.8036425e-09, 6.7980168e-09,\n",
      "       6.8212604e-09, 6.8547830e-09, 6.8059096e-09, 6.8147648e-09,\n",
      "       6.8560970e-09, 6.8427881e-09, 6.8119839e-09, 6.8302928e-09,\n",
      "       6.8400965e-09, 6.8169062e-09, 6.8307644e-09, 6.8460912e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_2/conv2d_67/Conv2D\n",
      "index : 128\n",
      "shape : [ 64   1   1 112]\n",
      "shape_signature : [ 64   1   1 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00110495, 0.00111679, 0.00119613, 0.00117251, 0.00115627,\n",
      "       0.00117747, 0.00113053, 0.0011665 , 0.00112841, 0.00116992,\n",
      "       0.00122382, 0.00116832, 0.00122963, 0.00113072, 0.00118755,\n",
      "       0.00117038, 0.00122233, 0.00108836, 0.00113739, 0.00117088,\n",
      "       0.00105386, 0.00122917, 0.0011286 , 0.00114564, 0.00120413,\n",
      "       0.00113502, 0.00115785, 0.00118698, 0.00117382, 0.0011713 ,\n",
      "       0.0011411 , 0.0010834 , 0.00116326, 0.00121644, 0.00123879,\n",
      "       0.00114783, 0.00119533, 0.0011919 , 0.00117833, 0.00107619,\n",
      "       0.00115171, 0.00118002, 0.00113687, 0.0012002 , 0.00113442,\n",
      "       0.00118891, 0.00110235, 0.00118881, 0.00103256, 0.00114151,\n",
      "       0.00112158, 0.00118661, 0.0012406 , 0.00121694, 0.0012204 ,\n",
      "       0.00114772, 0.00111422, 0.00115415, 0.00115443, 0.00114622,\n",
      "       0.0011899 , 0.00108426, 0.00112872, 0.00118925], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_2/batch_normalization_51/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_2/conv2d_67/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_2/conv2d_67/BiasAdd\n",
      "index : 129\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.0476892e-07, 2.0696368e-07, 2.2166724e-07, 2.1728958e-07,\n",
      "       2.1427958e-07, 2.1820981e-07, 2.0951096e-07, 2.1617689e-07,\n",
      "       2.0911828e-07, 2.1680980e-07, 2.2679799e-07, 2.1651302e-07,\n",
      "       2.2787519e-07, 2.0954519e-07, 2.2007649e-07, 2.1689563e-07,\n",
      "       2.2652240e-07, 2.0169566e-07, 2.1078131e-07, 2.1698742e-07,\n",
      "       1.9530111e-07, 2.2779010e-07, 2.0915284e-07, 2.1230962e-07,\n",
      "       2.2314946e-07, 2.1034258e-07, 2.1457254e-07, 2.1997100e-07,\n",
      "       2.1753283e-07, 2.1706582e-07, 2.1146937e-07, 2.0077665e-07,\n",
      "       2.1557601e-07, 2.2543112e-07, 2.2957296e-07, 2.1271624e-07,\n",
      "       2.2151947e-07, 2.2088258e-07, 2.1836942e-07, 1.9944008e-07,\n",
      "       2.1343480e-07, 2.1868226e-07, 2.1068560e-07, 2.2242200e-07,\n",
      "       2.1023065e-07, 2.2033015e-07, 2.0428807e-07, 2.2031004e-07,\n",
      "       1.9135393e-07, 2.1154447e-07, 2.0785197e-07, 2.1990229e-07,\n",
      "       2.2990784e-07, 2.2552403e-07, 2.2616429e-07, 2.1269551e-07,\n",
      "       2.0648814e-07, 2.1388773e-07, 2.1393953e-07, 2.1241743e-07,\n",
      "       2.2051256e-07, 2.0093577e-07, 2.0917412e-07, 2.2039205e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/strided_slice\n",
      "index : 130\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001957779284566641, -128)\n",
      "quantization_parameters : {'scales': array([0.00195778], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/strided_slice\n",
      "index : 131\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013070876011624932, -128)\n",
      "quantization_parameters : {'scales': array([0.00130709], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/conv2d_45/Conv2D\n",
      "index : 132\n",
      "shape : [672   1   1 112]\n",
      "shape_signature : [672   1   1 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00065959, 0.00068095, 0.00070218, 0.00068925, 0.00067118,\n",
      "       0.00068216, 0.00068293, 0.00069241, 0.00069119, 0.00068878,\n",
      "       0.00068436, 0.00070156, 0.00068568, 0.00069215, 0.00068439,\n",
      "       0.00065128, 0.00068442, 0.00068745, 0.00069219, 0.00068669,\n",
      "       0.00068307, 0.0006915 , 0.00068219, 0.00066942, 0.00069263,\n",
      "       0.00067848, 0.00069337, 0.00068722, 0.0006859 , 0.00069651,\n",
      "       0.00068312, 0.00066133, 0.0006897 , 0.00069278, 0.00069096,\n",
      "       0.00066912, 0.00068743, 0.00069585, 0.0006839 , 0.00068782,\n",
      "       0.00066937, 0.00069529, 0.00069731, 0.00069697, 0.00069179,\n",
      "       0.00067186, 0.00067069, 0.00067516, 0.00068865, 0.00065792,\n",
      "       0.00067867, 0.00068246, 0.0006867 , 0.00068194, 0.0006948 ,\n",
      "       0.00069621, 0.00066753, 0.00069585, 0.00068283, 0.0006919 ,\n",
      "       0.00069582, 0.0006538 , 0.00069853, 0.00069595, 0.00068047,\n",
      "       0.00068567, 0.00069387, 0.00069658, 0.00068718, 0.00067781,\n",
      "       0.00068712, 0.00068172, 0.00069552, 0.00069162, 0.0006961 ,\n",
      "       0.00069024, 0.00068179, 0.00068849, 0.0006826 , 0.00070342,\n",
      "       0.00068753, 0.00069479, 0.00070227, 0.00068613, 0.00069481,\n",
      "       0.00069749, 0.00068941, 0.00069653, 0.00069118, 0.00069541,\n",
      "       0.00068266, 0.00067195, 0.00066372, 0.0006863 , 0.00068103,\n",
      "       0.00068331, 0.00068122, 0.00068461, 0.0006867 , 0.00069533,\n",
      "       0.00068883, 0.00068816, 0.00068359, 0.00064299, 0.00068231,\n",
      "       0.00067828, 0.00069001, 0.0006863 , 0.00068418, 0.00067776,\n",
      "       0.00066816, 0.00067606, 0.00069208, 0.00068428, 0.00068655,\n",
      "       0.0006712 , 0.00068996, 0.00068043, 0.00065846, 0.00068346,\n",
      "       0.00069143, 0.00069497, 0.0006845 , 0.00067967, 0.00067846,\n",
      "       0.0006889 , 0.0006721 , 0.00069781, 0.00066143, 0.00070153,\n",
      "       0.00066308, 0.00069321, 0.00069837, 0.00069625, 0.00068131,\n",
      "       0.00068609, 0.00068285, 0.00068306, 0.00068933, 0.00067125,\n",
      "       0.00068861, 0.00068205, 0.00068558, 0.00066463, 0.00067671,\n",
      "       0.00069668, 0.00068671, 0.00068712, 0.00068385, 0.00069154,\n",
      "       0.0006932 , 0.00068219, 0.00069341, 0.00068244, 0.00067416,\n",
      "       0.00070113, 0.00069778, 0.00065549, 0.00069231, 0.00068391,\n",
      "       0.00068205, 0.00068724, 0.00068759, 0.00068562, 0.00067842,\n",
      "       0.00068955, 0.0006884 , 0.00067363, 0.00068852, 0.00067097,\n",
      "       0.0006813 , 0.00068793, 0.00068088, 0.00067736, 0.00068864,\n",
      "       0.00069533, 0.00069056, 0.00069073, 0.00069003, 0.00069231,\n",
      "       0.00069061, 0.00068767, 0.00067009, 0.00068389, 0.00068844,\n",
      "       0.00068963, 0.00068662, 0.00068845, 0.00067887, 0.00069695,\n",
      "       0.00067486, 0.00068861, 0.00069086, 0.00067331, 0.00068879,\n",
      "       0.00069747, 0.00069726, 0.00068152, 0.00067752, 0.00068056,\n",
      "       0.00067937, 0.00067006, 0.00068574, 0.00069466, 0.00065077,\n",
      "       0.00068741, 0.0006923 , 0.00069051, 0.00068092, 0.00069394,\n",
      "       0.00069019, 0.00069301, 0.00068569, 0.00068809, 0.00070151,\n",
      "       0.00067591, 0.00069757, 0.00066192, 0.0006855 , 0.0006923 ,\n",
      "       0.00067914, 0.00068291, 0.00069273, 0.00068347, 0.00066778,\n",
      "       0.0006777 , 0.00067749, 0.00069972, 0.00068865, 0.00068497,\n",
      "       0.00068864, 0.00068049, 0.00068547, 0.00067388, 0.00067813,\n",
      "       0.00067783, 0.00069525, 0.00065219, 0.00067538, 0.00065655,\n",
      "       0.00069335, 0.00068191, 0.00068777, 0.00067421, 0.00069034,\n",
      "       0.00068723, 0.00069088, 0.00069053, 0.00068423, 0.00067872,\n",
      "       0.00069095, 0.00067333, 0.00069835, 0.00067416, 0.00068538,\n",
      "       0.00067154, 0.00066373, 0.00069094, 0.00067342, 0.00069545,\n",
      "       0.00069736, 0.00068822, 0.00068352, 0.00068801, 0.00068003,\n",
      "       0.00066796, 0.00068986, 0.00067282, 0.00067421, 0.00068854,\n",
      "       0.00068536, 0.00069399, 0.00069216, 0.0006645 , 0.00068729,\n",
      "       0.00068505, 0.00069367, 0.00067646, 0.00069357, 0.00069401,\n",
      "       0.00068968, 0.00067601, 0.00067447, 0.00067921, 0.00068152,\n",
      "       0.00068915, 0.00069311, 0.00067902, 0.00069315, 0.00068614,\n",
      "       0.00068288, 0.0006855 , 0.0006772 , 0.00067927, 0.00068904,\n",
      "       0.00069306, 0.00069858, 0.00068426, 0.00068435, 0.00068908,\n",
      "       0.00068804, 0.00069331, 0.00068226, 0.00067251, 0.00069073,\n",
      "       0.00069346, 0.00065622, 0.00067023, 0.00068664, 0.00068458,\n",
      "       0.00069854, 0.00069499, 0.000683  , 0.00069675, 0.00065409,\n",
      "       0.00067209, 0.00068931, 0.00068813, 0.00068812, 0.00069445,\n",
      "       0.00068181, 0.00069305, 0.00068903, 0.00069408, 0.00069138,\n",
      "       0.00069752, 0.000679  , 0.00068978, 0.00069131, 0.00067636,\n",
      "       0.00067864, 0.00067798, 0.00070061, 0.00068133, 0.00069093,\n",
      "       0.00067519, 0.0006994 , 0.00069366, 0.00067319, 0.00069401,\n",
      "       0.00068639, 0.0006912 , 0.00069859, 0.00069281, 0.00068992,\n",
      "       0.00068893, 0.00068331, 0.00069037, 0.00069887, 0.00067605,\n",
      "       0.00067805, 0.00069471, 0.00068396, 0.00068456, 0.00067562,\n",
      "       0.00068746, 0.00068391, 0.00069189, 0.00065627, 0.00069371,\n",
      "       0.00067935, 0.00067745, 0.00068207, 0.00068842, 0.0006874 ,\n",
      "       0.00068808, 0.00066222, 0.00066806, 0.00069319, 0.00068284,\n",
      "       0.00068223, 0.00069449, 0.00068198, 0.00069688, 0.0006915 ,\n",
      "       0.00068241, 0.00065982, 0.00069085, 0.00068112, 0.00067362,\n",
      "       0.00068812, 0.00068697, 0.0006806 , 0.00070151, 0.00067827,\n",
      "       0.00067659, 0.0006667 , 0.00067073, 0.00069994, 0.00068507,\n",
      "       0.00067926, 0.00068921, 0.00068945, 0.00068088, 0.00069377,\n",
      "       0.00068744, 0.00069204, 0.00067112, 0.0006949 , 0.00067274,\n",
      "       0.00068009, 0.00069163, 0.00068218, 0.00068776, 0.00067926,\n",
      "       0.00067082, 0.00068931, 0.00068899, 0.00068582, 0.00068537,\n",
      "       0.00068502, 0.00066974, 0.00069209, 0.00065593, 0.000688  ,\n",
      "       0.00065272, 0.00067312, 0.00067915, 0.00067819, 0.0006781 ,\n",
      "       0.00067588, 0.00068818, 0.00068761, 0.00068785, 0.00068683,\n",
      "       0.00068272, 0.00069043, 0.00068288, 0.00068596, 0.00068155,\n",
      "       0.00068973, 0.0006751 , 0.00066074, 0.00068046, 0.00066801,\n",
      "       0.0006776 , 0.00069285, 0.00068552, 0.00069406, 0.00068123,\n",
      "       0.00066613, 0.00066462, 0.00068425, 0.00067847, 0.00069401,\n",
      "       0.00069022, 0.00066349, 0.00066144, 0.00069337, 0.00069446,\n",
      "       0.00068643, 0.00065201, 0.00068317, 0.00068513, 0.00065859,\n",
      "       0.00069899, 0.00067556, 0.00068497, 0.00069058, 0.00069177,\n",
      "       0.0006984 , 0.00066596, 0.00068155, 0.00069457, 0.00066646,\n",
      "       0.00068954, 0.00068032, 0.00068001, 0.00067614, 0.00068176,\n",
      "       0.00067781, 0.00066836, 0.00068705, 0.00068677, 0.00068567,\n",
      "       0.00068971, 0.0006882 , 0.000694  , 0.00065751, 0.0006917 ,\n",
      "       0.00069466, 0.00069484, 0.00068533, 0.00068837, 0.0006809 ,\n",
      "       0.00066564, 0.00068414, 0.00068907, 0.00069196, 0.00066561,\n",
      "       0.00067402, 0.00068322, 0.00068504, 0.00067907, 0.0006867 ,\n",
      "       0.00068717, 0.0006837 , 0.00068517, 0.00068055, 0.00070829,\n",
      "       0.00068011, 0.00069449, 0.00068362, 0.00068899, 0.00069045,\n",
      "       0.00068437, 0.00068515, 0.00069425, 0.00068271, 0.00069109,\n",
      "       0.00067543, 0.00066967, 0.00069731, 0.0006636 , 0.00068208,\n",
      "       0.00069395, 0.00070286, 0.00067693, 0.00068696, 0.00067176,\n",
      "       0.00067727, 0.00067482, 0.00069652, 0.00068672, 0.0006827 ,\n",
      "       0.00068312, 0.00067689, 0.00067113, 0.00069374, 0.00068269,\n",
      "       0.00069695, 0.00069064, 0.00068823, 0.00067203, 0.00069447,\n",
      "       0.00068061, 0.00068466, 0.00069112, 0.00067668, 0.00068677,\n",
      "       0.00067707, 0.00067551, 0.00068789, 0.00067284, 0.0006768 ,\n",
      "       0.00069032, 0.00068477, 0.00066947, 0.0006961 , 0.00068817,\n",
      "       0.00068365, 0.00068626, 0.00066826, 0.00067661, 0.0007025 ,\n",
      "       0.0006855 , 0.00068189, 0.00069391, 0.00068433, 0.00067884,\n",
      "       0.00068204, 0.00066857, 0.00068958, 0.00069877, 0.00067308,\n",
      "       0.00069436, 0.00068078, 0.00065028, 0.00068412, 0.00069137,\n",
      "       0.00068909, 0.00066634, 0.00068241, 0.00067715, 0.00067922,\n",
      "       0.00068004, 0.00069223, 0.00068607, 0.00068775, 0.00067269,\n",
      "       0.00068002, 0.00069935, 0.00068672, 0.00067896, 0.00069749,\n",
      "       0.00067693, 0.00067998, 0.00067222, 0.00068228, 0.00068896,\n",
      "       0.00070553, 0.00069178, 0.0006708 , 0.0006927 , 0.00070063,\n",
      "       0.00069075, 0.00068523, 0.00068507, 0.00069986, 0.00068081,\n",
      "       0.00069343, 0.0006988 , 0.00068535, 0.00069093, 0.00068572,\n",
      "       0.00068287, 0.00069594, 0.00069206, 0.0006905 , 0.00068676,\n",
      "       0.00068202, 0.00068906, 0.00069003, 0.00066883, 0.00069195,\n",
      "       0.00068783, 0.00068278, 0.00069424, 0.00065634, 0.00068537,\n",
      "       0.0006971 , 0.00067814, 0.00068391, 0.00069887, 0.00066909,\n",
      "       0.00066037, 0.00067925, 0.00067133, 0.00068742, 0.00069108,\n",
      "       0.00067218, 0.00067207, 0.0006839 , 0.00069107, 0.00068669,\n",
      "       0.0006804 , 0.00067877, 0.00068086, 0.00069505, 0.00069125,\n",
      "       0.00067985, 0.00065895, 0.00069084, 0.00066839, 0.000675  ,\n",
      "       0.00070428, 0.00066789, 0.00068897, 0.00064126, 0.00069316,\n",
      "       0.00068356, 0.00068684, 0.00069667, 0.00069241, 0.00068021,\n",
      "       0.00067695, 0.00067976, 0.00069575, 0.00067585, 0.00068719,\n",
      "       0.00068384, 0.00068031, 0.00069436, 0.00069142, 0.00069034,\n",
      "       0.00067598, 0.0006949 , 0.00067919, 0.00068554, 0.00068235,\n",
      "       0.00069161, 0.00068614], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_34/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/conv2d_45/Conv2D\n",
      "index : 133\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.2223587e-07, 1.2619384e-07, 1.3012884e-07, 1.2773140e-07,\n",
      "       1.2438267e-07, 1.2641758e-07, 1.2656039e-07, 1.2831825e-07,\n",
      "       1.2809228e-07, 1.2764541e-07, 1.2682521e-07, 1.3001397e-07,\n",
      "       1.2707009e-07, 1.2826963e-07, 1.2683208e-07, 1.2069523e-07,\n",
      "       1.2683716e-07, 1.2739785e-07, 1.2827728e-07, 1.2725685e-07,\n",
      "       1.2658606e-07, 1.2814972e-07, 1.2642337e-07, 1.2405631e-07,\n",
      "       1.2835851e-07, 1.2573634e-07, 1.2849516e-07, 1.2735649e-07,\n",
      "       1.2711162e-07, 1.2907813e-07, 1.2659602e-07, 1.2255747e-07,\n",
      "       1.2781550e-07, 1.2838593e-07, 1.2804874e-07, 1.2400213e-07,\n",
      "       1.2739447e-07, 1.2895592e-07, 1.2674082e-07, 1.2746732e-07,\n",
      "       1.2404726e-07, 1.2885064e-07, 1.2922509e-07, 1.2916199e-07,\n",
      "       1.2820256e-07, 1.2450991e-07, 1.2429217e-07, 1.2512034e-07,\n",
      "       1.2762183e-07, 1.2192690e-07, 1.2577108e-07, 1.2647465e-07,\n",
      "       1.2725920e-07, 1.2637656e-07, 1.2876049e-07, 1.2902279e-07,\n",
      "       1.2370634e-07, 1.2895592e-07, 1.2654307e-07, 1.2822406e-07,\n",
      "       1.2895032e-07, 1.2116325e-07, 1.2945098e-07, 1.2897301e-07,\n",
      "       1.2610580e-07, 1.2706946e-07, 1.2858889e-07, 1.2909004e-07,\n",
      "       1.2734938e-07, 1.2561125e-07, 1.2733696e-07, 1.2633615e-07,\n",
      "       1.2889420e-07, 1.2817043e-07, 1.2900196e-07, 1.2791607e-07,\n",
      "       1.2635053e-07, 1.2759097e-07, 1.2649886e-07, 1.3035843e-07,\n",
      "       1.2741278e-07, 1.2875937e-07, 1.3014575e-07, 1.2715387e-07,\n",
      "       1.2876305e-07, 1.2925997e-07, 1.2776231e-07, 1.2908093e-07,\n",
      "       1.2809039e-07, 1.2887431e-07, 1.2651157e-07, 1.2452682e-07,\n",
      "       1.2300180e-07, 1.2718543e-07, 1.2620816e-07, 1.2663112e-07,\n",
      "       1.2624390e-07, 1.2687255e-07, 1.2725985e-07, 1.2885974e-07,\n",
      "       1.2765487e-07, 1.2752919e-07, 1.2668241e-07, 1.1915947e-07,\n",
      "       1.2644617e-07, 1.2569988e-07, 1.2787244e-07, 1.2718604e-07,\n",
      "       1.2679294e-07, 1.2560326e-07, 1.2382364e-07, 1.2528781e-07,\n",
      "       1.2825595e-07, 1.2681177e-07, 1.2723167e-07, 1.2438677e-07,\n",
      "       1.2786354e-07, 1.2609715e-07, 1.2202567e-07, 1.2665900e-07,\n",
      "       1.2813535e-07, 1.2879285e-07, 1.2685108e-07, 1.2595581e-07,\n",
      "       1.2573256e-07, 1.2766732e-07, 1.2455396e-07, 1.2931854e-07,\n",
      "       1.2257627e-07, 1.3000775e-07, 1.2288142e-07, 1.2846645e-07,\n",
      "       1.2942185e-07, 1.2902876e-07, 1.2626127e-07, 1.2714605e-07,\n",
      "       1.2654681e-07, 1.2658563e-07, 1.2774768e-07, 1.2439605e-07,\n",
      "       1.2761394e-07, 1.2639737e-07, 1.2705178e-07, 1.2316949e-07,\n",
      "       1.2540833e-07, 1.2910823e-07, 1.2726147e-07, 1.2733813e-07,\n",
      "       1.2673085e-07, 1.2815632e-07, 1.2846489e-07, 1.2642376e-07,\n",
      "       1.2850312e-07, 1.2647094e-07, 1.2493648e-07, 1.2993411e-07,\n",
      "       1.2931253e-07, 1.2147596e-07, 1.2829918e-07, 1.2674167e-07,\n",
      "       1.2639730e-07, 1.2736020e-07, 1.2742385e-07, 1.2706022e-07,\n",
      "       1.2572491e-07, 1.2778760e-07, 1.2757532e-07, 1.2483679e-07,\n",
      "       1.2759665e-07, 1.2434359e-07, 1.2625802e-07, 1.2748733e-07,\n",
      "       1.2618013e-07, 1.2552869e-07, 1.2761922e-07, 1.2885808e-07,\n",
      "       1.2797570e-07, 1.2800700e-07, 1.2787747e-07, 1.2829830e-07,\n",
      "       1.2798502e-07, 1.2743995e-07, 1.2418080e-07, 1.2673928e-07,\n",
      "       1.2758277e-07, 1.2780282e-07, 1.2724404e-07, 1.2758431e-07,\n",
      "       1.2580797e-07, 1.2915923e-07, 1.2506545e-07, 1.2761379e-07,\n",
      "       1.2803086e-07, 1.2477743e-07, 1.2764760e-07, 1.2925594e-07,\n",
      "       1.2921628e-07, 1.2629981e-07, 1.2555813e-07, 1.2612129e-07,\n",
      "       1.2590084e-07, 1.2417674e-07, 1.2708256e-07, 1.2873470e-07,\n",
      "       1.2060161e-07, 1.2739112e-07, 1.2829690e-07, 1.2796552e-07,\n",
      "       1.2618889e-07, 1.2860080e-07, 1.2790639e-07, 1.2842801e-07,\n",
      "       1.2707228e-07, 1.2751735e-07, 1.3000343e-07, 1.2525912e-07,\n",
      "       1.2927489e-07, 1.2266771e-07, 1.2703701e-07, 1.2829771e-07,\n",
      "       1.2585943e-07, 1.2655680e-07, 1.2837654e-07, 1.2666140e-07,\n",
      "       1.2375328e-07, 1.2559117e-07, 1.2555329e-07, 1.2967189e-07,\n",
      "       1.2762047e-07, 1.2693911e-07, 1.2761915e-07, 1.2610890e-07,\n",
      "       1.2703234e-07, 1.2488321e-07, 1.2567129e-07, 1.2561593e-07,\n",
      "       1.2884385e-07, 1.2086497e-07, 1.2516247e-07, 1.2167260e-07,\n",
      "       1.2849161e-07, 1.2637135e-07, 1.2745710e-07, 1.2494571e-07,\n",
      "       1.2793431e-07, 1.2735809e-07, 1.2803400e-07, 1.2796905e-07,\n",
      "       1.2680218e-07, 1.2578160e-07, 1.2804733e-07, 1.2478169e-07,\n",
      "       1.2941874e-07, 1.2493567e-07, 1.2701558e-07, 1.2445057e-07,\n",
      "       1.2300248e-07, 1.2804496e-07, 1.2479779e-07, 1.2888120e-07,\n",
      "       1.2923449e-07, 1.2754082e-07, 1.2666935e-07, 1.2750182e-07,\n",
      "       1.2602271e-07, 1.2378672e-07, 1.2784567e-07, 1.2468792e-07,\n",
      "       1.2494517e-07, 1.2760107e-07, 1.2701132e-07, 1.2860988e-07,\n",
      "       1.2827215e-07, 1.2314536e-07, 1.2736962e-07, 1.2695406e-07,\n",
      "       1.2855143e-07, 1.2536179e-07, 1.2853324e-07, 1.2861500e-07,\n",
      "       1.2781180e-07, 1.2527838e-07, 1.2499271e-07, 1.2587110e-07,\n",
      "       1.2629937e-07, 1.2771275e-07, 1.2844805e-07, 1.2583621e-07,\n",
      "       1.2845410e-07, 1.2715510e-07, 1.2655245e-07, 1.2703742e-07,\n",
      "       1.2549890e-07, 1.2588309e-07, 1.2769330e-07, 1.2843815e-07,\n",
      "       1.2946025e-07, 1.2680752e-07, 1.2682482e-07, 1.2770025e-07,\n",
      "       1.2750805e-07, 1.2848500e-07, 1.2643613e-07, 1.2463035e-07,\n",
      "       1.2800700e-07, 1.2851191e-07, 1.2161119e-07, 1.2420679e-07,\n",
      "       1.2724882e-07, 1.2686652e-07, 1.2945456e-07, 1.2879634e-07,\n",
      "       1.2657473e-07, 1.2912180e-07, 1.2121542e-07, 1.2455142e-07,\n",
      "       1.2774261e-07, 1.2752528e-07, 1.2752346e-07, 1.2869637e-07,\n",
      "       1.2635302e-07, 1.2843704e-07, 1.2769054e-07, 1.2862635e-07,\n",
      "       1.2812636e-07, 1.2926434e-07, 1.2583276e-07, 1.2783018e-07,\n",
      "       1.2811442e-07, 1.2534403e-07, 1.2576507e-07, 1.2564313e-07,\n",
      "       1.2983691e-07, 1.2626469e-07, 1.2804354e-07, 1.2512700e-07,\n",
      "       1.2961348e-07, 1.2854883e-07, 1.2475607e-07, 1.2861416e-07,\n",
      "       1.2720255e-07, 1.2809303e-07, 1.2946325e-07, 1.2839097e-07,\n",
      "       1.2785669e-07, 1.2767241e-07, 1.2663095e-07, 1.2794001e-07,\n",
      "       1.2951558e-07, 1.2528641e-07, 1.2565619e-07, 1.2874369e-07,\n",
      "       1.2675258e-07, 1.2686250e-07, 1.2520707e-07, 1.2740099e-07,\n",
      "       1.2674323e-07, 1.2822133e-07, 1.2161942e-07, 1.2855919e-07,\n",
      "       1.2589688e-07, 1.2554470e-07, 1.2640089e-07, 1.2757828e-07,\n",
      "       1.2738921e-07, 1.2751521e-07, 1.2272251e-07, 1.2380485e-07,\n",
      "       1.2846256e-07, 1.2654462e-07, 1.2643081e-07, 1.2870325e-07,\n",
      "       1.2638549e-07, 1.2914651e-07, 1.2814998e-07, 1.2646538e-07,\n",
      "       1.2227765e-07, 1.2802897e-07, 1.2622600e-07, 1.2483483e-07,\n",
      "       1.2752277e-07, 1.2731032e-07, 1.2612891e-07, 1.3000478e-07,\n",
      "       1.2569649e-07, 1.2538682e-07, 1.2355386e-07, 1.2430017e-07,\n",
      "       1.2971226e-07, 1.2695834e-07, 1.2588049e-07, 1.2772529e-07,\n",
      "       1.2776964e-07, 1.2618051e-07, 1.2856984e-07, 1.2739741e-07,\n",
      "       1.2824947e-07, 1.2437158e-07, 1.2877959e-07, 1.2467316e-07,\n",
      "       1.2603482e-07, 1.2817350e-07, 1.2642256e-07, 1.2745535e-07,\n",
      "       1.2588065e-07, 1.2431586e-07, 1.2774285e-07, 1.2768400e-07,\n",
      "       1.2709680e-07, 1.2701300e-07, 1.2694736e-07, 1.2411651e-07,\n",
      "       1.2825774e-07, 1.2155638e-07, 1.2749996e-07, 1.2096207e-07,\n",
      "       1.2474231e-07, 1.2586079e-07, 1.2568303e-07, 1.2566628e-07,\n",
      "       1.2525443e-07, 1.2753429e-07, 1.2742804e-07, 1.2747306e-07,\n",
      "       1.2728378e-07, 1.2652272e-07, 1.2795005e-07, 1.2655083e-07,\n",
      "       1.2712188e-07, 1.2630439e-07, 1.2782111e-07, 1.2510985e-07,\n",
      "       1.2244887e-07, 1.2610369e-07, 1.2379667e-07, 1.2557278e-07,\n",
      "       1.2839902e-07, 1.2704055e-07, 1.2862324e-07, 1.2624665e-07,\n",
      "       1.2344739e-07, 1.2316674e-07, 1.2680619e-07, 1.2573419e-07,\n",
      "       1.2861481e-07, 1.2791219e-07, 1.2295820e-07, 1.2257861e-07,\n",
      "       1.2849516e-07, 1.2869678e-07, 1.2721017e-07, 1.2083119e-07,\n",
      "       1.2660506e-07, 1.2696822e-07, 1.2205003e-07, 1.2953723e-07,\n",
      "       1.2519546e-07, 1.2693933e-07, 1.2797911e-07, 1.2819845e-07,\n",
      "       1.2942870e-07, 1.2341599e-07, 1.2630538e-07, 1.2871712e-07,\n",
      "       1.2350883e-07, 1.2778543e-07, 1.2607715e-07, 1.2601889e-07,\n",
      "       1.2530256e-07, 1.2634358e-07, 1.2561148e-07, 1.2386060e-07,\n",
      "       1.2732360e-07, 1.2727236e-07, 1.2706877e-07, 1.2781815e-07,\n",
      "       1.2753718e-07, 1.2861172e-07, 1.2184945e-07, 1.2818620e-07,\n",
      "       1.2873457e-07, 1.2876889e-07, 1.2700481e-07, 1.2756890e-07,\n",
      "       1.2618551e-07, 1.2335718e-07, 1.2678541e-07, 1.2769947e-07,\n",
      "       1.2823379e-07, 1.2335089e-07, 1.2490985e-07, 1.2661428e-07,\n",
      "       1.2695102e-07, 1.2584576e-07, 1.2725968e-07, 1.2734669e-07,\n",
      "       1.2670381e-07, 1.2697578e-07, 1.2612011e-07, 1.3125971e-07,\n",
      "       1.2603853e-07, 1.2870302e-07, 1.2668951e-07, 1.2768460e-07,\n",
      "       1.2795530e-07, 1.2682820e-07, 1.2697306e-07, 1.2865929e-07,\n",
      "       1.2652072e-07, 1.2807314e-07, 1.2517174e-07, 1.2410281e-07,\n",
      "       1.2922604e-07, 1.2297795e-07, 1.2640346e-07, 1.2860342e-07,\n",
      "       1.3025408e-07, 1.2544872e-07, 1.2730800e-07, 1.2448994e-07,\n",
      "       1.2551222e-07, 1.2505794e-07, 1.2907900e-07, 1.2726338e-07,\n",
      "       1.2651806e-07, 1.2659588e-07, 1.2544159e-07, 1.2437397e-07,\n",
      "       1.2856415e-07, 1.2651635e-07, 1.2915996e-07, 1.2798930e-07,\n",
      "       1.2754248e-07, 1.2454160e-07, 1.2869933e-07, 1.2613158e-07,\n",
      "       1.2688145e-07, 1.2807949e-07, 1.2540214e-07, 1.2727303e-07,\n",
      "       1.2547400e-07, 1.2518599e-07, 1.2747928e-07, 1.2469022e-07,\n",
      "       1.2542404e-07, 1.2793119e-07, 1.2690272e-07, 1.2406591e-07,\n",
      "       1.2900092e-07, 1.2753154e-07, 1.2669510e-07, 1.2717754e-07,\n",
      "       1.2384220e-07, 1.2538929e-07, 1.3018807e-07, 1.2703694e-07,\n",
      "       1.2636869e-07, 1.2859488e-07, 1.2681974e-07, 1.2580210e-07,\n",
      "       1.2639656e-07, 1.2390009e-07, 1.2779236e-07, 1.2949643e-07,\n",
      "       1.2473585e-07, 1.2867864e-07, 1.2616266e-07, 1.2051044e-07,\n",
      "       1.2678071e-07, 1.2812465e-07, 1.2770300e-07, 1.2348642e-07,\n",
      "       1.2646498e-07, 1.2549027e-07, 1.2587427e-07, 1.2602443e-07,\n",
      "       1.2828430e-07, 1.2714368e-07, 1.2745477e-07, 1.2466241e-07,\n",
      "       1.2602108e-07, 1.2960349e-07, 1.2726372e-07, 1.2582481e-07,\n",
      "       1.2925922e-07, 1.2544845e-07, 1.2601356e-07, 1.2457592e-07,\n",
      "       1.2644075e-07, 1.2767866e-07, 1.3074890e-07, 1.2820020e-07,\n",
      "       1.2431245e-07, 1.2837219e-07, 1.2984118e-07, 1.2801060e-07,\n",
      "       1.2698654e-07, 1.2695675e-07, 1.2969767e-07, 1.2616829e-07,\n",
      "       1.2850630e-07, 1.2950180e-07, 1.2700981e-07, 1.2804280e-07,\n",
      "       1.2707724e-07, 1.2654969e-07, 1.2897239e-07, 1.2825289e-07,\n",
      "       1.2796390e-07, 1.2727138e-07, 1.2639316e-07, 1.2769773e-07,\n",
      "       1.2787741e-07, 1.2394760e-07, 1.2823203e-07, 1.2746963e-07,\n",
      "       1.2653217e-07, 1.2865630e-07, 1.2163261e-07, 1.2701273e-07,\n",
      "       1.2918734e-07, 1.2567385e-07, 1.2674278e-07, 1.2951543e-07,\n",
      "       1.2399524e-07, 1.2237918e-07, 1.2587924e-07, 1.2441080e-07,\n",
      "       1.2739244e-07, 1.2807078e-07, 1.2456945e-07, 1.2454852e-07,\n",
      "       1.2674150e-07, 1.2806973e-07, 1.2725754e-07, 1.2609151e-07,\n",
      "       1.2579032e-07, 1.2617640e-07, 1.2880727e-07, 1.2810291e-07,\n",
      "       1.2598970e-07, 1.2211629e-07, 1.2802700e-07, 1.2386619e-07,\n",
      "       1.2509103e-07, 1.3051688e-07, 1.2377289e-07, 1.2767957e-07,\n",
      "       1.1883913e-07, 1.2845611e-07, 1.2667711e-07, 1.2728540e-07,\n",
      "       1.2910698e-07, 1.2831730e-07, 1.2605675e-07, 1.2545286e-07,\n",
      "       1.2597266e-07, 1.2893749e-07, 1.2524792e-07, 1.2735089e-07,\n",
      "       1.2673034e-07, 1.2607616e-07, 1.2867956e-07, 1.2813338e-07,\n",
      "       1.2793325e-07, 1.2527259e-07, 1.2877832e-07, 1.2586861e-07,\n",
      "       1.2704527e-07, 1.2645377e-07, 1.2816858e-07, 1.2715637e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_35/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/depthwise_conv2d_11/depthwise;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D\n",
      "index : 134\n",
      "shape : [  1   5   5 672]\n",
      "shape_signature : [  1   5   5 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00016186, 0.00015691, 0.00016027, 0.00014972, 0.00015506,\n",
      "       0.00015321, 0.00015611, 0.00014553, 0.00014787, 0.00015396,\n",
      "       0.00016201, 0.0001563 , 0.00016352, 0.00015543, 0.00016424,\n",
      "       0.00016695, 0.00015831, 0.00015046, 0.00013986, 0.00016122,\n",
      "       0.0001535 , 0.00015857, 0.00016545, 0.00016171, 0.00016858,\n",
      "       0.00016339, 0.00015917, 0.00014343, 0.00015822, 0.00015903,\n",
      "       0.00016121, 0.000147  , 0.00014946, 0.00015587, 0.00014898,\n",
      "       0.00015847, 0.00015545, 0.0001626 , 0.00014757, 0.00015115,\n",
      "       0.00015695, 0.00015179, 0.00016459, 0.00015289, 0.00016368,\n",
      "       0.00016278, 0.00016144, 0.00016214, 0.00015512, 0.00015485,\n",
      "       0.00016093, 0.0001521 , 0.00015432, 0.00015479, 0.00016563,\n",
      "       0.00017016, 0.00015142, 0.00014961, 0.00016562, 0.0001405 ,\n",
      "       0.00016178, 0.00014806, 0.00016268, 0.0001545 , 0.00016608,\n",
      "       0.00015899, 0.00015965, 0.00016269, 0.00015866, 0.00014731,\n",
      "       0.00014871, 0.00016676, 0.00014578, 0.00015785, 0.0001593 ,\n",
      "       0.00015945, 0.00016547, 0.0001676 , 0.00015491, 0.00016118,\n",
      "       0.00015216, 0.00014933, 0.00015427, 0.00016186, 0.00012958,\n",
      "       0.00014924, 0.00014451, 0.00016099, 0.00015693, 0.00016048,\n",
      "       0.00014911, 0.00015913, 0.00016107, 0.00016131, 0.00015694,\n",
      "       0.00015813, 0.00015938, 0.00016178, 0.00016132, 0.0001564 ,\n",
      "       0.00015869, 0.00014654, 0.00014696, 0.00016104, 0.0001537 ,\n",
      "       0.00016182, 0.00015814, 0.00015988, 0.00015846, 0.00016331,\n",
      "       0.00015058, 0.00015701, 0.00015265, 0.00015795, 0.00015128,\n",
      "       0.00015807, 0.00015829, 0.00014628, 0.00015798, 0.0001579 ,\n",
      "       0.00015296, 0.00015428, 0.00015651, 0.00016155, 0.0001558 ,\n",
      "       0.00016695, 0.00016018, 0.00015676, 0.00016354, 0.0001578 ,\n",
      "       0.00016367, 0.00015715, 0.00016011, 0.00015641, 0.00016459,\n",
      "       0.00015462, 0.00015609, 0.0001628 , 0.00015823, 0.00015823,\n",
      "       0.00016153, 0.00015816, 0.00015493, 0.00014959, 0.00016355,\n",
      "       0.00015467, 0.00015907, 0.00015265, 0.00014194, 0.00015045,\n",
      "       0.00016127, 0.00016022, 0.00015852, 0.00015607, 0.00016072,\n",
      "       0.00015254, 0.00015687, 0.00016162, 0.00016165, 0.00016838,\n",
      "       0.00015921, 0.00016129, 0.00015472, 0.00017005, 0.00015306,\n",
      "       0.00012986, 0.00016421, 0.00015653, 0.00014401, 0.00015343,\n",
      "       0.00015415, 0.00016179, 0.00016023, 0.00015106, 0.0001674 ,\n",
      "       0.00016238, 0.00016493, 0.00014862, 0.00015532, 0.00015751,\n",
      "       0.00015949, 0.00016578, 0.00016091, 0.00016295, 0.0001618 ,\n",
      "       0.0001586 , 0.00015398, 0.00015851, 0.0001625 , 0.00015868,\n",
      "       0.000157  , 0.0001548 , 0.00015681, 0.00015378, 0.00016039,\n",
      "       0.0001489 , 0.00016528, 0.00016325, 0.00016581, 0.00016688,\n",
      "       0.00015817, 0.00014465, 0.00016079, 0.00015456, 0.00015391,\n",
      "       0.00016097, 0.00014488, 0.00015822, 0.00015857, 0.00015734,\n",
      "       0.00016081, 0.00015906, 0.00016095, 0.00015457, 0.00015857,\n",
      "       0.00016008, 0.00016684, 0.00015343, 0.00015572, 0.00015003,\n",
      "       0.00015392, 0.00016454, 0.00015849, 0.00016021, 0.00015825,\n",
      "       0.00016447, 0.0001562 , 0.00016508, 0.00014207, 0.00014307,\n",
      "       0.00015445, 0.00016218, 0.00015482, 0.00015138, 0.00015983,\n",
      "       0.0001506 , 0.00014847, 0.00015372, 0.00016176, 0.00015827,\n",
      "       0.00013826, 0.00015512, 0.00015325, 0.00015663, 0.0001591 ,\n",
      "       0.0001459 , 0.00014984, 0.00016316, 0.00014839, 0.00016215,\n",
      "       0.00015413, 0.00013187, 0.00014723, 0.00016798, 0.00015202,\n",
      "       0.00014816, 0.00016354, 0.00016546, 0.00015597, 0.00015573,\n",
      "       0.00016057, 0.00016253, 0.00015986, 0.00016545, 0.00014947,\n",
      "       0.00015179, 0.00016428, 0.00015361, 0.00016414, 0.00015997,\n",
      "       0.00016148, 0.00014521, 0.00015385, 0.0001557 , 0.00015361,\n",
      "       0.00015116, 0.00015709, 0.00015438, 0.00016802, 0.00016321,\n",
      "       0.00016143, 0.00014437, 0.00016089, 0.00016052, 0.00015139,\n",
      "       0.00015307, 0.00015945, 0.00015274, 0.00015619, 0.00015814,\n",
      "       0.00016464, 0.00016435, 0.00015973, 0.00015414, 0.00016114,\n",
      "       0.00016745, 0.00016123, 0.00016115, 0.00016706, 0.00016591,\n",
      "       0.00014952, 0.00016289, 0.0001602 , 0.00015183, 0.00016378,\n",
      "       0.0001306 , 0.00015953, 0.00015178, 0.00016327, 0.00016061,\n",
      "       0.00016072, 0.00016639, 0.00015888, 0.00014798, 0.00015603,\n",
      "       0.00014419, 0.00016217, 0.00015728, 0.00015989, 0.00015239,\n",
      "       0.00016429, 0.00015615, 0.00014135, 0.00015413, 0.00015238,\n",
      "       0.00015325, 0.00014667, 0.00014668, 0.00016102, 0.00016051,\n",
      "       0.0001596 , 0.00016371, 0.00014947, 0.00015798, 0.00016206,\n",
      "       0.00015404, 0.00015872, 0.00015256, 0.00016559, 0.00015933,\n",
      "       0.00016202, 0.00014987, 0.00015893, 0.00015865, 0.00014452,\n",
      "       0.00015451, 0.00015952, 0.00016344, 0.00016235, 0.00014436,\n",
      "       0.00016283, 0.00015331, 0.00015339, 0.00013425, 0.00015778,\n",
      "       0.00015622, 0.00015583, 0.00015373, 0.00016148, 0.00012993,\n",
      "       0.00016533, 0.00016616, 0.00016128, 0.00016075, 0.00014925,\n",
      "       0.00016178, 0.00015657, 0.00015547, 0.00015896, 0.0001625 ,\n",
      "       0.00017107, 0.00015261, 0.0001576 , 0.00015768, 0.00016125,\n",
      "       0.00016233, 0.00016066, 0.00015352, 0.00015907, 0.00015179,\n",
      "       0.00014797, 0.00015553, 0.00015707, 0.00015785, 0.00015991,\n",
      "       0.00014582, 0.00015728, 0.00015138, 0.00016074, 0.00016113,\n",
      "       0.00016898, 0.00016572, 0.00015475, 0.00015445, 0.00014165,\n",
      "       0.00015552, 0.00016328, 0.00015342, 0.00016334, 0.00015503,\n",
      "       0.00014989, 0.00015164, 0.00016725, 0.0001559 , 0.00015617,\n",
      "       0.00015778, 0.00016131, 0.00014968, 0.00015355, 0.00015754,\n",
      "       0.0001557 , 0.00016171, 0.00015824, 0.00015641, 0.00015621,\n",
      "       0.00015003, 0.00015552, 0.00016053, 0.00015035, 0.0001529 ,\n",
      "       0.00015229, 0.00016297, 0.00015509, 0.00014756, 0.00016213,\n",
      "       0.00014889, 0.00016535, 0.00016181, 0.00015953, 0.00015376,\n",
      "       0.00015622, 0.00015889, 0.00015379, 0.00015389, 0.0001536 ,\n",
      "       0.0001625 , 0.00016122, 0.00016184, 0.00015928, 0.00015868,\n",
      "       0.00015765, 0.00015905, 0.00014879, 0.00015717, 0.0001452 ,\n",
      "       0.00015647, 0.00015784, 0.00015852, 0.0001549 , 0.00016761,\n",
      "       0.00015834, 0.00014121, 0.0001621 , 0.0001441 , 0.00015902,\n",
      "       0.00014254, 0.00016368, 0.00014854, 0.00015934, 0.00016823,\n",
      "       0.00015805, 0.0001576 , 0.00015666, 0.00015871, 0.00014409,\n",
      "       0.00015638, 0.00013075, 0.00015261, 0.00015192, 0.00015878,\n",
      "       0.00013882, 0.00014486, 0.00016036, 0.00015504, 0.00014635,\n",
      "       0.00014435, 0.0001629 , 0.00015133, 0.0001635 , 0.00016154,\n",
      "       0.00014978, 0.00015549, 0.00015114, 0.00016373, 0.00015013,\n",
      "       0.00015827, 0.00014712, 0.00016259, 0.00013477, 0.00016615,\n",
      "       0.00016056, 0.00014941, 0.00015622, 0.00016134, 0.00015791,\n",
      "       0.00015453, 0.00015722, 0.00016449, 0.00014745, 0.00015956,\n",
      "       0.00016257, 0.00016193, 0.00014708, 0.00016429, 0.00016214,\n",
      "       0.00015569, 0.00016408, 0.00015733, 0.00015866, 0.00016111,\n",
      "       0.00016178, 0.00016559, 0.00015449, 0.00015242, 0.00014792,\n",
      "       0.00016381, 0.00014935, 0.00015167, 0.00016043, 0.00014611,\n",
      "       0.00015383, 0.00016283, 0.00016218, 0.00016633, 0.00014792,\n",
      "       0.00016398, 0.00016306, 0.00016404, 0.00013716, 0.00015127,\n",
      "       0.00014736, 0.00016228, 0.00016097, 0.00015119, 0.00016303,\n",
      "       0.00016223, 0.00015831, 0.00016221, 0.0001534 , 0.00016014,\n",
      "       0.00014967, 0.00015794, 0.0001569 , 0.00015251, 0.00015675,\n",
      "       0.00016598, 0.00015067, 0.00016107, 0.00016298, 0.00014918,\n",
      "       0.00013708, 0.0001427 , 0.000153  , 0.00015587, 0.00016357,\n",
      "       0.00016071, 0.00014462, 0.00015927, 0.00015685, 0.00016169,\n",
      "       0.00015606, 0.00016138, 0.00015528, 0.0001606 , 0.00015371,\n",
      "       0.00015689, 0.00016561, 0.00015972, 0.00014663, 0.00015902,\n",
      "       0.000158  , 0.00016   , 0.00015458, 0.00015226, 0.00015746,\n",
      "       0.00015549, 0.00016092, 0.00016109, 0.0001516 , 0.00016144,\n",
      "       0.00016314, 0.00015385, 0.00015464, 0.00015464, 0.00015983,\n",
      "       0.00014473, 0.00016168, 0.00016465, 0.00015527, 0.00015844,\n",
      "       0.00016232, 0.00015663, 0.00014765, 0.00015715, 0.00015489,\n",
      "       0.00014836, 0.00015875, 0.00016272, 0.00015223, 0.00015798,\n",
      "       0.00015553, 0.00014571, 0.00016341, 0.00016029, 0.00016217,\n",
      "       0.00016075, 0.00015443, 0.0001558 , 0.00014793, 0.00015112,\n",
      "       0.00016664, 0.00015772, 0.00016457, 0.00016516, 0.00015949,\n",
      "       0.00014686, 0.00014438, 0.000155  , 0.00016642, 0.00015561,\n",
      "       0.00015663, 0.00016323, 0.00015645, 0.00016182, 0.00016592,\n",
      "       0.00016085, 0.00016023, 0.00014045, 0.00015432, 0.00014511,\n",
      "       0.00015844, 0.00015073, 0.0001642 , 0.00015818, 0.00015435,\n",
      "       0.00014876, 0.00016215, 0.00015662, 0.00016276, 0.00015168,\n",
      "       0.00015055, 0.00015773, 0.00015932, 0.00016491, 0.00016407,\n",
      "       0.00015743, 0.00015106, 0.00016071, 0.0001614 , 0.00015512,\n",
      "       0.00015539, 0.00015789, 0.0001645 , 0.00016113, 0.00016211,\n",
      "       0.00014991, 0.00015791, 0.00014978, 0.00014454, 0.00016471,\n",
      "       0.00015971, 0.00014521, 0.00015852, 0.00016401, 0.00016152,\n",
      "       0.00016289, 0.00015087, 0.00016202, 0.00014926, 0.00014593,\n",
      "       0.00013764, 0.00015902], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_35/FusedBatchNormV3\n",
      "index : 135\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.13684182e-08, 1.10204432e-08, 1.12563709e-08, 1.05154134e-08,\n",
      "       1.08908980e-08, 1.07604716e-08, 1.09641451e-08, 1.02212363e-08,\n",
      "       1.03856879e-08, 1.08134381e-08, 1.13787522e-08, 1.09779892e-08,\n",
      "       1.14849250e-08, 1.09166951e-08, 1.15357874e-08, 1.17261214e-08,\n",
      "       1.11193259e-08, 1.05674589e-08, 9.82304638e-09, 1.13235776e-08,\n",
      "       1.07813412e-08, 1.11369909e-08, 1.16204113e-08, 1.13578551e-08,\n",
      "       1.18401688e-08, 1.14754570e-08, 1.11790603e-08, 1.00738458e-08,\n",
      "       1.11125695e-08, 1.11694050e-08, 1.13223635e-08, 1.03249729e-08,\n",
      "       1.04976561e-08, 1.09476845e-08, 1.04635651e-08, 1.11301750e-08,\n",
      "       1.09184608e-08, 1.14200436e-08, 1.03644728e-08, 1.06159721e-08,\n",
      "       1.10234142e-08, 1.06610800e-08, 1.15600933e-08, 1.07381455e-08,\n",
      "       1.14962511e-08, 1.14332810e-08, 1.13390390e-08, 1.13877681e-08,\n",
      "       1.08949143e-08, 1.08758300e-08, 1.13029648e-08, 1.06826183e-08,\n",
      "       1.08384128e-08, 1.08720632e-08, 1.16327987e-08, 1.19515384e-08,\n",
      "       1.06351301e-08, 1.05079714e-08, 1.16321823e-08, 9.86815074e-09,\n",
      "       1.13626610e-08, 1.03993614e-08, 1.14260956e-08, 1.08514469e-08,\n",
      "       1.16646488e-08, 1.11668967e-08, 1.12132428e-08, 1.14264083e-08,\n",
      "       1.11434968e-08, 1.03461071e-08, 1.04449871e-08, 1.17127525e-08,\n",
      "       1.02389741e-08, 1.10863807e-08, 1.11882246e-08, 1.11993224e-08,\n",
      "       1.16218146e-08, 1.17711449e-08, 1.08803837e-08, 1.13204042e-08,\n",
      "       1.06871054e-08, 1.04884919e-08, 1.08351959e-08, 1.13686358e-08,\n",
      "       9.10088005e-09, 1.04817817e-08, 1.01497273e-08, 1.13072334e-08,\n",
      "       1.10219407e-08, 1.12717213e-08, 1.04729674e-08, 1.11768728e-08,\n",
      "       1.13125713e-08, 1.13294485e-08, 1.10224621e-08, 1.11066774e-08,\n",
      "       1.11942340e-08, 1.13624035e-08, 1.13305862e-08, 1.09848468e-08,\n",
      "       1.11453646e-08, 1.02922328e-08, 1.03218118e-08, 1.13110454e-08,\n",
      "       1.07950280e-08, 1.13654997e-08, 1.11067253e-08, 1.12291243e-08,\n",
      "       1.11293366e-08, 1.14701137e-08, 1.05762714e-08, 1.10279963e-08,\n",
      "       1.07212648e-08, 1.10937162e-08, 1.06255094e-08, 1.11018013e-08,\n",
      "       1.11177130e-08, 1.02743600e-08, 1.10960912e-08, 1.10904912e-08,\n",
      "       1.07431939e-08, 1.08358806e-08, 1.09926503e-08, 1.13468523e-08,\n",
      "       1.09429328e-08, 1.17255787e-08, 1.12505765e-08, 1.10100151e-08,\n",
      "       1.14861924e-08, 1.10832374e-08, 1.14957599e-08, 1.10378613e-08,\n",
      "       1.12452714e-08, 1.09856737e-08, 1.15601715e-08, 1.08597211e-08,\n",
      "       1.09633929e-08, 1.14345520e-08, 1.11133893e-08, 1.11134710e-08,\n",
      "       1.13453495e-08, 1.11085043e-08, 1.08818297e-08, 1.05063060e-08,\n",
      "       1.14868071e-08, 1.08631726e-08, 1.11725997e-08, 1.07212168e-08,\n",
      "       9.96900340e-09, 1.05668931e-08, 1.13269456e-08, 1.12533067e-08,\n",
      "       1.11337943e-08, 1.09618927e-08, 1.12884635e-08, 1.07138831e-08,\n",
      "       1.10180203e-08, 1.13511751e-08, 1.13534222e-08, 1.18259358e-08,\n",
      "       1.11821956e-08, 1.13285710e-08, 1.08670122e-08, 1.19436594e-08,\n",
      "       1.07501261e-08, 9.12055675e-09, 1.15331895e-08, 1.09941505e-08,\n",
      "       1.01146531e-08, 1.07764553e-08, 1.08266853e-08, 1.13634941e-08,\n",
      "       1.12535998e-08, 1.06095825e-08, 1.17577823e-08, 1.14050724e-08,\n",
      "       1.15836638e-08, 1.04383391e-08, 1.09089227e-08, 1.10628884e-08,\n",
      "       1.12019594e-08, 1.16434489e-08, 1.13013385e-08, 1.14449117e-08,\n",
      "       1.13639933e-08, 1.11392886e-08, 1.08149392e-08, 1.11331975e-08,\n",
      "       1.14135688e-08, 1.11451222e-08, 1.10268168e-08, 1.08722826e-08,\n",
      "       1.10139862e-08, 1.08009086e-08, 1.12647793e-08, 1.04578017e-08,\n",
      "       1.16086740e-08, 1.14662679e-08, 1.16456542e-08, 1.17205738e-08,\n",
      "       1.11094449e-08, 1.01593551e-08, 1.12934080e-08, 1.08559126e-08,\n",
      "       1.08101714e-08, 1.13059633e-08, 1.01759099e-08, 1.11126042e-08,\n",
      "       1.11375922e-08, 1.10508571e-08, 1.12942828e-08, 1.11714202e-08,\n",
      "       1.13045600e-08, 1.08564819e-08, 1.11371783e-08, 1.12436060e-08,\n",
      "       1.17180896e-08, 1.07759570e-08, 1.09368417e-08, 1.05377929e-08,\n",
      "       1.08103713e-08, 1.15564385e-08, 1.11316547e-08, 1.12522267e-08,\n",
      "       1.11149117e-08, 1.15517009e-08, 1.09710383e-08, 1.15945760e-08,\n",
      "       9.97807970e-09, 1.00483177e-08, 1.08480265e-08, 1.13908030e-08,\n",
      "       1.08739941e-08, 1.06319655e-08, 1.12259215e-08, 1.05773417e-08,\n",
      "       1.04276703e-08, 1.07963691e-08, 1.13615757e-08, 1.11160885e-08,\n",
      "       9.71053371e-09, 1.08948699e-08, 1.07637703e-08, 1.10013172e-08,\n",
      "       1.11742917e-08, 1.02475006e-08, 1.05243823e-08, 1.14596679e-08,\n",
      "       1.04223368e-08, 1.13886403e-08, 1.08254019e-08, 9.26230115e-09,\n",
      "       1.03408730e-08, 1.17984165e-08, 1.06775433e-08, 1.04063496e-08,\n",
      "       1.14860974e-08, 1.16208518e-08, 1.09544391e-08, 1.09380629e-08,\n",
      "       1.12777760e-08, 1.14153060e-08, 1.12277760e-08, 1.16204095e-08,\n",
      "       1.04978994e-08, 1.06610418e-08, 1.15380256e-08, 1.07891758e-08,\n",
      "       1.15284564e-08, 1.12358531e-08, 1.13418945e-08, 1.01989075e-08,\n",
      "       1.08059801e-08, 1.09358576e-08, 1.07886828e-08, 1.06167111e-08,\n",
      "       1.10334408e-08, 1.08431131e-08, 1.18010277e-08, 1.14634835e-08,\n",
      "       1.13380052e-08, 1.01395869e-08, 1.12998899e-08, 1.12744605e-08,\n",
      "       1.06328235e-08, 1.07509637e-08, 1.11988472e-08, 1.07277014e-08,\n",
      "       1.09700586e-08, 1.11071445e-08, 1.15634977e-08, 1.15430039e-08,\n",
      "       1.12183978e-08, 1.08264429e-08, 1.13180887e-08, 1.17606573e-08,\n",
      "       1.13238361e-08, 1.13181740e-08, 1.17338637e-08, 1.16528902e-08,\n",
      "       1.05018128e-08, 1.14404939e-08, 1.12520429e-08, 1.06637099e-08,\n",
      "       1.15028502e-08, 9.17305254e-09, 1.12045244e-08, 1.06606510e-08,\n",
      "       1.14671703e-08, 1.12808101e-08, 1.12882583e-08, 1.16862289e-08,\n",
      "       1.11590985e-08, 1.03931228e-08, 1.09591181e-08, 1.01275734e-08,\n",
      "       1.13903313e-08, 1.10469935e-08, 1.12302585e-08, 1.07034444e-08,\n",
      "       1.15389565e-08, 1.09674092e-08, 9.92777327e-09, 1.08254099e-08,\n",
      "       1.07024203e-08, 1.07635634e-08, 1.03016404e-08, 1.03019682e-08,\n",
      "       1.13092593e-08, 1.12732570e-08, 1.12099148e-08, 1.14982388e-08,\n",
      "       1.04983311e-08, 1.10957741e-08, 1.13826530e-08, 1.08192921e-08,\n",
      "       1.11477503e-08, 1.07153975e-08, 1.16305516e-08, 1.11903669e-08,\n",
      "       1.13797780e-08, 1.05260582e-08, 1.11627987e-08, 1.11430545e-08,\n",
      "       1.01502398e-08, 1.08518527e-08, 1.12036940e-08, 1.14795000e-08,\n",
      "       1.14030847e-08, 1.01393907e-08, 1.14362679e-08, 1.07678311e-08,\n",
      "       1.07734248e-08, 9.42914280e-09, 1.10819709e-08, 1.09719656e-08,\n",
      "       1.09449179e-08, 1.07975966e-08, 1.13415171e-08, 9.12556164e-09,\n",
      "       1.16121388e-08, 1.16701599e-08, 1.13274785e-08, 1.12904619e-08,\n",
      "       1.04828324e-08, 1.13624790e-08, 1.09967733e-08, 1.09196376e-08,\n",
      "       1.11645502e-08, 1.14134213e-08, 1.20151924e-08, 1.07183871e-08,\n",
      "       1.10690532e-08, 1.10745182e-08, 1.13251497e-08, 1.14014451e-08,\n",
      "       1.12842597e-08, 1.07827640e-08, 1.11726628e-08, 1.06608402e-08,\n",
      "       1.03931059e-08, 1.09239746e-08, 1.10315810e-08, 1.10868132e-08,\n",
      "       1.12314202e-08, 1.02415667e-08, 1.10468914e-08, 1.06324292e-08,\n",
      "       1.12896723e-08, 1.13170957e-08, 1.18684582e-08, 1.16395125e-08,\n",
      "       1.08687788e-08, 1.08479155e-08, 9.94915528e-09, 1.09233520e-08,\n",
      "       1.14681136e-08, 1.07751985e-08, 1.14719372e-08, 1.08888836e-08,\n",
      "       1.05276579e-08, 1.06504734e-08, 1.17471606e-08, 1.09495479e-08,\n",
      "       1.09684475e-08, 1.10816538e-08, 1.13296732e-08, 1.05128484e-08,\n",
      "       1.07847402e-08, 1.10652003e-08, 1.09358380e-08, 1.13576570e-08,\n",
      "       1.11137863e-08, 1.09857261e-08, 1.09713545e-08, 1.05372528e-08,\n",
      "       1.09230962e-08, 1.12748682e-08, 1.05601297e-08, 1.07391420e-08,\n",
      "       1.06959988e-08, 1.14460086e-08, 1.08930562e-08, 1.03637205e-08,\n",
      "       1.13869794e-08, 1.04575166e-08, 1.16134791e-08, 1.13648184e-08,\n",
      "       1.12043521e-08, 1.07996572e-08, 1.09719158e-08, 1.11595035e-08,\n",
      "       1.08013731e-08, 1.08082236e-08, 1.07884395e-08, 1.14134835e-08,\n",
      "       1.13235012e-08, 1.13672352e-08, 1.11874385e-08, 1.11446452e-08,\n",
      "       1.10728422e-08, 1.11708891e-08, 1.04502664e-08, 1.10386882e-08,\n",
      "       1.01980575e-08, 1.09900622e-08, 1.10857012e-08, 1.11336611e-08,\n",
      "       1.08791403e-08, 1.17720829e-08, 1.11212097e-08, 9.91792870e-09,\n",
      "       1.13851515e-08, 1.01210897e-08, 1.11686944e-08, 1.00113695e-08,\n",
      "       1.14959766e-08, 1.04324585e-08, 1.11914149e-08, 1.18153816e-08,\n",
      "       1.11008163e-08, 1.10694467e-08, 1.10030784e-08, 1.11473621e-08,\n",
      "       1.01202291e-08, 1.09833262e-08, 9.18318843e-09, 1.07189138e-08,\n",
      "       1.06702291e-08, 1.11519523e-08, 9.75001324e-09, 1.01740616e-08,\n",
      "       1.12627578e-08, 1.08893143e-08, 1.02792548e-08, 1.01386304e-08,\n",
      "       1.14414194e-08, 1.06290843e-08, 1.14834027e-08, 1.13455272e-08,\n",
      "       1.05200924e-08, 1.09206875e-08, 1.06153450e-08, 1.14998961e-08,\n",
      "       1.05448059e-08, 1.11160015e-08, 1.03332569e-08, 1.14192638e-08,\n",
      "       9.46589207e-09, 1.16698669e-08, 1.12773035e-08, 1.04939630e-08,\n",
      "       1.09724922e-08, 1.13319780e-08, 1.10907541e-08, 1.08535705e-08,\n",
      "       1.10424025e-08, 1.15531007e-08, 1.03562172e-08, 1.12065415e-08,\n",
      "       1.14182779e-08, 1.13735528e-08, 1.03304627e-08, 1.15386678e-08,\n",
      "       1.13879848e-08, 1.09352696e-08, 1.15243370e-08, 1.10505027e-08,\n",
      "       1.11436362e-08, 1.13157057e-08, 1.13624701e-08, 1.16304477e-08,\n",
      "       1.08503437e-08, 1.07052882e-08, 1.03890399e-08, 1.15052234e-08,\n",
      "       1.04897655e-08, 1.06529665e-08, 1.12675940e-08, 1.02621822e-08,\n",
      "       1.08045741e-08, 1.14363772e-08, 1.13911138e-08, 1.16820118e-08,\n",
      "       1.03893667e-08, 1.15169030e-08, 1.14528573e-08, 1.15217826e-08,\n",
      "       9.63381463e-09, 1.06247171e-08, 1.03498250e-08, 1.13978977e-08,\n",
      "       1.13058114e-08, 1.06186198e-08, 1.14502603e-08, 1.13941532e-08,\n",
      "       1.11188081e-08, 1.13931851e-08, 1.07740465e-08, 1.12472183e-08,\n",
      "       1.05118474e-08, 1.10929674e-08, 1.10200915e-08, 1.07113376e-08,\n",
      "       1.10097487e-08, 1.16574324e-08, 1.05825375e-08, 1.13127347e-08,\n",
      "       1.14467698e-08, 1.04774598e-08, 9.62755209e-09, 1.00223758e-08,\n",
      "       1.07462901e-08, 1.09475575e-08, 1.14883250e-08, 1.12877574e-08,\n",
      "       1.01572519e-08, 1.11866987e-08, 1.10167777e-08, 1.13563337e-08,\n",
      "       1.09611626e-08, 1.13348868e-08, 1.09061498e-08, 1.12799752e-08,\n",
      "       1.07956382e-08, 1.10195089e-08, 1.16319541e-08, 1.12177121e-08,\n",
      "       1.02986490e-08, 1.11690950e-08, 1.10972165e-08, 1.12380167e-08,\n",
      "       1.08573648e-08, 1.06938689e-08, 1.10595497e-08, 1.09205880e-08,\n",
      "       1.13020544e-08, 1.13141034e-08, 1.06478169e-08, 1.13386713e-08,\n",
      "       1.14583347e-08, 1.08057714e-08, 1.08609628e-08, 1.08615765e-08,\n",
      "       1.12260050e-08, 1.01653690e-08, 1.13559349e-08, 1.15639578e-08,\n",
      "       1.09057945e-08, 1.11284688e-08, 1.14006795e-08, 1.10007345e-08,\n",
      "       1.03701012e-08, 1.10373941e-08, 1.08785603e-08, 1.04200719e-08,\n",
      "       1.11499157e-08, 1.14289866e-08, 1.06922267e-08, 1.10955964e-08,\n",
      "       1.09238352e-08, 1.02342428e-08, 1.14773577e-08, 1.12577094e-08,\n",
      "       1.13902443e-08, 1.12900826e-08, 1.08464580e-08, 1.09427685e-08,\n",
      "       1.03896554e-08, 1.06141380e-08, 1.17038272e-08, 1.10778480e-08,\n",
      "       1.15586767e-08, 1.15997967e-08, 1.12019816e-08, 1.03149800e-08,\n",
      "       1.01402984e-08, 1.08863585e-08, 1.16882601e-08, 1.09293730e-08,\n",
      "       1.10010712e-08, 1.14642207e-08, 1.09883329e-08, 1.13655911e-08,\n",
      "       1.16536567e-08, 1.12975238e-08, 1.12539418e-08, 9.86461579e-09,\n",
      "       1.08390150e-08, 1.01917825e-08, 1.11284617e-08, 1.05864100e-08,\n",
      "       1.15327756e-08, 1.11096057e-08, 1.08408411e-08, 1.04482387e-08,\n",
      "       1.13888987e-08, 1.10002674e-08, 1.14313892e-08, 1.06531699e-08,\n",
      "       1.05737312e-08, 1.10784821e-08, 1.11899530e-08, 1.15826690e-08,\n",
      "       1.15233778e-08, 1.10574527e-08, 1.06100257e-08, 1.12873506e-08,\n",
      "       1.13362342e-08, 1.08947482e-08, 1.09137774e-08, 1.10896528e-08,\n",
      "       1.15540457e-08, 1.13171117e-08, 1.13859651e-08, 1.05286757e-08,\n",
      "       1.10905640e-08, 1.05199254e-08, 1.01519380e-08, 1.15682095e-08,\n",
      "       1.12171330e-08, 1.01989617e-08, 1.11339347e-08, 1.15193064e-08,\n",
      "       1.13446577e-08, 1.14405836e-08, 1.05966347e-08, 1.13797922e-08,\n",
      "       1.04835998e-08, 1.02497983e-08, 9.66693747e-09, 1.11691820e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D\n",
      "index : 136\n",
      "shape : [168   1   1 672]\n",
      "shape_signature : [168   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0006652 , 0.00066327, 0.00066586, 0.00066568, 0.00066712,\n",
      "       0.00066538, 0.00066681, 0.0006661 , 0.00066952, 0.00066721,\n",
      "       0.0006645 , 0.00066715, 0.0006625 , 0.00066723, 0.0006654 ,\n",
      "       0.00066675, 0.00066961, 0.00066759, 0.00066392, 0.00066652,\n",
      "       0.00066559, 0.00066944, 0.0006653 , 0.00066539, 0.00066728,\n",
      "       0.00066336, 0.00066768, 0.00066917, 0.0006646 , 0.00066584,\n",
      "       0.00066442, 0.00066487, 0.00066835, 0.00066601, 0.0006661 ,\n",
      "       0.00066157, 0.00066592, 0.00066579, 0.00066963, 0.00066608,\n",
      "       0.00066777, 0.00066495, 0.00066601, 0.00066633, 0.00066496,\n",
      "       0.00066714, 0.00066418, 0.00067016, 0.0006689 , 0.00066569,\n",
      "       0.00066788, 0.00066733, 0.00067166, 0.0006684 , 0.0006671 ,\n",
      "       0.000669  , 0.0006681 , 0.00066635, 0.00066905, 0.00066766,\n",
      "       0.00066635, 0.00066705, 0.00066463, 0.00066359, 0.00066701,\n",
      "       0.00066946, 0.00066485, 0.00066929, 0.00066847, 0.00066536,\n",
      "       0.00066716, 0.00066844, 0.00066526, 0.0006664 , 0.00066828,\n",
      "       0.00066945, 0.00066892, 0.00067067, 0.0006668 , 0.00066443,\n",
      "       0.00067016, 0.00066795, 0.00066625, 0.00066646, 0.0006664 ,\n",
      "       0.00066462, 0.00067073, 0.00066452, 0.00066399, 0.00066511,\n",
      "       0.00066668, 0.00066887, 0.00066506, 0.00066313, 0.0006651 ,\n",
      "       0.00066671, 0.00066703, 0.00067268, 0.00066373, 0.00066729,\n",
      "       0.00066634, 0.00066383, 0.00066422, 0.00066299, 0.0006649 ,\n",
      "       0.00066727, 0.00067006, 0.00066399, 0.00066794, 0.00066918,\n",
      "       0.00066514, 0.00066491, 0.00066716, 0.00066462, 0.00066845,\n",
      "       0.00066701, 0.00066248, 0.00066818, 0.00066907, 0.00066782,\n",
      "       0.00066591, 0.00067084, 0.00066356, 0.0006635 , 0.00066614,\n",
      "       0.00066537, 0.00066592, 0.00066637, 0.00066804, 0.00066621,\n",
      "       0.0006679 , 0.00066685, 0.00066474, 0.00066553, 0.00066573,\n",
      "       0.00066773, 0.00066671, 0.00066541, 0.00066659, 0.00066516,\n",
      "       0.00066276, 0.00066345, 0.00066587, 0.00066569, 0.00066793,\n",
      "       0.00066631, 0.00066752, 0.0006667 , 0.00066332, 0.00066574,\n",
      "       0.00066546, 0.00066595, 0.00066942, 0.00066589, 0.00066276,\n",
      "       0.00066303, 0.00066614, 0.00066666, 0.00066935, 0.00066615,\n",
      "       0.00066587, 0.00067106, 0.00066442, 0.00066732, 0.00066575,\n",
      "       0.00066452, 0.00066526, 0.00066334], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/BiasAdd/ReadVariableOp/resource\n",
      "index : 137\n",
      "shape : [168]\n",
      "shape_signature : [168]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.7503285e-08, 2.7423631e-08, 2.7530533e-08, 2.7523207e-08,\n",
      "       2.7582722e-08, 2.7510868e-08, 2.7569726e-08, 2.7540310e-08,\n",
      "       2.7681800e-08, 2.7586442e-08, 2.7474476e-08, 2.7583704e-08,\n",
      "       2.7391476e-08, 2.7587072e-08, 2.7511609e-08, 2.7567147e-08,\n",
      "       2.7685441e-08, 2.7602079e-08, 2.7450492e-08, 2.7557983e-08,\n",
      "       2.7519299e-08, 2.7678450e-08, 2.7507532e-08, 2.7511300e-08,\n",
      "       2.7589317e-08, 2.7427374e-08, 2.7605672e-08, 2.7667264e-08,\n",
      "       2.7478327e-08, 2.7529834e-08, 2.7471092e-08, 2.7489682e-08,\n",
      "       2.7633339e-08, 2.7536556e-08, 2.7540285e-08, 2.7353254e-08,\n",
      "       2.7533098e-08, 2.7527488e-08, 2.7686372e-08, 2.7539603e-08,\n",
      "       2.7609586e-08, 2.7492774e-08, 2.7536531e-08, 2.7549980e-08,\n",
      "       2.7493156e-08, 2.7583555e-08, 2.7460874e-08, 2.7708188e-08,\n",
      "       2.7656313e-08, 2.7523450e-08, 2.7614165e-08, 2.7591295e-08,\n",
      "       2.7770314e-08, 2.7635569e-08, 2.7581599e-08, 2.7660258e-08,\n",
      "       2.7623077e-08, 2.7550762e-08, 2.7662477e-08, 2.7604870e-08,\n",
      "       2.7550659e-08, 2.7579777e-08, 2.7479720e-08, 2.7436878e-08,\n",
      "       2.7578061e-08, 2.7679393e-08, 2.7488774e-08, 2.7672163e-08,\n",
      "       2.7638347e-08, 2.7509943e-08, 2.7584329e-08, 2.7637091e-08,\n",
      "       2.7505797e-08, 2.7552870e-08, 2.7630531e-08, 2.7678928e-08,\n",
      "       2.7656972e-08, 2.7729417e-08, 2.7569477e-08, 2.7471597e-08,\n",
      "       2.7708294e-08, 2.7616883e-08, 2.7546736e-08, 2.7555384e-08,\n",
      "       2.7552854e-08, 2.7479249e-08, 2.7731982e-08, 2.7475320e-08,\n",
      "       2.7453330e-08, 2.7499468e-08, 2.7564617e-08, 2.7654883e-08,\n",
      "       2.7497359e-08, 2.7417675e-08, 2.7498951e-08, 2.7565797e-08,\n",
      "       2.7578801e-08, 2.7812545e-08, 2.7442576e-08, 2.7589634e-08,\n",
      "       2.7550577e-08, 2.7446715e-08, 2.7462823e-08, 2.7412003e-08,\n",
      "       2.7490978e-08, 2.7588683e-08, 2.7704017e-08, 2.7453117e-08,\n",
      "       2.7616567e-08, 2.7667719e-08, 2.7500766e-08, 2.7491403e-08,\n",
      "       2.7584372e-08, 2.7479114e-08, 2.7637773e-08, 2.7578183e-08,\n",
      "       2.7390719e-08, 2.7626287e-08, 2.7663459e-08, 2.7611605e-08,\n",
      "       2.7532487e-08, 2.7736499e-08, 2.7435542e-08, 2.7433114e-08,\n",
      "       2.7541923e-08, 2.7510085e-08, 2.7533165e-08, 2.7551494e-08,\n",
      "       2.7620661e-08, 2.7545211e-08, 2.7614774e-08, 2.7571319e-08,\n",
      "       2.7484113e-08, 2.7517075e-08, 2.7524958e-08, 2.7607978e-08,\n",
      "       2.7565871e-08, 2.7511780e-08, 2.7560748e-08, 2.7501665e-08,\n",
      "       2.7402447e-08, 2.7431033e-08, 2.7530922e-08, 2.7523404e-08,\n",
      "       2.7616283e-08, 2.7549282e-08, 2.7599302e-08, 2.7565132e-08,\n",
      "       2.7425704e-08, 2.7525658e-08, 2.7514004e-08, 2.7534204e-08,\n",
      "       2.7677922e-08, 2.7531732e-08, 2.7402322e-08, 2.7413636e-08,\n",
      "       2.7542002e-08, 2.7563798e-08, 2.7674986e-08, 2.7542717e-08,\n",
      "       2.7531078e-08, 2.7745690e-08, 2.7470874e-08, 2.7590803e-08,\n",
      "       2.7525815e-08, 2.7475194e-08, 2.7505566e-08, 2.7426458e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D\n",
      "index : 138\n",
      "shape : [672   1   1 168]\n",
      "shape_signature : [672   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0006587 , 0.00066517, 0.00066786, 0.00065849, 0.00065865,\n",
      "       0.00065964, 0.00066369, 0.00066095, 0.0006664 , 0.00065607,\n",
      "       0.00066045, 0.00066578, 0.00066767, 0.00065032, 0.0006628 ,\n",
      "       0.00065118, 0.00066231, 0.00066481, 0.00066635, 0.0006615 ,\n",
      "       0.00065967, 0.00066241, 0.00066586, 0.00066546, 0.00066732,\n",
      "       0.00065483, 0.00066611, 0.00066387, 0.00066109, 0.00066539,\n",
      "       0.00066367, 0.000663  , 0.0006526 , 0.00064782, 0.00065892,\n",
      "       0.00066444, 0.00066132, 0.00065976, 0.00066695, 0.00066539,\n",
      "       0.0006654 , 0.00065341, 0.00066309, 0.0006641 , 0.00066611,\n",
      "       0.00066525, 0.00066741, 0.00065861, 0.000659  , 0.00065969,\n",
      "       0.00066604, 0.00066469, 0.00066191, 0.0006591 , 0.00066867,\n",
      "       0.00065834, 0.00066502, 0.00066666, 0.00064946, 0.00064599,\n",
      "       0.00066515, 0.00065469, 0.00066255, 0.00066049, 0.00066354,\n",
      "       0.00066097, 0.0006457 , 0.0006639 , 0.00066434, 0.00066368,\n",
      "       0.00066338, 0.00065943, 0.00066084, 0.00066443, 0.00066739,\n",
      "       0.00066851, 0.00066284, 0.00066318, 0.00066314, 0.0006594 ,\n",
      "       0.00066229, 0.0006645 , 0.00066409, 0.0006601 , 0.00066193,\n",
      "       0.0006649 , 0.00066301, 0.00065598, 0.00066034, 0.00066124,\n",
      "       0.00066232, 0.00065818, 0.00065666, 0.00065981, 0.00065941,\n",
      "       0.00066081, 0.00065416, 0.00065845, 0.00066347, 0.00065854,\n",
      "       0.0006624 , 0.000657  , 0.00065556, 0.00065229, 0.00066114,\n",
      "       0.0006609 , 0.00066388, 0.0006672 , 0.00066167, 0.00065036,\n",
      "       0.00065877, 0.00066861, 0.00066183, 0.00066454, 0.00065816,\n",
      "       0.00066562, 0.0006635 , 0.00066035, 0.00066348, 0.00066029,\n",
      "       0.00066641, 0.00066061, 0.00066341, 0.00066379, 0.0006629 ,\n",
      "       0.00066441, 0.0006597 , 0.00066254, 0.00066394, 0.00066223,\n",
      "       0.00066671, 0.00066345, 0.00066432, 0.00065626, 0.00066375,\n",
      "       0.00066534, 0.00065863, 0.00065125, 0.00065501, 0.00066362,\n",
      "       0.00065695, 0.00066217, 0.00066203, 0.00065671, 0.00065905,\n",
      "       0.00066593, 0.00064981, 0.0006692 , 0.00066397, 0.00066606,\n",
      "       0.00066677, 0.00066373, 0.00066229, 0.00066275, 0.0006693 ,\n",
      "       0.00066249, 0.00065229, 0.00066215, 0.00066791, 0.00066009,\n",
      "       0.00066872, 0.00065952, 0.00066138, 0.00065926, 0.00065498,\n",
      "       0.00066278, 0.00066351, 0.00066876, 0.00067082, 0.00065798,\n",
      "       0.0006568 , 0.00066299, 0.00066116, 0.00066309, 0.00066077,\n",
      "       0.00065022, 0.00065965, 0.00066153, 0.0006652 , 0.00066123,\n",
      "       0.00066778, 0.00066691, 0.00066494, 0.00065425, 0.00066398,\n",
      "       0.00065506, 0.0006589 , 0.00066832, 0.00066306, 0.00065549,\n",
      "       0.00066015, 0.00064706, 0.00066657, 0.00066582, 0.00066034,\n",
      "       0.00066075, 0.00065696, 0.00066656, 0.00066077, 0.00065949,\n",
      "       0.00066604, 0.00066639, 0.00066279, 0.00066629, 0.00066448,\n",
      "       0.00066215, 0.00066629, 0.00065677, 0.00066533, 0.00065799,\n",
      "       0.00066211, 0.00066292, 0.00066438, 0.00065944, 0.00066181,\n",
      "       0.00066184, 0.00066422, 0.00066375, 0.0006623 , 0.00066305,\n",
      "       0.00066888, 0.00066442, 0.00066677, 0.0006683 , 0.00065991,\n",
      "       0.00065844, 0.00066714, 0.00066301, 0.0006636 , 0.00066005,\n",
      "       0.00066896, 0.00064448, 0.00066654, 0.0006601 , 0.00066793,\n",
      "       0.0006667 , 0.00065163, 0.00066498, 0.00066527, 0.00066581,\n",
      "       0.00066443, 0.00066334, 0.00066275, 0.00066133, 0.00066361,\n",
      "       0.00066625, 0.00066554, 0.00066555, 0.00066518, 0.00066403,\n",
      "       0.00065851, 0.00066342, 0.0006596 , 0.00066792, 0.00064942,\n",
      "       0.00066199, 0.0006595 , 0.00066286, 0.00066405, 0.00066482,\n",
      "       0.00066727, 0.0006631 , 0.00066421, 0.00066905, 0.00066357,\n",
      "       0.00066142, 0.00066563, 0.00066319, 0.00066189, 0.00066146,\n",
      "       0.00065796, 0.00066267, 0.00066223, 0.0006654 , 0.00066526,\n",
      "       0.00066603, 0.00066226, 0.00065053, 0.00065887, 0.00066432,\n",
      "       0.00066216, 0.00066463, 0.00066115, 0.00066228, 0.00066286,\n",
      "       0.00066335, 0.00066579, 0.00066856, 0.00066424, 0.00066489,\n",
      "       0.00066776, 0.00065909, 0.00066193, 0.00065721, 0.00066078,\n",
      "       0.0006704 , 0.00066542, 0.00066634, 0.00066614, 0.00066313,\n",
      "       0.00066165, 0.000662  , 0.00065794, 0.00066518, 0.00066499,\n",
      "       0.00066609, 0.00066173, 0.00066019, 0.00065377, 0.00066348,\n",
      "       0.00066301, 0.00064834, 0.00066131, 0.00066399, 0.00066507,\n",
      "       0.00066458, 0.00066644, 0.00066213, 0.00066891, 0.00066888,\n",
      "       0.00066239, 0.00066926, 0.00066085, 0.00066229, 0.00065829,\n",
      "       0.0006639 , 0.00066897, 0.00065909, 0.00066205, 0.00066772,\n",
      "       0.00066462, 0.0006652 , 0.00066523, 0.00066655, 0.00066149,\n",
      "       0.0006623 , 0.00065972, 0.00066204, 0.00066841, 0.00066072,\n",
      "       0.00066567, 0.00065566, 0.00066995, 0.00065888, 0.00065556,\n",
      "       0.00066399, 0.00066578, 0.00066183, 0.0006653 , 0.00066558,\n",
      "       0.00066561, 0.00066365, 0.00066586, 0.00066632, 0.00065819,\n",
      "       0.00066437, 0.00066168, 0.00065761, 0.00066488, 0.00066434,\n",
      "       0.00066601, 0.00066353, 0.00066099, 0.00066746, 0.00066442,\n",
      "       0.00066444, 0.00065536, 0.00066188, 0.00066412, 0.00066279,\n",
      "       0.00066557, 0.00066552, 0.00066749, 0.00066632, 0.00066331,\n",
      "       0.00066246, 0.00066119, 0.00066369, 0.00065687, 0.00066697,\n",
      "       0.00066283, 0.00066449, 0.00064799, 0.00066054, 0.00066321,\n",
      "       0.00065866, 0.00066897, 0.00065808, 0.00066225, 0.00066187,\n",
      "       0.00066388, 0.00066774, 0.00066467, 0.00066184, 0.00066448,\n",
      "       0.00066324, 0.00066551, 0.00066464, 0.00067005, 0.0006647 ,\n",
      "       0.00065606, 0.00066077, 0.00066083, 0.00066088, 0.00066119,\n",
      "       0.00066571, 0.00066345, 0.00065701, 0.00066219, 0.00066522,\n",
      "       0.00066896, 0.00066398, 0.00066016, 0.0006512 , 0.00066377,\n",
      "       0.00066189, 0.00065974, 0.00066167, 0.00066997, 0.0006608 ,\n",
      "       0.00066601, 0.00066403, 0.00065207, 0.00066591, 0.0006639 ,\n",
      "       0.00066632, 0.00066218, 0.00066269, 0.00066681, 0.0006634 ,\n",
      "       0.00066169, 0.00066279, 0.00065378, 0.00065626, 0.00065949,\n",
      "       0.00066656, 0.00066161, 0.00067   , 0.00066755, 0.00066486,\n",
      "       0.00065822, 0.00066125, 0.00066301, 0.0006627 , 0.00066376,\n",
      "       0.00066201, 0.0006654 , 0.00065843, 0.00066828, 0.00066818,\n",
      "       0.00066139, 0.00066731, 0.00066006, 0.00066638, 0.00066722,\n",
      "       0.00066487, 0.00066434, 0.00066597, 0.00066053, 0.00066483,\n",
      "       0.00066199, 0.00065969, 0.00066423, 0.00066278, 0.00066293,\n",
      "       0.00065608, 0.00066534, 0.00066022, 0.00066221, 0.00066681,\n",
      "       0.00066273, 0.00066454, 0.00066407, 0.00066301, 0.00066886,\n",
      "       0.0006645 , 0.00066692, 0.00066098, 0.00065976, 0.00065736,\n",
      "       0.00066301, 0.0006683 , 0.00066216, 0.00066371, 0.00066448,\n",
      "       0.00065761, 0.00066598, 0.00067077, 0.00066322, 0.00066053,\n",
      "       0.00065958, 0.00066374, 0.00066693, 0.00065516, 0.00066217,\n",
      "       0.00066896, 0.00066728, 0.00066766, 0.00065969, 0.00066324,\n",
      "       0.00066722, 0.00065383, 0.00065356, 0.00066682, 0.00065871,\n",
      "       0.00065988, 0.00066377, 0.000666  , 0.00066437, 0.0006652 ,\n",
      "       0.00066604, 0.00065977, 0.00066341, 0.00065694, 0.0006549 ,\n",
      "       0.00065945, 0.00066372, 0.00065113, 0.00066101, 0.00066888,\n",
      "       0.00066141, 0.0006594 , 0.00066075, 0.00066612, 0.00065893,\n",
      "       0.00066674, 0.0006643 , 0.00066214, 0.00066007, 0.00066075,\n",
      "       0.00066515, 0.00066076, 0.00066284, 0.00066723, 0.00065531,\n",
      "       0.00066974, 0.00066878, 0.0006685 , 0.00066416, 0.0006648 ,\n",
      "       0.00066811, 0.0006658 , 0.00065979, 0.00066859, 0.00066515,\n",
      "       0.00066552, 0.00066752, 0.00066547, 0.00065952, 0.00066768,\n",
      "       0.00066446, 0.00066022, 0.0006579 , 0.0006621 , 0.00066707,\n",
      "       0.00065504, 0.00066638, 0.00066694, 0.00065474, 0.00065082,\n",
      "       0.00066174, 0.00066425, 0.00066729, 0.00065691, 0.00067021,\n",
      "       0.00066408, 0.0006618 , 0.00066431, 0.00066357, 0.00065956,\n",
      "       0.00066331, 0.00065622, 0.00066309, 0.00066072, 0.00066219,\n",
      "       0.00066495, 0.00065846, 0.00065832, 0.00066179, 0.00066497,\n",
      "       0.00065566, 0.00066629, 0.00066554, 0.00064098, 0.0006498 ,\n",
      "       0.00066628, 0.00065442, 0.00066747, 0.00065142, 0.00066315,\n",
      "       0.000666  , 0.00065301, 0.00065497, 0.00066099, 0.00065576,\n",
      "       0.00066539, 0.00066167, 0.000662  , 0.00066022, 0.00066557,\n",
      "       0.00066774, 0.00066303, 0.00065841, 0.00066073, 0.00065813,\n",
      "       0.00066031, 0.00066843, 0.00066319, 0.00065988, 0.00065931,\n",
      "       0.00066029, 0.00066459, 0.00066776, 0.00066021, 0.0006631 ,\n",
      "       0.00065674, 0.00066519, 0.00066183, 0.00066628, 0.00067057,\n",
      "       0.00066265, 0.00066349, 0.00066589, 0.00066141, 0.00065845,\n",
      "       0.00066744, 0.00065655, 0.00065946, 0.00066427, 0.00066237,\n",
      "       0.00066703, 0.00065836, 0.00065791, 0.00065284, 0.00066267,\n",
      "       0.00067133, 0.00066113, 0.00065905, 0.00066529, 0.00065607,\n",
      "       0.00067058, 0.00065953, 0.00065958, 0.00066195, 0.00065755,\n",
      "       0.00066719, 0.00066765, 0.00065956, 0.00066717, 0.00066214,\n",
      "       0.00066239, 0.00066307, 0.00066669, 0.00066285, 0.00066908,\n",
      "       0.00066904, 0.0006641 , 0.00065895, 0.00066606, 0.00066553,\n",
      "       0.00065897, 0.00066722, 0.0006588 , 0.00066484, 0.0006651 ,\n",
      "       0.00066559, 0.00066257, 0.00066549, 0.0006622 , 0.00066546,\n",
      "       0.00066278, 0.00065181], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/BiasAdd/ReadVariableOp/resource\n",
      "index : 139\n",
      "shape : [672]\n",
      "shape_signature : [672]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.44295234e-08, 1.45711301e-08, 1.46300181e-08, 1.44249119e-08,\n",
      "       1.44283288e-08, 1.44499559e-08, 1.45387746e-08, 1.44787560e-08,\n",
      "       1.45980898e-08, 1.43718690e-08, 1.44677665e-08, 1.45844536e-08,\n",
      "       1.46258436e-08, 1.42459404e-08, 1.45191450e-08, 1.42647831e-08,\n",
      "       1.45084433e-08, 1.45633514e-08, 1.45970631e-08, 1.44907562e-08,\n",
      "       1.44507766e-08, 1.45107117e-08, 1.45861945e-08, 1.45776120e-08,\n",
      "       1.46181938e-08, 1.43447112e-08, 1.45916657e-08, 1.45427981e-08,\n",
      "       1.44818930e-08, 1.45759564e-08, 1.45383936e-08, 1.45236445e-08,\n",
      "       1.42958072e-08, 1.41910785e-08, 1.44342636e-08, 1.45552876e-08,\n",
      "       1.44867940e-08, 1.44526400e-08, 1.46101327e-08, 1.45760826e-08,\n",
      "       1.45762487e-08, 1.43134580e-08, 1.45256820e-08, 1.45478296e-08,\n",
      "       1.45918477e-08, 1.45729215e-08, 1.46203174e-08, 1.44274512e-08,\n",
      "       1.44360817e-08, 1.44512171e-08, 1.45902606e-08, 1.45606194e-08,\n",
      "       1.44997250e-08, 1.44382648e-08, 1.46477621e-08, 1.44214463e-08,\n",
      "       1.45677870e-08, 1.46038541e-08, 1.42270640e-08, 1.41510421e-08,\n",
      "       1.45707926e-08, 1.43415395e-08, 1.45137413e-08, 1.44685899e-08,\n",
      "       1.45353960e-08, 1.44792303e-08, 1.41447440e-08, 1.45434109e-08,\n",
      "       1.45529055e-08, 1.45384345e-08, 1.45319081e-08, 1.44455310e-08,\n",
      "       1.44762113e-08, 1.45549510e-08, 1.46198609e-08, 1.46443790e-08,\n",
      "       1.45201255e-08, 1.45275454e-08, 1.45266883e-08, 1.44446695e-08,\n",
      "       1.45080259e-08, 1.45564893e-08, 1.45475338e-08, 1.44600776e-08,\n",
      "       1.45002934e-08, 1.45651651e-08, 1.45239580e-08, 1.43697854e-08,\n",
      "       1.44654457e-08, 1.44849750e-08, 1.45087071e-08, 1.44181103e-08,\n",
      "       1.43846535e-08, 1.44537413e-08, 1.44450798e-08, 1.44757468e-08,\n",
      "       1.43300243e-08, 1.44239118e-08, 1.45339305e-08, 1.44259316e-08,\n",
      "       1.45104844e-08, 1.43921275e-08, 1.43606114e-08, 1.42891023e-08,\n",
      "       1.44828380e-08, 1.44775489e-08, 1.45428656e-08, 1.46155816e-08,\n",
      "       1.44945691e-08, 1.42467202e-08, 1.44309986e-08, 1.46465240e-08,\n",
      "       1.44979984e-08, 1.45574628e-08, 1.44176413e-08, 1.45810599e-08,\n",
      "       1.45345833e-08, 1.44655949e-08, 1.45341490e-08, 1.44641854e-08,\n",
      "       1.45984185e-08, 1.44712029e-08, 1.45326275e-08, 1.45409631e-08,\n",
      "       1.45213592e-08, 1.45545807e-08, 1.44513761e-08, 1.45135131e-08,\n",
      "       1.45442298e-08, 1.45066705e-08, 1.46049306e-08, 1.45334669e-08,\n",
      "       1.45526275e-08, 1.43760115e-08, 1.45400012e-08, 1.45749874e-08,\n",
      "       1.44279753e-08, 1.42661687e-08, 1.43486218e-08, 1.45371342e-08,\n",
      "       1.43911443e-08, 1.45054537e-08, 1.45023149e-08, 1.43858809e-08,\n",
      "       1.44371146e-08, 1.45878660e-08, 1.42346730e-08, 1.46595518e-08,\n",
      "       1.45449626e-08, 1.45905910e-08, 1.46061163e-08, 1.45395402e-08,\n",
      "       1.45080863e-08, 1.45182586e-08, 1.46616514e-08, 1.45125503e-08,\n",
      "       1.42889931e-08, 1.45049679e-08, 1.46312438e-08, 1.44598182e-08,\n",
      "       1.46490082e-08, 1.44473065e-08, 1.44881955e-08, 1.44416141e-08,\n",
      "       1.43478784e-08, 1.45189079e-08, 1.45348231e-08, 1.46497179e-08,\n",
      "       1.46950274e-08, 1.44135912e-08, 1.43879211e-08, 1.45233683e-08,\n",
      "       1.44832386e-08, 1.45255212e-08, 1.44748888e-08, 1.42437013e-08,\n",
      "       1.44502588e-08, 1.44915084e-08, 1.45717198e-08, 1.44847636e-08,\n",
      "       1.46282888e-08, 1.46092098e-08, 1.45661767e-08, 1.43319125e-08,\n",
      "       1.45450052e-08, 1.43496246e-08, 1.44337635e-08, 1.46400909e-08,\n",
      "       1.45249972e-08, 1.43590508e-08, 1.44611825e-08, 1.41743817e-08,\n",
      "       1.46018495e-08, 1.45854342e-08, 1.44653400e-08, 1.44742938e-08,\n",
      "       1.43912962e-08, 1.46015449e-08, 1.44748213e-08, 1.44466963e-08,\n",
      "       1.45901486e-08, 1.45979300e-08, 1.45190349e-08, 1.45957015e-08,\n",
      "       1.45560346e-08, 1.45049484e-08, 1.45957699e-08, 1.43871342e-08,\n",
      "       1.45745922e-08, 1.44138799e-08, 1.45041703e-08, 1.45218841e-08,\n",
      "       1.45538595e-08, 1.44455932e-08, 1.44975498e-08, 1.44981884e-08,\n",
      "       1.45503067e-08, 1.45400323e-08, 1.45083439e-08, 1.45247716e-08,\n",
      "       1.46524268e-08, 1.45546597e-08, 1.46062078e-08, 1.46398067e-08,\n",
      "       1.44559031e-08, 1.44237440e-08, 1.46142973e-08, 1.45239021e-08,\n",
      "       1.45367025e-08, 1.44589594e-08, 1.46541748e-08, 1.41179006e-08,\n",
      "       1.46011141e-08, 1.44600687e-08, 1.46315839e-08, 1.46047201e-08,\n",
      "       1.42746543e-08, 1.45670107e-08, 1.45733221e-08, 1.45850922e-08,\n",
      "       1.45549865e-08, 1.45310795e-08, 1.45181627e-08, 1.44871288e-08,\n",
      "       1.45369654e-08, 1.45947325e-08, 1.45792809e-08, 1.45795500e-08,\n",
      "       1.45713894e-08, 1.45462318e-08, 1.44253818e-08, 1.45327581e-08,\n",
      "       1.44490580e-08, 1.46314489e-08, 1.42261882e-08, 1.45016035e-08,\n",
      "       1.44468970e-08, 1.45206611e-08, 1.45467380e-08, 1.45636125e-08,\n",
      "       1.46172443e-08, 1.45258516e-08, 1.45501566e-08, 1.46560808e-08,\n",
      "       1.45361918e-08, 1.44889523e-08, 1.45812749e-08, 1.45278412e-08,\n",
      "       1.44992995e-08, 1.44899337e-08, 1.44132422e-08, 1.45163765e-08,\n",
      "       1.45067238e-08, 1.45761199e-08, 1.45730619e-08, 1.45900474e-08,\n",
      "       1.45073438e-08, 1.42503955e-08, 1.44331089e-08, 1.45525174e-08,\n",
      "       1.45051740e-08, 1.45594505e-08, 1.44830237e-08, 1.45079326e-08,\n",
      "       1.45205794e-08, 1.45313770e-08, 1.45848142e-08, 1.46455257e-08,\n",
      "       1.45508183e-08, 1.45650976e-08, 1.46278403e-08, 1.44380659e-08,\n",
      "       1.45002108e-08, 1.43967274e-08, 1.44749830e-08, 1.46857015e-08,\n",
      "       1.45765950e-08, 1.45969086e-08, 1.45923220e-08, 1.45263925e-08,\n",
      "       1.44940646e-08, 1.45018371e-08, 1.44127892e-08, 1.45714303e-08,\n",
      "       1.45671493e-08, 1.45914072e-08, 1.44958117e-08, 1.44620955e-08,\n",
      "       1.43214560e-08, 1.45342103e-08, 1.45238550e-08, 1.42023939e-08,\n",
      "       1.44866901e-08, 1.45452361e-08, 1.45689754e-08, 1.45581778e-08,\n",
      "       1.45990846e-08, 1.45046304e-08, 1.46530219e-08, 1.46524304e-08,\n",
      "       1.45102943e-08, 1.46606904e-08, 1.44765657e-08, 1.45081636e-08,\n",
      "       1.44205634e-08, 1.45434242e-08, 1.46545087e-08, 1.44380108e-08,\n",
      "       1.45027741e-08, 1.46270587e-08, 1.45590988e-08, 1.45717758e-08,\n",
      "       1.45724641e-08, 1.46014827e-08, 1.44904604e-08, 1.45082693e-08,\n",
      "       1.44517678e-08, 1.45026835e-08, 1.46420884e-08, 1.44737697e-08,\n",
      "       1.45822261e-08, 1.43628807e-08, 1.46759698e-08, 1.44333958e-08,\n",
      "       1.43607632e-08, 1.45453649e-08, 1.45845274e-08, 1.44980277e-08,\n",
      "       1.45740158e-08, 1.45800776e-08, 1.45808787e-08, 1.45378172e-08,\n",
      "       1.45861865e-08, 1.45964574e-08, 1.44181840e-08, 1.45535521e-08,\n",
      "       1.44947450e-08, 1.44056029e-08, 1.45649031e-08, 1.45530468e-08,\n",
      "       1.45894736e-08, 1.45353267e-08, 1.44796193e-08, 1.46212376e-08,\n",
      "       1.45548018e-08, 1.45551828e-08, 1.43562513e-08, 1.44989993e-08,\n",
      "       1.45482089e-08, 1.45190260e-08, 1.45798609e-08, 1.45787373e-08,\n",
      "       1.46220893e-08, 1.45964565e-08, 1.45304782e-08, 1.45117580e-08,\n",
      "       1.44839456e-08, 1.45388013e-08, 1.43893431e-08, 1.46106149e-08,\n",
      "       1.45198538e-08, 1.45563224e-08, 1.41949075e-08, 1.44697907e-08,\n",
      "       1.45281893e-08, 1.44285517e-08, 1.46543941e-08, 1.44157539e-08,\n",
      "       1.45072701e-08, 1.44989549e-08, 1.45428514e-08, 1.46274601e-08,\n",
      "       1.45601540e-08, 1.44983217e-08, 1.45561190e-08, 1.45289309e-08,\n",
      "       1.45785375e-08, 1.45595687e-08, 1.46781218e-08, 1.45608752e-08,\n",
      "       1.43716896e-08, 1.44748515e-08, 1.44759973e-08, 1.44771111e-08,\n",
      "       1.44839767e-08, 1.45829961e-08, 1.45334651e-08, 1.43923495e-08,\n",
      "       1.45058561e-08, 1.45721764e-08, 1.46542689e-08, 1.45451748e-08,\n",
      "       1.44614418e-08, 1.42650451e-08, 1.45404444e-08, 1.44993617e-08,\n",
      "       1.44522856e-08, 1.44945496e-08, 1.46763055e-08, 1.44754049e-08,\n",
      "       1.45895953e-08, 1.45460923e-08, 1.42842813e-08, 1.45874122e-08,\n",
      "       1.45433869e-08, 1.45964609e-08, 1.45057095e-08, 1.45167931e-08,\n",
      "       1.46071235e-08, 1.45324961e-08, 1.44950318e-08, 1.45189878e-08,\n",
      "       1.43217616e-08, 1.43758943e-08, 1.44466661e-08, 1.46016985e-08,\n",
      "       1.44932830e-08, 1.46768713e-08, 1.46232626e-08, 1.45644607e-08,\n",
      "       1.44188830e-08, 1.44852130e-08, 1.45238932e-08, 1.45170844e-08,\n",
      "       1.45403645e-08, 1.45018975e-08, 1.45761883e-08, 1.44235690e-08,\n",
      "       1.46392907e-08, 1.46371804e-08, 1.44884282e-08, 1.46179762e-08,\n",
      "       1.44591228e-08, 1.45976333e-08, 1.46160293e-08, 1.45646224e-08,\n",
      "       1.45528993e-08, 1.45886121e-08, 1.44696122e-08, 1.45637031e-08,\n",
      "       1.45015546e-08, 1.44511878e-08, 1.45505998e-08, 1.45188030e-08,\n",
      "       1.45220982e-08, 1.43719872e-08, 1.45749892e-08, 1.44626382e-08,\n",
      "       1.45063073e-08, 1.46070009e-08, 1.45177017e-08, 1.45574699e-08,\n",
      "       1.45471510e-08, 1.45238230e-08, 1.46520156e-08, 1.45564094e-08,\n",
      "       1.46095207e-08, 1.44793368e-08, 1.44526497e-08, 1.44001158e-08,\n",
      "       1.45238488e-08, 1.46396841e-08, 1.45052850e-08, 1.45392152e-08,\n",
      "       1.45561643e-08, 1.44055710e-08, 1.45889150e-08, 1.46937955e-08,\n",
      "       1.45285597e-08, 1.44694239e-08, 1.44486743e-08, 1.45397872e-08,\n",
      "       1.46097845e-08, 1.43518166e-08, 1.45054475e-08, 1.46541286e-08,\n",
      "       1.46174761e-08, 1.46256189e-08, 1.44511745e-08, 1.45289389e-08,\n",
      "       1.46160879e-08, 1.43228114e-08, 1.43167442e-08, 1.46072336e-08,\n",
      "       1.44296788e-08, 1.44553480e-08, 1.45405954e-08, 1.45892720e-08,\n",
      "       1.45537165e-08, 1.45718531e-08, 1.45903014e-08, 1.44529659e-08,\n",
      "       1.45326533e-08, 1.43907837e-08, 1.43461820e-08, 1.44459325e-08,\n",
      "       1.45394852e-08, 1.42636569e-08, 1.44801309e-08, 1.46525423e-08,\n",
      "       1.44886956e-08, 1.44448320e-08, 1.44743453e-08, 1.45920342e-08,\n",
      "       1.44345185e-08, 1.46054635e-08, 1.45520866e-08, 1.45048240e-08,\n",
      "       1.44594816e-08, 1.44744146e-08, 1.45707890e-08, 1.44744927e-08,\n",
      "       1.45201877e-08, 1.46163481e-08, 1.43552557e-08, 1.46713512e-08,\n",
      "       1.46503414e-08, 1.46442147e-08, 1.45490890e-08, 1.45630361e-08,\n",
      "       1.46354706e-08, 1.45850061e-08, 1.44532910e-08, 1.46461145e-08,\n",
      "       1.45707082e-08, 1.45789327e-08, 1.46227119e-08, 1.45777816e-08,\n",
      "       1.44474646e-08, 1.46261057e-08, 1.45557060e-08, 1.44628070e-08,\n",
      "       1.44119259e-08, 1.45039900e-08, 1.46128345e-08, 1.43493430e-08,\n",
      "       1.45975836e-08, 1.46100385e-08, 1.43426284e-08, 1.42567496e-08,\n",
      "       1.44960168e-08, 1.45510270e-08, 1.46175472e-08, 1.43902223e-08,\n",
      "       1.46816488e-08, 1.45473171e-08, 1.44973162e-08, 1.45522741e-08,\n",
      "       1.45361279e-08, 1.44481938e-08, 1.45304693e-08, 1.43752175e-08,\n",
      "       1.45256402e-08, 1.44735806e-08, 1.45059333e-08, 1.45663499e-08,\n",
      "       1.44242209e-08, 1.44210226e-08, 1.44972212e-08, 1.45668331e-08,\n",
      "       1.43628256e-08, 1.45957086e-08, 1.45793084e-08, 1.40412517e-08,\n",
      "       1.42345593e-08, 1.45954013e-08, 1.43357317e-08, 1.46215351e-08,\n",
      "       1.42700385e-08, 1.45270107e-08, 1.45892560e-08, 1.43047094e-08,\n",
      "       1.43476395e-08, 1.44794994e-08, 1.43651224e-08, 1.45760994e-08,\n",
      "       1.44944652e-08, 1.45016763e-08, 1.44628300e-08, 1.45798920e-08,\n",
      "       1.46275108e-08, 1.45241890e-08, 1.44230796e-08, 1.44739758e-08,\n",
      "       1.44169485e-08, 1.44648000e-08, 1.46425148e-08, 1.45277603e-08,\n",
      "       1.44552486e-08, 1.44428913e-08, 1.44643026e-08, 1.45583829e-08,\n",
      "       1.46279637e-08, 1.44626044e-08, 1.45259147e-08, 1.43865710e-08,\n",
      "       1.45716834e-08, 1.44980001e-08, 1.45955328e-08, 1.46894843e-08,\n",
      "       1.45160604e-08, 1.45343950e-08, 1.45869823e-08, 1.44888750e-08,\n",
      "       1.44240344e-08, 1.46208095e-08, 1.43822332e-08, 1.44460195e-08,\n",
      "       1.45514250e-08, 1.45097498e-08, 1.46120254e-08, 1.44219969e-08,\n",
      "       1.44120769e-08, 1.43011514e-08, 1.45163295e-08, 1.47062140e-08,\n",
      "       1.44827625e-08, 1.44370249e-08, 1.45737546e-08, 1.43717909e-08,\n",
      "       1.46896264e-08, 1.44476786e-08, 1.44486307e-08, 1.45005465e-08,\n",
      "       1.44042165e-08, 1.46153303e-08, 1.46254111e-08, 1.44483021e-08,\n",
      "       1.46149848e-08, 1.45047210e-08, 1.45103467e-08, 1.45250727e-08,\n",
      "       1.46044634e-08, 1.45203689e-08, 1.46568064e-08, 1.46560462e-08,\n",
      "       1.45476493e-08, 1.44349910e-08, 1.45907180e-08, 1.45790384e-08,\n",
      "       1.44354066e-08, 1.46160239e-08, 1.44316950e-08, 1.45639669e-08,\n",
      "       1.45695394e-08, 1.45803432e-08, 1.45142289e-08, 1.45781840e-08,\n",
      "       1.45060008e-08, 1.45775685e-08, 1.45187098e-08, 1.42784931e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/conv2d_48/Conv2D\n",
      "index : 140\n",
      "shape : [192   1   1 672]\n",
      "shape_signature : [192   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00071189, 0.00071272, 0.00071233, 0.00071077, 0.00071238,\n",
      "       0.00071392, 0.00070848, 0.00071123, 0.00071609, 0.00070916,\n",
      "       0.00070811, 0.00071395, 0.00071274, 0.0007131 , 0.00071289,\n",
      "       0.00071844, 0.00071451, 0.00071617, 0.00071543, 0.00071836,\n",
      "       0.00070946, 0.00071322, 0.00070668, 0.00071091, 0.00071495,\n",
      "       0.00071481, 0.00070641, 0.0007145 , 0.00071522, 0.00071826,\n",
      "       0.0007155 , 0.00071088, 0.00071314, 0.00071202, 0.00071569,\n",
      "       0.00071455, 0.00071047, 0.00071272, 0.00071078, 0.00071505,\n",
      "       0.00071367, 0.00071439, 0.00071485, 0.00071038, 0.00070975,\n",
      "       0.00071518, 0.00071437, 0.00071433, 0.00071469, 0.00071318,\n",
      "       0.00071332, 0.00071207, 0.00071297, 0.00071435, 0.00071562,\n",
      "       0.00071192, 0.00071732, 0.00071131, 0.00071298, 0.00071159,\n",
      "       0.00071695, 0.00071667, 0.00071396, 0.000712  , 0.00071287,\n",
      "       0.00071184, 0.0007135 , 0.00071199, 0.00071593, 0.0007156 ,\n",
      "       0.0007138 , 0.00071245, 0.00070291, 0.00071704, 0.00070869,\n",
      "       0.00070655, 0.00071268, 0.00071025, 0.00071451, 0.00071188,\n",
      "       0.00071246, 0.00070922, 0.00071211, 0.00071525, 0.00071388,\n",
      "       0.0007091 , 0.00071354, 0.00071199, 0.00071188, 0.00071472,\n",
      "       0.00071971, 0.0007143 , 0.0007112 , 0.00071363, 0.00071396,\n",
      "       0.00071032, 0.00071207, 0.00071909, 0.00070884, 0.00071115,\n",
      "       0.0007144 , 0.0007123 , 0.00071425, 0.00071358, 0.00071114,\n",
      "       0.00071148, 0.00071537, 0.00070605, 0.00071308, 0.00071244,\n",
      "       0.00071239, 0.00071427, 0.00071537, 0.00071373, 0.00071392,\n",
      "       0.00071332, 0.00071194, 0.00071529, 0.00071204, 0.000706  ,\n",
      "       0.00071201, 0.00071303, 0.00071345, 0.00071686, 0.00070985,\n",
      "       0.00071502, 0.00071198, 0.00070782, 0.00071774, 0.00071344,\n",
      "       0.00071379, 0.00071645, 0.00071344, 0.00071023, 0.00071333,\n",
      "       0.00071905, 0.00071247, 0.00071433, 0.0007121 , 0.00070828,\n",
      "       0.00071186, 0.0007136 , 0.00071524, 0.00071461, 0.0007137 ,\n",
      "       0.00071699, 0.0007103 , 0.00071321, 0.00071163, 0.00071272,\n",
      "       0.00071118, 0.00071488, 0.00071904, 0.00071251, 0.00071279,\n",
      "       0.00071907, 0.00071444, 0.00070919, 0.00071452, 0.000712  ,\n",
      "       0.00071344, 0.00071564, 0.00070881, 0.00071202, 0.00071895,\n",
      "       0.00070917, 0.00071699, 0.00070924, 0.00070979, 0.00071509,\n",
      "       0.00071264, 0.00071517, 0.00071348, 0.0007133 , 0.00071446,\n",
      "       0.00070944, 0.00071332, 0.00071444, 0.00071036, 0.00071304,\n",
      "       0.00071343, 0.00071428, 0.00071568, 0.00071662, 0.00071578,\n",
      "       0.00071633, 0.00070861, 0.00071331, 0.00070971, 0.00071621,\n",
      "       0.00071567, 0.00071527], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_36/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/conv2d_48/Conv2D\n",
      "index : 141\n",
      "shape : [192]\n",
      "shape_signature : [192]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.4197475e-09, 7.4283806e-09, 7.4242830e-09, 7.4080431e-09,\n",
      "       7.4248026e-09, 7.4408995e-09, 7.3841839e-09, 7.4127953e-09,\n",
      "       7.4634476e-09, 7.3912929e-09, 7.3802853e-09, 7.4412001e-09,\n",
      "       7.4285982e-09, 7.4322961e-09, 7.4301871e-09, 7.4879765e-09,\n",
      "       7.4470705e-09, 7.4643030e-09, 7.4566584e-09, 7.4871203e-09,\n",
      "       7.3943487e-09, 7.4335702e-09, 7.3654709e-09, 7.4094846e-09,\n",
      "       7.4516251e-09, 7.4501894e-09, 7.3626567e-09, 7.4468915e-09,\n",
      "       7.4544326e-09, 7.4861424e-09, 7.4573903e-09, 7.4091662e-09,\n",
      "       7.4327735e-09, 7.4211037e-09, 7.4592830e-09, 7.4474773e-09,\n",
      "       7.4049056e-09, 7.4283255e-09, 7.4081998e-09, 7.4526891e-09,\n",
      "       7.4382367e-09, 7.4457587e-09, 7.4505659e-09, 7.4039463e-09,\n",
      "       7.3974378e-09, 7.4540463e-09, 7.4455841e-09, 7.4451272e-09,\n",
      "       7.4488709e-09, 7.4331248e-09, 7.4346178e-09, 7.4215594e-09,\n",
      "       7.4310131e-09, 7.4453474e-09, 7.4586248e-09, 7.4200415e-09,\n",
      "       7.4763111e-09, 7.4136808e-09, 7.4310385e-09, 7.4165731e-09,\n",
      "       7.4724804e-09, 7.4695761e-09, 7.4412765e-09, 7.4209217e-09,\n",
      "       7.4299118e-09, 7.4191706e-09, 7.4365136e-09, 7.4207485e-09,\n",
      "       7.4617956e-09, 7.4584028e-09, 7.4396023e-09, 7.4256028e-09,\n",
      "       7.3261068e-09, 7.4733775e-09, 7.3863720e-09, 7.3640369e-09,\n",
      "       7.4279827e-09, 7.4025914e-09, 7.4470479e-09, 7.4196693e-09,\n",
      "       7.4256334e-09, 7.3919462e-09, 7.4220554e-09, 7.4546955e-09,\n",
      "       7.4404953e-09, 7.3906468e-09, 7.4368969e-09, 7.4207667e-09,\n",
      "       7.4196129e-09, 7.4492337e-09, 7.5012112e-09, 7.4448572e-09,\n",
      "       7.4125017e-09, 7.4378428e-09, 7.4412947e-09, 7.4033464e-09,\n",
      "       7.4216460e-09, 7.4948137e-09, 7.3879312e-09, 7.4120563e-09,\n",
      "       7.4458435e-09, 7.4240223e-09, 7.4443429e-09, 7.4373787e-09,\n",
      "       7.4118893e-09, 7.4154887e-09, 7.4559905e-09, 7.3588180e-09,\n",
      "       7.4321704e-09, 7.4254674e-09, 7.4249633e-09, 7.4445441e-09,\n",
      "       7.4560269e-09, 7.4389126e-09, 7.4408866e-09, 7.4346671e-09,\n",
      "       7.4202937e-09, 7.4551707e-09, 7.4212618e-09, 7.3582993e-09,\n",
      "       7.4209701e-09, 7.4316455e-09, 7.4360034e-09, 7.4715247e-09,\n",
      "       7.3984805e-09, 7.4523943e-09, 7.4206423e-09, 7.3772664e-09,\n",
      "       7.4807298e-09, 7.4359296e-09, 7.4394868e-09, 7.4672570e-09,\n",
      "       7.4358653e-09, 7.4024284e-09, 7.4346951e-09, 7.4943793e-09,\n",
      "       7.4257867e-09, 7.4451298e-09, 7.4219013e-09, 7.3820896e-09,\n",
      "       7.4194006e-09, 7.4375364e-09, 7.4546316e-09, 7.4481035e-09,\n",
      "       7.4386159e-09, 7.4728712e-09, 7.4031905e-09, 7.4334783e-09,\n",
      "       7.4170474e-09, 7.4283570e-09, 7.4123543e-09, 7.4508373e-09,\n",
      "       7.4941955e-09, 7.4261606e-09, 7.4290982e-09, 7.4945676e-09,\n",
      "       7.4463511e-09, 7.3915731e-09, 7.4471238e-09, 7.4208528e-09,\n",
      "       7.4358386e-09, 7.4588540e-09, 7.3876230e-09, 7.4210496e-09,\n",
      "       7.4933162e-09, 7.3913409e-09, 7.4729076e-09, 7.3921416e-09,\n",
      "       7.3977975e-09, 7.4530497e-09, 7.4275386e-09, 7.4538633e-09,\n",
      "       7.4363151e-09, 7.4344055e-09, 7.4465003e-09, 7.3942399e-09,\n",
      "       7.4346609e-09, 7.4462490e-09, 7.4037443e-09, 7.4317050e-09,\n",
      "       7.4357729e-09, 7.4446742e-09, 7.4592261e-09, 7.4689988e-09,\n",
      "       7.4603062e-09, 7.4659523e-09, 7.3855748e-09, 7.4345361e-09,\n",
      "       7.3969670e-09, 7.4647595e-09, 7.4590831e-09, 7.4549549e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/conv2d_49/Conv2D\n",
      "index : 142\n",
      "shape : [1152    1    1  192]\n",
      "shape_signature : [1152    1    1  192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00055888, 0.00055632, 0.00055682, ..., 0.00055616, 0.00056015,\n",
      "       0.00055353], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_37/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/conv2d_49/Conv2D\n",
      "index : 143\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.2231906e-08, 7.1900942e-08, 7.1965573e-08, ..., 7.1880805e-08,\n",
      "       7.2396212e-08, 7.1540647e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_38/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_12/depthwise_conv2d_12/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D\n",
      "index : 144\n",
      "shape : [   1    5    5 1152]\n",
      "shape_signature : [   1    5    5 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00011442, 0.0001101 , 0.00011321, ..., 0.00012158, 0.00011379,\n",
      "       0.00010982], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_38/FusedBatchNormV3\n",
      "index : 145\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.4740804e-09, 6.2291337e-09, 6.4052887e-09, ..., 6.8791879e-09,\n",
      "       6.4379617e-09, 6.2138104e-09], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/Conv2D\n",
      "index : 146\n",
      "shape : [ 288    1    1 1152]\n",
      "shape_signature : [ 288    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0005085 , 0.00050989, 0.00051027, 0.00051   , 0.00050792,\n",
      "       0.00050958, 0.00050852, 0.00050793, 0.00051026, 0.00051192,\n",
      "       0.0005112 , 0.00050904, 0.00050803, 0.00051091, 0.00050854,\n",
      "       0.00051049, 0.00050834, 0.00050934, 0.00050809, 0.00051191,\n",
      "       0.0005094 , 0.00051144, 0.00051181, 0.00050784, 0.00051017,\n",
      "       0.00050878, 0.00050972, 0.00051102, 0.00050747, 0.00050815,\n",
      "       0.00050833, 0.00051082, 0.00051102, 0.00050925, 0.00051067,\n",
      "       0.00051023, 0.00051086, 0.00050889, 0.00051023, 0.00051284,\n",
      "       0.00050826, 0.00051295, 0.00050772, 0.00051222, 0.00051278,\n",
      "       0.00050955, 0.00051033, 0.00051333, 0.00050953, 0.00051135,\n",
      "       0.00050855, 0.00050988, 0.00050788, 0.00050892, 0.00050793,\n",
      "       0.0005108 , 0.00050932, 0.00050683, 0.00051187, 0.00051025,\n",
      "       0.0005116 , 0.00050705, 0.00050764, 0.0005084 , 0.00050847,\n",
      "       0.00051032, 0.00050809, 0.0005103 , 0.00051252, 0.00050905,\n",
      "       0.00051126, 0.00050842, 0.00050759, 0.00051362, 0.00050991,\n",
      "       0.00050956, 0.00050957, 0.0005126 , 0.00050885, 0.00050946,\n",
      "       0.00051038, 0.0005068 , 0.00051098, 0.00051306, 0.00050879,\n",
      "       0.00050836, 0.00050899, 0.00050986, 0.00050815, 0.00051385,\n",
      "       0.00050873, 0.00050945, 0.000512  , 0.00050954, 0.00051037,\n",
      "       0.00051067, 0.00050808, 0.00050863, 0.00050815, 0.00050862,\n",
      "       0.00050994, 0.00051218, 0.00051029, 0.00050868, 0.00050942,\n",
      "       0.00051095, 0.00051109, 0.00050919, 0.00050925, 0.00051068,\n",
      "       0.00050976, 0.00051325, 0.00050849, 0.00050821, 0.00050998,\n",
      "       0.00050852, 0.00050778, 0.00051315, 0.00050831, 0.00051078,\n",
      "       0.00050942, 0.00051063, 0.0005096 , 0.00050992, 0.00051047,\n",
      "       0.00051071, 0.00050717, 0.00050983, 0.00051483, 0.00051038,\n",
      "       0.00050895, 0.00051071, 0.00050832, 0.00051284, 0.00050796,\n",
      "       0.00050815, 0.00051031, 0.00051078, 0.00051084, 0.00050991,\n",
      "       0.00050934, 0.00050917, 0.00051285, 0.00050873, 0.00050902,\n",
      "       0.0005106 , 0.00050814, 0.00050598, 0.00051086, 0.00050942,\n",
      "       0.00051122, 0.00050819, 0.00050892, 0.00051031, 0.00051012,\n",
      "       0.00050879, 0.00051139, 0.00050977, 0.00051049, 0.00051005,\n",
      "       0.00051116, 0.00050987, 0.00050821, 0.00050936, 0.00051089,\n",
      "       0.00050975, 0.00051139, 0.00050973, 0.00050878, 0.00050942,\n",
      "       0.00051099, 0.00050717, 0.00051173, 0.00050917, 0.00051054,\n",
      "       0.00051226, 0.00050843, 0.00050838, 0.00051108, 0.00050956,\n",
      "       0.00050889, 0.00050862, 0.00051038, 0.00050723, 0.00051092,\n",
      "       0.00050996, 0.00050885, 0.0005095 , 0.00050925, 0.0005099 ,\n",
      "       0.00050917, 0.00050838, 0.00050991, 0.0005076 , 0.00050978,\n",
      "       0.00050981, 0.00050844, 0.00051081, 0.00050956, 0.00050761,\n",
      "       0.00050997, 0.00051046, 0.00051246, 0.00050932, 0.00050979,\n",
      "       0.0005086 , 0.00051486, 0.00051038, 0.00051094, 0.00050958,\n",
      "       0.00050755, 0.0005098 , 0.00050961, 0.00050972, 0.00051156,\n",
      "       0.00051213, 0.00050979, 0.00051094, 0.00051028, 0.00051045,\n",
      "       0.00051376, 0.00050841, 0.00050871, 0.00050915, 0.00050834,\n",
      "       0.0005087 , 0.00051114, 0.00050903, 0.00051418, 0.00050869,\n",
      "       0.00050815, 0.00050821, 0.00051004, 0.00051021, 0.00050903,\n",
      "       0.0005124 , 0.00050931, 0.00051174, 0.00050774, 0.00050748,\n",
      "       0.00051326, 0.00050787, 0.00050975, 0.00050853, 0.00050981,\n",
      "       0.00051338, 0.00050928, 0.00051054, 0.00050996, 0.00051023,\n",
      "       0.00051418, 0.00051395, 0.00051292, 0.00050996, 0.0005077 ,\n",
      "       0.00050754, 0.00050995, 0.00050917, 0.00051085, 0.00050766,\n",
      "       0.00051014, 0.00050952, 0.00051215, 0.00050907, 0.0005087 ,\n",
      "       0.00051302, 0.00051056, 0.00050864, 0.00051208, 0.0005118 ,\n",
      "       0.00050756, 0.00050963, 0.00050949, 0.0005087 , 0.00051251,\n",
      "       0.00051031, 0.000512  , 0.00050976, 0.00051004, 0.00051013,\n",
      "       0.0005118 , 0.00051157, 0.0005101 , 0.00050838, 0.0005079 ,\n",
      "       0.00050897, 0.00051295, 0.0005091 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/BiasAdd/ReadVariableOp/resource\n",
      "index : 147\n",
      "shape : [288]\n",
      "shape_signature : [288]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.48431347e-08, 1.48839723e-08, 1.48949724e-08, 1.48869184e-08,\n",
      "       1.48263393e-08, 1.48747992e-08, 1.48437298e-08, 1.48266350e-08,\n",
      "       1.48946038e-08, 1.49430850e-08, 1.49219890e-08, 1.48589567e-08,\n",
      "       1.48294195e-08, 1.49136596e-08, 1.48444990e-08, 1.49014650e-08,\n",
      "       1.48386476e-08, 1.48677852e-08, 1.48313735e-08, 1.49428097e-08,\n",
      "       1.48693946e-08, 1.49289878e-08, 1.49399533e-08, 1.48238843e-08,\n",
      "       1.48920414e-08, 1.48513086e-08, 1.48787729e-08, 1.49169441e-08,\n",
      "       1.48130672e-08, 1.48329606e-08, 1.48381938e-08, 1.49110555e-08,\n",
      "       1.49169619e-08, 1.48650718e-08, 1.49064974e-08, 1.48936898e-08,\n",
      "       1.49122101e-08, 1.48547059e-08, 1.48937866e-08, 1.49699133e-08,\n",
      "       1.48363810e-08, 1.49731942e-08, 1.48204107e-08, 1.49518300e-08,\n",
      "       1.49681512e-08, 1.48738870e-08, 1.48965800e-08, 1.49841455e-08,\n",
      "       1.48732884e-08, 1.49264281e-08, 1.48446571e-08, 1.48836428e-08,\n",
      "       1.48251518e-08, 1.48555754e-08, 1.48265942e-08, 1.49104675e-08,\n",
      "       1.48672585e-08, 1.47944590e-08, 1.49414916e-08, 1.48943169e-08,\n",
      "       1.49338053e-08, 1.48008343e-08, 1.48182959e-08, 1.48403734e-08,\n",
      "       1.48422563e-08, 1.48963100e-08, 1.48313752e-08, 1.48958970e-08,\n",
      "       1.49606372e-08, 1.48593564e-08, 1.49238293e-08, 1.48408770e-08,\n",
      "       1.48168446e-08, 1.49927768e-08, 1.48843649e-08, 1.48742414e-08,\n",
      "       1.48744101e-08, 1.49630193e-08, 1.48533585e-08, 1.48714090e-08,\n",
      "       1.48982231e-08, 1.47935024e-08, 1.49156225e-08, 1.49763490e-08,\n",
      "       1.48515982e-08, 1.48392418e-08, 1.48576635e-08, 1.48828185e-08,\n",
      "       1.48331729e-08, 1.49995323e-08, 1.48498662e-08, 1.48709489e-08,\n",
      "       1.49455293e-08, 1.48736214e-08, 1.48977319e-08, 1.49067159e-08,\n",
      "       1.48311479e-08, 1.48471804e-08, 1.48330708e-08, 1.48468455e-08,\n",
      "       1.48853792e-08, 1.49506363e-08, 1.48956127e-08, 1.48484833e-08,\n",
      "       1.48700758e-08, 1.49147716e-08, 1.49187382e-08, 1.48635140e-08,\n",
      "       1.48650292e-08, 1.49068455e-08, 1.48801105e-08, 1.49819943e-08,\n",
      "       1.48430583e-08, 1.48347992e-08, 1.48863712e-08, 1.48438772e-08,\n",
      "       1.48222119e-08, 1.49788981e-08, 1.48378128e-08, 1.49098920e-08,\n",
      "       1.48700980e-08, 1.49054067e-08, 1.48754991e-08, 1.48847423e-08,\n",
      "       1.49006896e-08, 1.49077142e-08, 1.48044803e-08, 1.48820902e-08,\n",
      "       1.50279771e-08, 1.48980499e-08, 1.48564610e-08, 1.49076573e-08,\n",
      "       1.48379664e-08, 1.49700128e-08, 1.48274166e-08, 1.48329926e-08,\n",
      "       1.48962176e-08, 1.49097126e-08, 1.49115760e-08, 1.48842885e-08,\n",
      "       1.48677817e-08, 1.48627306e-08, 1.49702188e-08, 1.48498529e-08,\n",
      "       1.48583741e-08, 1.49044563e-08, 1.48328061e-08, 1.47697747e-08,\n",
      "       1.49120396e-08, 1.48701416e-08, 1.49227954e-08, 1.48341837e-08,\n",
      "       1.48554857e-08, 1.48961279e-08, 1.48905919e-08, 1.48518122e-08,\n",
      "       1.49277248e-08, 1.48804267e-08, 1.49012660e-08, 1.48883643e-08,\n",
      "       1.49208716e-08, 1.48832502e-08, 1.48348871e-08, 1.48684194e-08,\n",
      "       1.49130379e-08, 1.48798334e-08, 1.49277266e-08, 1.48792116e-08,\n",
      "       1.48514605e-08, 1.48701780e-08, 1.49158108e-08, 1.48044599e-08,\n",
      "       1.49374220e-08, 1.48628221e-08, 1.49026711e-08, 1.49530610e-08,\n",
      "       1.48411194e-08, 1.48396992e-08, 1.49185162e-08, 1.48741126e-08,\n",
      "       1.48547379e-08, 1.48466412e-08, 1.48980526e-08, 1.48061705e-08,\n",
      "       1.49137893e-08, 1.48860009e-08, 1.48535486e-08, 1.48723389e-08,\n",
      "       1.48650647e-08, 1.48841801e-08, 1.48629118e-08, 1.48398591e-08,\n",
      "       1.48843196e-08, 1.48169246e-08, 1.48805164e-08, 1.48813726e-08,\n",
      "       1.48416195e-08, 1.49105563e-08, 1.48740638e-08, 1.48173207e-08,\n",
      "       1.48861012e-08, 1.49005883e-08, 1.49588608e-08, 1.48672905e-08,\n",
      "       1.48810635e-08, 1.48462576e-08, 1.50287747e-08, 1.48981698e-08,\n",
      "       1.49143435e-08, 1.48747361e-08, 1.48155959e-08, 1.48811043e-08,\n",
      "       1.48758019e-08, 1.48789194e-08, 1.49326151e-08, 1.49492276e-08,\n",
      "       1.48808139e-08, 1.49144164e-08, 1.48951695e-08, 1.49003041e-08,\n",
      "       1.49968056e-08, 1.48405706e-08, 1.48493298e-08, 1.48623140e-08,\n",
      "       1.48386317e-08, 1.48490207e-08, 1.49202517e-08, 1.48586015e-08,\n",
      "       1.50090784e-08, 1.48488146e-08, 1.48330859e-08, 1.48347681e-08,\n",
      "       1.48883270e-08, 1.48931836e-08, 1.48587258e-08, 1.49571235e-08,\n",
      "       1.48669850e-08, 1.49377257e-08, 1.48211825e-08, 1.48136179e-08,\n",
      "       1.49821329e-08, 1.48247405e-08, 1.48797659e-08, 1.48441233e-08,\n",
      "       1.48816230e-08, 1.49858437e-08, 1.48661510e-08, 1.49029162e-08,\n",
      "       1.48858499e-08, 1.48937866e-08, 1.50092045e-08, 1.50022164e-08,\n",
      "       1.49723629e-08, 1.48858632e-08, 1.48197925e-08, 1.48152708e-08,\n",
      "       1.48854609e-08, 1.48629136e-08, 1.49119863e-08, 1.48186086e-08,\n",
      "       1.48912243e-08, 1.48731036e-08, 1.49498867e-08, 1.48597703e-08,\n",
      "       1.48492445e-08, 1.49753188e-08, 1.49033799e-08, 1.48472639e-08,\n",
      "       1.49476556e-08, 1.49395039e-08, 1.48158881e-08, 1.48763757e-08,\n",
      "       1.48721773e-08, 1.48492072e-08, 1.49604524e-08, 1.48960160e-08,\n",
      "       1.49455737e-08, 1.48799320e-08, 1.48880774e-08, 1.48907686e-08,\n",
      "       1.49394737e-08, 1.49330077e-08, 1.48900465e-08, 1.48397028e-08,\n",
      "       1.48258392e-08, 1.48570045e-08, 1.49730379e-08, 1.48606629e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/Conv2D\n",
      "index : 148\n",
      "shape : [1152    1    1  288]\n",
      "shape_signature : [1152    1    1  288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00050775, 0.00050819, 0.00050892, ..., 0.00050929, 0.00051113,\n",
      "       0.00050754], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/BiasAdd/ReadVariableOp/resource\n",
      "index : 149\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.0112120e-08, 1.0120898e-08, 1.0135436e-08, ..., 1.0142815e-08,\n",
      "       1.0179440e-08, 1.0107919e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/conv2d_52/Conv2D\n",
      "index : 150\n",
      "shape : [ 192    1    1 1152]\n",
      "shape_signature : [ 192    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00057115, 0.00057526, 0.0005775 , 0.00057359, 0.00057494,\n",
      "       0.0005723 , 0.00057293, 0.00057307, 0.00057553, 0.00057837,\n",
      "       0.00057249, 0.00057571, 0.00057457, 0.00057419, 0.00057312,\n",
      "       0.00057447, 0.00057423, 0.00057757, 0.00057283, 0.00057073,\n",
      "       0.00057744, 0.00057488, 0.00057348, 0.00056888, 0.00057577,\n",
      "       0.00057375, 0.0005732 , 0.00057038, 0.00057482, 0.00057544,\n",
      "       0.00057216, 0.00057142, 0.00057703, 0.00057424, 0.00057349,\n",
      "       0.00057274, 0.00057429, 0.00057772, 0.00057723, 0.00057447,\n",
      "       0.00057717, 0.00057712, 0.00057507, 0.00057427, 0.00057343,\n",
      "       0.00057264, 0.00057684, 0.0005755 , 0.00057604, 0.0005729 ,\n",
      "       0.00057244, 0.00057591, 0.00057465, 0.00057368, 0.0005724 ,\n",
      "       0.00057434, 0.00057612, 0.00057443, 0.00057495, 0.00057358,\n",
      "       0.00057519, 0.00057478, 0.00057495, 0.00057612, 0.00057509,\n",
      "       0.00057483, 0.00057661, 0.00057461, 0.00057289, 0.00057725,\n",
      "       0.00057453, 0.00057604, 0.00057503, 0.00056991, 0.00057483,\n",
      "       0.00057116, 0.00057245, 0.000576  , 0.00057319, 0.00057381,\n",
      "       0.00057021, 0.00057343, 0.00057375, 0.00057751, 0.00057323,\n",
      "       0.00057248, 0.00057123, 0.00057556, 0.00057558, 0.00057842,\n",
      "       0.00057482, 0.00057757, 0.00057494, 0.00057604, 0.00057634,\n",
      "       0.00057457, 0.00057163, 0.00057158, 0.00057404, 0.00057856,\n",
      "       0.00057878, 0.00057583, 0.00057293, 0.00057339, 0.00057723,\n",
      "       0.00057921, 0.00057486, 0.00057516, 0.00057355, 0.00057319,\n",
      "       0.00057313, 0.00057773, 0.00057516, 0.00057235, 0.00057712,\n",
      "       0.00057038, 0.00057225, 0.00057303, 0.00057473, 0.00057593,\n",
      "       0.00057543, 0.0005749 , 0.00057463, 0.00056918, 0.00057585,\n",
      "       0.00057621, 0.00057368, 0.00057503, 0.00057553, 0.00057589,\n",
      "       0.00057388, 0.00057739, 0.00057494, 0.00057464, 0.00057368,\n",
      "       0.00057254, 0.00057711, 0.0005779 , 0.00057462, 0.00057513,\n",
      "       0.00057157, 0.0005711 , 0.00057447, 0.00057792, 0.00057349,\n",
      "       0.00057627, 0.00057892, 0.00057466, 0.00057086, 0.00057016,\n",
      "       0.00057423, 0.00057295, 0.0005753 , 0.00056978, 0.0005688 ,\n",
      "       0.00057371, 0.00057695, 0.00057304, 0.00057534, 0.00057467,\n",
      "       0.0005754 , 0.00057625, 0.00057615, 0.00057138, 0.00057581,\n",
      "       0.00056982, 0.00057128, 0.00057586, 0.00057415, 0.00057406,\n",
      "       0.00057396, 0.00057498, 0.00057619, 0.00057718, 0.00057448,\n",
      "       0.00057597, 0.00057389, 0.00057634, 0.00057493, 0.0005729 ,\n",
      "       0.00057516, 0.00057603, 0.00057758, 0.00057514, 0.00057549,\n",
      "       0.0005771 , 0.00057482, 0.00057545, 0.00057535, 0.00057499,\n",
      "       0.00057294, 0.00057756], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_39/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/conv2d_52/Conv2D\n",
      "index : 151\n",
      "shape : [192]\n",
      "shape_signature : [192]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.2160395e-09, 4.2463357e-09, 4.2628936e-09, 4.2340198e-09,\n",
      "       4.2439781e-09, 4.2244896e-09, 4.2291286e-09, 4.2301775e-09,\n",
      "       4.2483750e-09, 4.2693191e-09, 4.2259369e-09, 4.2497068e-09,\n",
      "       4.2412571e-09, 4.2384660e-09, 4.2305657e-09, 4.2405013e-09,\n",
      "       4.2387800e-09, 4.2633865e-09, 4.2283870e-09, 4.2128963e-09,\n",
      "       4.2624184e-09, 4.2435584e-09, 4.2332498e-09, 4.1992427e-09,\n",
      "       4.2501473e-09, 4.2352220e-09, 4.2311834e-09, 4.2103374e-09,\n",
      "       4.2431134e-09, 4.2476858e-09, 4.2235007e-09, 4.2180370e-09,\n",
      "       4.2594488e-09, 4.2387986e-09, 4.2333257e-09, 4.2277799e-09,\n",
      "       4.2392174e-09, 4.2645474e-09, 4.2609050e-09, 4.2405524e-09,\n",
      "       4.2604889e-09, 4.2600896e-09, 4.2449346e-09, 4.2390100e-09,\n",
      "       4.2328114e-09, 4.2270241e-09, 4.2579971e-09, 4.2481352e-09,\n",
      "       4.2521444e-09, 4.2289563e-09, 4.2255079e-09, 4.2511719e-09,\n",
      "       4.2418287e-09, 4.2346566e-09, 4.2252100e-09, 4.2395776e-09,\n",
      "       4.2527160e-09, 4.2402073e-09, 4.2440531e-09, 4.2339749e-09,\n",
      "       4.2458717e-09, 4.2428412e-09, 4.2440851e-09, 4.2526929e-09,\n",
      "       4.2451149e-09, 4.2431476e-09, 4.2563428e-09, 4.2415564e-09,\n",
      "       4.2288666e-09, 4.2610528e-09, 4.2409605e-09, 4.2521355e-09,\n",
      "       4.2446242e-09, 4.2068327e-09, 4.2431534e-09, 4.2160853e-09,\n",
      "       4.2255848e-09, 4.2517856e-09, 4.2311092e-09, 4.2356252e-09,\n",
      "       4.2091037e-09, 4.2328181e-09, 4.2352055e-09, 4.2629371e-09,\n",
      "       4.2313895e-09, 4.2258623e-09, 4.2166404e-09, 4.2485993e-09,\n",
      "       4.2487049e-09, 4.2696655e-09, 4.2431130e-09, 4.2633759e-09,\n",
      "       4.2439687e-09, 4.2520800e-09, 4.2543102e-09, 4.2412904e-09,\n",
      "       4.2195434e-09, 4.2191717e-09, 4.2373620e-09, 4.2706958e-09,\n",
      "       4.2723700e-09, 4.2505719e-09, 4.2291650e-09, 4.2325423e-09,\n",
      "       4.2609023e-09, 4.2754786e-09, 4.2434203e-09, 4.2455888e-09,\n",
      "       4.2337542e-09, 4.2310475e-09, 4.2306438e-09, 4.2646011e-09,\n",
      "       4.2455950e-09, 4.2248653e-09, 4.2600865e-09, 4.2103667e-09,\n",
      "       4.2241655e-09, 4.2299213e-09, 4.2424446e-09, 4.2513202e-09,\n",
      "       4.2475863e-09, 4.2437236e-09, 4.2416968e-09, 4.2014383e-09,\n",
      "       4.2506976e-09, 4.2533652e-09, 4.2346775e-09, 4.2446890e-09,\n",
      "       4.2483812e-09, 4.2509947e-09, 4.2361563e-09, 4.2620423e-09,\n",
      "       4.2439847e-09, 4.2417434e-09, 4.2347135e-09, 4.2262869e-09,\n",
      "       4.2600141e-09, 4.2658108e-09, 4.2416106e-09, 4.2453951e-09,\n",
      "       4.2190789e-09, 4.2156341e-09, 4.2405315e-09, 4.2660138e-09,\n",
      "       4.2333248e-09, 4.2537893e-09, 4.2733972e-09, 4.2419610e-09,\n",
      "       4.2138391e-09, 4.2086739e-09, 4.2387471e-09, 4.2293351e-09,\n",
      "       4.2466239e-09, 4.2058810e-09, 4.1986716e-09, 4.2349226e-09,\n",
      "       4.2588368e-09, 4.2299737e-09, 4.2469646e-09, 4.2420076e-09,\n",
      "       4.2473691e-09, 4.2536308e-09, 4.2529362e-09, 4.2177493e-09,\n",
      "       4.2503845e-09, 4.2061914e-09, 4.2169739e-09, 4.2507771e-09,\n",
      "       4.2381485e-09, 4.2375210e-09, 4.2367412e-09, 4.2442880e-09,\n",
      "       4.2532395e-09, 4.2604924e-09, 4.2405603e-09, 4.2516155e-09,\n",
      "       4.2362762e-09, 4.2543333e-09, 4.2439519e-09, 4.2289279e-09,\n",
      "       4.2456039e-09, 4.2520125e-09, 4.2634811e-09, 4.2454800e-09,\n",
      "       4.2480530e-09, 4.2599666e-09, 4.2431076e-09, 4.2477213e-09,\n",
      "       4.2470329e-09, 4.2443697e-09, 4.2291974e-09, 4.2633590e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/conv2d_53/Conv2D\n",
      "index : 152\n",
      "shape : [1152    1    1  192]\n",
      "shape_signature : [1152    1    1  192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00054212, 0.00054097, 0.00054084, ..., 0.00054998, 0.00055008,\n",
      "       0.00053261], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_40/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/conv2d_53/Conv2D\n",
      "index : 153\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([8.7406178e-08, 8.7221586e-08, 8.7199844e-08, ..., 8.8672934e-08,\n",
      "       8.8689283e-08, 8.5872436e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_41/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_13/depthwise_conv2d_13/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D\n",
      "index : 154\n",
      "shape : [   1    5    5 1152]\n",
      "shape_signature : [   1    5    5 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00011791, 0.00011801, 0.00011819, ..., 0.00011517, 0.00012548,\n",
      "       0.00012268], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_41/FusedBatchNormV3\n",
      "index : 155\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.2481735e-09, 6.2535723e-09, 6.2629195e-09, ..., 6.1030918e-09,\n",
      "       6.6491874e-09, 6.5008789e-09], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/Conv2D\n",
      "index : 156\n",
      "shape : [ 288    1    1 1152]\n",
      "shape_signature : [ 288    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00051026, 0.00051001, 0.00050889, 0.00050853, 0.00051013,\n",
      "       0.00050842, 0.00051062, 0.00050761, 0.00051049, 0.00050843,\n",
      "       0.00050859, 0.00050845, 0.00051135, 0.00051147, 0.00050952,\n",
      "       0.0005122 , 0.0005098 , 0.0005137 , 0.00050892, 0.00051116,\n",
      "       0.00051317, 0.00051079, 0.000509  , 0.00051084, 0.000511  ,\n",
      "       0.00051067, 0.00050879, 0.00050896, 0.00050985, 0.00051063,\n",
      "       0.00050848, 0.00050976, 0.00051191, 0.00051287, 0.00051487,\n",
      "       0.0005118 , 0.00050966, 0.00050811, 0.0005105 , 0.00051092,\n",
      "       0.00050901, 0.00051169, 0.00051104, 0.00050858, 0.00051108,\n",
      "       0.00050853, 0.00050926, 0.00051106, 0.00051225, 0.00050829,\n",
      "       0.00051155, 0.00051079, 0.0005134 , 0.00051304, 0.00050982,\n",
      "       0.00050973, 0.00051162, 0.0005091 , 0.00050882, 0.00050858,\n",
      "       0.00051104, 0.00050812, 0.00051102, 0.00050707, 0.00050953,\n",
      "       0.00050786, 0.00050864, 0.00051468, 0.00050932, 0.00050933,\n",
      "       0.000509  , 0.00050816, 0.00050864, 0.00051062, 0.00051145,\n",
      "       0.0005101 , 0.00050858, 0.00050715, 0.0005117 , 0.00050808,\n",
      "       0.00051112, 0.00050815, 0.00050728, 0.00050796, 0.00051146,\n",
      "       0.00051121, 0.0005095 , 0.00050821, 0.00051438, 0.00050817,\n",
      "       0.00050958, 0.00050944, 0.00050711, 0.00051122, 0.00050642,\n",
      "       0.00051092, 0.00050806, 0.00051056, 0.00050661, 0.0005092 ,\n",
      "       0.00050914, 0.00050968, 0.0005097 , 0.00051157, 0.00050914,\n",
      "       0.00050891, 0.00050709, 0.0005116 , 0.00050887, 0.00051015,\n",
      "       0.00050835, 0.00050738, 0.00050863, 0.00051234, 0.00050598,\n",
      "       0.00050824, 0.0005111 , 0.00051242, 0.00051189, 0.00051335,\n",
      "       0.00050724, 0.00050789, 0.00051141, 0.0005123 , 0.00050953,\n",
      "       0.0005092 , 0.00051014, 0.00051289, 0.00050881, 0.00050909,\n",
      "       0.00050806, 0.00050803, 0.0005091 , 0.00051134, 0.000509  ,\n",
      "       0.00050738, 0.00051085, 0.00051165, 0.00051079, 0.00051179,\n",
      "       0.00050792, 0.00051396, 0.00050971, 0.00051171, 0.00051016,\n",
      "       0.00050803, 0.0005111 , 0.00050752, 0.00050936, 0.00050952,\n",
      "       0.00050833, 0.00050876, 0.00050448, 0.00050836, 0.00050657,\n",
      "       0.00050823, 0.00051163, 0.00050827, 0.0005147 , 0.00050916,\n",
      "       0.00051048, 0.00051271, 0.0005114 , 0.00050895, 0.00050902,\n",
      "       0.00051449, 0.00051013, 0.00051035, 0.00051001, 0.00050726,\n",
      "       0.00051078, 0.00050859, 0.0005091 , 0.00051269, 0.00051398,\n",
      "       0.00050925, 0.00051324, 0.00050794, 0.00051023, 0.00050859,\n",
      "       0.00051059, 0.00050989, 0.00050836, 0.00050868, 0.00050922,\n",
      "       0.00050897, 0.0005074 , 0.00050888, 0.00050871, 0.00051083,\n",
      "       0.00050814, 0.00050934, 0.00051068, 0.00051097, 0.00051061,\n",
      "       0.00050817, 0.00051247, 0.00050894, 0.0005124 , 0.00051409,\n",
      "       0.00051154, 0.00050823, 0.00051126, 0.00050877, 0.00050842,\n",
      "       0.00051036, 0.00050818, 0.00050852, 0.00050954, 0.00051175,\n",
      "       0.00051053, 0.00050901, 0.00050917, 0.00050832, 0.00050986,\n",
      "       0.00050903, 0.00051148, 0.00050929, 0.0005111 , 0.00050809,\n",
      "       0.00050885, 0.00050995, 0.00051157, 0.00051171, 0.00051119,\n",
      "       0.00051228, 0.00050814, 0.00050763, 0.00050983, 0.00050851,\n",
      "       0.00051249, 0.0005072 , 0.00050801, 0.00050817, 0.00050797,\n",
      "       0.0005099 , 0.00050851, 0.00050929, 0.00051064, 0.00051306,\n",
      "       0.00051047, 0.00050789, 0.00051222, 0.0005112 , 0.00050993,\n",
      "       0.00050786, 0.00050992, 0.0005128 , 0.00051071, 0.00050892,\n",
      "       0.00051342, 0.00051002, 0.00051154, 0.00050978, 0.00051029,\n",
      "       0.00051085, 0.00050951, 0.00050943, 0.00050993, 0.00050775,\n",
      "       0.00050921, 0.0005106 , 0.00050926, 0.00051204, 0.00050973,\n",
      "       0.00050809, 0.00050838, 0.00051039, 0.00050813, 0.00050936,\n",
      "       0.00050822, 0.00051061, 0.00051038, 0.00050966, 0.00050985,\n",
      "       0.00051122, 0.00050808, 0.00050972, 0.00050984, 0.00051211,\n",
      "       0.00051031, 0.00050752, 0.00050816, 0.00050629, 0.00050871,\n",
      "       0.00050989, 0.0005112 , 0.00050869], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/BiasAdd/ReadVariableOp/resource\n",
      "index : 157\n",
      "shape : [288]\n",
      "shape_signature : [288]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.7115424e-08, 1.7107062e-08, 1.7069519e-08, 1.7057568e-08,\n",
      "       1.7111205e-08, 1.7053909e-08, 1.7127535e-08, 1.7026739e-08,\n",
      "       1.7123066e-08, 1.7054203e-08, 1.7059309e-08, 1.7054830e-08,\n",
      "       1.7152161e-08, 1.7155971e-08, 1.7090599e-08, 1.7180556e-08,\n",
      "       1.7100040e-08, 1.7230992e-08, 1.7070684e-08, 1.7145728e-08,\n",
      "       1.7212932e-08, 1.7133232e-08, 1.7073130e-08, 1.7134859e-08,\n",
      "       1.7140437e-08, 1.7129084e-08, 1.7066080e-08, 1.7071716e-08,\n",
      "       1.7101637e-08, 1.7128032e-08, 1.7055624e-08, 1.7098797e-08,\n",
      "       1.7170727e-08, 1.7203186e-08, 1.7270123e-08, 1.7167105e-08,\n",
      "       1.7095203e-08, 1.7043375e-08, 1.7123391e-08, 1.7137788e-08,\n",
      "       1.7073608e-08, 1.7163517e-08, 1.7141570e-08, 1.7059055e-08,\n",
      "       1.7142950e-08, 1.7057429e-08, 1.7082009e-08, 1.7142337e-08,\n",
      "       1.7182234e-08, 1.7049318e-08, 1.7158653e-08, 1.7133335e-08,\n",
      "       1.7220804e-08, 1.7208684e-08, 1.7100641e-08, 1.7097729e-08,\n",
      "       1.7161195e-08, 1.7076735e-08, 1.7067130e-08, 1.7059007e-08,\n",
      "       1.7141531e-08, 1.7043837e-08, 1.7141023e-08, 1.7008354e-08,\n",
      "       1.7091150e-08, 1.7034994e-08, 1.7061215e-08, 1.7263591e-08,\n",
      "       1.7084089e-08, 1.7084217e-08, 1.7073173e-08, 1.7045199e-08,\n",
      "       1.7061154e-08, 1.7127617e-08, 1.7155431e-08, 1.7110160e-08,\n",
      "       1.7059143e-08, 1.7011070e-08, 1.7163947e-08, 1.7042293e-08,\n",
      "       1.7144302e-08, 1.7044824e-08, 1.7015395e-08, 1.7038285e-08,\n",
      "       1.7155877e-08, 1.7147315e-08, 1.7090148e-08, 1.7046711e-08,\n",
      "       1.7253731e-08, 1.7045464e-08, 1.7092770e-08, 1.7088054e-08,\n",
      "       1.7009897e-08, 1.7147601e-08, 1.6986750e-08, 1.7137609e-08,\n",
      "       1.7041547e-08, 1.7125519e-08, 1.6993141e-08, 1.7079987e-08,\n",
      "       1.7077895e-08, 1.7095987e-08, 1.7096728e-08, 1.7159351e-08,\n",
      "       1.7077962e-08, 1.7070210e-08, 1.7009100e-08, 1.7160499e-08,\n",
      "       1.7068750e-08, 1.7111718e-08, 1.7051542e-08, 1.7018843e-08,\n",
      "       1.7060888e-08, 1.7185281e-08, 1.6971978e-08, 1.7047746e-08,\n",
      "       1.7143671e-08, 1.7188013e-08, 1.7170308e-08, 1.7219216e-08,\n",
      "       1.7014115e-08, 1.7036044e-08, 1.7154145e-08, 1.7184014e-08,\n",
      "       1.7090983e-08, 1.7079913e-08, 1.7111610e-08, 1.7203698e-08,\n",
      "       1.7066734e-08, 1.7076355e-08, 1.7041808e-08, 1.7040756e-08,\n",
      "       1.7076445e-08, 1.7151688e-08, 1.7073212e-08, 1.7018948e-08,\n",
      "       1.7135259e-08, 1.7162002e-08, 1.7133392e-08, 1.7166945e-08,\n",
      "       1.7037035e-08, 1.7239573e-08, 1.7096873e-08, 1.7163973e-08,\n",
      "       1.7112095e-08, 1.7040518e-08, 1.7143641e-08, 1.7023607e-08,\n",
      "       1.7085309e-08, 1.7090555e-08, 1.7050811e-08, 1.7065320e-08,\n",
      "       1.6921696e-08, 1.7051690e-08, 1.6991718e-08, 1.7047309e-08,\n",
      "       1.7161526e-08, 1.7048595e-08, 1.7264494e-08, 1.7078655e-08,\n",
      "       1.7122735e-08, 1.7197694e-08, 1.7153747e-08, 1.7071509e-08,\n",
      "       1.7073955e-08, 1.7257298e-08, 1.7111093e-08, 1.7118523e-08,\n",
      "       1.7107178e-08, 1.7014848e-08, 1.7132798e-08, 1.7059341e-08,\n",
      "       1.7076657e-08, 1.7196927e-08, 1.7240213e-08, 1.7081559e-08,\n",
      "       1.7215296e-08, 1.7037577e-08, 1.7114401e-08, 1.7059408e-08,\n",
      "       1.7126588e-08, 1.7102982e-08, 1.7051885e-08, 1.7062455e-08,\n",
      "       1.7080648e-08, 1.7072258e-08, 1.7019467e-08, 1.7069116e-08,\n",
      "       1.7063432e-08, 1.7134715e-08, 1.7044281e-08, 1.7084533e-08,\n",
      "       1.7129645e-08, 1.7139417e-08, 1.7127133e-08, 1.7045490e-08,\n",
      "       1.7189656e-08, 1.7071333e-08, 1.7187158e-08, 1.7244032e-08,\n",
      "       1.7158390e-08, 1.7047489e-08, 1.7149167e-08, 1.7065457e-08,\n",
      "       1.7053791e-08, 1.7118674e-08, 1.7045760e-08, 1.7057170e-08,\n",
      "       1.7091354e-08, 1.7165451e-08, 1.7124675e-08, 1.7073509e-08,\n",
      "       1.7078815e-08, 1.7050571e-08, 1.7101915e-08, 1.7074337e-08,\n",
      "       1.7156506e-08, 1.7082881e-08, 1.7143744e-08, 1.7042529e-08,\n",
      "       1.7068201e-08, 1.7105052e-08, 1.7159479e-08, 1.7164107e-08,\n",
      "       1.7146546e-08, 1.7183124e-08, 1.7044302e-08, 1.7027359e-08,\n",
      "       1.7101062e-08, 1.7056923e-08, 1.7190317e-08, 1.7012965e-08,\n",
      "       1.7039953e-08, 1.7045480e-08, 1.7038595e-08, 1.7103549e-08,\n",
      "       1.7056745e-08, 1.7082924e-08, 1.7128150e-08, 1.7209530e-08,\n",
      "       1.7122554e-08, 1.7036124e-08, 1.7181197e-08, 1.7147096e-08,\n",
      "       1.7104306e-08, 1.7035019e-08, 1.7104234e-08, 1.7200785e-08,\n",
      "       1.7130722e-08, 1.7070525e-08, 1.7221362e-08, 1.7107542e-08,\n",
      "       1.7158390e-08, 1.7099470e-08, 1.7116616e-08, 1.7135333e-08,\n",
      "       1.7090224e-08, 1.7087679e-08, 1.7104540e-08, 1.7031445e-08,\n",
      "       1.7080426e-08, 1.7126826e-08, 1.7081801e-08, 1.7175052e-08,\n",
      "       1.7097790e-08, 1.7042654e-08, 1.7052560e-08, 1.7119728e-08,\n",
      "       1.7043975e-08, 1.7085174e-08, 1.7046958e-08, 1.7127118e-08,\n",
      "       1.7119621e-08, 1.7095331e-08, 1.7101890e-08, 1.7147748e-08,\n",
      "       1.7042384e-08, 1.7097324e-08, 1.7101481e-08, 1.7177525e-08,\n",
      "       1.7117006e-08, 1.7023725e-08, 1.7045155e-08, 1.6982279e-08,\n",
      "       1.7063392e-08, 1.7103030e-08, 1.7146915e-08, 1.7062890e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/Conv2D\n",
      "index : 158\n",
      "shape : [1152    1    1  288]\n",
      "shape_signature : [1152    1    1  288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00050581, 0.0005048 , 0.00050904, ..., 0.00051105, 0.00051275,\n",
      "       0.00050876], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/BiasAdd/ReadVariableOp/resource\n",
      "index : 159\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.2006598e-09, 9.1822869e-09, 9.2594981e-09, ..., 9.2960555e-09,\n",
      "       9.3270023e-09, 9.2543582e-09], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/conv2d_56/Conv2D\n",
      "index : 160\n",
      "shape : [ 192    1    1 1152]\n",
      "shape_signature : [ 192    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00057471, 0.00057286, 0.00057122, 0.00057686, 0.00057462,\n",
      "       0.00057468, 0.00057414, 0.00057516, 0.00057556, 0.0005749 ,\n",
      "       0.00057671, 0.00057437, 0.00057533, 0.00057371, 0.00057673,\n",
      "       0.00057458, 0.00057776, 0.0005743 , 0.00057554, 0.00057624,\n",
      "       0.00057442, 0.00057009, 0.00057585, 0.00057249, 0.00057357,\n",
      "       0.00057291, 0.00057392, 0.00057673, 0.0005752 , 0.00057645,\n",
      "       0.00057529, 0.0005746 , 0.00057527, 0.00057265, 0.00057293,\n",
      "       0.00057508, 0.00057802, 0.00057338, 0.00057807, 0.00057991,\n",
      "       0.00057308, 0.00057494, 0.00057529, 0.00057458, 0.00057629,\n",
      "       0.00057271, 0.00057586, 0.00057147, 0.0005736 , 0.00057444,\n",
      "       0.00057582, 0.00057473, 0.00057508, 0.00057839, 0.00057304,\n",
      "       0.00057297, 0.00057305, 0.00057291, 0.00057558, 0.00057701,\n",
      "       0.00057432, 0.00057542, 0.00056962, 0.0005759 , 0.0005785 ,\n",
      "       0.00057208, 0.00057484, 0.00057755, 0.0005765 , 0.00057638,\n",
      "       0.00057304, 0.00057936, 0.00057548, 0.00057422, 0.00057644,\n",
      "       0.00057132, 0.0005727 , 0.00057808, 0.00057403, 0.0005761 ,\n",
      "       0.0005776 , 0.00057738, 0.00057455, 0.00057352, 0.00057673,\n",
      "       0.00057341, 0.00057364, 0.00057677, 0.00057549, 0.00057346,\n",
      "       0.00057244, 0.00057337, 0.00057536, 0.00057871, 0.00057511,\n",
      "       0.00057343, 0.00057292, 0.00057607, 0.0005747 , 0.00057697,\n",
      "       0.00057899, 0.00057443, 0.00057758, 0.00057756, 0.00057245,\n",
      "       0.0005762 , 0.00057418, 0.00057414, 0.00057368, 0.00057233,\n",
      "       0.00057566, 0.00057211, 0.00057671, 0.00057493, 0.00057248,\n",
      "       0.00057474, 0.00057525, 0.00057173, 0.0005751 , 0.00057503,\n",
      "       0.00057373, 0.00057312, 0.00057315, 0.00057493, 0.00057332,\n",
      "       0.00057373, 0.00057372, 0.00057512, 0.00057705, 0.00057684,\n",
      "       0.00058025, 0.00057361, 0.00057612, 0.00057517, 0.00057594,\n",
      "       0.00057656, 0.00057283, 0.00057372, 0.00057585, 0.00057733,\n",
      "       0.00057436, 0.00057608, 0.00057549, 0.0005715 , 0.00057414,\n",
      "       0.00057444, 0.00057632, 0.00057389, 0.00057297, 0.00057707,\n",
      "       0.00057533, 0.00057504, 0.00057454, 0.00057496, 0.00057333,\n",
      "       0.00057421, 0.00057009, 0.00057576, 0.00057717, 0.00057944,\n",
      "       0.00057244, 0.00057601, 0.00057707, 0.00057522, 0.00056989,\n",
      "       0.0005737 , 0.00057252, 0.00057139, 0.00057367, 0.00057718,\n",
      "       0.00057418, 0.00057281, 0.00057165, 0.0005746 , 0.00057713,\n",
      "       0.00057706, 0.00057466, 0.00057101, 0.00057527, 0.00057397,\n",
      "       0.00057524, 0.00057426, 0.00057753, 0.00057567, 0.00057572,\n",
      "       0.00057551, 0.00057458, 0.00057558, 0.00057602, 0.00057586,\n",
      "       0.00057291, 0.00057102], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_42/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/conv2d_56/Conv2D\n",
      "index : 161\n",
      "shape : [192]\n",
      "shape_signature : [192]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.8742561e-09, 4.8586171e-09, 4.8446909e-09, 4.8925508e-09,\n",
      "       4.8735687e-09, 4.8740674e-09, 4.8694671e-09, 4.8781135e-09,\n",
      "       4.8815010e-09, 4.8759232e-09, 4.8912487e-09, 4.8714548e-09,\n",
      "       4.8795914e-09, 4.8657993e-09, 4.8914606e-09, 4.8731530e-09,\n",
      "       4.9001847e-09, 4.8708597e-09, 4.8813287e-09, 4.8872812e-09,\n",
      "       4.8718745e-09, 4.8351199e-09, 4.8839532e-09, 4.8554711e-09,\n",
      "       4.8645981e-09, 4.8590674e-09, 4.8675743e-09, 4.8914477e-09,\n",
      "       4.8784567e-09, 4.8890523e-09, 4.8791935e-09, 4.8733413e-09,\n",
      "       4.8790789e-09, 4.8568594e-09, 4.8592330e-09, 4.8774038e-09,\n",
      "       4.9023519e-09, 4.8630415e-09, 4.9028204e-09, 4.9184186e-09,\n",
      "       4.8605129e-09, 4.8762798e-09, 4.8792308e-09, 4.8731903e-09,\n",
      "       4.8877400e-09, 4.8573625e-09, 4.8840176e-09, 4.8468207e-09,\n",
      "       4.8648836e-09, 4.8719655e-09, 4.8837503e-09, 4.8744324e-09,\n",
      "       4.8774260e-09, 4.9054991e-09, 4.8601150e-09, 4.8595754e-09,\n",
      "       4.8602424e-09, 4.8590389e-09, 4.8817115e-09, 4.8937943e-09,\n",
      "       4.8709814e-09, 4.8803241e-09, 4.8311630e-09, 4.8843587e-09,\n",
      "       4.9064721e-09, 4.8520286e-09, 4.8753672e-09, 4.8983928e-09,\n",
      "       4.8894706e-09, 4.8884212e-09, 4.8601492e-09, 4.9137356e-09,\n",
      "       4.8808255e-09, 4.8701683e-09, 4.8889373e-09, 4.8455115e-09,\n",
      "       4.8572528e-09, 4.9029110e-09, 4.8685638e-09, 4.8861022e-09,\n",
      "       4.8987978e-09, 4.8969326e-09, 4.8729016e-09, 4.8642068e-09,\n",
      "       4.8914459e-09, 4.8632645e-09, 4.8651985e-09, 4.8917848e-09,\n",
      "       4.8808912e-09, 4.8636637e-09, 4.8550604e-09, 4.8629136e-09,\n",
      "       4.8798086e-09, 4.9082018e-09, 4.8776827e-09, 4.8634159e-09,\n",
      "       4.8591424e-09, 4.8858397e-09, 4.8741788e-09, 4.8934261e-09,\n",
      "       4.9105680e-09, 4.8719038e-09, 4.8986561e-09, 4.8984892e-09,\n",
      "       4.8550994e-09, 4.8868940e-09, 4.8697646e-09, 4.8694715e-09,\n",
      "       4.8655986e-09, 4.8541224e-09, 4.8823825e-09, 4.8522475e-09,\n",
      "       4.8912456e-09, 4.8761311e-09, 4.8554258e-09, 4.8745448e-09,\n",
      "       4.8788760e-09, 4.8490403e-09, 4.8776432e-09, 4.8769757e-09,\n",
      "       4.8659672e-09, 4.8608304e-09, 4.8610747e-09, 4.8761999e-09,\n",
      "       4.8625304e-09, 4.8659712e-09, 4.8659112e-09, 4.8777546e-09,\n",
      "       4.8941828e-09, 4.8924016e-09, 4.9212745e-09, 4.8649942e-09,\n",
      "       4.8862385e-09, 4.8782036e-09, 4.8847610e-09, 4.8900191e-09,\n",
      "       4.8583484e-09, 4.8658744e-09, 4.8839732e-09, 4.8965294e-09,\n",
      "       4.8713651e-09, 4.8859263e-09, 4.8808806e-09, 4.8470414e-09,\n",
      "       4.8694537e-09, 4.8719677e-09, 4.8879869e-09, 4.8673097e-09,\n",
      "       4.8595084e-09, 4.8943138e-09, 4.8795612e-09, 4.8771298e-09,\n",
      "       4.8728781e-09, 4.8764521e-09, 4.8625521e-09, 4.8700648e-09,\n",
      "       4.8350870e-09, 4.8831654e-09, 4.8951425e-09, 4.9144186e-09,\n",
      "       4.8550333e-09, 4.8853552e-09, 4.8943294e-09, 4.8786295e-09,\n",
      "       4.8334465e-09, 4.8657669e-09, 4.8556887e-09, 4.8461555e-09,\n",
      "       4.8654747e-09, 4.8952526e-09, 4.8698228e-09, 4.8581654e-09,\n",
      "       4.8483586e-09, 4.8733484e-09, 4.8948383e-09, 4.8942352e-09,\n",
      "       4.8738547e-09, 4.8429123e-09, 4.8790580e-09, 4.8679887e-09,\n",
      "       4.8787876e-09, 4.8704676e-09, 4.8982116e-09, 4.8824016e-09,\n",
      "       4.8828861e-09, 4.8810707e-09, 4.8731721e-09, 4.8816546e-09,\n",
      "       4.8854054e-09, 4.8840723e-09, 4.8590625e-09, 4.8430300e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_57/Conv2D\n",
      "index : 162\n",
      "shape : [1152    1    1  192]\n",
      "shape_signature : [1152    1    1  192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00053004, 0.00052763, 0.00052605, ..., 0.00052121, 0.00052764,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.00052946], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_43/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_57/Conv2D\n",
      "index : 163\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.0816620e-08, 9.0403546e-08, 9.0132978e-08, ..., 8.9304365e-08,\n",
      "       9.0405578e-08, 9.0718423e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_44/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/depthwise_conv2d_14/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D\n",
      "index : 164\n",
      "shape : [   1    5    5 1152]\n",
      "shape_signature : [   1    5    5 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00012313, 0.00011502, 0.00012185, ..., 0.00012021, 0.00012466,\n",
      "       0.00012084], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_44/FusedBatchNormV3\n",
      "index : 165\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.3823241e-09, 6.8956871e-09, 7.3053474e-09, ..., 7.2070363e-09,\n",
      "       7.4741102e-09, 7.2450486e-09], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/Conv2D\n",
      "index : 166\n",
      "shape : [ 288    1    1 1152]\n",
      "shape_signature : [ 288    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00051157, 0.0005083 , 0.00050913, 0.00051247, 0.00051105,\n",
      "       0.0005112 , 0.00051022, 0.00051109, 0.00050986, 0.00051399,\n",
      "       0.00050906, 0.00051088, 0.00050836, 0.00050876, 0.00050808,\n",
      "       0.00050748, 0.00050983, 0.00051037, 0.00050867, 0.00050845,\n",
      "       0.00050811, 0.000512  , 0.00050805, 0.00051066, 0.00051063,\n",
      "       0.00050843, 0.00051061, 0.00051119, 0.00050839, 0.00051015,\n",
      "       0.00051073, 0.00050803, 0.00051025, 0.00050834, 0.00051227,\n",
      "       0.00051008, 0.00050885, 0.00050843, 0.00050988, 0.00050814,\n",
      "       0.00050997, 0.00051091, 0.00051218, 0.00050841, 0.00051096,\n",
      "       0.0005091 , 0.00050912, 0.0005102 , 0.00051086, 0.00050895,\n",
      "       0.00050892, 0.00051084, 0.00050893, 0.00050924, 0.00050855,\n",
      "       0.00050726, 0.00050772, 0.00051081, 0.00050798, 0.0005092 ,\n",
      "       0.00051161, 0.0005141 , 0.00050993, 0.00051296, 0.00050928,\n",
      "       0.00050512, 0.00051025, 0.00050914, 0.00050988, 0.00051012,\n",
      "       0.00051031, 0.00050997, 0.00051003, 0.00050761, 0.00051121,\n",
      "       0.0005113 , 0.00051028, 0.00050923, 0.0005074 , 0.00051183,\n",
      "       0.00051343, 0.00050749, 0.00050865, 0.00051006, 0.00051121,\n",
      "       0.00050979, 0.00050821, 0.00050807, 0.00051256, 0.00050943,\n",
      "       0.0005074 , 0.0005101 , 0.00050816, 0.00051119, 0.00051115,\n",
      "       0.00050729, 0.00050997, 0.00050976, 0.00051098, 0.00050895,\n",
      "       0.00051012, 0.00051047, 0.00051291, 0.00050888, 0.00050815,\n",
      "       0.00050962, 0.00050815, 0.00050668, 0.00050934, 0.00050891,\n",
      "       0.00051011, 0.00050965, 0.0005108 , 0.00050947, 0.00050698,\n",
      "       0.00050852, 0.00050896, 0.00051045, 0.00051384, 0.00050878,\n",
      "       0.00050928, 0.00050975, 0.00050824, 0.00050979, 0.00051062,\n",
      "       0.0005108 , 0.0005095 , 0.00051141, 0.00050965, 0.00050939,\n",
      "       0.00050791, 0.0005107 , 0.00051007, 0.00051035, 0.0005105 ,\n",
      "       0.00051035, 0.00050937, 0.00050811, 0.00050939, 0.00050932,\n",
      "       0.00050689, 0.00051112, 0.00050901, 0.00050852, 0.00050978,\n",
      "       0.00050952, 0.00050662, 0.00050915, 0.00050901, 0.00050923,\n",
      "       0.00050816, 0.00051034, 0.00050815, 0.00050874, 0.00050718,\n",
      "       0.00050997, 0.00050898, 0.00051006, 0.00050832, 0.0005076 ,\n",
      "       0.00050984, 0.00050868, 0.00050819, 0.00050818, 0.00050982,\n",
      "       0.00050734, 0.00051177, 0.00050663, 0.00050894, 0.00050808,\n",
      "       0.00050955, 0.00050926, 0.00050996, 0.00050921, 0.00051015,\n",
      "       0.0005073 , 0.00050798, 0.00050781, 0.00051139, 0.0005104 ,\n",
      "       0.00050951, 0.00050811, 0.00051098, 0.00050964, 0.00051193,\n",
      "       0.000506  , 0.00051278, 0.00051164, 0.00050929, 0.00050904,\n",
      "       0.00050768, 0.00050969, 0.00051151, 0.00050929, 0.00051055,\n",
      "       0.00050826, 0.0005098 , 0.0005101 , 0.00050914, 0.00051003,\n",
      "       0.00050758, 0.00050789, 0.00050858, 0.00051424, 0.00051186,\n",
      "       0.00050952, 0.00051002, 0.00051036, 0.00050872, 0.00050927,\n",
      "       0.00050877, 0.00051285, 0.00050757, 0.00050974, 0.00051018,\n",
      "       0.00051062, 0.00051132, 0.00050924, 0.00050775, 0.00050906,\n",
      "       0.00051131, 0.00050992, 0.0005091 , 0.00051182, 0.00051053,\n",
      "       0.00051027, 0.00050908, 0.00051013, 0.00051183, 0.00051175,\n",
      "       0.00050898, 0.0005127 , 0.00050966, 0.00051227, 0.00050914,\n",
      "       0.00051049, 0.00050995, 0.00050687, 0.00050761, 0.00051268,\n",
      "       0.00051143, 0.00051125, 0.00050997, 0.00051093, 0.00050915,\n",
      "       0.00050867, 0.00050829, 0.00050834, 0.00051176, 0.00050857,\n",
      "       0.00050858, 0.00050935, 0.0005077 , 0.00050859, 0.00050807,\n",
      "       0.00050808, 0.00051009, 0.00050999, 0.00050778, 0.00051129,\n",
      "       0.00051071, 0.00051019, 0.00051027, 0.00050675, 0.00050903,\n",
      "       0.00050675, 0.00050869, 0.00051095, 0.00050782, 0.00050853,\n",
      "       0.00051103, 0.00051026, 0.00051095, 0.00050927, 0.00051138,\n",
      "       0.00050776, 0.00050935, 0.00050975, 0.00050994, 0.00051059,\n",
      "       0.00050947, 0.0005079 , 0.00051005, 0.00050945, 0.00050995,\n",
      "       0.00050961, 0.00050964, 0.00051215], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/BiasAdd/ReadVariableOp/resource\n",
      "index : 167\n",
      "shape : [288]\n",
      "shape_signature : [288]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.5720675e-08, 1.5620076e-08, 1.5645591e-08, 1.5748288e-08,\n",
      "       1.5704623e-08, 1.5709270e-08, 1.5679037e-08, 1.5706016e-08,\n",
      "       1.5668025e-08, 1.5794948e-08, 1.5643447e-08, 1.5699415e-08,\n",
      "       1.5621906e-08, 1.5634177e-08, 1.5613553e-08, 1.5594914e-08,\n",
      "       1.5667318e-08, 1.5683634e-08, 1.5631523e-08, 1.5624718e-08,\n",
      "       1.5614248e-08, 1.5733935e-08, 1.5612375e-08, 1.5692690e-08,\n",
      "       1.5691855e-08, 1.5624179e-08, 1.5691233e-08, 1.5709118e-08,\n",
      "       1.5622927e-08, 1.5677001e-08, 1.5694990e-08, 1.5611826e-08,\n",
      "       1.5680230e-08, 1.5621474e-08, 1.5742208e-08, 1.5674965e-08,\n",
      "       1.5637012e-08, 1.5624041e-08, 1.5668864e-08, 1.5615230e-08,\n",
      "       1.5671549e-08, 1.5700355e-08, 1.5739356e-08, 1.5623533e-08,\n",
      "       1.5701945e-08, 1.5644821e-08, 1.5645341e-08, 1.5678431e-08,\n",
      "       1.5698852e-08, 1.5640209e-08, 1.5639282e-08, 1.5698154e-08,\n",
      "       1.5639619e-08, 1.5649015e-08, 1.5627908e-08, 1.5588311e-08,\n",
      "       1.5602250e-08, 1.5697310e-08, 1.5610391e-08, 1.5647673e-08,\n",
      "       1.5722001e-08, 1.5798493e-08, 1.5670283e-08, 1.5763435e-08,\n",
      "       1.5650128e-08, 1.5522330e-08, 1.5680028e-08, 1.5645840e-08,\n",
      "       1.5668759e-08, 1.5676115e-08, 1.5681982e-08, 1.5671587e-08,\n",
      "       1.5673381e-08, 1.5599108e-08, 1.5709469e-08, 1.5712375e-08,\n",
      "       1.5680891e-08, 1.5648670e-08, 1.5592617e-08, 1.5728681e-08,\n",
      "       1.5777896e-08, 1.5595125e-08, 1.5630878e-08, 1.5674367e-08,\n",
      "       1.5709469e-08, 1.5666050e-08, 1.5617362e-08, 1.5613100e-08,\n",
      "       1.5751171e-08, 1.5655038e-08, 1.5592553e-08, 1.5675417e-08,\n",
      "       1.5615905e-08, 1.5709054e-08, 1.5707725e-08, 1.5589066e-08,\n",
      "       1.5671414e-08, 1.5665147e-08, 1.5702497e-08, 1.5640248e-08,\n",
      "       1.5676147e-08, 1.5686728e-08, 1.5761819e-08, 1.5638044e-08,\n",
      "       1.5615571e-08, 1.5660781e-08, 1.5615568e-08, 1.5570297e-08,\n",
      "       1.5652178e-08, 1.5638886e-08, 1.5675749e-08, 1.5661524e-08,\n",
      "       1.5697070e-08, 1.5656161e-08, 1.5579577e-08, 1.5627062e-08,\n",
      "       1.5640561e-08, 1.5686167e-08, 1.5790524e-08, 1.5635043e-08,\n",
      "       1.5650228e-08, 1.5664858e-08, 1.5618442e-08, 1.5665988e-08,\n",
      "       1.5691507e-08, 1.5697051e-08, 1.5657021e-08, 1.5715802e-08,\n",
      "       1.5661650e-08, 1.5653603e-08, 1.5608244e-08, 1.5693917e-08,\n",
      "       1.5674694e-08, 1.5683217e-08, 1.5687677e-08, 1.5683097e-08,\n",
      "       1.5653134e-08, 1.5614283e-08, 1.5653681e-08, 1.5651484e-08,\n",
      "       1.5576859e-08, 1.5706958e-08, 1.5642010e-08, 1.5626961e-08,\n",
      "       1.5665695e-08, 1.5657688e-08, 1.5568572e-08, 1.5646272e-08,\n",
      "       1.5641927e-08, 1.5648805e-08, 1.5615759e-08, 1.5682934e-08,\n",
      "       1.5615688e-08, 1.5633663e-08, 1.5585691e-08, 1.5671620e-08,\n",
      "       1.5641149e-08, 1.5674198e-08, 1.5620735e-08, 1.5598530e-08,\n",
      "       1.5667560e-08, 1.5631789e-08, 1.5616662e-08, 1.5616422e-08,\n",
      "       1.5666934e-08, 1.5590723e-08, 1.5726780e-08, 1.5568739e-08,\n",
      "       1.5639845e-08, 1.5613505e-08, 1.5658685e-08, 1.5649725e-08,\n",
      "       1.5671292e-08, 1.5648050e-08, 1.5676862e-08, 1.5589290e-08,\n",
      "       1.5610189e-08, 1.5604968e-08, 1.5715047e-08, 1.5684686e-08,\n",
      "       1.5657331e-08, 1.5614400e-08, 1.5702405e-08, 1.5661353e-08,\n",
      "       1.5731853e-08, 1.5549359e-08, 1.5757966e-08, 1.5722936e-08,\n",
      "       1.5650444e-08, 1.5642986e-08, 1.5601060e-08, 1.5662819e-08,\n",
      "       1.5718911e-08, 1.5650620e-08, 1.5689187e-08, 1.5619042e-08,\n",
      "       1.5666346e-08, 1.5675559e-08, 1.5646068e-08, 1.5673375e-08,\n",
      "       1.5597937e-08, 1.5607460e-08, 1.5628736e-08, 1.5802605e-08,\n",
      "       1.5729592e-08, 1.5657591e-08, 1.5672974e-08, 1.5683357e-08,\n",
      "       1.5633084e-08, 1.5649908e-08, 1.5634457e-08, 1.5760063e-08,\n",
      "       1.5597735e-08, 1.5664416e-08, 1.5677882e-08, 1.5691562e-08,\n",
      "       1.5712901e-08, 1.5649187e-08, 1.5603213e-08, 1.5643497e-08,\n",
      "       1.5712676e-08, 1.5670089e-08, 1.5644758e-08, 1.5728451e-08,\n",
      "       1.5688739e-08, 1.5680778e-08, 1.5644174e-08, 1.5676475e-08,\n",
      "       1.5728608e-08, 1.5726316e-08, 1.5640977e-08, 1.5755433e-08,\n",
      "       1.5662058e-08, 1.5742302e-08, 1.5646064e-08, 1.5687526e-08,\n",
      "       1.5670935e-08, 1.5576264e-08, 1.5598843e-08, 1.5754726e-08,\n",
      "       1.5716219e-08, 1.5710924e-08, 1.5671418e-08, 1.5700868e-08,\n",
      "       1.5646325e-08, 1.5631601e-08, 1.5619765e-08, 1.5621396e-08,\n",
      "       1.5726473e-08, 1.5628435e-08, 1.5628839e-08, 1.5652461e-08,\n",
      "       1.5601733e-08, 1.5629009e-08, 1.5613228e-08, 1.5613251e-08,\n",
      "       1.5675118e-08, 1.5672095e-08, 1.5604261e-08, 1.5712059e-08,\n",
      "       1.5694363e-08, 1.5678332e-08, 1.5680582e-08, 1.5572530e-08,\n",
      "       1.5642486e-08, 1.5572564e-08, 1.5632153e-08, 1.5701699e-08,\n",
      "       1.5605346e-08, 1.5627338e-08, 1.5704128e-08, 1.5680413e-08,\n",
      "       1.5701561e-08, 1.5649967e-08, 1.5714688e-08, 1.5603471e-08,\n",
      "       1.5652381e-08, 1.5664806e-08, 1.5670453e-08, 1.5690494e-08,\n",
      "       1.5656246e-08, 1.5607840e-08, 1.5673836e-08, 1.5655619e-08,\n",
      "       1.5670908e-08, 1.5660369e-08, 1.5661291e-08, 1.5738447e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/Conv2D\n",
      "index : 168\n",
      "shape : [1152    1    1  288]\n",
      "shape_signature : [1152    1    1  288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00050668, 0.00050994, 0.00050176, ..., 0.00050685, 0.00050936,\n",
      "       0.00050623], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/BiasAdd/ReadVariableOp/resource\n",
      "index : 169\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.04392957e-08, 1.05063620e-08, 1.03377378e-08, ...,\n",
      "       1.04427045e-08, 1.04943947e-08, 1.04299032e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D\n",
      "index : 170\n",
      "shape : [ 192    1    1 1152]\n",
      "shape_signature : [ 192    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00057369, 0.00057905, 0.00057453, 0.00057591, 0.00057652,\n",
      "       0.0005771 , 0.00057337, 0.00057843, 0.00057381, 0.00057581,\n",
      "       0.0005764 , 0.00057614, 0.00057735, 0.0005745 , 0.00057372,\n",
      "       0.00057603, 0.00057161, 0.00057914, 0.00057051, 0.00057185,\n",
      "       0.00057774, 0.00057721, 0.00057508, 0.00057889, 0.00057569,\n",
      "       0.00057688, 0.00057723, 0.00057577, 0.00057329, 0.00057754,\n",
      "       0.00057456, 0.00057439, 0.00057277, 0.00057529, 0.00057422,\n",
      "       0.00057241, 0.00057348, 0.00056964, 0.0005749 , 0.00057682,\n",
      "       0.00057303, 0.00057019, 0.00057566, 0.0005766 , 0.00057592,\n",
      "       0.00057565, 0.00057294, 0.00057392, 0.00057044, 0.00057453,\n",
      "       0.00057506, 0.00057001, 0.00057801, 0.00057134, 0.00057202,\n",
      "       0.0005731 , 0.00057443, 0.00057743, 0.00057465, 0.00057356,\n",
      "       0.00057176, 0.00057161, 0.00057734, 0.00057335, 0.00057695,\n",
      "       0.0005767 , 0.00057596, 0.00057567, 0.00057129, 0.00057248,\n",
      "       0.00057509, 0.00057371, 0.00057157, 0.00057471, 0.00057576,\n",
      "       0.00057555, 0.00057488, 0.00057818, 0.00057542, 0.00057378,\n",
      "       0.0005728 , 0.00057654, 0.00057151, 0.00057448, 0.00057162,\n",
      "       0.00057566, 0.00057778, 0.00057417, 0.00057522, 0.00057512,\n",
      "       0.00057504, 0.0005738 , 0.00057212, 0.00057503, 0.00057758,\n",
      "       0.00057148, 0.00057616, 0.00057283, 0.00057191, 0.00057595,\n",
      "       0.00057019, 0.00057683, 0.00057286, 0.00057614, 0.00057262,\n",
      "       0.00057202, 0.00057653, 0.00057661, 0.00057545, 0.00057344,\n",
      "       0.00057802, 0.00057586, 0.00057376, 0.00057332, 0.00057286,\n",
      "       0.00057764, 0.00057171, 0.00057415, 0.00057507, 0.00057528,\n",
      "       0.00057486, 0.00057442, 0.00057084, 0.00057743, 0.00057423,\n",
      "       0.00057681, 0.00057631, 0.00057677, 0.00057566, 0.00057565,\n",
      "       0.00056988, 0.00057499, 0.00057264, 0.00057528, 0.0005729 ,\n",
      "       0.00057357, 0.0005756 , 0.00057869, 0.00057125, 0.00057896,\n",
      "       0.0005751 , 0.00057347, 0.00057743, 0.00057238, 0.00057769,\n",
      "       0.00057634, 0.00057474, 0.00057798, 0.00057938, 0.00057481,\n",
      "       0.00057199, 0.0005741 , 0.00057675, 0.00057051, 0.00057511,\n",
      "       0.00057711, 0.00057819, 0.00057536, 0.00057496, 0.00057499,\n",
      "       0.00057281, 0.00057524, 0.00057277, 0.00057255, 0.00057624,\n",
      "       0.00057818, 0.00057519, 0.00057484, 0.00057361, 0.00057552,\n",
      "       0.00057748, 0.00057087, 0.00057958, 0.00057343, 0.00057123,\n",
      "       0.00057384, 0.00057881, 0.00057352, 0.00057658, 0.00057852,\n",
      "       0.00057759, 0.00057425, 0.0005695 , 0.00057212, 0.00057727,\n",
      "       0.00057517, 0.00057034, 0.00057756, 0.00057613, 0.00057482,\n",
      "       0.00057593, 0.00057448], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_45/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D\n",
      "index : 171\n",
      "shape : [192]\n",
      "shape_signature : [192]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.5774020e-09, 4.6201674e-09, 4.5840340e-09, 4.5951043e-09,\n",
      "       4.5999640e-09, 4.6045843e-09, 4.5748432e-09, 4.6151838e-09,\n",
      "       4.5783395e-09, 4.5942588e-09, 4.5989701e-09, 4.5969126e-09,\n",
      "       4.6065893e-09, 4.5837933e-09, 4.5775685e-09, 4.5960249e-09,\n",
      "       4.5607402e-09, 4.6208148e-09, 4.5519686e-09, 4.5626587e-09,\n",
      "       4.6096664e-09, 4.6054129e-09, 4.5884718e-09, 4.6188795e-09,\n",
      "       4.5933022e-09, 4.6027790e-09, 4.6055808e-09, 4.5939590e-09,\n",
      "       4.5742130e-09, 4.6080468e-09, 4.5843356e-09, 4.5829500e-09,\n",
      "       4.5699884e-09, 4.5901376e-09, 4.5815698e-09, 4.5671684e-09,\n",
      "       4.5756963e-09, 4.5450812e-09, 4.5870356e-09, 4.6023119e-09,\n",
      "       4.5721200e-09, 4.5494204e-09, 4.5931228e-09, 4.6005648e-09,\n",
      "       4.5951434e-09, 4.5929758e-09, 4.5713593e-09, 4.5792188e-09,\n",
      "       4.5514508e-09, 4.5840767e-09, 4.5882698e-09, 4.5479704e-09,\n",
      "       4.6118691e-09, 4.5585811e-09, 4.5640132e-09, 4.5726525e-09,\n",
      "       4.5832742e-09, 4.6071995e-09, 4.5850266e-09, 4.5763175e-09,\n",
      "       4.5619490e-09, 4.5607398e-09, 4.6064801e-09, 4.5746740e-09,\n",
      "       4.6033586e-09, 4.6014015e-09, 4.5954809e-09, 4.5932036e-09,\n",
      "       4.5581912e-09, 4.5676947e-09, 4.5885304e-09, 4.5775370e-09,\n",
      "       4.5604267e-09, 4.5855417e-09, 4.5938453e-09, 4.5922333e-09,\n",
      "       4.5868394e-09, 4.6132049e-09, 4.5911528e-09, 4.5780721e-09,\n",
      "       4.5702837e-09, 4.6001207e-09, 4.5600106e-09, 4.5837005e-09,\n",
      "       4.5608881e-09, 4.5930806e-09, 4.6099791e-09, 4.5812092e-09,\n",
      "       4.5895421e-09, 4.5887547e-09, 4.5881312e-09, 4.5782089e-09,\n",
      "       4.5648769e-09, 4.5880313e-09, 4.6084221e-09, 4.5597126e-09,\n",
      "       4.5970849e-09, 4.5704791e-09, 4.5631876e-09, 4.5953881e-09,\n",
      "       4.5494306e-09, 4.6024216e-09, 4.5707407e-09, 4.5969282e-09,\n",
      "       4.5688098e-09, 4.5640118e-09, 4.5999866e-09, 4.6007003e-09,\n",
      "       4.5914406e-09, 4.5753654e-09, 4.6119446e-09, 4.5946922e-09,\n",
      "       4.5779203e-09, 4.5744177e-09, 4.5707300e-09, 4.6088968e-09,\n",
      "       4.5615880e-09, 4.5810404e-09, 4.5884052e-09, 4.5900448e-09,\n",
      "       4.5866901e-09, 4.5831667e-09, 4.5546016e-09, 4.6071809e-09,\n",
      "       4.5816861e-09, 4.6022692e-09, 4.5982795e-09, 4.6019624e-09,\n",
      "       4.5930837e-09, 4.5929802e-09, 4.5469783e-09, 4.5877449e-09,\n",
      "       4.5690123e-09, 4.5900150e-09, 4.5710382e-09, 4.5764157e-09,\n",
      "       4.5926436e-09, 4.6172319e-09, 4.5579291e-09, 4.6194066e-09,\n",
      "       4.5885864e-09, 4.5756350e-09, 4.6071875e-09, 4.5669166e-09,\n",
      "       4.6093196e-09, 4.5985344e-09, 4.5857194e-09, 4.6115933e-09,\n",
      "       4.6227782e-09, 4.5863420e-09, 4.5637933e-09, 4.5806092e-09,\n",
      "       4.6018007e-09, 4.5519792e-09, 4.5886845e-09, 4.6046793e-09,\n",
      "       4.6132476e-09, 4.5907034e-09, 4.5874602e-09, 4.5877204e-09,\n",
      "       4.5703148e-09, 4.5896988e-09, 4.5700355e-09, 4.5682467e-09,\n",
      "       4.5977280e-09, 4.6131925e-09, 4.5893520e-09, 4.5865445e-09,\n",
      "       4.5767101e-09, 4.5919477e-09, 4.6075899e-09, 4.5548396e-09,\n",
      "       4.6243991e-09, 4.5752544e-09, 4.5577591e-09, 4.5785602e-09,\n",
      "       4.6182049e-09, 4.5759907e-09, 4.6004422e-09, 4.6159356e-09,\n",
      "       4.6085220e-09, 4.5818527e-09, 4.5439070e-09, 4.5648529e-09,\n",
      "       4.6059334e-09, 4.5891855e-09, 4.5506505e-09, 4.6082129e-09,\n",
      "       4.5968713e-09, 4.5864130e-09, 4.5952615e-09, 4.5836956e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_3/conv2d_68/Conv2D\n",
      "index : 172\n",
      "shape : [ 64   1   1 192]\n",
      "shape_signature : [ 64   1   1 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00088631, 0.00087551, 0.00082755, 0.00087016, 0.00084837,\n",
      "       0.00087646, 0.0008496 , 0.00082552, 0.00090068, 0.0008799 ,\n",
      "       0.00080685, 0.00090007, 0.00088254, 0.00086984, 0.00086048,\n",
      "       0.00084374, 0.00085224, 0.00086714, 0.00086311, 0.00085675,\n",
      "       0.00084716, 0.00080829, 0.00084088, 0.00087064, 0.00081306,\n",
      "       0.00086639, 0.00089815, 0.00085054, 0.00079245, 0.00084397,\n",
      "       0.00078779, 0.00084187, 0.00090304, 0.00086876, 0.00085263,\n",
      "       0.0008735 , 0.00083565, 0.00089601, 0.00086448, 0.00086096,\n",
      "       0.00087638, 0.00089034, 0.00083616, 0.00092984, 0.00088602,\n",
      "       0.00083943, 0.00083121, 0.00085636, 0.00087035, 0.00085555,\n",
      "       0.000856  , 0.00082451, 0.00089332, 0.00087826, 0.0008328 ,\n",
      "       0.00086604, 0.00086053, 0.00088135, 0.00084871, 0.00088471,\n",
      "       0.00082877, 0.00089314, 0.00088716, 0.00084447], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_3/batch_normalization_52/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_3/conv2d_68/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_3/conv2d_68/BiasAdd\n",
      "index : 173\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8024849e-07, 1.7805310e-07, 1.6829799e-07, 1.7696503e-07,\n",
      "       1.7253315e-07, 1.7824520e-07, 1.7278310e-07, 1.6788643e-07,\n",
      "       1.8317124e-07, 1.7894470e-07, 1.6408920e-07, 1.8304732e-07,\n",
      "       1.7948260e-07, 1.7689804e-07, 1.7499453e-07, 1.7159130e-07,\n",
      "       1.7332067e-07, 1.7635038e-07, 1.7553087e-07, 1.7423694e-07,\n",
      "       1.7228575e-07, 1.6438193e-07, 1.7101029e-07, 1.7706137e-07,\n",
      "       1.6535219e-07, 1.7619756e-07, 1.8265700e-07, 1.7297461e-07,\n",
      "       1.6115958e-07, 1.7163784e-07, 1.6021220e-07, 1.7121171e-07,\n",
      "       1.8365112e-07, 1.7667860e-07, 1.7339987e-07, 1.7764312e-07,\n",
      "       1.6994635e-07, 1.8222214e-07, 1.7581000e-07, 1.7509379e-07,\n",
      "       1.7822912e-07, 1.8106718e-07, 1.7004938e-07, 1.8910069e-07,\n",
      "       1.8018940e-07, 1.7071454e-07, 1.6904251e-07, 1.7415756e-07,\n",
      "       1.7700337e-07, 1.7399321e-07, 1.7408527e-07, 1.6768064e-07,\n",
      "       1.8167422e-07, 1.7861244e-07, 1.6936586e-07, 1.7612706e-07,\n",
      "       1.7500523e-07, 1.7924062e-07, 1.7260091e-07, 1.7992318e-07,\n",
      "       1.6854625e-07, 1.8163797e-07, 1.8042060e-07, 1.7173981e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/strided_slice\n",
      "index : 174\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001960653578862548, -128)\n",
      "quantization_parameters : {'scales': array([0.00196065], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/strided_slice\n",
      "index : 175\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00130754173733294, -128)\n",
      "quantization_parameters : {'scales': array([0.00130754], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/conv2d_61/Conv2D\n",
      "index : 176\n",
      "shape : [1152    1    1  192]\n",
      "shape_signature : [1152    1    1  192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00049729, 0.000519  , 0.00051629, ..., 0.00052154, 0.00050733,\n",
      "       0.00050879], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_46/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_6/mb_conv_15/conv2d_61/Conv2D\n",
      "index : 177\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.01134532e-07, 1.05549027e-07, 1.04997852e-07, ...,\n",
      "       1.06065244e-07, 1.03174706e-07, 1.03472203e-07], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_47/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/depthwise_conv2d_15/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D\n",
      "index : 178\n",
      "shape : [   1    3    3 1152]\n",
      "shape_signature : [   1    3    3 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00017446, 0.00018439, 0.00019275, ..., 0.00019077, 0.00017016,\n",
      "       0.00016777], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_47/FusedBatchNormV3\n",
      "index : 179\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.1227842e-08, 1.1866990e-08, 1.2404787e-08, ..., 1.2277546e-08,\n",
      "       1.0950941e-08, 1.0797148e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D\n",
      "index : 180\n",
      "shape : [ 288    1    1 1152]\n",
      "shape_signature : [ 288    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00050921, 0.00050919, 0.00050965, 0.00050726, 0.00050993,\n",
      "       0.00050917, 0.00051031, 0.00051212, 0.0005095 , 0.00050721,\n",
      "       0.00050947, 0.00050814, 0.00050996, 0.00050822, 0.00050711,\n",
      "       0.00051086, 0.00051011, 0.00050859, 0.00051019, 0.00050942,\n",
      "       0.00050985, 0.00050842, 0.00050905, 0.00050843, 0.00050844,\n",
      "       0.00050861, 0.00050864, 0.00050965, 0.00051335, 0.00050816,\n",
      "       0.00051184, 0.00051122, 0.00050725, 0.00050803, 0.00051173,\n",
      "       0.00051013, 0.00050845, 0.00051069, 0.00051148, 0.00050959,\n",
      "       0.00051027, 0.00050923, 0.00051013, 0.00051097, 0.00051101,\n",
      "       0.00051234, 0.00050786, 0.00050781, 0.00050757, 0.00050993,\n",
      "       0.00051125, 0.0005101 , 0.00050804, 0.00051055, 0.00050942,\n",
      "       0.00050882, 0.00050839, 0.0005124 , 0.00050722, 0.00050848,\n",
      "       0.00051049, 0.00051028, 0.00051118, 0.00050836, 0.00051231,\n",
      "       0.00051169, 0.00051006, 0.00050944, 0.00050698, 0.00050822,\n",
      "       0.00051105, 0.00051399, 0.00051102, 0.00050941, 0.00050744,\n",
      "       0.00051084, 0.00051151, 0.00051046, 0.00050964, 0.00050758,\n",
      "       0.00050827, 0.00050953, 0.00050961, 0.00051193, 0.00050828,\n",
      "       0.00051174, 0.00051403, 0.0005114 , 0.0005072 , 0.00051227,\n",
      "       0.00050775, 0.00050879, 0.0005115 , 0.00050983, 0.00050844,\n",
      "       0.00050991, 0.00050926, 0.0005131 , 0.00051258, 0.00051218,\n",
      "       0.00050896, 0.00051214, 0.00050939, 0.00051292, 0.00050759,\n",
      "       0.00050844, 0.00050897, 0.00050928, 0.00050942, 0.00050956,\n",
      "       0.00051014, 0.00050982, 0.00051003, 0.00050737, 0.00051084,\n",
      "       0.000509  , 0.00050998, 0.00051426, 0.00050961, 0.00050717,\n",
      "       0.00050804, 0.0005085 , 0.00050977, 0.00050951, 0.00050882,\n",
      "       0.00050914, 0.00050922, 0.00051492, 0.00050864, 0.00050654,\n",
      "       0.00050895, 0.00050743, 0.00050883, 0.00050735, 0.00050979,\n",
      "       0.00050802, 0.00050892, 0.00050884, 0.00050983, 0.00050796,\n",
      "       0.00050775, 0.00050804, 0.00050842, 0.00050942, 0.00050709,\n",
      "       0.00050843, 0.00050895, 0.00051023, 0.00050842, 0.00051038,\n",
      "       0.00050891, 0.00050828, 0.00050891, 0.00050909, 0.0005086 ,\n",
      "       0.00051047, 0.00051364, 0.00051044, 0.00050811, 0.00050873,\n",
      "       0.00050931, 0.00051175, 0.0005104 , 0.00051171, 0.00050705,\n",
      "       0.00051031, 0.00050988, 0.00050923, 0.00050973, 0.00050887,\n",
      "       0.00050768, 0.00050915, 0.00050716, 0.00051195, 0.00051137,\n",
      "       0.00050844, 0.00051052, 0.00050787, 0.00050801, 0.00050905,\n",
      "       0.00050807, 0.00050768, 0.0005063 , 0.00050858, 0.0005078 ,\n",
      "       0.00050906, 0.00050983, 0.00050726, 0.00051101, 0.00050997,\n",
      "       0.00050868, 0.00051235, 0.00050979, 0.00051094, 0.00051109,\n",
      "       0.00051017, 0.00050534, 0.00050961, 0.00050976, 0.00050762,\n",
      "       0.00050841, 0.00051229, 0.00050758, 0.00050956, 0.00050889,\n",
      "       0.00050751, 0.00050748, 0.00050782, 0.00051047, 0.00051078,\n",
      "       0.00051091, 0.00050854, 0.00051117, 0.00051142, 0.00051043,\n",
      "       0.00051184, 0.00050968, 0.00050758, 0.00050897, 0.00050926,\n",
      "       0.00051091, 0.0005091 , 0.00051067, 0.00050884, 0.00050874,\n",
      "       0.00051083, 0.00051212, 0.00051092, 0.00050979, 0.00050769,\n",
      "       0.00050805, 0.00051153, 0.00051267, 0.00051009, 0.00051282,\n",
      "       0.00051117, 0.00051196, 0.00050922, 0.0005084 , 0.00051111,\n",
      "       0.00051015, 0.00051063, 0.00050878, 0.00050812, 0.00050845,\n",
      "       0.00050931, 0.00051417, 0.00051298, 0.00051004, 0.00051   ,\n",
      "       0.0005073 , 0.00051165, 0.00050767, 0.00051156, 0.00050784,\n",
      "       0.00051207, 0.00051183, 0.00050799, 0.00050932, 0.00051342,\n",
      "       0.00051128, 0.00051098, 0.00051127, 0.00051094, 0.00050899,\n",
      "       0.00050904, 0.00050798, 0.00051168, 0.00051338, 0.00050927,\n",
      "       0.00051118, 0.00050744, 0.00051165, 0.00050811, 0.00050906,\n",
      "       0.00051227, 0.00050814, 0.00050799, 0.00050985, 0.00051161,\n",
      "       0.00051175, 0.00050919, 0.00050891, 0.00050806, 0.00051376,\n",
      "       0.00050786, 0.00050928, 0.0005094 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/BiasAdd/ReadVariableOp/resource\n",
      "index : 181\n",
      "shape : [288]\n",
      "shape_signature : [288]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.7366299e-08, 1.7365661e-08, 1.7381449e-08, 1.7299964e-08,\n",
      "       1.7391077e-08, 1.7364981e-08, 1.7404064e-08, 1.7465830e-08,\n",
      "       1.7376216e-08, 1.7298182e-08, 1.7375230e-08, 1.7330008e-08,\n",
      "       1.7392091e-08, 1.7332777e-08, 1.7294658e-08, 1.7422526e-08,\n",
      "       1.7397085e-08, 1.7345107e-08, 1.7399769e-08, 1.7373699e-08,\n",
      "       1.7388224e-08, 1.7339577e-08, 1.7361044e-08, 1.7339769e-08,\n",
      "       1.7340110e-08, 1.7346069e-08, 1.7347016e-08, 1.7381565e-08,\n",
      "       1.7507464e-08, 1.7330507e-08, 1.7456083e-08, 1.7435125e-08,\n",
      "       1.7299545e-08, 1.7326270e-08, 1.7452457e-08, 1.7397861e-08,\n",
      "       1.7340611e-08, 1.7416911e-08, 1.7443689e-08, 1.7379426e-08,\n",
      "       1.7402646e-08, 1.7366979e-08, 1.7397872e-08, 1.7426306e-08,\n",
      "       1.7427777e-08, 1.7473043e-08, 1.7320451e-08, 1.7318635e-08,\n",
      "       1.7310414e-08, 1.7391057e-08, 1.7435910e-08, 1.7396918e-08,\n",
      "       1.7326625e-08, 1.7412109e-08, 1.7373635e-08, 1.7353255e-08,\n",
      "       1.7338575e-08, 1.7475248e-08, 1.7298639e-08, 1.7341367e-08,\n",
      "       1.7410070e-08, 1.7403034e-08, 1.7433637e-08, 1.7337477e-08,\n",
      "       1.7472095e-08, 1.7450979e-08, 1.7395276e-08, 1.7374113e-08,\n",
      "       1.7290205e-08, 1.7332759e-08, 1.7429015e-08, 1.7529285e-08,\n",
      "       1.7428146e-08, 1.7373106e-08, 1.7306023e-08, 1.7422000e-08,\n",
      "       1.7444776e-08, 1.7409031e-08, 1.7380982e-08, 1.7310954e-08,\n",
      "       1.7334278e-08, 1.7377445e-08, 1.7380030e-08, 1.7459019e-08,\n",
      "       1.7334846e-08, 1.7452827e-08, 1.7530867e-08, 1.7440943e-08,\n",
      "       1.7297708e-08, 1.7470631e-08, 1.7316600e-08, 1.7352225e-08,\n",
      "       1.7444536e-08, 1.7387672e-08, 1.7340026e-08, 1.7390200e-08,\n",
      "       1.7367958e-08, 1.7499147e-08, 1.7481362e-08, 1.7467832e-08,\n",
      "       1.7357751e-08, 1.7466199e-08, 1.7372564e-08, 1.7492958e-08,\n",
      "       1.7311102e-08, 1.7340138e-08, 1.7358099e-08, 1.7368924e-08,\n",
      "       1.7373686e-08, 1.7378527e-08, 1.7398136e-08, 1.7387221e-08,\n",
      "       1.7394420e-08, 1.7303631e-08, 1.7422176e-08, 1.7359428e-08,\n",
      "       1.7392695e-08, 1.7538520e-08, 1.7380101e-08, 1.7296845e-08,\n",
      "       1.7326380e-08, 1.7342355e-08, 1.7385508e-08, 1.7376676e-08,\n",
      "       1.7353191e-08, 1.7363972e-08, 1.7366837e-08, 1.7561048e-08,\n",
      "       1.7347093e-08, 1.7275321e-08, 1.7357488e-08, 1.7305831e-08,\n",
      "       1.7353457e-08, 1.7302932e-08, 1.7386199e-08, 1.7325974e-08,\n",
      "       1.7356452e-08, 1.7353738e-08, 1.7387668e-08, 1.7323696e-08,\n",
      "       1.7316610e-08, 1.7326531e-08, 1.7339538e-08, 1.7373628e-08,\n",
      "       1.7293974e-08, 1.7339815e-08, 1.7357600e-08, 1.7401208e-08,\n",
      "       1.7339637e-08, 1.7406492e-08, 1.7356113e-08, 1.7334795e-08,\n",
      "       1.7356152e-08, 1.7362437e-08, 1.7345764e-08, 1.7409459e-08,\n",
      "       1.7517587e-08, 1.7408414e-08, 1.7328947e-08, 1.7349995e-08,\n",
      "       1.7369743e-08, 1.7452944e-08, 1.7406949e-08, 1.7451612e-08,\n",
      "       1.7292761e-08, 1.7404016e-08, 1.7389221e-08, 1.7367073e-08,\n",
      "       1.7384213e-08, 1.7354965e-08, 1.7314367e-08, 1.7364428e-08,\n",
      "       1.7296429e-08, 1.7459886e-08, 1.7439959e-08, 1.7340023e-08,\n",
      "       1.7411205e-08, 1.7320819e-08, 1.7325418e-08, 1.7361122e-08,\n",
      "       1.7327645e-08, 1.7314216e-08, 1.7267300e-08, 1.7345101e-08,\n",
      "       1.7318410e-08, 1.7361234e-08, 1.7387451e-08, 1.7299993e-08,\n",
      "       1.7427739e-08, 1.7392438e-08, 1.7348420e-08, 1.7473484e-08,\n",
      "       1.7386212e-08, 1.7425315e-08, 1.7430647e-08, 1.7399282e-08,\n",
      "       1.7234392e-08, 1.7379946e-08, 1.7385210e-08, 1.7312042e-08,\n",
      "       1.7339282e-08, 1.7471297e-08, 1.7310827e-08, 1.7378408e-08,\n",
      "       1.7355353e-08, 1.7308292e-08, 1.7307363e-08, 1.7318930e-08,\n",
      "       1.7409414e-08, 1.7419822e-08, 1.7424313e-08, 1.7343716e-08,\n",
      "       1.7433360e-08, 1.7441629e-08, 1.7407917e-08, 1.7455996e-08,\n",
      "       1.7382293e-08, 1.7310713e-08, 1.7358071e-08, 1.7368034e-08,\n",
      "       1.7424334e-08, 1.7362639e-08, 1.7416228e-08, 1.7353921e-08,\n",
      "       1.7350335e-08, 1.7421760e-08, 1.7465581e-08, 1.7424833e-08,\n",
      "       1.7386311e-08, 1.7314639e-08, 1.7326951e-08, 1.7445373e-08,\n",
      "       1.7484254e-08, 1.7396507e-08, 1.7489407e-08, 1.7433116e-08,\n",
      "       1.7460316e-08, 1.7366864e-08, 1.7338829e-08, 1.7431219e-08,\n",
      "       1.7398603e-08, 1.7414681e-08, 1.7351821e-08, 1.7329157e-08,\n",
      "       1.7340506e-08, 1.7369983e-08, 1.7535477e-08, 1.7494951e-08,\n",
      "       1.7394660e-08, 1.7393374e-08, 1.7301183e-08, 1.7449738e-08,\n",
      "       1.7313770e-08, 1.7446640e-08, 1.7319667e-08, 1.7464076e-08,\n",
      "       1.7455898e-08, 1.7324972e-08, 1.7370033e-08, 1.7509850e-08,\n",
      "       1.7437134e-08, 1.7426895e-08, 1.7436530e-08, 1.7425252e-08,\n",
      "       1.7359067e-08, 1.7360517e-08, 1.7324556e-08, 1.7450679e-08,\n",
      "       1.7508484e-08, 1.7368365e-08, 1.7433727e-08, 1.7306224e-08,\n",
      "       1.7449763e-08, 1.7328997e-08, 1.7361284e-08, 1.7470940e-08,\n",
      "       1.7329914e-08, 1.7324787e-08, 1.7388093e-08, 1.7448363e-08,\n",
      "       1.7453081e-08, 1.7365808e-08, 1.7356145e-08, 1.7327164e-08,\n",
      "       1.7521522e-08, 1.7320463e-08, 1.7368951e-08, 1.7372951e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D\n",
      "index : 182\n",
      "shape : [1152    1    1  288]\n",
      "shape_signature : [1152    1    1  288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00051062, 0.00050677, 0.00051057, ..., 0.00050257, 0.00051077,\n",
      "       0.00051091], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/BiasAdd/ReadVariableOp/resource\n",
      "index : 183\n",
      "shape : [1152]\n",
      "shape_signature : [1152]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.1625978e-08, 1.1538350e-08, 1.1624818e-08, ..., 1.1442787e-08,\n",
      "       1.1629536e-08, 1.1632739e-08], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/conv2d_64/Conv2D\n",
      "index : 184\n",
      "shape : [ 320    1    1 1152]\n",
      "shape_signature : [ 320    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00054936, 0.00054995, 0.00054737, 0.00055291, 0.00055133,\n",
      "       0.00055139, 0.00054749, 0.00054583, 0.0005497 , 0.00054764,\n",
      "       0.00055042, 0.00055054, 0.00054948, 0.00055018, 0.0005503 ,\n",
      "       0.00054856, 0.00054764, 0.00054732, 0.00054893, 0.00054928,\n",
      "       0.00054561, 0.00054785, 0.00054986, 0.00054899, 0.00055115,\n",
      "       0.00054846, 0.00055049, 0.00055281, 0.00054949, 0.00054814,\n",
      "       0.00054883, 0.00054886, 0.00055002, 0.00055019, 0.00054898,\n",
      "       0.00054952, 0.00054934, 0.00055117, 0.0005488 , 0.0005514 ,\n",
      "       0.00055511, 0.00054998, 0.00054709, 0.00055035, 0.00055093,\n",
      "       0.00055126, 0.00055009, 0.00055177, 0.00055272, 0.0005473 ,\n",
      "       0.00055081, 0.00054813, 0.00055269, 0.0005508 , 0.00055318,\n",
      "       0.0005495 , 0.00055078, 0.00055193, 0.0005474 , 0.00054655,\n",
      "       0.00054741, 0.00054857, 0.00054905, 0.00055169, 0.00054852,\n",
      "       0.00055171, 0.00055481, 0.00054947, 0.00054805, 0.00055112,\n",
      "       0.00055109, 0.00055053, 0.00054954, 0.00055163, 0.0005498 ,\n",
      "       0.00055126, 0.00054874, 0.00054932, 0.00055346, 0.00055243,\n",
      "       0.0005515 , 0.00054982, 0.00054447, 0.00055238, 0.00054893,\n",
      "       0.0005487 , 0.00055223, 0.00054871, 0.00054955, 0.0005486 ,\n",
      "       0.00055546, 0.00054788, 0.00054998, 0.00055137, 0.00054773,\n",
      "       0.00055011, 0.00054959, 0.00055071, 0.00054594, 0.00054929,\n",
      "       0.00055064, 0.00054766, 0.00055079, 0.00054878, 0.00055467,\n",
      "       0.00055289, 0.00055038, 0.00054626, 0.00054809, 0.00055099,\n",
      "       0.00054881, 0.00054863, 0.0005496 , 0.00055047, 0.00055032,\n",
      "       0.00055258, 0.00055033, 0.00055062, 0.00055049, 0.000549  ,\n",
      "       0.00054595, 0.00054897, 0.00054962, 0.00054714, 0.00055038,\n",
      "       0.00055056, 0.00054916, 0.00054803, 0.00055185, 0.00054961,\n",
      "       0.00055109, 0.00055162, 0.00055   , 0.00055182, 0.00054859,\n",
      "       0.0005492 , 0.00055277, 0.00055358, 0.00055039, 0.00055431,\n",
      "       0.00054683, 0.00055054, 0.0005447 , 0.00054523, 0.00054973,\n",
      "       0.00054731, 0.00054921, 0.00055086, 0.00055143, 0.00054573,\n",
      "       0.00055011, 0.00055261, 0.0005498 , 0.00055009, 0.00054851,\n",
      "       0.00054602, 0.00054841, 0.00054586, 0.00054917, 0.0005508 ,\n",
      "       0.00055173, 0.00055048, 0.00054715, 0.00055256, 0.00055142,\n",
      "       0.0005505 , 0.0005524 , 0.0005532 , 0.00055154, 0.00055013,\n",
      "       0.00054911, 0.00055305, 0.00054924, 0.00055041, 0.00055143,\n",
      "       0.00054867, 0.00054896, 0.00054999, 0.00054869, 0.00055102,\n",
      "       0.00054162, 0.00054963, 0.00055091, 0.00054795, 0.00054992,\n",
      "       0.00054771, 0.00054905, 0.00054783, 0.00055151, 0.0005491 ,\n",
      "       0.00055369, 0.00054804, 0.00054993, 0.00055059, 0.00054763,\n",
      "       0.00054917, 0.00054983, 0.00055167, 0.00054917, 0.00054845,\n",
      "       0.0005499 , 0.00054895, 0.00054825, 0.00055257, 0.00055172,\n",
      "       0.00054722, 0.00055026, 0.00054772, 0.0005481 , 0.00054698,\n",
      "       0.00054728, 0.00054866, 0.0005512 , 0.00055066, 0.00054869,\n",
      "       0.00055142, 0.0005484 , 0.00054941, 0.00055069, 0.00054808,\n",
      "       0.00054623, 0.00054722, 0.00055121, 0.00055116, 0.00054794,\n",
      "       0.00055107, 0.00055128, 0.00054722, 0.00054785, 0.00054893,\n",
      "       0.00054682, 0.00055124, 0.00055161, 0.00054825, 0.00054847,\n",
      "       0.00055025, 0.0005475 , 0.00054989, 0.00054415, 0.00055171,\n",
      "       0.00055033, 0.00055023, 0.00054934, 0.00054823, 0.00055177,\n",
      "       0.00054966, 0.00054992, 0.00055228, 0.00054673, 0.00054974,\n",
      "       0.00054942, 0.00054937, 0.00054787, 0.00054849, 0.00055351,\n",
      "       0.000552  , 0.00054668, 0.00055019, 0.00055367, 0.00055334,\n",
      "       0.0005506 , 0.00054755, 0.00054217, 0.00054998, 0.00054919,\n",
      "       0.00054816, 0.00055046, 0.00055332, 0.0005475 , 0.00055254,\n",
      "       0.00055133, 0.00055023, 0.00055072, 0.00054896, 0.0005532 ,\n",
      "       0.00055132, 0.00055148, 0.00054926, 0.00055368, 0.00054906,\n",
      "       0.00055049, 0.00055085, 0.00055013, 0.00055035, 0.00054745,\n",
      "       0.00055006, 0.00055367, 0.00054874, 0.00055087, 0.00055151,\n",
      "       0.00055293, 0.00054873, 0.00055105, 0.00054899, 0.00055154,\n",
      "       0.00054845, 0.0005504 , 0.00054977, 0.00054869, 0.00054824,\n",
      "       0.0005492 , 0.00055263, 0.0005474 , 0.00055325, 0.00054734,\n",
      "       0.00055158, 0.00054765, 0.00055024, 0.00055154, 0.00054469,\n",
      "       0.00054808, 0.00054831, 0.00054827, 0.00054974, 0.00055137,\n",
      "       0.00055068, 0.00055162, 0.00054893, 0.00054641, 0.00054717],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_48/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/conv2d_64/Conv2D\n",
      "index : 185\n",
      "shape : [320]\n",
      "shape_signature : [320]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.7780220e-09, 4.7831383e-09, 4.7607296e-09, 4.8089248e-09,\n",
      "       4.7951727e-09, 4.7956741e-09, 4.7618065e-09, 4.7473425e-09,\n",
      "       4.7810147e-09, 4.7630695e-09, 4.7872954e-09, 4.7883386e-09,\n",
      "       4.7791118e-09, 4.7851341e-09, 4.7862243e-09, 4.7710671e-09,\n",
      "       4.7630784e-09, 4.7602975e-09, 4.7743320e-09, 4.7773616e-09,\n",
      "       4.7454281e-09, 4.7649036e-09, 4.7823603e-09, 4.7748125e-09,\n",
      "       4.7935726e-09, 4.7702562e-09, 4.7878697e-09, 4.8080402e-09,\n",
      "       4.7791704e-09, 4.7673923e-09, 4.7734017e-09, 4.7736819e-09,\n",
      "       4.7837876e-09, 4.7852429e-09, 4.7747144e-09, 4.7794293e-09,\n",
      "       4.7778537e-09, 4.7937538e-09, 4.7732045e-09, 4.7958082e-09,\n",
      "       4.8280810e-09, 4.7834061e-09, 4.7582818e-09, 4.7866240e-09,\n",
      "       4.7916653e-09, 4.7945505e-09, 4.7843880e-09, 4.7990314e-09,\n",
      "       4.8073003e-09, 4.7601403e-09, 4.7906723e-09, 4.7673785e-09,\n",
      "       4.8070388e-09, 4.7905271e-09, 4.8113025e-09, 4.7792490e-09,\n",
      "       4.7904365e-09, 4.8004147e-09, 4.7609761e-09, 4.7535891e-09,\n",
      "       4.7610755e-09, 4.7711879e-09, 4.7753161e-09, 4.7983013e-09,\n",
      "       4.7707087e-09, 4.7984963e-09, 4.8254489e-09, 4.7789763e-09,\n",
      "       4.7666262e-09, 4.7933848e-09, 4.7931028e-09, 4.7882502e-09,\n",
      "       4.7796416e-09, 4.7977755e-09, 4.7818633e-09, 4.7945625e-09,\n",
      "       4.7726472e-09, 4.7776791e-09, 4.8137370e-09, 4.8047513e-09,\n",
      "       4.7966910e-09, 4.7820694e-09, 4.7354884e-09, 4.8042672e-09,\n",
      "       4.7743045e-09, 4.7723292e-09, 4.8030357e-09, 4.7723816e-09,\n",
      "       4.7797166e-09, 4.7714357e-09, 4.8310898e-09, 4.7651687e-09,\n",
      "       4.7834563e-09, 4.7955440e-09, 4.7639035e-09, 4.7846007e-09,\n",
      "       4.7800626e-09, 4.7897553e-09, 4.7482911e-09, 4.7774615e-09,\n",
      "       4.7891699e-09, 4.7632982e-09, 4.7905218e-09, 4.7730011e-09,\n",
      "       4.8242006e-09, 4.8087201e-09, 4.7869282e-09, 4.7511119e-09,\n",
      "       4.7669571e-09, 4.7921813e-09, 4.7732858e-09, 4.7716573e-09,\n",
      "       4.7800968e-09, 4.7877386e-09, 4.7863571e-09, 4.8060684e-09,\n",
      "       4.7864392e-09, 4.7890407e-09, 4.7878617e-09, 4.7749182e-09,\n",
      "       4.7484083e-09, 4.7746251e-09, 4.7802673e-09, 4.7587019e-09,\n",
      "       4.7869344e-09, 4.7885029e-09, 4.7763202e-09, 4.7664628e-09,\n",
      "       4.7996833e-09, 4.7802144e-09, 4.7930881e-09, 4.7976902e-09,\n",
      "       4.7835900e-09, 4.7994444e-09, 4.7713060e-09, 4.7766440e-09,\n",
      "       4.8077391e-09, 4.8147575e-09, 4.7870046e-09, 4.8211333e-09,\n",
      "       4.7560569e-09, 4.7883160e-09, 4.7375295e-09, 4.7421169e-09,\n",
      "       4.7812621e-09, 4.7601918e-09, 4.7767621e-09, 4.7910942e-09,\n",
      "       4.7960809e-09, 4.7464459e-09, 4.7845958e-09, 4.8063287e-09,\n",
      "       4.7818940e-09, 4.7844129e-09, 4.7706772e-09, 4.7489950e-09,\n",
      "       4.7698192e-09, 4.7475606e-09, 4.7763882e-09, 4.7905973e-09,\n",
      "       4.7986179e-09, 4.7878266e-09, 4.7587951e-09, 4.8058331e-09,\n",
      "       4.7960032e-09, 4.7879878e-09, 4.8044591e-09, 4.8114202e-09,\n",
      "       4.7969908e-09, 4.7847384e-09, 4.7758895e-09, 4.8101536e-09,\n",
      "       4.7770370e-09, 4.7871698e-09, 4.7960413e-09, 4.7720143e-09,\n",
      "       4.7745519e-09, 4.7835296e-09, 4.7722422e-09, 4.7925059e-09,\n",
      "       4.7107034e-09, 4.7803961e-09, 4.7915374e-09, 4.7657962e-09,\n",
      "       4.7829358e-09, 4.7637334e-09, 4.7753521e-09, 4.7647419e-09,\n",
      "       4.7967346e-09, 4.7757651e-09, 4.8156825e-09, 4.7665818e-09,\n",
      "       4.7829820e-09, 4.7887219e-09, 4.7629709e-09, 4.7763860e-09,\n",
      "       4.7821436e-09, 4.7981388e-09, 4.7763504e-09, 4.7701696e-09,\n",
      "       4.7827209e-09, 4.7745070e-09, 4.7684239e-09, 4.8059952e-09,\n",
      "       4.7985340e-09, 4.7594702e-09, 4.7858828e-09, 4.7638165e-09,\n",
      "       4.7670570e-09, 4.7573421e-09, 4.7599213e-09, 4.7719637e-09,\n",
      "       4.7940887e-09, 4.7893791e-09, 4.7721951e-09, 4.7959547e-09,\n",
      "       4.7697171e-09, 4.7784594e-09, 4.7896132e-09, 4.7669309e-09,\n",
      "       4.7508082e-09, 4.7594626e-09, 4.7941455e-09, 4.7937196e-09,\n",
      "       4.7656887e-09, 4.7929580e-09, 4.7947313e-09, 4.7594177e-09,\n",
      "       4.7649382e-09, 4.7743214e-09, 4.7559499e-09, 4.7943831e-09,\n",
      "       4.7976170e-09, 4.7683986e-09, 4.7703037e-09, 4.7858100e-09,\n",
      "       4.7618762e-09, 4.7826774e-09, 4.7327160e-09, 4.7985216e-09,\n",
      "       4.7864757e-09, 4.7855937e-09, 4.7778888e-09, 4.7682023e-09,\n",
      "       4.7990434e-09, 4.7806492e-09, 4.7828879e-09, 4.8034363e-09,\n",
      "       4.7551989e-09, 4.7813340e-09, 4.7785260e-09, 4.7781623e-09,\n",
      "       4.7651185e-09, 4.7705164e-09, 4.8141136e-09, 4.8009996e-09,\n",
      "       4.7547304e-09, 4.7852540e-09, 4.8155480e-09, 4.8126561e-09,\n",
      "       4.7888364e-09, 4.7622977e-09, 4.7154725e-09, 4.7834607e-09,\n",
      "       4.7765871e-09, 4.7676028e-09, 4.7875939e-09, 4.8124718e-09,\n",
      "       4.7618460e-09, 4.8057438e-09, 4.7952171e-09, 4.7856301e-09,\n",
      "       4.7898849e-09, 4.7745932e-09, 4.8114406e-09, 4.7950630e-09,\n",
      "       4.7965076e-09, 4.7772035e-09, 4.8156301e-09, 4.7754534e-09,\n",
      "       4.7878532e-09, 4.7910365e-09, 4.7847397e-09, 4.7866351e-09,\n",
      "       4.7614352e-09, 4.7841429e-09, 4.8154982e-09, 4.7726099e-09,\n",
      "       4.7911799e-09, 4.7967288e-09, 4.8090647e-09, 4.7725801e-09,\n",
      "       4.7927169e-09, 4.7747939e-09, 4.7969722e-09, 4.7701385e-09,\n",
      "       4.7870836e-09, 4.7815711e-09, 4.7722120e-09, 4.7683075e-09,\n",
      "       4.7766449e-09, 4.8064903e-09, 4.7609894e-09, 4.8118536e-09,\n",
      "       4.7604383e-09, 4.7973354e-09, 4.7631530e-09, 4.7856936e-09,\n",
      "       4.7970383e-09, 4.7374553e-09, 4.7668873e-09, 4.7689244e-09,\n",
      "       4.7686002e-09, 4.7813411e-09, 4.7955098e-09, 4.7895341e-09,\n",
      "       4.7977409e-09, 4.7743285e-09, 4.7523447e-09, 4.7589532e-09],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_4/conv2d_69/Conv2D\n",
      "index : 186\n",
      "shape : [ 64   1   1 320]\n",
      "shape_signature : [ 64   1   1 320]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00092431, 0.00092208, 0.00090788, 0.0009263 , 0.00094482,\n",
      "       0.00092945, 0.00093601, 0.00091861, 0.00091947, 0.00089638,\n",
      "       0.00094054, 0.00095627, 0.00092832, 0.00090072, 0.00096649,\n",
      "       0.00091615, 0.00092186, 0.0009424 , 0.00093353, 0.00091185,\n",
      "       0.00092573, 0.00094876, 0.00094012, 0.00091001, 0.0009415 ,\n",
      "       0.00094488, 0.00093129, 0.00093245, 0.00094118, 0.00092883,\n",
      "       0.00094057, 0.00093529, 0.00093662, 0.00093873, 0.00092908,\n",
      "       0.0009212 , 0.00096109, 0.00093621, 0.00096399, 0.00092032,\n",
      "       0.00092664, 0.00094757, 0.0009496 , 0.00092097, 0.00092312,\n",
      "       0.00095872, 0.00095075, 0.00093171, 0.00093874, 0.00092162,\n",
      "       0.00093129, 0.00096747, 0.00092498, 0.00094189, 0.00094475,\n",
      "       0.00094235, 0.0009462 , 0.00092628, 0.00089495, 0.00092517,\n",
      "       0.00091424, 0.00092162, 0.00091368, 0.00093077], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_4/batch_normalization_53/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_4/conv2d_69/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_4/conv2d_69/BiasAdd\n",
      "index : 187\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([8.2694477e-08, 8.2495212e-08, 8.1224385e-08, 8.2872958e-08,\n",
      "       8.4529063e-08, 8.3154070e-08, 8.3741398e-08, 8.2184791e-08,\n",
      "       8.2261685e-08, 8.0195399e-08, 8.4146990e-08, 8.5553729e-08,\n",
      "       8.3053592e-08, 8.0584115e-08, 8.6467956e-08, 8.1964551e-08,\n",
      "       8.2474891e-08, 8.4312930e-08, 8.3519076e-08, 8.1579650e-08,\n",
      "       8.2821906e-08, 8.4882004e-08, 8.4108677e-08, 8.1414981e-08,\n",
      "       8.4232816e-08, 8.4534676e-08, 8.3319328e-08, 8.3423132e-08,\n",
      "       8.4203371e-08, 8.3099245e-08, 8.4148830e-08, 8.3677264e-08,\n",
      "       8.3796152e-08, 8.3984688e-08, 8.3121293e-08, 8.2416399e-08,\n",
      "       8.5985221e-08, 8.3759481e-08, 8.6244164e-08, 8.2337550e-08,\n",
      "       8.2902545e-08, 8.4775472e-08, 8.4957200e-08, 8.2395260e-08,\n",
      "       8.2587640e-08, 8.5772740e-08, 8.5060194e-08, 8.3356632e-08,\n",
      "       8.3985938e-08, 8.2453603e-08, 8.3319286e-08, 8.6556305e-08,\n",
      "       8.2754482e-08, 8.4267015e-08, 8.4523641e-08, 8.4308496e-08,\n",
      "       8.4653216e-08, 8.2871018e-08, 8.0067821e-08, 8.2771798e-08,\n",
      "       8.1793615e-08, 8.2454022e-08, 8.1743373e-08, 8.3272745e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/strided_slice_1\n",
      "index : 188\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001960915746167302, -128)\n",
      "quantization_parameters : {'scales': array([0.00196092], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/separable_conv2d/depthwise\n",
      "index : 189\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078073, 0.00070208, 0.00076545, 0.00055012, 0.00079488,\n",
      "       0.00073035, 0.00078826, 0.00074533, 0.00065099, 0.00069441,\n",
      "       0.00079267, 0.00072198, 0.00077019, 0.0005486 , 0.00072863,\n",
      "       0.00067821, 0.00067639, 0.00073677, 0.00068699, 0.00077304,\n",
      "       0.00079099, 0.00073775, 0.00077169, 0.00062591, 0.00069934,\n",
      "       0.00071266, 0.00069206, 0.0007507 , 0.00062542, 0.00065113,\n",
      "       0.00073683, 0.00078349, 0.00068679, 0.00069207, 0.00070093,\n",
      "       0.00077655, 0.00072993, 0.00072538, 0.00076914, 0.00070469,\n",
      "       0.00066315, 0.00075932, 0.00077707, 0.00074307, 0.00076863,\n",
      "       0.00075423, 0.00079756, 0.00078126, 0.00073229, 0.00073933,\n",
      "       0.00070299, 0.00078476, 0.00070778, 0.00065648, 0.00056432,\n",
      "       0.00056559, 0.00054069, 0.00079023, 0.00072248, 0.00077743,\n",
      "       0.00072743, 0.00067989, 0.00074008, 0.00071318], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4\n",
      "index : 190\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.6549242e-08, 3.2867405e-08, 3.5833729e-08, 2.5753122e-08,\n",
      "       3.7211649e-08, 3.4190638e-08, 3.6901461e-08, 3.4892135e-08,\n",
      "       3.0475658e-08, 3.2508186e-08, 3.7107899e-08, 3.3798919e-08,\n",
      "       3.6055585e-08, 2.5682043e-08, 3.4110148e-08, 3.1749654e-08,\n",
      "       3.1664559e-08, 3.4491098e-08, 3.2160816e-08, 3.6189238e-08,\n",
      "       3.7029288e-08, 3.4536956e-08, 3.6125762e-08, 2.9301184e-08,\n",
      "       3.2738928e-08, 3.3362550e-08, 3.2398251e-08, 3.5143227e-08,\n",
      "       2.9278517e-08, 3.0481871e-08, 3.4493855e-08, 3.6678220e-08,\n",
      "       3.2151640e-08, 3.2398752e-08, 3.2813478e-08, 3.6353388e-08,\n",
      "       3.4171180e-08, 3.3958194e-08, 3.6006735e-08, 3.2989252e-08,\n",
      "       3.1044600e-08, 3.5546623e-08, 3.6377678e-08, 3.4786360e-08,\n",
      "       3.5982474e-08, 3.5308751e-08, 3.7336793e-08, 3.6573919e-08,\n",
      "       3.4281658e-08, 3.4610942e-08, 3.2909593e-08, 3.6737926e-08,\n",
      "       3.3133954e-08, 3.0732366e-08, 2.6418279e-08, 2.6477696e-08,\n",
      "       2.5312108e-08, 3.6993978e-08, 3.3822456e-08, 3.6394606e-08,\n",
      "       3.4054143e-08, 3.1828453e-08, 3.4646057e-08, 3.3386694e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_41\n",
      "index : 191\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.9045575e-08, 3.7044323e-08, 5.3853498e-08, 5.6098077e-08,\n",
      "       5.5717287e-08, 5.5684698e-08, 5.3688368e-08, 5.5529206e-08,\n",
      "       4.2656655e-08, 5.6263179e-08, 4.5250701e-08, 4.3279414e-08,\n",
      "       4.9589449e-08, 5.1951520e-08, 5.4909584e-08, 5.3460447e-08,\n",
      "       5.5558587e-08, 5.4132087e-08, 4.6329518e-08, 5.4955709e-08,\n",
      "       5.7203646e-08, 4.6803972e-08, 5.5593386e-08, 5.4657686e-08,\n",
      "       5.6349982e-08, 5.5178262e-08, 5.6460010e-08, 4.9061224e-08,\n",
      "       5.6144824e-08, 4.8686008e-08, 5.6810574e-08, 4.2478678e-08,\n",
      "       5.2660411e-08, 4.9836881e-08, 5.4694290e-08, 5.5498354e-08,\n",
      "       5.7258099e-08, 5.2690520e-08, 4.8851440e-08, 5.4637191e-08,\n",
      "       5.0982219e-08, 4.1813529e-08, 5.5398164e-08, 5.6685703e-08,\n",
      "       3.8349480e-08, 5.0210588e-08, 5.3092602e-08, 5.3660226e-08,\n",
      "       5.3210911e-08, 5.6359831e-08, 4.9381644e-08, 5.4152665e-08,\n",
      "       5.2241447e-08, 5.5977612e-08, 5.5256066e-08, 5.2956985e-08,\n",
      "       4.5863207e-08, 5.3452368e-08, 5.6257839e-08, 5.1078132e-08,\n",
      "       5.5089043e-08, 5.0977896e-08, 5.3582106e-08, 4.6514490e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_42\n",
      "index : 192\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.0248781e-08, 3.6293727e-08, 2.9903855e-08, 3.4440852e-08,\n",
      "       3.5008000e-08, 3.2883658e-08, 3.3883243e-08, 3.6036578e-08,\n",
      "       3.6688075e-08, 3.5613610e-08, 3.6135766e-08, 3.3198642e-08,\n",
      "       3.0363058e-08, 3.6091187e-08, 3.2492689e-08, 3.6563559e-08,\n",
      "       3.5631313e-08, 3.5726327e-08, 3.4621447e-08, 3.5954482e-08,\n",
      "       3.2565630e-08, 3.4382733e-08, 3.6457919e-08, 3.5255496e-08,\n",
      "       3.2599683e-08, 3.6409112e-08, 3.5108418e-08, 3.5139557e-08,\n",
      "       2.9398807e-08, 3.5442270e-08, 3.5807506e-08, 3.4447403e-08,\n",
      "       3.4767687e-08, 2.7810298e-08, 3.5948677e-08, 3.5717054e-08,\n",
      "       2.9158628e-08, 3.6513917e-08, 3.0622491e-08, 3.6113693e-08,\n",
      "       3.2977773e-08, 3.4452171e-08, 3.6730409e-08, 3.6287190e-08,\n",
      "       3.4057027e-08, 3.5882767e-08, 3.5692473e-08, 3.4162479e-08,\n",
      "       3.6257902e-08, 3.4532249e-08, 3.2661305e-08, 3.2151053e-08,\n",
      "       3.5062069e-08, 3.3515441e-08, 3.6683758e-08, 3.3810768e-08,\n",
      "       3.2298388e-08, 3.6709917e-08, 3.4092910e-08, 3.6057692e-08,\n",
      "       3.5674290e-08, 3.2437384e-08, 3.1757260e-08, 3.5382449e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_43\n",
      "index : 193\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.3739405e-08, 4.6348092e-08, 4.1610004e-08, 3.8306077e-08,\n",
      "       3.8650022e-08, 4.0483318e-08, 4.0778581e-08, 4.4976119e-08,\n",
      "       4.6113499e-08, 4.4538218e-08, 3.0072666e-08, 3.8648039e-08,\n",
      "       4.5371618e-08, 4.1122167e-08, 4.2146951e-08, 4.3026887e-08,\n",
      "       4.5239542e-08, 4.6625701e-08, 4.5379437e-08, 4.6267537e-08,\n",
      "       4.6901114e-08, 4.5414176e-08, 4.6729852e-08, 4.2494623e-08,\n",
      "       4.6590444e-08, 4.0778335e-08, 4.4886079e-08, 3.1465031e-08,\n",
      "       4.4027527e-08, 4.6616471e-08, 4.3807614e-08, 3.7197978e-08,\n",
      "       3.9737017e-08, 4.0279172e-08, 4.5495860e-08, 4.4672461e-08,\n",
      "       4.4548134e-08, 4.5513673e-08, 4.6634483e-08, 4.6609770e-08,\n",
      "       4.1140019e-08, 4.4408640e-08, 4.6338609e-08, 4.3887709e-08,\n",
      "       4.5483556e-08, 3.6532391e-08, 3.3929538e-08, 3.9588379e-08,\n",
      "       3.8769926e-08, 3.7484789e-08, 4.3028312e-08, 4.4648864e-08,\n",
      "       4.7060503e-08, 4.5045415e-08, 2.9041450e-08, 4.5751257e-08,\n",
      "       4.5590483e-08, 4.3989232e-08, 4.3972310e-08, 4.3902940e-08,\n",
      "       3.7474283e-08, 3.5967666e-08, 3.7700161e-08, 4.4060954e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_44\n",
      "index : 194\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.7618311e-08, 2.9187863e-08, 3.1606415e-08, 3.1294430e-08,\n",
      "       2.3117192e-08, 2.9675649e-08, 2.9021511e-08, 2.8047264e-08,\n",
      "       3.1273487e-08, 2.7011287e-08, 3.0695130e-08, 2.5124532e-08,\n",
      "       2.8029792e-08, 2.9475668e-08, 2.7265701e-08, 3.0424644e-08,\n",
      "       2.2949862e-08, 2.5018032e-08, 2.6657469e-08, 2.4999164e-08,\n",
      "       2.9620214e-08, 2.9148362e-08, 2.7641942e-08, 2.8607795e-08,\n",
      "       2.9567053e-08, 2.7514098e-08, 2.9163134e-08, 2.6359482e-08,\n",
      "       2.4173074e-08, 2.9263628e-08, 2.8119235e-08, 3.0170451e-08,\n",
      "       2.7164587e-08, 2.8788559e-08, 2.6529086e-08, 2.2812111e-08,\n",
      "       2.8161566e-08, 3.1171808e-08, 2.7275487e-08, 3.0846394e-08,\n",
      "       3.1317168e-08, 2.7815151e-08, 2.5082032e-08, 2.5176339e-08,\n",
      "       2.8660386e-08, 2.7071954e-08, 3.1481086e-08, 2.9440450e-08,\n",
      "       2.8391883e-08, 3.0302079e-08, 2.9567499e-08, 2.5833454e-08,\n",
      "       2.8279940e-08, 2.6712472e-08, 2.3430671e-08, 2.7785438e-08,\n",
      "       3.0396087e-08, 1.5192489e-08, 3.0269071e-08, 3.0359168e-08,\n",
      "       2.9565820e-08, 3.0920337e-08, 2.8341058e-08, 3.1370490e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_45\n",
      "index : 195\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.8256652e-08, 3.0534977e-08, 2.3656451e-08, 2.7386262e-08,\n",
      "       3.0290646e-08, 2.9774247e-08, 3.0186744e-08, 2.9584397e-08,\n",
      "       2.6091776e-08, 2.9224996e-08, 3.0355821e-08, 3.0416963e-08,\n",
      "       2.1073557e-08, 2.8450003e-08, 2.8378258e-08, 2.7244447e-08,\n",
      "       2.2546653e-08, 2.8115572e-08, 2.9179851e-08, 2.5146978e-08,\n",
      "       2.4281546e-08, 2.3787816e-08, 2.9654402e-08, 2.5445754e-08,\n",
      "       3.0256327e-08, 3.0373918e-08, 2.9095174e-08, 2.6367847e-08,\n",
      "       2.9667078e-08, 2.9824612e-08, 2.8381981e-08, 2.9458874e-08,\n",
      "       2.1573058e-08, 2.7297958e-08, 2.4099627e-08, 2.9764031e-08,\n",
      "       2.3686876e-08, 2.9052888e-08, 2.7480590e-08, 2.6251890e-08,\n",
      "       2.5541224e-08, 2.9511218e-08, 2.9416311e-08, 2.9527088e-08,\n",
      "       3.0207072e-08, 2.8032746e-08, 2.9677850e-08, 3.0335976e-08,\n",
      "       3.0041072e-08, 2.9919203e-08, 2.7242320e-08, 2.6921288e-08,\n",
      "       2.4254099e-08, 2.5299336e-08, 2.7118269e-08, 2.5434877e-08,\n",
      "       2.0912081e-08, 2.9047724e-08, 2.9543580e-08, 2.7553893e-08,\n",
      "       2.6485449e-08, 2.7072364e-08, 2.6934444e-08, 2.7576659e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_46\n",
      "index : 196\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.2922499e-08, 2.3715730e-08, 2.2238185e-08, 3.0872975e-08,\n",
      "       3.0690167e-08, 2.6791223e-08, 2.6159150e-08, 2.8943036e-08,\n",
      "       2.9562653e-08, 2.7398928e-08, 3.0606522e-08, 3.2469469e-08,\n",
      "       3.1960091e-08, 2.4622834e-08, 3.0676230e-08, 2.8689680e-08,\n",
      "       3.0283417e-08, 2.9651623e-08, 3.1441648e-08, 2.6398613e-08,\n",
      "       3.2473444e-08, 3.0224939e-08, 3.1489559e-08, 3.1329968e-08,\n",
      "       2.6793392e-08, 2.9599116e-08, 2.8540414e-08, 2.4057965e-08,\n",
      "       3.1097432e-08, 2.5411410e-08, 2.9747518e-08, 3.0095944e-08,\n",
      "       2.9766831e-08, 3.1294178e-08, 2.5625052e-08, 2.6772623e-08,\n",
      "       3.2222953e-08, 3.1590513e-08, 3.0316762e-08, 3.1346719e-08,\n",
      "       2.9751130e-08, 2.9423145e-08, 2.7294160e-08, 2.7997007e-08,\n",
      "       3.1291922e-08, 3.1734729e-08, 2.5637632e-08, 3.1866481e-08,\n",
      "       2.8393037e-08, 3.1839267e-08, 2.9098587e-08, 2.2962674e-08,\n",
      "       3.1330497e-08, 3.2827554e-08, 3.1531435e-08, 3.2780598e-08,\n",
      "       2.9590309e-08, 2.4974266e-08, 3.2306993e-08, 2.9690778e-08,\n",
      "       2.6346573e-08, 3.1318333e-08, 2.7800899e-08, 2.2695367e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_47\n",
      "index : 197\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.0746996e-08, 2.8863878e-08, 2.7618654e-08, 2.5712081e-08,\n",
      "       3.0332778e-08, 2.8540647e-08, 2.9491131e-08, 2.9280327e-08,\n",
      "       3.1695848e-08, 2.9187943e-08, 3.0510801e-08, 3.1886458e-08,\n",
      "       2.9918109e-08, 3.1506872e-08, 2.8269156e-08, 3.1633661e-08,\n",
      "       2.9379187e-08, 2.9928650e-08, 3.1618956e-08, 3.1044117e-08,\n",
      "       2.2729701e-08, 3.0873039e-08, 1.8977151e-08, 2.4911820e-08,\n",
      "       2.7798135e-08, 3.1776676e-08, 2.9552007e-08, 3.0255553e-08,\n",
      "       2.9376929e-08, 2.8311577e-08, 2.4865507e-08, 2.9619400e-08,\n",
      "       2.5803423e-08, 3.0609471e-08, 3.0323932e-08, 2.5851419e-08,\n",
      "       2.9790295e-08, 2.4985493e-08, 3.0120034e-08, 3.1579571e-08,\n",
      "       2.8272900e-08, 3.1658608e-08, 2.1118939e-08, 2.9382857e-08,\n",
      "       2.7472563e-08, 2.3053520e-08, 2.9021262e-08, 3.0766888e-08,\n",
      "       2.9926341e-08, 2.5302645e-08, 2.8810597e-08, 2.8313215e-08,\n",
      "       2.9586202e-08, 2.2849891e-08, 2.2321025e-08, 2.0217222e-08,\n",
      "       2.6998709e-08, 2.6278141e-08, 2.8891488e-08, 3.1093457e-08,\n",
      "       2.6871195e-08, 2.7545088e-08, 3.1641378e-08, 3.1503088e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_48\n",
      "index : 198\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.6628084e-08, 3.3172228e-08, 3.1145294e-08, 3.5092828e-08,\n",
      "       2.9081155e-08, 3.5865259e-08, 2.8178452e-08, 3.6080561e-08,\n",
      "       3.5651496e-08, 3.6242799e-08, 3.6787377e-08, 3.6760103e-08,\n",
      "       3.4080177e-08, 3.5124373e-08, 3.7527666e-08, 3.7815060e-08,\n",
      "       3.5910894e-08, 3.4835853e-08, 3.6767574e-08, 3.6219056e-08,\n",
      "       3.1989931e-08, 3.7098353e-08, 3.1004610e-08, 3.4937621e-08,\n",
      "       2.3450514e-08, 3.5578513e-08, 3.4713967e-08, 3.1352542e-08,\n",
      "       3.6055962e-08, 3.3938466e-08, 3.6001829e-08, 3.2259951e-08,\n",
      "       3.4165371e-08, 3.6916102e-08, 3.4454896e-08, 3.7009912e-08,\n",
      "       3.4864286e-08, 3.5818140e-08, 3.6059038e-08, 2.9356642e-08,\n",
      "       3.7651521e-08, 3.2675256e-08, 3.1839303e-08, 3.3515114e-08,\n",
      "       3.4969712e-08, 3.1425778e-08, 3.6763513e-08, 3.1222957e-08,\n",
      "       3.4241019e-08, 3.5229295e-08, 3.1697319e-08, 3.2767044e-08,\n",
      "       3.6539614e-08, 2.8623226e-08, 3.3214548e-08, 3.3249943e-08,\n",
      "       3.1275782e-08, 3.7536001e-08, 3.6724735e-08, 3.1534906e-08,\n",
      "       3.5413525e-08, 3.6327911e-08, 3.6007417e-08, 3.6599410e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_49\n",
      "index : 199\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.3095141e-08, 3.1176935e-08, 2.9048071e-08, 2.6221102e-08,\n",
      "       3.1522124e-08, 3.0875359e-08, 2.6412492e-08, 3.2049414e-08,\n",
      "       2.7464248e-08, 3.1626168e-08, 2.8173334e-08, 2.7961946e-08,\n",
      "       2.7563512e-08, 3.1996006e-08, 2.6803891e-08, 3.3227934e-08,\n",
      "       3.0236205e-08, 3.3532494e-08, 2.6738837e-08, 3.3635054e-08,\n",
      "       3.0977862e-08, 2.9559107e-08, 3.2173904e-08, 3.0252835e-08,\n",
      "       2.4588907e-08, 2.8751369e-08, 3.1474887e-08, 2.5933199e-08,\n",
      "       3.2895315e-08, 3.2491847e-08, 3.0246120e-08, 3.2470805e-08,\n",
      "       1.3921268e-08, 2.7406863e-08, 3.1972306e-08, 3.3515192e-08,\n",
      "       2.5107086e-08, 3.3033885e-08, 3.2021745e-08, 2.2880265e-08,\n",
      "       3.0902683e-08, 3.2670364e-08, 3.0407136e-08, 2.8864802e-08,\n",
      "       3.1916489e-08, 3.0507927e-08, 2.8683584e-08, 3.1740456e-08,\n",
      "       3.0510154e-08, 2.4472548e-08, 3.1715999e-08, 2.2761826e-08,\n",
      "       2.9345077e-08, 3.2010551e-08, 3.2704140e-08, 2.7958457e-08,\n",
      "       3.1961200e-08, 3.4067039e-08, 3.1328483e-08, 2.9420770e-08,\n",
      "       2.8222090e-08, 3.0014029e-08, 3.2162326e-08, 3.3125417e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_410\n",
      "index : 200\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.0320202e-08, 2.4970072e-08, 2.1628246e-08, 2.5971520e-08,\n",
      "       2.5680146e-08, 2.4269776e-08, 2.5404253e-08, 2.3465912e-08,\n",
      "       2.1865560e-08, 2.5003555e-08, 1.8850415e-08, 2.4498966e-08,\n",
      "       2.3532570e-08, 2.0358565e-08, 2.5670875e-08, 2.5484818e-08,\n",
      "       2.4760228e-08, 2.2999284e-08, 2.1729132e-08, 2.1139989e-08,\n",
      "       2.4200400e-08, 2.0901842e-08, 2.2728287e-08, 2.2919615e-08,\n",
      "       2.1393163e-08, 2.0905224e-08, 2.0181350e-08, 2.5720212e-08,\n",
      "       2.2311918e-08, 2.2917495e-08, 2.2828402e-08, 2.2848614e-08,\n",
      "       2.5594717e-08, 2.3237146e-08, 2.4527690e-08, 2.3853515e-08,\n",
      "       2.2050971e-08, 2.4990712e-08, 1.9844402e-08, 2.2829424e-08,\n",
      "       2.4305210e-08, 2.5873469e-08, 2.5559681e-08, 2.0951559e-08,\n",
      "       2.4466150e-08, 2.5420331e-08, 2.3271483e-08, 2.4291706e-08,\n",
      "       2.5392760e-08, 2.5262116e-08, 1.8582892e-08, 2.3889037e-08,\n",
      "       2.3781448e-08, 2.5806358e-08, 2.2765956e-08, 2.4175673e-08,\n",
      "       2.5569356e-08, 2.2422032e-08, 2.5375650e-08, 2.4870650e-08,\n",
      "       2.0807644e-08, 2.4711282e-08, 2.4766369e-08, 2.5461363e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_411\n",
      "index : 201\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.2989768e-08, 2.1698192e-08, 2.0521680e-08, 2.1517149e-08,\n",
      "       1.9545466e-08, 1.8099438e-08, 2.3560254e-08, 2.3859283e-08,\n",
      "       2.2333481e-08, 2.2812245e-08, 2.1527278e-08, 2.2615358e-08,\n",
      "       1.3303799e-08, 2.1586407e-08, 1.9541407e-08, 1.8173809e-08,\n",
      "       1.7060763e-08, 2.1890033e-08, 2.0601782e-08, 2.1432422e-08,\n",
      "       1.7532873e-08, 1.9769386e-08, 2.3423880e-08, 1.7924302e-08,\n",
      "       2.4115755e-08, 2.1991934e-08, 2.3304178e-08, 2.2261951e-08,\n",
      "       2.3268283e-08, 2.2884754e-08, 2.3697870e-08, 2.1623071e-08,\n",
      "       2.3219389e-08, 2.0948741e-08, 2.0442361e-08, 1.9371372e-08,\n",
      "       2.2324611e-08, 2.3488914e-08, 2.0944750e-08, 2.3283839e-08,\n",
      "       2.1333431e-08, 2.4036417e-08, 2.3099512e-08, 2.3031534e-08,\n",
      "       1.8946780e-08, 1.7186066e-08, 2.0056941e-08, 1.9236079e-08,\n",
      "       2.3089171e-08, 2.2980867e-08, 2.3081560e-08, 2.2785137e-08,\n",
      "       2.2557481e-08, 2.1918417e-08, 1.7640891e-08, 2.2776423e-08,\n",
      "       2.3714101e-08, 2.4111813e-08, 2.1132823e-08, 2.1293339e-08,\n",
      "       2.3670063e-08, 2.2720998e-08, 1.9301361e-08, 2.2388642e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_412\n",
      "index : 202\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.6366483e-08, 1.4600971e-08, 1.9477513e-08, 1.9388551e-08,\n",
      "       2.0306565e-08, 1.7810599e-08, 2.0624535e-08, 1.9394284e-08,\n",
      "       1.8691660e-08, 2.0164011e-08, 1.9431742e-08, 1.9784025e-08,\n",
      "       1.9949272e-08, 1.9542403e-08, 1.4249102e-08, 2.0573923e-08,\n",
      "       1.4772779e-08, 1.9988148e-08, 1.6457403e-08, 1.5228235e-08,\n",
      "       1.7540801e-08, 1.6249635e-08, 1.9387302e-08, 1.9125041e-08,\n",
      "       1.9782471e-08, 1.6935768e-08, 1.3492493e-08, 1.9744162e-08,\n",
      "       1.4635040e-08, 1.8535555e-08, 1.8244243e-08, 1.9262290e-08,\n",
      "       2.0396495e-08, 1.9395985e-08, 1.3582105e-08, 1.8620590e-08,\n",
      "       1.7036179e-08, 1.9599893e-08, 1.9741970e-08, 1.8577891e-08,\n",
      "       1.4483205e-08, 1.7342574e-08, 1.8911148e-08, 1.8645192e-08,\n",
      "       1.9879465e-08, 1.9585032e-08, 1.9207608e-08, 1.9839135e-08,\n",
      "       2.0438335e-08, 1.9732237e-08, 1.9797861e-08, 1.9928516e-08,\n",
      "       1.8781202e-08, 1.9637110e-08, 1.5885430e-08, 2.0075559e-08,\n",
      "       1.7928468e-08, 1.7291789e-08, 1.9609594e-08, 1.1866209e-08,\n",
      "       2.0092912e-08, 1.7247450e-08, 1.8097163e-08, 1.5880183e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_413\n",
      "index : 203\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.3031514e-08, 2.1911655e-08, 2.2736804e-08, 2.1415028e-08,\n",
      "       2.2453113e-08, 2.2028884e-08, 2.2469415e-08, 2.1126944e-08,\n",
      "       2.2394010e-08, 1.9572962e-08, 1.7101506e-08, 2.1606528e-08,\n",
      "       1.8387908e-08, 1.9011850e-08, 2.0454422e-08, 2.1188514e-08,\n",
      "       2.2183784e-08, 2.2811713e-08, 1.8711829e-08, 1.9362744e-08,\n",
      "       2.1710461e-08, 2.2577096e-08, 2.0302187e-08, 2.1476447e-08,\n",
      "       1.8630955e-08, 2.2347123e-08, 2.2634172e-08, 1.9494168e-08,\n",
      "       2.2682295e-08, 2.1054914e-08, 2.3025081e-08, 2.2905720e-08,\n",
      "       2.2870470e-08, 2.0412713e-08, 2.2345326e-08, 2.2754971e-08,\n",
      "       2.2737421e-08, 2.1221172e-08, 2.1804945e-08, 1.6530457e-08,\n",
      "       2.3036055e-08, 1.7238666e-08, 1.6812962e-08, 1.9731726e-08,\n",
      "       2.2605345e-08, 1.9981082e-08, 2.2328893e-08, 2.1406267e-08,\n",
      "       2.2845732e-08, 1.9907715e-08, 2.2056819e-08, 1.3477150e-08,\n",
      "       2.0651850e-08, 2.2847203e-08, 2.1478398e-08, 2.1387798e-08,\n",
      "       2.0210996e-08, 2.1738165e-08, 2.3138986e-08, 1.7024716e-08,\n",
      "       2.0205061e-08, 2.3140863e-08, 1.8350930e-08, 2.0407173e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_414\n",
      "index : 204\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.2102599e-08, 1.8510530e-08, 2.4667807e-08, 2.5016677e-08,\n",
      "       2.6112678e-08, 2.4652744e-08, 2.4450653e-08, 2.4377158e-08,\n",
      "       2.4573911e-08, 2.3427528e-08, 2.5262890e-08, 2.0500961e-08,\n",
      "       2.2619057e-08, 2.3056662e-08, 2.4230387e-08, 2.4242615e-08,\n",
      "       2.5257233e-08, 2.5455906e-08, 2.5486214e-08, 2.1712053e-08,\n",
      "       2.5376181e-08, 2.4576925e-08, 2.3025397e-08, 2.3903779e-08,\n",
      "       2.2657447e-08, 2.1633445e-08, 2.5653238e-08, 2.5422818e-08,\n",
      "       2.3719286e-08, 2.5327925e-08, 2.4538476e-08, 2.2215485e-08,\n",
      "       2.4223466e-08, 2.3184025e-08, 1.8027158e-08, 2.5907948e-08,\n",
      "       2.5634899e-08, 1.6211629e-08, 2.5973812e-08, 2.3719801e-08,\n",
      "       2.2584821e-08, 2.4341119e-08, 2.5176519e-08, 2.1156172e-08,\n",
      "       2.4379530e-08, 2.1368123e-08, 2.5613268e-08, 2.1404228e-08,\n",
      "       2.3635318e-08, 2.5098831e-08, 2.4255575e-08, 2.5468736e-08,\n",
      "       2.5069365e-08, 2.4195710e-08, 2.2949218e-08, 2.5935218e-08,\n",
      "       2.3645590e-08, 2.3061050e-08, 1.8756673e-08, 2.5550261e-08,\n",
      "       2.4752136e-08, 2.2035771e-08, 2.0064995e-08, 2.5902020e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_415\n",
      "index : 205\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.6340097e-08, 2.5099865e-08, 3.5270887e-08, 3.6181657e-08,\n",
      "       3.5687332e-08, 3.6558024e-08, 3.6795726e-08, 3.5725883e-08,\n",
      "       3.3093279e-08, 3.7011340e-08, 3.6254839e-08, 3.5387462e-08,\n",
      "       2.9334876e-08, 3.4677960e-08, 3.5146247e-08, 2.6526569e-08,\n",
      "       3.5251354e-08, 3.2798809e-08, 3.4625490e-08, 2.8731673e-08,\n",
      "       3.6307846e-08, 3.3948478e-08, 2.3414115e-08, 3.6595907e-08,\n",
      "       3.5990048e-08, 3.5271093e-08, 3.3026211e-08, 3.3444795e-08,\n",
      "       2.8832032e-08, 3.5085911e-08, 3.0102761e-08, 2.7387884e-08,\n",
      "       2.2636968e-08, 3.4587764e-08, 3.2834173e-08, 2.8806776e-08,\n",
      "       3.4585117e-08, 3.2581735e-08, 3.5406924e-08, 3.3538221e-08,\n",
      "       3.7093276e-08, 3.1130497e-08, 3.5263589e-08, 3.7054100e-08,\n",
      "       3.7099849e-08, 2.9913679e-08, 3.7179529e-08, 3.2666740e-08,\n",
      "       3.0406191e-08, 3.5106957e-08, 3.6975536e-08, 3.7234269e-08,\n",
      "       3.2145021e-08, 2.8433002e-08, 3.6060744e-08, 3.6920706e-08,\n",
      "       3.4624311e-08, 3.5432276e-08, 3.6940357e-08, 3.6214182e-08,\n",
      "       2.5818313e-08, 3.7210448e-08, 3.2896679e-08, 3.6930366e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/separable_conv2d\n",
      "index : 206\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00183647, 0.00183397, 0.0018488 , 0.00175058, 0.00176082,\n",
      "       0.00184758, 0.00181392, 0.00184308, 0.00182719, 0.00182563,\n",
      "       0.00185294, 0.00181359, 0.00179142, 0.00181717, 0.00184206,\n",
      "       0.00175711, 0.00178283, 0.00184079, 0.00184233, 0.00180684,\n",
      "       0.00183294, 0.00184061, 0.00185368, 0.00180563, 0.00185472,\n",
      "       0.00178344, 0.00179058, 0.00181863, 0.00185141, 0.00179986,\n",
      "       0.00185724, 0.00183882, 0.00183889, 0.00183056, 0.00183252,\n",
      "       0.00183623, 0.0018096 , 0.00186008, 0.00184205, 0.00185322,\n",
      "       0.00184595, 0.00182382, 0.00178268, 0.00185453, 0.00181219,\n",
      "       0.00180425, 0.00182755, 0.00184023, 0.00182619, 0.00176921,\n",
      "       0.00184397, 0.00183709, 0.00184922, 0.00184096, 0.00185633,\n",
      "       0.00185568, 0.00183756, 0.00183813, 0.00178677, 0.00176786,\n",
      "       0.00184538, 0.00184615, 0.00178085, 0.00185222], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/batch_normalization_54/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/BiasAdd\n",
      "index : 207\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.8373751e-08, 1.8348711e-08, 1.8497119e-08, 1.7514420e-08,\n",
      "       1.7616827e-08, 1.8484931e-08, 1.8148086e-08, 1.8439884e-08,\n",
      "       1.8280847e-08, 1.8265261e-08, 1.8538520e-08, 1.8144847e-08,\n",
      "       1.7923039e-08, 1.8180677e-08, 1.8429635e-08, 1.7579719e-08,\n",
      "       1.7837117e-08, 1.8416994e-08, 1.8432411e-08, 1.8077266e-08,\n",
      "       1.8338445e-08, 1.8415150e-08, 1.8545890e-08, 1.8065212e-08,\n",
      "       1.8556344e-08, 1.7843135e-08, 1.7914624e-08, 1.8195284e-08,\n",
      "       1.8523194e-08, 1.8007492e-08, 1.8581526e-08, 1.8397248e-08,\n",
      "       1.8397982e-08, 1.8314623e-08, 1.8334209e-08, 1.8371374e-08,\n",
      "       1.8104872e-08, 1.8609933e-08, 1.8429517e-08, 1.8541350e-08,\n",
      "       1.8468553e-08, 1.8247182e-08, 1.7835527e-08, 1.8554417e-08,\n",
      "       1.8130827e-08, 1.8051344e-08, 1.8284510e-08, 1.8411356e-08,\n",
      "       1.8270905e-08, 1.7700843e-08, 1.8448803e-08, 1.8379904e-08,\n",
      "       1.8501296e-08, 1.8418707e-08, 1.8572466e-08, 1.8565901e-08,\n",
      "       1.8384597e-08, 1.8390375e-08, 1.7876525e-08, 1.7687258e-08,\n",
      "       1.8462927e-08, 1.8470551e-08, 1.7817227e-08, 1.8531271e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/strided_slice_1\n",
      "index : 208\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001963788876309991, -128)\n",
      "quantization_parameters : {'scales': array([0.00196379], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/separable_conv2d/depthwise\n",
      "index : 209\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00068666, 0.00051864, 0.00075397, 0.0007854 , 0.00078007,\n",
      "       0.00077961, 0.00075166, 0.00077743, 0.00059721, 0.00078771,\n",
      "       0.00063353, 0.00060593, 0.00069427, 0.00072734, 0.00076876,\n",
      "       0.00074847, 0.00077785, 0.00075787, 0.00064863, 0.0007694 ,\n",
      "       0.00080088, 0.00065528, 0.00077833, 0.00076523, 0.00078892,\n",
      "       0.00077252, 0.00079047, 0.00068688, 0.00078605, 0.00068163,\n",
      "       0.00079537, 0.00059472, 0.00073727, 0.00069774, 0.00076574,\n",
      "       0.000777  , 0.00080164, 0.00073769, 0.00068394, 0.00076495,\n",
      "       0.00071377, 0.00058541, 0.0007756 , 0.00079363, 0.00053691,\n",
      "       0.00070297, 0.00074332, 0.00075127, 0.00074498, 0.00078906,\n",
      "       0.00069137, 0.00075816, 0.0007314 , 0.00078371, 0.00077361,\n",
      "       0.00074142, 0.00064211, 0.00074836, 0.00078763, 0.00071512,\n",
      "       0.00077127, 0.00071371, 0.00075017, 0.00065122], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/separable_conv2d\n",
      "index : 210\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00184821, 0.00176567, 0.00176   , 0.00185715, 0.00185588,\n",
      "       0.00170252, 0.00184729, 0.00179622, 0.00184862, 0.00185127,\n",
      "       0.00184568, 0.00183482, 0.00180935, 0.00183025, 0.00183986,\n",
      "       0.00185836, 0.0017929 , 0.00176276, 0.00183896, 0.00178256,\n",
      "       0.00184516, 0.00181034, 0.0018562 , 0.00181642, 0.00181351,\n",
      "       0.00184639, 0.00183941, 0.00184006, 0.00185163, 0.00183903,\n",
      "       0.00183524, 0.0018327 , 0.00184845, 0.00177374, 0.00180378,\n",
      "       0.00184574, 0.00183334, 0.00184864, 0.00184755, 0.0018528 ,\n",
      "       0.00175522, 0.00184041, 0.00184657, 0.00184723, 0.00184545,\n",
      "       0.00183206, 0.00185151, 0.00179109, 0.00172436, 0.00180456,\n",
      "       0.00184712, 0.00179964, 0.00185819, 0.00184885, 0.0018408 ,\n",
      "       0.00185343, 0.00181212, 0.00182835, 0.00182408, 0.00185172,\n",
      "       0.00184013, 0.00185619, 0.00185525, 0.00181664], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/batch_normalization_55/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/BiasAdd\n",
      "index : 211\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.8197410e-08, 3.6491681e-08, 3.6374470e-08, 3.8382222e-08,\n",
      "       3.8355989e-08, 3.5186446e-08, 3.8178474e-08, 3.7123051e-08,\n",
      "       3.8206007e-08, 3.8260811e-08, 3.8145203e-08, 3.7920664e-08,\n",
      "       3.7394276e-08, 3.7826265e-08, 3.8024869e-08, 3.8407364e-08,\n",
      "       3.7054388e-08, 3.6431434e-08, 3.8006355e-08, 3.6840643e-08,\n",
      "       3.8134544e-08, 3.7414800e-08, 3.8362550e-08, 3.7540435e-08,\n",
      "       3.7480259e-08, 3.8159811e-08, 3.8015553e-08, 3.8029000e-08,\n",
      "       3.8268269e-08, 3.8007741e-08, 3.7929418e-08, 3.7876951e-08,\n",
      "       3.8202366e-08, 3.6658477e-08, 3.7279239e-08, 3.8146393e-08,\n",
      "       3.7890224e-08, 3.8206469e-08, 3.8183806e-08, 3.8292271e-08,\n",
      "       3.6275626e-08, 3.8036394e-08, 3.8163527e-08, 3.8177316e-08,\n",
      "       3.8140463e-08, 3.7863671e-08, 3.8265700e-08, 3.7016886e-08,\n",
      "       3.5637832e-08, 3.7295379e-08, 3.8174910e-08, 3.7193708e-08,\n",
      "       3.8403755e-08, 3.8210800e-08, 3.8044433e-08, 3.8305288e-08,\n",
      "       3.7451613e-08, 3.7786993e-08, 3.7698868e-08, 3.8270006e-08,\n",
      "       3.8030432e-08, 3.8362408e-08, 3.8343067e-08, 3.7545021e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/strided_slice_1\n",
      "index : 212\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0019629537127912045, -128)\n",
      "quantization_parameters : {'scales': array([0.00196295], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/separable_conv2d/depthwise\n",
      "index : 213\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0006557 , 0.00078673, 0.00064822, 0.00074657, 0.00075886,\n",
      "       0.00071281, 0.00073448, 0.00078116, 0.00079528, 0.00077199,\n",
      "       0.00078331, 0.00071964, 0.00065818, 0.00078234, 0.00070434,\n",
      "       0.00079258, 0.00077237, 0.00077443, 0.00075048, 0.00077938,\n",
      "       0.00070592, 0.00074531, 0.00079029, 0.00076423, 0.00070666,\n",
      "       0.00078923, 0.00076104, 0.00076171, 0.00063727, 0.00076828,\n",
      "       0.00077619, 0.00074671, 0.00075365, 0.00060284, 0.00077925,\n",
      "       0.00077423, 0.00063207, 0.00079151, 0.0006638 , 0.00078283,\n",
      "       0.00071485, 0.00074681, 0.0007962 , 0.00078659, 0.00073825,\n",
      "       0.00077783, 0.0007737 , 0.00074053, 0.00078596, 0.00074855,\n",
      "       0.00070799, 0.00069693, 0.00076004, 0.00072651, 0.00079519,\n",
      "       0.00073291, 0.00070013, 0.00079576, 0.00073903, 0.00078162,\n",
      "       0.00077331, 0.00070314, 0.0006884 , 0.00076698], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/separable_conv2d\n",
      "index : 214\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00184538, 0.00184716, 0.00181332, 0.00184157, 0.00180535,\n",
      "       0.00184543, 0.0018318 , 0.00184221, 0.00184047, 0.00179791,\n",
      "       0.00185313, 0.00182355, 0.00183338, 0.00185456, 0.00174575,\n",
      "       0.00176114, 0.00171118, 0.00183516, 0.00181055, 0.00180671,\n",
      "       0.00184807, 0.00183854, 0.0018429 , 0.00182394, 0.00181886,\n",
      "       0.00182553, 0.00181529, 0.00184876, 0.00182305, 0.00179486,\n",
      "       0.00184203, 0.00185326, 0.00185392, 0.00180119, 0.00184086,\n",
      "       0.00183516, 0.00183926, 0.00181589, 0.00185425, 0.00183412,\n",
      "       0.00178881, 0.00182529, 0.00183997, 0.00176862, 0.0017793 ,\n",
      "       0.00181181, 0.00184557, 0.00179844, 0.0018457 , 0.00184954,\n",
      "       0.00185276, 0.00184217, 0.00177621, 0.0018008 , 0.00181894,\n",
      "       0.0018326 , 0.00179158, 0.00178994, 0.00179761, 0.00181261,\n",
      "       0.00181614, 0.00184509, 0.00185066, 0.00186023], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/batch_normalization_56/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/BiasAdd\n",
      "index : 215\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.0286394e-08, 3.0315480e-08, 2.9760209e-08, 3.0223777e-08,\n",
      "       2.9629387e-08, 3.0287090e-08, 3.0063386e-08, 3.0234339e-08,\n",
      "       3.0205833e-08, 2.9507309e-08, 3.0413602e-08, 2.9928014e-08,\n",
      "       3.0089360e-08, 3.0436940e-08, 2.8651247e-08, 2.8903822e-08,\n",
      "       2.8083903e-08, 3.0118620e-08, 2.9714700e-08, 2.9651682e-08,\n",
      "       3.0330423e-08, 3.0174128e-08, 3.0245619e-08, 2.9934540e-08,\n",
      "       2.9851090e-08, 2.9960599e-08, 2.9792426e-08, 3.0341809e-08,\n",
      "       2.9919864e-08, 2.9457134e-08, 3.0231362e-08, 3.0415634e-08,\n",
      "       3.0426481e-08, 2.9561104e-08, 3.0212178e-08, 3.0118624e-08,\n",
      "       3.0185952e-08, 2.9802422e-08, 3.0431888e-08, 3.0101539e-08,\n",
      "       2.9357984e-08, 2.9956553e-08, 3.0197526e-08, 2.9026475e-08,\n",
      "       2.9201901e-08, 2.9735350e-08, 3.0289456e-08, 2.9515986e-08,\n",
      "       3.0291641e-08, 3.0354624e-08, 3.0407399e-08, 3.0233650e-08,\n",
      "       2.9151101e-08, 2.9554618e-08, 2.9852458e-08, 3.0076642e-08,\n",
      "       2.9403449e-08, 2.9376496e-08, 2.9502285e-08, 2.9748518e-08,\n",
      "       2.9806451e-08, 3.0281655e-08, 3.0373034e-08, 3.0530060e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/strided_slice_1\n",
      "index : 216\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0019588640425354242, -128)\n",
      "quantization_parameters : {'scales': array([0.00195886], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/separable_conv2d/depthwise\n",
      "index : 217\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00074427, 0.00078866, 0.00070804, 0.00065182, 0.00065767,\n",
      "       0.00068887, 0.00069389, 0.00076532, 0.00078467, 0.00075787,\n",
      "       0.00051172, 0.00065764, 0.00077205, 0.00069974, 0.00071718,\n",
      "       0.00073215, 0.0007698 , 0.00079339, 0.00077218, 0.00078729,\n",
      "       0.00079807, 0.00077277, 0.00079516, 0.00072309, 0.00079279,\n",
      "       0.00069389, 0.00076378, 0.00053541, 0.00074918, 0.00079323,\n",
      "       0.00074543, 0.00063296, 0.00067617, 0.00068539, 0.00077416,\n",
      "       0.00076015, 0.00075803, 0.00077446, 0.00079354, 0.00079312,\n",
      "       0.00070004, 0.00075566, 0.0007885 , 0.0007468 , 0.00077395,\n",
      "       0.00062164, 0.00057735, 0.00067364, 0.00065971, 0.00063784,\n",
      "       0.00073217, 0.00075975, 0.00080078, 0.0007665 , 0.00049417,\n",
      "       0.00077851, 0.00077577, 0.00074852, 0.00074824, 0.00074706,\n",
      "       0.00063766, 0.00061203, 0.00064151, 0.00074974], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/separable_conv2d\n",
      "index : 218\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00186181, 0.00179109, 0.00181473, 0.00178095, 0.00180096,\n",
      "       0.00179658, 0.00183749, 0.00183097, 0.0018301 , 0.00185802,\n",
      "       0.00182984, 0.00184102, 0.00183731, 0.00179836, 0.00180269,\n",
      "       0.0018052 , 0.00184386, 0.00184976, 0.00185913, 0.00181815,\n",
      "       0.001827  , 0.00181869, 0.00180577, 0.00185689, 0.0018497 ,\n",
      "       0.00183832, 0.00180791, 0.0018302 , 0.00176862, 0.00185813,\n",
      "       0.00184963, 0.00178553, 0.00180332, 0.00182462, 0.00182127,\n",
      "       0.00181036, 0.00184493, 0.0018374 , 0.00184824, 0.0018418 ,\n",
      "       0.00178383, 0.0018332 , 0.0017846 , 0.0018499 , 0.0018011 ,\n",
      "       0.00184002, 0.00182111, 0.00182174, 0.00186351, 0.00184901,\n",
      "       0.00184538, 0.00184869, 0.00185106, 0.00183762, 0.00183585,\n",
      "       0.00177442, 0.00183746, 0.00185288, 0.00182365, 0.00178466,\n",
      "       0.00182394, 0.00182038, 0.0018212 , 0.00180075], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/batch_normalization_57/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/BiasAdd\n",
      "index : 219\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.1502606e-08, 2.0685821e-08, 2.0958870e-08, 2.0568727e-08,\n",
      "       2.0799868e-08, 2.0749194e-08, 2.1221734e-08, 2.1146436e-08,\n",
      "       2.1136360e-08, 2.1458847e-08, 2.1133344e-08, 2.1262530e-08,\n",
      "       2.1219682e-08, 2.0769836e-08, 2.0819806e-08, 2.0848834e-08,\n",
      "       2.1295248e-08, 2.1363428e-08, 2.1471616e-08, 2.0998391e-08,\n",
      "       2.1100513e-08, 2.1004620e-08, 2.0855328e-08, 2.1445787e-08,\n",
      "       2.1362743e-08, 2.1231344e-08, 2.0880062e-08, 2.1137486e-08,\n",
      "       2.0426366e-08, 2.1460064e-08, 2.1361931e-08, 2.0621620e-08,\n",
      "       2.0827061e-08, 2.1073083e-08, 2.1034346e-08, 2.0908422e-08,\n",
      "       2.1307651e-08, 2.1220641e-08, 2.1345880e-08, 2.1271456e-08,\n",
      "       2.0601975e-08, 2.1172186e-08, 2.0610919e-08, 2.1365093e-08,\n",
      "       2.0801474e-08, 2.1250905e-08, 2.1032568e-08, 2.1039758e-08,\n",
      "       2.1522277e-08, 2.1354726e-08, 2.1312786e-08, 2.1351093e-08,\n",
      "       2.1378492e-08, 2.1223267e-08, 2.1202736e-08, 2.0493300e-08,\n",
      "       2.1221396e-08, 2.1399483e-08, 2.1061876e-08, 2.0611566e-08,\n",
      "       2.1065256e-08, 2.1024121e-08, 2.1033545e-08, 2.0797392e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/strided_slice_2\n",
      "index : 220\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013051757123321295, -128)\n",
      "quantization_parameters : {'scales': array([0.00130518], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/strided_slice\n",
      "index : 221\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0019596454221755266, -128)\n",
      "quantization_parameters : {'scales': array([0.00195965], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/strided_slice_1\n",
      "index : 222\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001307730795815587, -128)\n",
      "quantization_parameters : {'scales': array([0.00130773], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/separable_conv2d/depthwise\n",
      "index : 223\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00069129, 0.00073058, 0.00079111, 0.0007833 , 0.00057863,\n",
      "       0.00074279, 0.00072641, 0.00070203, 0.00078278, 0.0006761 ,\n",
      "       0.0007683 , 0.00062887, 0.00070159, 0.00073778, 0.00068246,\n",
      "       0.00076153, 0.00057444, 0.0006262 , 0.00066724, 0.00062573,\n",
      "       0.0007414 , 0.00072959, 0.00069188, 0.00071606, 0.00074007,\n",
      "       0.00068868, 0.00072996, 0.00065978, 0.00060506, 0.00073247,\n",
      "       0.00070383, 0.00075517, 0.00067993, 0.00072058, 0.00066403,\n",
      "       0.00057099, 0.00070489, 0.00078023, 0.00068271, 0.00077209,\n",
      "       0.00078387, 0.00069622, 0.00062781, 0.00063017, 0.00071737,\n",
      "       0.00067761, 0.00078798, 0.0007369 , 0.00071065, 0.00075847,\n",
      "       0.00074008, 0.00064661, 0.00070785, 0.00066862, 0.00058647,\n",
      "       0.00069547, 0.00076082, 0.00038027, 0.00075764, 0.00075989,\n",
      "       0.00074004, 0.00077394, 0.00070938, 0.00078521], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/separable_conv2d\n",
      "index : 224\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0017751 , 0.00185529, 0.00184879, 0.00184879, 0.00178273,\n",
      "       0.00183389, 0.00184077, 0.00184327, 0.00183721, 0.0018424 ,\n",
      "       0.00185605, 0.00184668, 0.0018271 , 0.00180401, 0.00183632,\n",
      "       0.00184302, 0.00181873, 0.00184182, 0.00178699, 0.00178976,\n",
      "       0.00184238, 0.00183873, 0.00185999, 0.00184618, 0.00175753,\n",
      "       0.00182259, 0.00184621, 0.00185039, 0.00177929, 0.00184926,\n",
      "       0.00184019, 0.00184856, 0.00181449, 0.00182836, 0.00183908,\n",
      "       0.00183552, 0.00185328, 0.00182838, 0.00183495, 0.00183754,\n",
      "       0.00185266, 0.00185055, 0.00181075, 0.00183175, 0.00181934,\n",
      "       0.00179837, 0.00183543, 0.001799  , 0.00184485, 0.00185262,\n",
      "       0.00185515, 0.00184631, 0.00182298, 0.00184816, 0.00181294,\n",
      "       0.00182323, 0.00179172, 0.0018488 , 0.00179429, 0.00181379,\n",
      "       0.00183469, 0.00178481, 0.00182386, 0.00179784], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/batch_normalization_58/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/BiasAdd\n",
      "index : 225\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.5183144e-08, 1.5869007e-08, 1.5813454e-08, 1.5813377e-08,\n",
      "       1.5248400e-08, 1.5685934e-08, 1.5744837e-08, 1.5766213e-08,\n",
      "       1.5714331e-08, 1.5758729e-08, 1.5875472e-08, 1.5795358e-08,\n",
      "       1.5627885e-08, 1.5430407e-08, 1.5706764e-08, 1.5764021e-08,\n",
      "       1.5556285e-08, 1.5753834e-08, 1.5284829e-08, 1.5308538e-08,\n",
      "       1.5758586e-08, 1.5727386e-08, 1.5909215e-08, 1.5791104e-08,\n",
      "       1.5032869e-08, 1.5589288e-08, 1.5791306e-08, 1.5827093e-08,\n",
      "       1.5218948e-08, 1.5817417e-08, 1.5739879e-08, 1.5811411e-08,\n",
      "       1.5520019e-08, 1.5638662e-08, 1.5730388e-08, 1.5699891e-08,\n",
      "       1.5851812e-08, 1.5638827e-08, 1.5695070e-08, 1.5717170e-08,\n",
      "       1.5846545e-08, 1.5828451e-08, 1.5488071e-08, 1.5667688e-08,\n",
      "       1.5561533e-08, 1.5382183e-08, 1.5699138e-08, 1.5387522e-08,\n",
      "       1.5779669e-08, 1.5846174e-08, 1.5867800e-08, 1.5792175e-08,\n",
      "       1.5592649e-08, 1.5808014e-08, 1.5506778e-08, 1.5594821e-08,\n",
      "       1.5325293e-08, 1.5813512e-08, 1.5347279e-08, 1.5514054e-08,\n",
      "       1.5692800e-08, 1.5266183e-08, 1.5600136e-08, 1.5377617e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/strided_slice_2\n",
      "index : 226\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013075012248009443, -128)\n",
      "quantization_parameters : {'scales': array([0.0013075], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/strided_slice\n",
      "index : 227\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001956979278475046, -128)\n",
      "quantization_parameters : {'scales': array([0.00195698], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/strided_slice\n",
      "index : 228\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001302767195738852, -128)\n",
      "quantization_parameters : {'scales': array([0.00130277], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/strided_slice_1\n",
      "index : 229\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013066515093669295, -128)\n",
      "quantization_parameters : {'scales': array([0.00130665], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/separable_conv2d/depthwise\n",
      "index : 230\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00073793, 0.00079743, 0.0006178 , 0.0007152 , 0.00079105,\n",
      "       0.00077756, 0.00078834, 0.00077261, 0.0006814 , 0.00076322,\n",
      "       0.00079275, 0.00079435, 0.00055034, 0.00074298, 0.00074111,\n",
      "       0.0007115 , 0.00058881, 0.00073425, 0.00076204, 0.00065672,\n",
      "       0.00063412, 0.00062123, 0.00077443, 0.00066452, 0.00079015,\n",
      "       0.00079323, 0.00075983, 0.00068861, 0.00077477, 0.00077888,\n",
      "       0.00074121, 0.00076933, 0.00056339, 0.0007129 , 0.00062937,\n",
      "       0.0007773 , 0.00061859, 0.00075873, 0.00071767, 0.00068558,\n",
      "       0.00066702, 0.0007707 , 0.00076822, 0.00077111, 0.00078887,\n",
      "       0.00073208, 0.00077505, 0.00079223, 0.00078453, 0.00078135,\n",
      "       0.00071144, 0.00070306, 0.0006334 , 0.0006607 , 0.0007082 ,\n",
      "       0.00066424, 0.00054613, 0.00075859, 0.00077154, 0.00071958,\n",
      "       0.00069168, 0.000707  , 0.0007034 , 0.00072017], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/separable_conv2d\n",
      "index : 231\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00183846, 0.00181506, 0.00181125, 0.00184952, 0.00184437,\n",
      "       0.00185026, 0.00184694, 0.00182633, 0.00182769, 0.00183268,\n",
      "       0.00185879, 0.00185032, 0.00183542, 0.00184958, 0.00185443,\n",
      "       0.00184442, 0.00179983, 0.00185371, 0.00185627, 0.00184918,\n",
      "       0.00185206, 0.00176334, 0.00181316, 0.00183632, 0.0018484 ,\n",
      "       0.0018407 , 0.00184702, 0.00182845, 0.0018585 , 0.00183512,\n",
      "       0.00179622, 0.00182013, 0.0018039 , 0.00185652, 0.00177955,\n",
      "       0.00179574, 0.00184496, 0.00184161, 0.0018445 , 0.00181355,\n",
      "       0.00182747, 0.00185875, 0.00183721, 0.00178728, 0.00179693,\n",
      "       0.00185127, 0.00185186, 0.00179247, 0.00182676, 0.00184666,\n",
      "       0.0018532 , 0.00180623, 0.00183757, 0.00172452, 0.00184412,\n",
      "       0.00183287, 0.0018065 , 0.00186104, 0.00184292, 0.00179812,\n",
      "       0.00183083, 0.00181383, 0.00185146, 0.00183119], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/batch_normalization_59/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/BiasAdd\n",
      "index : 232\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.6427798e-08, 1.6218689e-08, 1.6184654e-08, 1.6526615e-08,\n",
      "       1.6480557e-08, 1.6533198e-08, 1.6503533e-08, 1.6319420e-08,\n",
      "       1.6331565e-08, 1.6376175e-08, 1.6609436e-08, 1.6533766e-08,\n",
      "       1.6400628e-08, 1.6527187e-08, 1.6570482e-08, 1.6481028e-08,\n",
      "       1.6082561e-08, 1.6564053e-08, 1.6586940e-08, 1.6523593e-08,\n",
      "       1.6549302e-08, 1.5756564e-08, 1.6201737e-08, 1.6408682e-08,\n",
      "       1.6516628e-08, 1.6447839e-08, 1.6504293e-08, 1.6338307e-08,\n",
      "       1.6606862e-08, 1.6397918e-08, 1.6050354e-08, 1.6263984e-08,\n",
      "       1.6118980e-08, 1.6589176e-08, 1.5901366e-08, 1.6046078e-08,\n",
      "       1.6485837e-08, 1.6455946e-08, 1.6481762e-08, 1.6205240e-08,\n",
      "       1.6329610e-08, 1.6609125e-08, 1.6416625e-08, 1.5970487e-08,\n",
      "       1.6056690e-08, 1.6542264e-08, 1.6547519e-08, 1.6016818e-08,\n",
      "       1.6323218e-08, 1.6501023e-08, 1.6559495e-08, 1.6139756e-08,\n",
      "       1.6419850e-08, 1.5409650e-08, 1.6478372e-08, 1.6377788e-08,\n",
      "       1.6142206e-08, 1.6629507e-08, 1.6467594e-08, 1.6067277e-08,\n",
      "       1.6359648e-08, 1.6207720e-08, 1.6543957e-08, 1.6362781e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/strided_slice_2\n",
      "index : 233\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013055293820798397, -128)\n",
      "quantization_parameters : {'scales': array([0.00130553], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/strided_slice\n",
      "index : 234\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013048662804067135, -128)\n",
      "quantization_parameters : {'scales': array([0.00130487], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/strided_slice\n",
      "index : 235\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001956203021109104, -128)\n",
      "quantization_parameters : {'scales': array([0.0019562], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/strided_slice_1\n",
      "index : 236\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001308480161242187, -128)\n",
      "quantization_parameters : {'scales': array([0.00130848], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/separable_conv2d/depthwise\n",
      "index : 237\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00055737, 0.00057666, 0.00054074, 0.0007507 , 0.00074625,\n",
      "       0.00065145, 0.00063608, 0.00070377, 0.00071883, 0.00066622,\n",
      "       0.00074422, 0.00078952, 0.00077713, 0.00059872, 0.00074591,\n",
      "       0.00069761, 0.00073636, 0.000721  , 0.00076452, 0.0006419 ,\n",
      "       0.00078961, 0.00073494, 0.00076569, 0.00076181, 0.0006515 ,\n",
      "       0.00071972, 0.00069398, 0.00058498, 0.00075615, 0.00061789,\n",
      "       0.00072333, 0.0007318 , 0.0007238 , 0.00076094, 0.00062309,\n",
      "       0.00065099, 0.00078352, 0.00076814, 0.00073717, 0.00076221,\n",
      "       0.00072342, 0.00071544, 0.00066367, 0.00068076, 0.00076088,\n",
      "       0.00077165, 0.00062339, 0.00077485, 0.00069039, 0.00077419,\n",
      "       0.00070755, 0.00055835, 0.00076182, 0.00079822, 0.00076671,\n",
      "       0.00079708, 0.00071951, 0.00060726, 0.00078556, 0.00072195,\n",
      "       0.00064063, 0.00076152, 0.000676  , 0.00055185], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/separable_conv2d\n",
      "index : 238\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00185269, 0.00185761, 0.00185337, 0.00184283, 0.00182733,\n",
      "       0.00184778, 0.00182927, 0.00180643, 0.00184094, 0.00184646,\n",
      "       0.00183385, 0.00184748, 0.00183061, 0.00185464, 0.00185959,\n",
      "       0.00185118, 0.00184869, 0.00182318, 0.00183623, 0.00182208,\n",
      "       0.00185135, 0.00180558, 0.00182995, 0.00179846, 0.00180079,\n",
      "       0.00185331, 0.00182927, 0.001823  , 0.00179666, 0.00184411,\n",
      "       0.00183907, 0.00177326, 0.0018384 , 0.00181787, 0.00184726,\n",
      "       0.00183024, 0.00181474, 0.00184438, 0.0018362 , 0.00186029,\n",
      "       0.00182821, 0.00183529, 0.00173895, 0.00181611, 0.00183244,\n",
      "       0.00177773, 0.00185621, 0.00182562, 0.00184188, 0.00183114,\n",
      "       0.00180858, 0.00183114, 0.00179993, 0.00184356, 0.00185568,\n",
      "       0.00184852, 0.00180583, 0.00184348, 0.00184648, 0.00185425,\n",
      "       0.00185042, 0.00184035, 0.00181612, 0.00184334], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/batch_normalization_60/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/BiasAdd\n",
      "index : 239\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.2423466e-08, 2.2483013e-08, 2.2431715e-08, 2.2304160e-08,\n",
      "       2.2116531e-08, 2.2363992e-08, 2.2139947e-08, 2.1863563e-08,\n",
      "       2.2281215e-08, 2.2348015e-08, 2.2195429e-08, 2.2360350e-08,\n",
      "       2.2156247e-08, 2.2447097e-08, 2.2506997e-08, 2.2405228e-08,\n",
      "       2.2375069e-08, 2.2066320e-08, 2.2224205e-08, 2.2053005e-08,\n",
      "       2.2407271e-08, 2.1853289e-08, 2.2148175e-08, 2.1767121e-08,\n",
      "       2.1795344e-08, 2.2430951e-08, 2.2139963e-08, 2.2064100e-08,\n",
      "       2.1745318e-08, 2.2319579e-08, 2.2258591e-08, 2.1462048e-08,\n",
      "       2.2250475e-08, 2.2002071e-08, 2.2357689e-08, 2.2151784e-08,\n",
      "       2.1964182e-08, 2.2322899e-08, 2.2223887e-08, 2.2515392e-08,\n",
      "       2.2127216e-08, 2.2212918e-08, 2.1046855e-08, 2.1980734e-08,\n",
      "       2.2178378e-08, 2.1516191e-08, 2.2466091e-08, 2.2095877e-08,\n",
      "       2.2292571e-08, 2.2162693e-08, 2.1889532e-08, 2.2162686e-08,\n",
      "       2.1784917e-08, 2.2312994e-08, 2.2459638e-08, 2.2373017e-08,\n",
      "       2.1856311e-08, 2.2311950e-08, 2.2348297e-08, 2.2442403e-08,\n",
      "       2.2395975e-08, 2.2274088e-08, 2.1980879e-08, 2.2310328e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/strided_slice_1\n",
      "index : 240\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001960617257282138, -128)\n",
      "quantization_parameters : {'scales': array([0.00196062], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/strided_slice\n",
      "index : 241\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001307935337536037, -128)\n",
      "quantization_parameters : {'scales': array([0.00130794], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/strided_slice\n",
      "index : 242\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001958466600626707, -128)\n",
      "quantization_parameters : {'scales': array([0.00195847], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/strided_slice\n",
      "index : 243\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001960952067747712, -128)\n",
      "quantization_parameters : {'scales': array([0.00196095], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/separable_conv2d/depthwise\n",
      "index : 244\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00077025, 0.00072307, 0.00069188, 0.00064412, 0.00075987,\n",
      "       0.00071498, 0.00073879, 0.00073351, 0.00079402, 0.00073119,\n",
      "       0.00076433, 0.00079879, 0.00074948, 0.00078928, 0.00070818,\n",
      "       0.00079246, 0.00073598, 0.00074975, 0.00079209, 0.00077769,\n",
      "       0.00056941, 0.00077341, 0.0004754 , 0.00062407, 0.00069638,\n",
      "       0.00079604, 0.00074031, 0.00075794, 0.00073593, 0.00070924,\n",
      "       0.00062291, 0.000742  , 0.00064641, 0.0007668 , 0.00075965,\n",
      "       0.00064761, 0.00074628, 0.00062592, 0.00075454, 0.00079111,\n",
      "       0.00070827, 0.00079309, 0.00052905, 0.00073608, 0.00068822,\n",
      "       0.00057752, 0.00072702, 0.00077075, 0.00074969, 0.00063386,\n",
      "       0.00072174, 0.00070928, 0.00074117, 0.00057242, 0.00055917,\n",
      "       0.00050647, 0.00067635, 0.0006583 , 0.00072377, 0.00077893,\n",
      "       0.00067316, 0.00069004, 0.00079265, 0.00078919], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/separable_conv2d\n",
      "index : 245\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.001834  , 0.00185639, 0.0018365 , 0.00183742, 0.001778  ,\n",
      "       0.00181277, 0.00184443, 0.00184923, 0.00176419, 0.00178087,\n",
      "       0.00171642, 0.001818  , 0.00178221, 0.00185046, 0.00181553,\n",
      "       0.00183916, 0.00184723, 0.00185245, 0.00175006, 0.00180943,\n",
      "       0.00184415, 0.00183534, 0.00184596, 0.00182483, 0.00184868,\n",
      "       0.00182816, 0.00184245, 0.00184251, 0.00184309, 0.00182888,\n",
      "       0.00185886, 0.00185064, 0.00183507, 0.00184575, 0.00182563,\n",
      "       0.00183976, 0.00175712, 0.0018422 , 0.00183487, 0.00184891,\n",
      "       0.00185407, 0.0018396 , 0.00183635, 0.00173964, 0.00185845,\n",
      "       0.00175209, 0.0018274 , 0.00183743, 0.00173531, 0.00184834,\n",
      "       0.00185497, 0.00183948, 0.00185288, 0.0018405 , 0.00177788,\n",
      "       0.00179891, 0.00184712, 0.00183917, 0.00183631, 0.00185233,\n",
      "       0.00185522, 0.00184916, 0.00182881, 0.00184719], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/batch_normalization_61/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/BiasAdd\n",
      "index : 246\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.0453095e-08, 2.0702744e-08, 2.0480922e-08, 2.0491202e-08,\n",
      "       1.9828523e-08, 2.0216236e-08, 2.0569411e-08, 2.0622883e-08,\n",
      "       1.9674529e-08, 1.9860515e-08, 1.9141805e-08, 2.0274628e-08,\n",
      "       1.9875511e-08, 2.0636589e-08, 2.0247088e-08, 2.0510617e-08,\n",
      "       2.0600631e-08, 2.0658787e-08, 1.9516923e-08, 2.0179000e-08,\n",
      "       2.0566237e-08, 2.0467956e-08, 2.0586468e-08, 2.0350759e-08,\n",
      "       2.0616785e-08, 2.0387947e-08, 2.0547297e-08, 2.0547978e-08,\n",
      "       2.0554468e-08, 2.0395946e-08, 2.0730246e-08, 2.0638646e-08,\n",
      "       2.0464983e-08, 2.0584041e-08, 2.0359748e-08, 2.0517302e-08,\n",
      "       1.9595658e-08, 2.0544462e-08, 2.0462753e-08, 2.0619353e-08,\n",
      "       2.0676858e-08, 2.0515454e-08, 2.0479241e-08, 1.9400721e-08,\n",
      "       2.0725702e-08, 1.9539590e-08, 2.0379389e-08, 2.0491296e-08,\n",
      "       1.9352417e-08, 2.0612937e-08, 2.0686899e-08, 2.0514157e-08,\n",
      "       2.0663544e-08, 2.0525572e-08, 1.9827135e-08, 2.0061728e-08,\n",
      "       2.0599382e-08, 2.0510740e-08, 2.0478764e-08, 2.0657442e-08,\n",
      "       2.0689725e-08, 2.0622087e-08, 2.0395170e-08, 2.0600144e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/strided_slice_1\n",
      "index : 247\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001963102724403143, -128)\n",
      "quantization_parameters : {'scales': array([0.0019631], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/separable_conv2d/depthwise\n",
      "index : 248\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00077086, 0.00069813, 0.00065547, 0.00073855, 0.00061203,\n",
      "       0.00075481, 0.00059303, 0.00075934, 0.00075031, 0.00076275,\n",
      "       0.00077421, 0.00077364, 0.00071724, 0.00073921, 0.00078979,\n",
      "       0.00079584, 0.00075577, 0.00073314, 0.00077379, 0.00076225,\n",
      "       0.00067325, 0.00078076, 0.00065251, 0.00073528, 0.00049353,\n",
      "       0.00074877, 0.00073058, 0.00065983, 0.00075882, 0.00071425,\n",
      "       0.00075768, 0.00067893, 0.00071903, 0.00077692, 0.00072512,\n",
      "       0.0007789 , 0.00073374, 0.00075381, 0.00075888, 0.00061783,\n",
      "       0.0007924 , 0.00068767, 0.00067008, 0.00070534, 0.00073596,\n",
      "       0.00066137, 0.00077371, 0.00065711, 0.00072062, 0.00074142,\n",
      "       0.00066709, 0.0006896 , 0.000769  , 0.00060239, 0.00069902,\n",
      "       0.00069976, 0.00065822, 0.00078997, 0.00077289, 0.00066367,\n",
      "       0.0007453 , 0.00076454, 0.0007578 , 0.00077026], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/separable_conv2d\n",
      "index : 249\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00184993, 0.00183379, 0.00185786, 0.00185475, 0.00180981,\n",
      "       0.00183436, 0.0018027 , 0.00184977, 0.00184704, 0.00180343,\n",
      "       0.00186315, 0.00182991, 0.00182276, 0.00180016, 0.0018492 ,\n",
      "       0.00185308, 0.00181571, 0.00184373, 0.0018596 , 0.00185211,\n",
      "       0.00186236, 0.00185576, 0.00183642, 0.0018478 , 0.0017827 ,\n",
      "       0.0018508 , 0.0018446 , 0.00185027, 0.00184155, 0.00181977,\n",
      "       0.00181534, 0.00185487, 0.00183303, 0.00180076, 0.00183899,\n",
      "       0.0018117 , 0.00181584, 0.00185772, 0.00185589, 0.00183275,\n",
      "       0.00179577, 0.00185591, 0.00185126, 0.00185477, 0.00181042,\n",
      "       0.00180833, 0.0018435 , 0.0017264 , 0.00184514, 0.00180385,\n",
      "       0.00184325, 0.0018118 , 0.00183294, 0.00181395, 0.00185016,\n",
      "       0.0018454 , 0.00182916, 0.00183962, 0.00181837, 0.00183338,\n",
      "       0.00180335, 0.00180904, 0.00183843, 0.00186113], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/batch_normalization_62/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/BiasAdd\n",
      "index : 250\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.3603210e-08, 2.3397266e-08, 2.3704358e-08, 2.3664660e-08,\n",
      "       2.3091285e-08, 2.3404558e-08, 2.3000592e-08, 2.3601102e-08,\n",
      "       2.3566285e-08, 2.3009850e-08, 2.3771779e-08, 2.3347717e-08,\n",
      "       2.3256506e-08, 2.2968216e-08, 2.3593827e-08, 2.3643373e-08,\n",
      "       2.3166560e-08, 2.3524027e-08, 2.3726606e-08, 2.3631010e-08,\n",
      "       2.3761743e-08, 2.3677602e-08, 2.3430777e-08, 2.3575934e-08,\n",
      "       2.2745382e-08, 2.3614282e-08, 2.3535140e-08, 2.3607555e-08,\n",
      "       2.3496309e-08, 2.3218409e-08, 2.3161819e-08, 2.3666221e-08,\n",
      "       2.3387582e-08, 2.2975870e-08, 2.3463539e-08, 2.3115371e-08,\n",
      "       2.3168250e-08, 2.3702590e-08, 2.3679194e-08, 2.3384004e-08,\n",
      "       2.2912198e-08, 2.3679508e-08, 2.3620197e-08, 2.3664967e-08,\n",
      "       2.3099046e-08, 2.3072401e-08, 2.3521125e-08, 2.2027017e-08,\n",
      "       2.3542112e-08, 2.3015195e-08, 2.3517895e-08, 2.3116637e-08,\n",
      "       2.3386354e-08, 2.3144157e-08, 2.3606100e-08, 2.3545329e-08,\n",
      "       2.3338107e-08, 2.3471561e-08, 2.3200489e-08, 2.3391985e-08,\n",
      "       2.3008875e-08, 2.3081457e-08, 2.3456497e-08, 2.3746072e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/strided_slice_1\n",
      "index : 251\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001965364906936884, -128)\n",
      "quantization_parameters : {'scales': array([0.00196536], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/separable_conv2d/depthwise\n",
      "index : 252\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00078304, 0.00073765, 0.00068728, 0.0006204 , 0.00074582,\n",
      "       0.00073052, 0.00062493, 0.0007583 , 0.00064981, 0.00074828,\n",
      "       0.00066659, 0.00066159, 0.00065216, 0.00075703, 0.00063419,\n",
      "       0.00078618, 0.0007154 , 0.00079339, 0.00063265, 0.00079581,\n",
      "       0.00073294, 0.00069938, 0.00076124, 0.00071579, 0.00058178,\n",
      "       0.00068026, 0.0007447 , 0.00061359, 0.00077831, 0.00076876,\n",
      "       0.00071563, 0.00076827, 0.00032938, 0.00064845, 0.00075647,\n",
      "       0.00079298, 0.00059404, 0.00078159, 0.00075764, 0.00054135,\n",
      "       0.00073116, 0.00077299, 0.00071944, 0.00068295, 0.00075515,\n",
      "       0.00072182, 0.00067866, 0.00075099, 0.00072188, 0.00057903,\n",
      "       0.00075041, 0.00053855, 0.00069431, 0.00075738, 0.00077379,\n",
      "       0.0006615 , 0.00075621, 0.00080603, 0.00074124, 0.0006961 ,\n",
      "       0.00066774, 0.00071014, 0.00076097, 0.00078376], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/separable_conv2d\n",
      "index : 253\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00183239, 0.00182599, 0.00178236, 0.00182536, 0.00183435,\n",
      "       0.00182297, 0.00182177, 0.00179865, 0.00179088, 0.00177456,\n",
      "       0.00184901, 0.00180852, 0.0018428 , 0.00181672, 0.0018266 ,\n",
      "       0.00182713, 0.00184739, 0.00184544, 0.00185414, 0.00176897,\n",
      "       0.00182707, 0.00175769, 0.00179158, 0.00185881, 0.00183398,\n",
      "       0.00183985, 0.00184469, 0.00181982, 0.001843  , 0.00185034,\n",
      "       0.00185466, 0.00184682, 0.00182765, 0.00179563, 0.00182284,\n",
      "       0.00185219, 0.0018161 , 0.00185056, 0.00181077, 0.00180428,\n",
      "       0.0018612 , 0.00184951, 0.00181714, 0.00184315, 0.00181578,\n",
      "       0.00181956, 0.00183889, 0.00185587, 0.00181707, 0.00182376,\n",
      "       0.00182828, 0.00183197, 0.00184241, 0.00181109, 0.00183876,\n",
      "       0.00176474, 0.00185296, 0.00184787, 0.00183587, 0.00184523,\n",
      "       0.00184828, 0.00183769, 0.00183637, 0.0018358 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/batch_normalization_63/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/BiasAdd\n",
      "index : 254\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([2.0818641e-08, 2.0745864e-08, 2.0250216e-08, 2.0738780e-08,\n",
      "       2.0840913e-08, 2.0711626e-08, 2.0698016e-08, 2.0435271e-08,\n",
      "       2.0347050e-08, 2.0161618e-08, 2.1007414e-08, 2.0547452e-08,\n",
      "       2.0936941e-08, 2.0640547e-08, 2.0752896e-08, 2.0758861e-08,\n",
      "       2.0988997e-08, 2.0966869e-08, 2.1065693e-08, 2.0098126e-08,\n",
      "       2.0758183e-08, 1.9969969e-08, 2.0354960e-08, 2.1118819e-08,\n",
      "       2.0836659e-08, 2.0903348e-08, 2.0958321e-08, 2.0675792e-08,\n",
      "       2.0939197e-08, 2.1022524e-08, 2.1071703e-08, 2.0982620e-08,\n",
      "       2.0764769e-08, 2.0401032e-08, 2.0710155e-08, 2.1043592e-08,\n",
      "       2.0633559e-08, 2.1025043e-08, 2.0573022e-08, 2.0499206e-08,\n",
      "       2.1146002e-08, 2.1013152e-08, 2.0645345e-08, 2.0940918e-08,\n",
      "       2.0629876e-08, 2.0672893e-08, 2.0892488e-08, 2.1085450e-08,\n",
      "       2.0644562e-08, 2.0720567e-08, 2.0771902e-08, 2.0813912e-08,\n",
      "       2.0932449e-08, 2.0576591e-08, 2.0891008e-08, 2.0050033e-08,\n",
      "       2.1052292e-08, 2.0994490e-08, 2.0858169e-08, 2.0964491e-08,\n",
      "       2.0999119e-08, 2.0878788e-08, 2.0863840e-08, 2.0857374e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/strided_slice_1\n",
      "index : 255\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0019645881839096546, -128)\n",
      "quantization_parameters : {'scales': array([0.00196459], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/separable_conv2d/depthwise\n",
      "index : 256\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00062545, 0.00076857, 0.00066571, 0.0007994 , 0.00079043,\n",
      "       0.00074702, 0.00078194, 0.00072228, 0.00067302, 0.0007696 ,\n",
      "       0.00058021, 0.00075407, 0.00072433, 0.00062663, 0.00079014,\n",
      "       0.00078442, 0.00076212, 0.00070791, 0.00066882, 0.00065068,\n",
      "       0.00074488, 0.00064335, 0.00069957, 0.00070546, 0.00065848,\n",
      "       0.00064346, 0.00062118, 0.00079166, 0.00068676, 0.0007054 ,\n",
      "       0.00070265, 0.00070328, 0.0007878 , 0.00071523, 0.00075496,\n",
      "       0.00073421, 0.00067872, 0.00076921, 0.00061081, 0.00070269,\n",
      "       0.00074811, 0.00079638, 0.00078672, 0.00064489, 0.00075306,\n",
      "       0.00078243, 0.00071629, 0.00074769, 0.00078158, 0.00077756,\n",
      "       0.00057198, 0.0007353 , 0.00073199, 0.00079431, 0.00070073,\n",
      "       0.00074412, 0.00078702, 0.00069015, 0.00078106, 0.00076551,\n",
      "       0.00064046, 0.00076061, 0.0007623 , 0.0007837 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/separable_conv2d\n",
      "index : 257\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00179874, 0.00185911, 0.00183822, 0.00177375, 0.00179165,\n",
      "       0.00178003, 0.00184887, 0.00183655, 0.00180615, 0.00186542,\n",
      "       0.00184943, 0.00184686, 0.0018538 , 0.00185062, 0.00184598,\n",
      "       0.00184992, 0.00181902, 0.00184918, 0.00184676, 0.00183109,\n",
      "       0.00177121, 0.0017456 , 0.00183539, 0.00179095, 0.00184353,\n",
      "       0.00183307, 0.0018479 , 0.00185382, 0.00183597, 0.00185723,\n",
      "       0.00184459, 0.00183854, 0.00184835, 0.00183116, 0.00184797,\n",
      "       0.00184479, 0.00180987, 0.00181473, 0.0018117 , 0.0018538 ,\n",
      "       0.0018495 , 0.00184283, 0.00183693, 0.00182525, 0.00184576,\n",
      "       0.00182864, 0.001807  , 0.00183309, 0.00184443, 0.00177343,\n",
      "       0.0017045 , 0.00181907, 0.00177104, 0.00184703, 0.00184086,\n",
      "       0.00176685, 0.00185348, 0.00172842, 0.00185547, 0.00184378,\n",
      "       0.00168818, 0.00185505, 0.00182072, 0.00183234], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/batch_normalization_64/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/BiasAdd\n",
      "index : 258\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.7437872e-08, 1.8023092e-08, 1.7820529e-08, 1.7195566e-08,\n",
      "       1.7369137e-08, 1.7256410e-08, 1.7923837e-08, 1.7804370e-08,\n",
      "       1.7509702e-08, 1.8084210e-08, 1.7929199e-08, 1.7904298e-08,\n",
      "       1.7971580e-08, 1.7940812e-08, 1.7895758e-08, 1.7934001e-08,\n",
      "       1.7634475e-08, 1.7926791e-08, 1.7903327e-08, 1.7751406e-08,\n",
      "       1.7170946e-08, 1.6922654e-08, 1.7793134e-08, 1.7362273e-08,\n",
      "       1.7872024e-08, 1.7770601e-08, 1.7914392e-08, 1.7971832e-08,\n",
      "       1.7798788e-08, 1.8004830e-08, 1.7882348e-08, 1.7823659e-08,\n",
      "       1.7918810e-08, 1.7752155e-08, 1.7915085e-08, 1.7884258e-08,\n",
      "       1.7545693e-08, 1.7592823e-08, 1.7563508e-08, 1.7971603e-08,\n",
      "       1.7929949e-08, 1.7865220e-08, 1.7808064e-08, 1.7694827e-08,\n",
      "       1.7893663e-08, 1.7727720e-08, 1.7517944e-08, 1.7770876e-08,\n",
      "       1.7880749e-08, 1.7192434e-08, 1.6524169e-08, 1.7634891e-08,\n",
      "       1.7169320e-08, 1.7905977e-08, 1.7846169e-08, 1.7128650e-08,\n",
      "       1.7968455e-08, 1.6756138e-08, 1.7987796e-08, 1.7874429e-08,\n",
      "       1.6366013e-08, 1.7983737e-08, 1.7650898e-08, 1.7763600e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/strided_slice_1\n",
      "index : 259\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001961924135684967, -128)\n",
      "quantization_parameters : {'scales': array([0.00196192], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/separable_conv2d/depthwise\n",
      "index : 260\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00076352, 0.00072062, 0.00068155, 0.00071461, 0.00064913,\n",
      "       0.0006011 , 0.00078246, 0.00079239, 0.00074172, 0.00075762,\n",
      "       0.00071494, 0.00075108, 0.00044183, 0.00071691, 0.00064899,\n",
      "       0.00060357, 0.00056661, 0.00072699, 0.00068421, 0.00071179,\n",
      "       0.00058229, 0.00065656, 0.00077793, 0.00059529, 0.00080091,\n",
      "       0.00073038, 0.00077396, 0.00073934, 0.00077277, 0.00076003,\n",
      "       0.00078703, 0.00071813, 0.00077114, 0.00069573, 0.00067891,\n",
      "       0.00064334, 0.00074142, 0.00078009, 0.0006956 , 0.00077328,\n",
      "       0.00070851, 0.00079828, 0.00076716, 0.0007649 , 0.00062924,\n",
      "       0.00057077, 0.00066611, 0.00063885, 0.00076682, 0.00076322,\n",
      "       0.00076656, 0.00075672, 0.00074916, 0.00072793, 0.00058587,\n",
      "       0.00075643, 0.00078757, 0.00080078, 0.00070184, 0.00070718,\n",
      "       0.00078611, 0.00075459, 0.00064102, 0.00074355], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/separable_conv2d\n",
      "index : 261\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00185184, 0.00184419, 0.00185337, 0.00177755, 0.00184314,\n",
      "       0.00183064, 0.00184615, 0.00177567, 0.00184969, 0.0018045 ,\n",
      "       0.00180868, 0.00174366, 0.00186289, 0.00184438, 0.0017525 ,\n",
      "       0.00184197, 0.00183969, 0.00185118, 0.00182127, 0.00169133,\n",
      "       0.00186369, 0.00180084, 0.00182293, 0.00183969, 0.00183023,\n",
      "       0.00175048, 0.00183389, 0.00183695, 0.00184401, 0.00181548,\n",
      "       0.00174331, 0.00184284, 0.00186155, 0.00186198, 0.00182475,\n",
      "       0.00184742, 0.0018514 , 0.00184652, 0.00179837, 0.00181054,\n",
      "       0.00180748, 0.00184258, 0.00183667, 0.00183704, 0.00172953,\n",
      "       0.00185407, 0.00185019, 0.00185594, 0.00183454, 0.00185461,\n",
      "       0.00179016, 0.00185189, 0.00180961, 0.001814  , 0.00184179,\n",
      "       0.00185375, 0.00183673, 0.00184707, 0.00183201, 0.00182569,\n",
      "       0.00185188, 0.00185115, 0.00180169, 0.00181028], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/batch_normalization_65/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/BiasAdd\n",
      "index : 262\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.6081461e-08, 1.6015040e-08, 1.6094727e-08, 1.5436319e-08,\n",
      "       1.6005904e-08, 1.5897388e-08, 1.6032031e-08, 1.5419968e-08,\n",
      "       1.6062840e-08, 1.5670338e-08, 1.5706698e-08, 1.5142035e-08,\n",
      "       1.6177420e-08, 1.6016680e-08, 1.5218779e-08, 1.5995806e-08,\n",
      "       1.5975973e-08, 1.6075720e-08, 1.5816042e-08, 1.4687631e-08,\n",
      "       1.6184371e-08, 1.5638630e-08, 1.5830443e-08, 1.5975981e-08,\n",
      "       1.5893797e-08, 1.5201252e-08, 1.5925631e-08, 1.5952176e-08,\n",
      "       1.6013470e-08, 1.5765695e-08, 1.5138982e-08, 1.6003288e-08,\n",
      "       1.6165755e-08, 1.6169507e-08, 1.5846213e-08, 1.6043131e-08,\n",
      "       1.6077635e-08, 1.6035306e-08, 1.5617104e-08, 1.5722804e-08,\n",
      "       1.5696214e-08, 1.6001071e-08, 1.5949702e-08, 1.5952962e-08,\n",
      "       1.5019371e-08, 1.6100854e-08, 1.6067132e-08, 1.6117044e-08,\n",
      "       1.5931269e-08, 1.6105492e-08, 1.5545854e-08, 1.6081927e-08,\n",
      "       1.5714733e-08, 1.5752894e-08, 1.5994196e-08, 1.6098088e-08,\n",
      "       1.5950283e-08, 1.6040012e-08, 1.5909288e-08, 1.5854424e-08,\n",
      "       1.6081826e-08, 1.6075495e-08, 1.5645933e-08, 1.5720566e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/strided_slice_2\n",
      "index : 263\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013118083588778973, -128)\n",
      "quantization_parameters : {'scales': array([0.00131181], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/Conv2D_4\n",
      "index : 264\n",
      "shape : [64  3  3 64]\n",
      "shape_signature : [64  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0007931 , 0.00075584, 0.00077137, 0.00074438, 0.00071851,\n",
      "       0.00077613, 0.00076936, 0.0007319 , 0.00073208, 0.00076904,\n",
      "       0.00072241, 0.0007891 , 0.00076531, 0.00076028, 0.00075226,\n",
      "       0.00074689, 0.00076634, 0.00078387, 0.00071178, 0.00075614,\n",
      "       0.00077224, 0.00073935, 0.00079016, 0.00078527, 0.00071262,\n",
      "       0.00073046, 0.00075976, 0.00074309, 0.0007711 , 0.00072035,\n",
      "       0.00076427, 0.00074022, 0.00077728, 0.00076622, 0.00070739,\n",
      "       0.00077105, 0.00076705, 0.00075259, 0.00076494, 0.00072824,\n",
      "       0.00076516, 0.00077806, 0.00071899, 0.00073356, 0.00075341,\n",
      "       0.00075707, 0.00077276, 0.00074894, 0.00077357, 0.00075818,\n",
      "       0.00075322, 0.00075569, 0.00074532, 0.00075911, 0.0007722 ,\n",
      "       0.0007497 , 0.0007751 , 0.00076745, 0.00070465, 0.00075638,\n",
      "       0.00071849, 0.00075059, 0.00078246, 0.00075987], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_4\n",
      "index : 265\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.0828513e-08, 2.9380356e-08, 2.9983845e-08, 2.8934959e-08,\n",
      "       2.7929133e-08, 3.0169137e-08, 2.9905721e-08, 2.8449694e-08,\n",
      "       2.8456567e-08, 2.9893538e-08, 2.8080970e-08, 3.0673270e-08,\n",
      "       2.9748300e-08, 2.9552858e-08, 2.9241003e-08, 2.9032247e-08,\n",
      "       2.9788417e-08, 3.0469952e-08, 2.7667673e-08, 2.9392005e-08,\n",
      "       3.0017731e-08, 2.8739420e-08, 3.0714261e-08, 3.0524312e-08,\n",
      "       2.7700191e-08, 2.8393824e-08, 2.9532663e-08, 2.8884667e-08,\n",
      "       2.9973389e-08, 2.8000725e-08, 2.9707842e-08, 2.8773320e-08,\n",
      "       3.0213592e-08, 2.9783696e-08, 2.7496883e-08, 2.9971435e-08,\n",
      "       2.9816245e-08, 2.9253915e-08, 2.9734210e-08, 2.8307321e-08,\n",
      "       2.9742466e-08, 3.0244017e-08, 2.7947840e-08, 2.8514140e-08,\n",
      "       2.9286001e-08, 2.9428007e-08, 3.0037949e-08, 2.9112153e-08,\n",
      "       3.0069337e-08, 2.9471282e-08, 2.9278436e-08, 2.9374510e-08,\n",
      "       2.8971488e-08, 2.9507259e-08, 3.0016103e-08, 2.9141706e-08,\n",
      "       3.0129073e-08, 2.9831700e-08, 2.7390556e-08, 2.9401466e-08,\n",
      "       2.7928671e-08, 2.9176165e-08, 3.0414899e-08, 2.9536851e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_41\n",
      "index : 266\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.3258396e-08, 4.1226347e-08, 4.2073161e-08, 4.0601371e-08,\n",
      "       3.9189999e-08, 4.2333163e-08, 4.1963538e-08, 3.9920447e-08,\n",
      "       3.9930093e-08, 4.1946443e-08, 3.9403059e-08, 4.3040554e-08,\n",
      "       4.1742645e-08, 4.1468404e-08, 4.1030809e-08, 4.0737884e-08,\n",
      "       4.1798938e-08, 4.2755261e-08, 3.8823121e-08, 4.1242696e-08,\n",
      "       4.2120710e-08, 4.0326988e-08, 4.3098076e-08, 4.2831537e-08,\n",
      "       3.8868752e-08, 3.9842053e-08, 4.1440064e-08, 4.0530800e-08,\n",
      "       4.2058488e-08, 3.9290459e-08, 4.1685873e-08, 4.0374559e-08,\n",
      "       4.2395541e-08, 4.1792312e-08, 3.8583469e-08, 4.2055749e-08,\n",
      "       4.1837986e-08, 4.1048928e-08, 4.1722874e-08, 3.9720671e-08,\n",
      "       4.1734459e-08, 4.2438231e-08, 3.9216250e-08, 4.0010878e-08,\n",
      "       4.1093951e-08, 4.1293209e-08, 4.2149079e-08, 4.0850008e-08,\n",
      "       4.2193122e-08, 4.1353935e-08, 4.1083332e-08, 4.1218144e-08,\n",
      "       4.0652630e-08, 4.1404416e-08, 4.2118426e-08, 4.0891475e-08,\n",
      "       4.2276941e-08, 4.1859668e-08, 3.8434269e-08, 4.1255969e-08,\n",
      "       3.9189352e-08, 4.0939831e-08, 4.2678014e-08, 4.1445940e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_42\n",
      "index : 267\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([5.3957613e-08, 5.1422973e-08, 5.2479230e-08, 5.0643418e-08,\n",
      "       4.8882967e-08, 5.2803539e-08, 5.2342493e-08, 4.9794082e-08,\n",
      "       4.9806111e-08, 5.2321170e-08, 4.9148724e-08, 5.3685895e-08,\n",
      "       5.2066966e-08, 5.1724896e-08, 5.1179072e-08, 5.0813696e-08,\n",
      "       5.2137182e-08, 5.3330037e-08, 4.8425349e-08, 5.1443365e-08,\n",
      "       5.2538539e-08, 5.0301175e-08, 5.3757642e-08, 5.3425179e-08,\n",
      "       4.8482264e-08, 4.9696293e-08, 5.1689547e-08, 5.0555393e-08,\n",
      "       5.2460930e-08, 4.9008275e-08, 5.1996157e-08, 5.0360509e-08,\n",
      "       5.2881347e-08, 5.2128918e-08, 4.8126424e-08, 5.2457512e-08,\n",
      "       5.2185889e-08, 5.1201670e-08, 5.2042306e-08, 4.9544891e-08,\n",
      "       5.2056755e-08, 5.2934595e-08, 4.8915709e-08, 4.9906877e-08,\n",
      "       5.1257828e-08, 5.1506373e-08, 5.2573927e-08, 5.0953549e-08,\n",
      "       5.2628863e-08, 5.1582116e-08, 5.1244587e-08, 5.1412741e-08,\n",
      "       5.0707353e-08, 5.1645085e-08, 5.2535693e-08, 5.1005276e-08,\n",
      "       5.2733412e-08, 5.2212936e-08, 4.7940322e-08, 5.1459921e-08,\n",
      "       4.8882161e-08, 5.1065591e-08, 5.3233684e-08, 5.1696876e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_43\n",
      "index : 268\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.4422521e-08, 4.2335788e-08, 4.3205389e-08, 4.1693990e-08,\n",
      "       4.0244640e-08, 4.3472387e-08, 4.3092818e-08, 4.0994745e-08,\n",
      "       4.1004650e-08, 4.3075261e-08, 4.0463430e-08, 4.4198817e-08,\n",
      "       4.2865977e-08, 4.2584357e-08, 4.2134985e-08, 4.1834177e-08,\n",
      "       4.2923787e-08, 4.3905846e-08, 3.9867889e-08, 4.2352575e-08,\n",
      "       4.3254218e-08, 4.1412228e-08, 4.4257888e-08, 4.3984176e-08,\n",
      "       3.9914745e-08, 4.0914237e-08, 4.2555254e-08, 4.1621522e-08,\n",
      "       4.3190322e-08, 4.0347800e-08, 4.2807681e-08, 4.1461075e-08,\n",
      "       4.3536446e-08, 4.2916984e-08, 3.9621789e-08, 4.3187509e-08,\n",
      "       4.2963883e-08, 4.2153594e-08, 4.2845677e-08, 4.0789590e-08,\n",
      "       4.2857572e-08, 4.3580282e-08, 4.0271594e-08, 4.1087610e-08,\n",
      "       4.2199826e-08, 4.2404452e-08, 4.3283350e-08, 4.1949320e-08,\n",
      "       4.3328580e-08, 4.2466809e-08, 4.2188926e-08, 4.2327365e-08,\n",
      "       4.1746627e-08, 4.2518650e-08, 4.3251873e-08, 4.1991903e-08,\n",
      "       4.3414655e-08, 4.2986152e-08, 3.9468574e-08, 4.2366207e-08,\n",
      "       4.0243975e-08, 4.2041560e-08, 4.3826521e-08, 4.2561290e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_44\n",
      "index : 269\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.3880933e-08, 7.0410401e-08, 7.1856668e-08, 6.9343002e-08,\n",
      "       6.6932522e-08, 7.2300722e-08, 7.1669447e-08, 6.8180057e-08,\n",
      "       6.8196528e-08, 7.1640244e-08, 6.7296405e-08, 7.3508879e-08,\n",
      "       7.1292185e-08, 7.0823802e-08, 7.0076439e-08, 6.9576153e-08,\n",
      "       7.1388328e-08, 7.3021631e-08, 6.6305937e-08, 7.0438318e-08,\n",
      "       7.1937876e-08, 6.8874385e-08, 7.3607126e-08, 7.3151902e-08,\n",
      "       6.6383862e-08, 6.8046162e-08, 7.0775407e-08, 6.9222473e-08,\n",
      "       7.1831614e-08, 6.7104097e-08, 7.1195224e-08, 6.8955629e-08,\n",
      "       7.2407261e-08, 7.1377009e-08, 6.5896636e-08, 7.1826932e-08,\n",
      "       7.1455013e-08, 7.0107383e-08, 7.1258420e-08, 6.7838855e-08,\n",
      "       7.1278201e-08, 7.2480169e-08, 6.6977357e-08, 6.8334501e-08,\n",
      "       7.0184278e-08, 7.0524592e-08, 7.1986335e-08, 6.9767644e-08,\n",
      "       7.2061553e-08, 7.0628310e-08, 7.0166145e-08, 7.0396389e-08,\n",
      "       6.9430548e-08, 7.0714520e-08, 7.1933982e-08, 6.9838471e-08,\n",
      "       7.2204706e-08, 7.1492046e-08, 6.5641814e-08, 7.0460992e-08,\n",
      "       6.6931420e-08, 6.9921057e-08, 7.2889698e-08, 7.0785440e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/Conv2D_4\n",
      "index : 270\n",
      "shape : [64  3  3 64]\n",
      "shape_signature : [64  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00074255, 0.00073734, 0.00072066, 0.00070502, 0.00074945,\n",
      "       0.00073413, 0.00072146, 0.00075529, 0.00073703, 0.00072548,\n",
      "       0.0006826 , 0.00071681, 0.00069885, 0.00072228, 0.00069509,\n",
      "       0.00072534, 0.00074386, 0.00074578, 0.00070236, 0.00072873,\n",
      "       0.00074235, 0.00073031, 0.00074107, 0.00074188, 0.0007383 ,\n",
      "       0.00075199, 0.00075295, 0.0007272 , 0.00074808, 0.00074204,\n",
      "       0.00074346, 0.00065909, 0.00076547, 0.00074424, 0.00067908,\n",
      "       0.00072707, 0.00071   , 0.00075208, 0.00072134, 0.00068911,\n",
      "       0.00073683, 0.00074597, 0.00066305, 0.00071289, 0.00074226,\n",
      "       0.00076348, 0.00068162, 0.00072694, 0.00074898, 0.00069623,\n",
      "       0.00073288, 0.00073681, 0.00072304, 0.00074592, 0.0007483 ,\n",
      "       0.0007365 , 0.00075781, 0.00073592, 0.00072546, 0.00074012,\n",
      "       0.00072719, 0.00072645, 0.00072563, 0.00073827], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_4\n",
      "index : 271\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.6286568e-07, 7.5751586e-07, 7.4037285e-07, 7.2431328e-07,\n",
      "       7.6995508e-07, 7.5422008e-07, 7.4119492e-07, 7.7595843e-07,\n",
      "       7.5719851e-07, 7.4532477e-07, 7.0127857e-07, 7.3642184e-07,\n",
      "       7.1796734e-07, 7.4204581e-07, 7.1410972e-07, 7.4518840e-07,\n",
      "       7.6420798e-07, 7.6618261e-07, 7.2157638e-07, 7.4867188e-07,\n",
      "       7.6265792e-07, 7.5029283e-07, 7.6134768e-07, 7.6217998e-07,\n",
      "       7.5850255e-07, 7.7256647e-07, 7.7354701e-07, 7.4709584e-07,\n",
      "       7.6854934e-07, 7.6234062e-07, 7.6379609e-07, 6.7712483e-07,\n",
      "       7.8640761e-07, 7.6459742e-07, 6.9765849e-07, 7.4696123e-07,\n",
      "       7.2942214e-07, 7.7266122e-07, 7.4107078e-07, 7.0796392e-07,\n",
      "       7.5698688e-07, 7.6637861e-07, 6.8119090e-07, 7.3239772e-07,\n",
      "       7.6256651e-07, 7.8436483e-07, 7.0027136e-07, 7.4682856e-07,\n",
      "       7.6947600e-07, 7.1528308e-07, 7.5293599e-07, 7.5696454e-07,\n",
      "       7.4281752e-07, 7.6632557e-07, 7.6876893e-07, 7.5664889e-07,\n",
      "       7.7853917e-07, 7.5605664e-07, 7.4531118e-07, 7.6036747e-07,\n",
      "       7.4708333e-07, 7.4632152e-07, 7.4548171e-07, 7.5846998e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_41\n",
      "index : 272\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.5310987e-07, 7.4782844e-07, 7.3090467e-07, 7.1505048e-07,\n",
      "       7.6010855e-07, 7.4457483e-07, 7.3171623e-07, 7.6603516e-07,\n",
      "       7.4751512e-07, 7.3579326e-07, 6.9231032e-07, 7.2700414e-07,\n",
      "       7.0878571e-07, 7.3255620e-07, 7.0497737e-07, 7.3565866e-07,\n",
      "       7.5443495e-07, 7.5638440e-07, 7.1234854e-07, 7.3909757e-07,\n",
      "       7.5290473e-07, 7.4069777e-07, 7.5161125e-07, 7.5243292e-07,\n",
      "       7.4880251e-07, 7.6268657e-07, 7.6365461e-07, 7.3754171e-07,\n",
      "       7.5872083e-07, 7.5259146e-07, 7.5402835e-07, 6.6846553e-07,\n",
      "       7.7635070e-07, 7.5481944e-07, 6.8873658e-07, 7.3740881e-07,\n",
      "       7.2009402e-07, 7.6278013e-07, 7.3159367e-07, 6.9891018e-07,\n",
      "       7.4730622e-07, 7.5657783e-07, 6.7247959e-07, 7.2303158e-07,\n",
      "       7.5281451e-07, 7.7433407e-07, 6.9131602e-07, 7.3727779e-07,\n",
      "       7.5963567e-07, 7.0613572e-07, 7.4330717e-07, 7.4728422e-07,\n",
      "       7.3331807e-07, 7.5652548e-07, 7.5893763e-07, 7.4697255e-07,\n",
      "       7.6858288e-07, 7.4638785e-07, 7.3577985e-07, 7.5064361e-07,\n",
      "       7.3752938e-07, 7.3677722e-07, 7.3594822e-07, 7.4877033e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_42\n",
      "index : 273\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.5826409e-07, 7.5294651e-07, 7.3590695e-07, 7.1994424e-07,\n",
      "       7.6531069e-07, 7.4967062e-07, 7.3672408e-07, 7.7127783e-07,\n",
      "       7.5263108e-07, 7.4082897e-07, 6.9704845e-07, 7.3197975e-07,\n",
      "       7.1363661e-07, 7.3756979e-07, 7.0980224e-07, 7.4069345e-07,\n",
      "       7.5959827e-07, 7.6156101e-07, 7.1722383e-07, 7.4415590e-07,\n",
      "       7.5805752e-07, 7.4576707e-07, 7.5675524e-07, 7.5758248e-07,\n",
      "       7.5392728e-07, 7.6790639e-07, 7.6888102e-07, 7.4258941e-07,\n",
      "       7.6391348e-07, 7.5774216e-07, 7.5918888e-07, 6.7304046e-07,\n",
      "       7.8166397e-07, 7.5998537e-07, 6.9345026e-07, 7.4245560e-07,\n",
      "       7.2502229e-07, 7.6800052e-07, 7.3660067e-07, 7.0369350e-07,\n",
      "       7.5242070e-07, 7.6175581e-07, 6.7708197e-07, 7.2797991e-07,\n",
      "       7.5796675e-07, 7.7963352e-07, 6.9604732e-07, 7.4232366e-07,\n",
      "       7.6483457e-07, 7.1096849e-07, 7.4839431e-07, 7.5239853e-07,\n",
      "       7.3833684e-07, 7.6170306e-07, 7.6413176e-07, 7.5208476e-07,\n",
      "       7.7384300e-07, 7.5149609e-07, 7.4081549e-07, 7.5578095e-07,\n",
      "       7.4257696e-07, 7.4181969e-07, 7.4098500e-07, 7.5389488e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_43\n",
      "index : 274\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.5840603e-07, 7.5308748e-07, 7.3604474e-07, 7.2007902e-07,\n",
      "       7.6545399e-07, 7.4981097e-07, 7.3686198e-07, 7.7142221e-07,\n",
      "       7.5277200e-07, 7.4096766e-07, 6.9717896e-07, 7.3211675e-07,\n",
      "       7.1377019e-07, 7.3770786e-07, 7.0993508e-07, 7.4083209e-07,\n",
      "       7.5974049e-07, 7.6170357e-07, 7.1735809e-07, 7.4429522e-07,\n",
      "       7.5819946e-07, 7.4590668e-07, 7.5689690e-07, 7.5772431e-07,\n",
      "       7.5406842e-07, 7.6805014e-07, 7.6902495e-07, 7.4272839e-07,\n",
      "       7.6405644e-07, 7.5788398e-07, 7.5933099e-07, 6.7316643e-07,\n",
      "       7.8181034e-07, 7.6012759e-07, 6.9358003e-07, 7.4259458e-07,\n",
      "       7.2515797e-07, 7.6814428e-07, 7.3673857e-07, 7.0382521e-07,\n",
      "       7.5256156e-07, 7.6189843e-07, 6.7720873e-07, 7.2811622e-07,\n",
      "       7.5810863e-07, 7.7977950e-07, 6.9617761e-07, 7.4246265e-07,\n",
      "       7.6497770e-07, 7.1110156e-07, 7.4853438e-07, 7.5253939e-07,\n",
      "       7.3847508e-07, 7.6184568e-07, 7.6427477e-07, 7.5222556e-07,\n",
      "       7.7398789e-07, 7.5163678e-07, 7.4095414e-07, 7.5592243e-07,\n",
      "       7.4271594e-07, 7.4195856e-07, 7.4112370e-07, 7.5403602e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_44\n",
      "index : 275\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.6727378e-07, 7.6189298e-07, 7.4465095e-07, 7.2849861e-07,\n",
      "       7.7440410e-07, 7.5857815e-07, 7.4547779e-07, 7.8044212e-07,\n",
      "       7.6157380e-07, 7.4963145e-07, 7.0533076e-07, 7.4067708e-07,\n",
      "       7.2211600e-07, 7.4633351e-07, 7.1823604e-07, 7.4949429e-07,\n",
      "       7.6862381e-07, 7.7060986e-07, 7.2574585e-07, 7.5299795e-07,\n",
      "       7.6706476e-07, 7.5462822e-07, 7.6574696e-07, 7.6658404e-07,\n",
      "       7.6288541e-07, 7.7703061e-07, 7.7801678e-07, 7.5141276e-07,\n",
      "       7.7299023e-07, 7.6674559e-07, 7.6820947e-07, 6.8103748e-07,\n",
      "       7.9095167e-07, 7.6901546e-07, 7.0168977e-07, 7.5127741e-07,\n",
      "       7.3363697e-07, 7.7712588e-07, 7.4535291e-07, 7.1205477e-07,\n",
      "       7.6136092e-07, 7.7080693e-07, 6.8512702e-07, 7.3662977e-07,\n",
      "       7.6697285e-07, 7.8889713e-07, 7.0431770e-07, 7.5114394e-07,\n",
      "       7.7392224e-07, 7.1941616e-07, 7.5728667e-07, 7.6133853e-07,\n",
      "       7.4710971e-07, 7.7075362e-07, 7.7321107e-07, 7.6102100e-07,\n",
      "       7.8303776e-07, 7.6042534e-07, 7.4961781e-07, 7.6476113e-07,\n",
      "       7.5140019e-07, 7.5063394e-07, 7.4978931e-07, 7.6285261e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/Conv2D_4\n",
      "index : 276\n",
      "shape : [64  3  3 64]\n",
      "shape_signature : [64  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00073756, 0.00073875, 0.00070787, 0.00073945, 0.00074542,\n",
      "       0.00074453, 0.00074712, 0.00075994, 0.00072715, 0.00071895,\n",
      "       0.00071957, 0.00073419, 0.00072015, 0.00070988, 0.00074446,\n",
      "       0.00074085, 0.00073414, 0.00073557, 0.00074984, 0.00072913,\n",
      "       0.00070026, 0.00074313, 0.00070692, 0.00074012, 0.00074647,\n",
      "       0.00073101, 0.00074117, 0.00071528, 0.00073069, 0.0007414 ,\n",
      "       0.00068305, 0.00074489, 0.00072707, 0.0007453 , 0.00075202,\n",
      "       0.00075135, 0.00074163, 0.0007228 , 0.00073205, 0.00071029,\n",
      "       0.00074642, 0.00072227, 0.00074755, 0.00072415, 0.00070311,\n",
      "       0.00073358, 0.00073261, 0.00070343, 0.00074195, 0.0007346 ,\n",
      "       0.00070157, 0.00070155, 0.00074038, 0.00072666, 0.00074475,\n",
      "       0.000727  , 0.00073226, 0.00074306, 0.00074246, 0.00073934,\n",
      "       0.00071815, 0.00073563, 0.00069884, 0.00071526], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_4\n",
      "index : 277\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.3629154e-07, 9.3779909e-07, 8.9859572e-07, 9.3868579e-07,\n",
      "       9.4626427e-07, 9.4512893e-07, 9.4842454e-07, 9.6469159e-07,\n",
      "       9.2306595e-07, 9.1265775e-07, 9.1344970e-07, 9.3201089e-07,\n",
      "       9.1418269e-07, 9.0114855e-07, 9.4505168e-07, 9.4045726e-07,\n",
      "       9.3194302e-07, 9.3376195e-07, 9.5187357e-07, 9.2557997e-07,\n",
      "       8.8894058e-07, 9.4336019e-07, 8.9738955e-07, 9.3953946e-07,\n",
      "       9.4759406e-07, 9.2796779e-07, 9.4086374e-07, 9.0800739e-07,\n",
      "       9.2756443e-07, 9.4116217e-07, 8.6709360e-07, 9.4559681e-07,\n",
      "       9.2296585e-07, 9.4610715e-07, 9.5464770e-07, 9.5378789e-07,\n",
      "       9.4145940e-07, 9.1754913e-07, 9.2928610e-07, 9.0167163e-07,\n",
      "       9.4753318e-07, 9.1688003e-07, 9.4896495e-07, 9.1926779e-07,\n",
      "       8.9255627e-07, 9.3123606e-07, 9.2999954e-07, 8.9295764e-07,\n",
      "       9.4186237e-07, 9.3252851e-07, 8.9059779e-07, 8.9057846e-07,\n",
      "       9.3986654e-07, 9.2245017e-07, 9.4541775e-07, 9.2287917e-07,\n",
      "       9.2955889e-07, 9.4327464e-07, 9.4250652e-07, 9.3855050e-07,\n",
      "       9.1165180e-07, 9.3383579e-07, 8.8712858e-07, 9.0798153e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_41\n",
      "index : 278\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.3562920e-07, 9.3713567e-07, 8.9796004e-07, 9.3802174e-07,\n",
      "       9.4559488e-07, 9.4446034e-07, 9.4775362e-07, 9.6400925e-07,\n",
      "       9.2241294e-07, 9.1201213e-07, 9.1280350e-07, 9.3135156e-07,\n",
      "       9.1353598e-07, 9.0051105e-07, 9.4438315e-07, 9.3979196e-07,\n",
      "       9.3128375e-07, 9.3310143e-07, 9.5120015e-07, 9.2492519e-07,\n",
      "       8.8831172e-07, 9.4269285e-07, 8.9675473e-07, 9.3887479e-07,\n",
      "       9.4692371e-07, 9.2731136e-07, 9.4019811e-07, 9.0736506e-07,\n",
      "       9.2690829e-07, 9.4049636e-07, 8.6648021e-07, 9.4492788e-07,\n",
      "       9.2231289e-07, 9.4543788e-07, 9.5397240e-07, 9.5311316e-07,\n",
      "       9.4079343e-07, 9.1690004e-07, 9.2862871e-07, 9.0103379e-07,\n",
      "       9.4686288e-07, 9.1623139e-07, 9.4829363e-07, 9.1861750e-07,\n",
      "       8.9192486e-07, 9.3057730e-07, 9.2934164e-07, 8.9232594e-07,\n",
      "       9.4119605e-07, 9.3186884e-07, 8.8996779e-07, 8.8994841e-07,\n",
      "       9.3920170e-07, 9.2179761e-07, 9.4474893e-07, 9.2222632e-07,\n",
      "       9.2890133e-07, 9.4260736e-07, 9.4183980e-07, 9.3788651e-07,\n",
      "       9.1100685e-07, 9.3317516e-07, 8.8650097e-07, 9.0733926e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_42\n",
      "index : 279\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.3357852e-07, 9.3508169e-07, 8.9599189e-07, 9.3596583e-07,\n",
      "       9.4352231e-07, 9.4239027e-07, 9.4567633e-07, 9.6189626e-07,\n",
      "       9.2039124e-07, 9.1001317e-07, 9.1080284e-07, 9.2931026e-07,\n",
      "       9.1153373e-07, 8.9853734e-07, 9.4231331e-07, 9.3773212e-07,\n",
      "       9.2924256e-07, 9.3105626e-07, 9.4911536e-07, 9.2289798e-07,\n",
      "       8.8636477e-07, 9.4062665e-07, 8.9478925e-07, 9.3681700e-07,\n",
      "       9.4484830e-07, 9.2527887e-07, 9.3813742e-07, 9.0537634e-07,\n",
      "       9.2487670e-07, 9.3843499e-07, 8.6458107e-07, 9.4285679e-07,\n",
      "       9.2029143e-07, 9.4336571e-07, 9.5188147e-07, 9.5102416e-07,\n",
      "       9.3873143e-07, 9.1489039e-07, 9.2659337e-07, 8.9905893e-07,\n",
      "       9.4478759e-07, 9.1422322e-07, 9.4621521e-07, 9.1660411e-07,\n",
      "       8.8997001e-07, 9.2853770e-07, 9.2730471e-07, 8.9037019e-07,\n",
      "       9.3913314e-07, 9.2982640e-07, 8.8801715e-07, 8.8799789e-07,\n",
      "       9.3714317e-07, 9.1977722e-07, 9.4267830e-07, 9.2020497e-07,\n",
      "       9.2686537e-07, 9.4054138e-07, 9.3977548e-07, 9.3583088e-07,\n",
      "       9.0901017e-07, 9.3112988e-07, 8.8455795e-07, 9.0535053e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_43\n",
      "index : 280\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.3289316e-07, 9.3439519e-07, 8.9533410e-07, 9.3527871e-07,\n",
      "       9.4282967e-07, 9.4169843e-07, 9.4498211e-07, 9.6119015e-07,\n",
      "       9.1971555e-07, 9.0934515e-07, 9.1013419e-07, 9.2862803e-07,\n",
      "       9.1086457e-07, 8.9787773e-07, 9.4162152e-07, 9.3704369e-07,\n",
      "       9.2856038e-07, 9.3037278e-07, 9.4841857e-07, 9.2222041e-07,\n",
      "       8.8571403e-07, 9.3993611e-07, 8.9413237e-07, 9.3612925e-07,\n",
      "       9.4415464e-07, 9.2459965e-07, 9.3744870e-07, 9.0471167e-07,\n",
      "       9.2419771e-07, 9.3774611e-07, 8.6394635e-07, 9.4216460e-07,\n",
      "       9.1961579e-07, 9.4267313e-07, 9.5118270e-07, 9.5032601e-07,\n",
      "       9.3804226e-07, 9.1421873e-07, 9.2591313e-07, 8.9839887e-07,\n",
      "       9.4409398e-07, 9.1355207e-07, 9.4552058e-07, 9.1593120e-07,\n",
      "       8.8931665e-07, 9.2785604e-07, 9.2662395e-07, 8.8971655e-07,\n",
      "       9.3844375e-07, 9.2914377e-07, 8.8736527e-07, 8.8734595e-07,\n",
      "       9.3645519e-07, 9.1910198e-07, 9.4198623e-07, 9.1952944e-07,\n",
      "       9.2618495e-07, 9.3985091e-07, 9.3908557e-07, 9.3514387e-07,\n",
      "       9.0834283e-07, 9.3044633e-07, 8.8390857e-07, 9.0468592e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_44\n",
      "index : 281\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.2773689e-07, 9.2923062e-07, 8.9038542e-07, 9.3010919e-07,\n",
      "       9.3761844e-07, 9.3649351e-07, 9.3975899e-07, 9.5587745e-07,\n",
      "       9.1463210e-07, 9.0431899e-07, 9.0510372e-07, 9.2349535e-07,\n",
      "       9.0583001e-07, 8.9291495e-07, 9.3641700e-07, 9.3186446e-07,\n",
      "       9.2342805e-07, 9.2523038e-07, 9.4317647e-07, 9.1712315e-07,\n",
      "       8.8081850e-07, 9.3474091e-07, 8.8919035e-07, 9.3095508e-07,\n",
      "       9.3893613e-07, 9.1948920e-07, 9.3226726e-07, 8.9971115e-07,\n",
      "       9.1908947e-07, 9.3256295e-07, 8.5917117e-07, 9.3695706e-07,\n",
      "       9.1453290e-07, 9.3746280e-07, 9.4592531e-07, 9.4507334e-07,\n",
      "       9.3285752e-07, 9.0916564e-07, 9.2079540e-07, 8.9343325e-07,\n",
      "       9.3887581e-07, 9.0850267e-07, 9.4029451e-07, 9.1086866e-07,\n",
      "       8.8440117e-07, 9.2272757e-07, 9.2150231e-07, 8.8479891e-07,\n",
      "       9.3325679e-07, 9.2400819e-07, 8.8246060e-07, 8.8244144e-07,\n",
      "       9.3127920e-07, 9.1402194e-07, 9.3677971e-07, 9.1444701e-07,\n",
      "       9.2106575e-07, 9.3465616e-07, 9.3389508e-07, 9.2997516e-07,\n",
      "       9.0332225e-07, 9.2530354e-07, 8.7902305e-07, 8.9968552e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/Conv2D_4\n",
      "index : 282\n",
      "shape : [36  3  3 64]\n",
      "shape_signature : [36  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0006424 , 0.00064297, 0.00064458, 0.00064133, 0.00064641,\n",
      "       0.0006428 , 0.00064449, 0.00064358, 0.00064506, 0.000641  ,\n",
      "       0.00064506, 0.00064401, 0.00064141, 0.00064285, 0.00064454,\n",
      "       0.00064833, 0.00064334, 0.00064066, 0.00064067, 0.00064287,\n",
      "       0.0006457 , 0.00064505, 0.00064837, 0.00064515, 0.00064498,\n",
      "       0.00064491, 0.00064492, 0.00063741, 0.00064073, 0.00064279,\n",
      "       0.00064053, 0.00064402, 0.00063953, 0.0006448 , 0.00064428,\n",
      "       0.00064384], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_4;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource\n",
      "index : 283\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.1116494e-07, 7.1179727e-07, 7.1358801e-07, 7.0998561e-07,\n",
      "       7.1560765e-07, 7.1161071e-07, 7.1347887e-07, 7.1248036e-07,\n",
      "       7.1410886e-07, 7.0962210e-07, 7.1411210e-07, 7.1294977e-07,\n",
      "       7.1007054e-07, 7.1166477e-07, 7.1353770e-07, 7.1773900e-07,\n",
      "       7.1221086e-07, 7.0924324e-07, 7.0925302e-07, 7.1168489e-07,\n",
      "       7.1482356e-07, 7.1409880e-07, 7.1778129e-07, 7.1421874e-07,\n",
      "       7.1402798e-07, 7.1394641e-07, 7.1395419e-07, 7.0564687e-07,\n",
      "       7.0931992e-07, 7.1160315e-07, 7.0909454e-07, 7.1296273e-07,\n",
      "       7.0799439e-07, 7.1382090e-07, 7.1324632e-07, 7.1276520e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_4;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource1\n",
      "index : 284\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.1124902e-07, 7.1188140e-07, 7.1367236e-07, 7.1006951e-07,\n",
      "       7.1569224e-07, 7.1169478e-07, 7.1356317e-07, 7.1256460e-07,\n",
      "       7.1419328e-07, 7.0970600e-07, 7.1419646e-07, 7.1303407e-07,\n",
      "       7.1015450e-07, 7.1174890e-07, 7.1362200e-07, 7.1782387e-07,\n",
      "       7.1229505e-07, 7.0932703e-07, 7.0933686e-07, 7.1176896e-07,\n",
      "       7.1490803e-07, 7.1418322e-07, 7.1786616e-07, 7.1430316e-07,\n",
      "       7.1411239e-07, 7.1403082e-07, 7.1403861e-07, 7.0573032e-07,\n",
      "       7.0940371e-07, 7.1168728e-07, 7.0917838e-07, 7.1304703e-07,\n",
      "       7.0807806e-07, 7.1390525e-07, 7.1333068e-07, 7.1284944e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_4;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource2\n",
      "index : 285\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.1108570e-07, 7.1171792e-07, 7.1350848e-07, 7.0990649e-07,\n",
      "       7.1552790e-07, 7.1153136e-07, 7.1339929e-07, 7.1240095e-07,\n",
      "       7.1402928e-07, 7.0954303e-07, 7.1403247e-07, 7.1287030e-07,\n",
      "       7.0999141e-07, 7.1158541e-07, 7.1345812e-07, 7.1765902e-07,\n",
      "       7.1213151e-07, 7.0916417e-07, 7.0917395e-07, 7.1160554e-07,\n",
      "       7.1474386e-07, 7.1401922e-07, 7.1770131e-07, 7.1413911e-07,\n",
      "       7.1394840e-07, 7.1386683e-07, 7.1387461e-07, 7.0556820e-07,\n",
      "       7.0924085e-07, 7.1152385e-07, 7.0901552e-07, 7.1288326e-07,\n",
      "       7.0791549e-07, 7.1374131e-07, 7.1316686e-07, 7.1268573e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_4;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource3\n",
      "index : 286\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.1021731e-07, 7.1084872e-07, 7.1263707e-07, 7.0903951e-07,\n",
      "       7.1465405e-07, 7.1066245e-07, 7.1252811e-07, 7.1153096e-07,\n",
      "       7.1315725e-07, 7.0867651e-07, 7.1316049e-07, 7.1199975e-07,\n",
      "       7.0912432e-07, 7.1071645e-07, 7.1258683e-07, 7.1678261e-07,\n",
      "       7.1126181e-07, 7.0829810e-07, 7.0830788e-07, 7.1073651e-07,\n",
      "       7.1387097e-07, 7.1314724e-07, 7.1682479e-07, 7.1326701e-07,\n",
      "       7.1307647e-07, 7.1299502e-07, 7.1300281e-07, 7.0470657e-07,\n",
      "       7.0837467e-07, 7.1065489e-07, 7.0814963e-07, 7.1201271e-07,\n",
      "       7.0705096e-07, 7.1286968e-07, 7.1229590e-07, 7.1181540e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_4;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource4\n",
      "index : 287\n",
      "shape : [36]\n",
      "shape_signature : [36]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.0135457e-07, 7.0197814e-07, 7.0374415e-07, 7.0019149e-07,\n",
      "       7.0573594e-07, 7.0179414e-07, 7.0363649e-07, 7.0265179e-07,\n",
      "       7.0425784e-07, 6.9983298e-07, 7.0426103e-07, 7.0311478e-07,\n",
      "       7.0027522e-07, 7.0184745e-07, 7.0369452e-07, 7.0783790e-07,\n",
      "       7.0238605e-07, 6.9945929e-07, 6.9946896e-07, 7.0186729e-07,\n",
      "       7.0496264e-07, 7.0424790e-07, 7.0787962e-07, 7.0436619e-07,\n",
      "       7.0417809e-07, 7.0409760e-07, 7.0410533e-07, 6.9591260e-07,\n",
      "       6.9953495e-07, 7.0178669e-07, 6.9931269e-07, 7.0312751e-07,\n",
      "       6.9822772e-07, 7.0397385e-07, 7.0340724e-07, 7.0293271e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/Conv2D_4\n",
      "index : 288\n",
      "shape : [64  3  3 64]\n",
      "shape_signature : [64  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00077367, 0.00069136, 0.00077676, 0.00072757, 0.00075832,\n",
      "       0.00078819, 0.00073385, 0.00077386, 0.00077257, 0.00074353,\n",
      "       0.00077149, 0.00075724, 0.000764  , 0.00075679, 0.00073079,\n",
      "       0.00076985, 0.00076574, 0.00075039, 0.00078606, 0.00077392,\n",
      "       0.00074957, 0.00078066, 0.00076226, 0.00077258, 0.00074667,\n",
      "       0.00076279, 0.0007585 , 0.00076727, 0.00079236, 0.00072371,\n",
      "       0.00076247, 0.00076266, 0.00078782, 0.00073484, 0.00076172,\n",
      "       0.00073517, 0.00076408, 0.00076176, 0.00069965, 0.00075541,\n",
      "       0.00078454, 0.00076469, 0.00077888, 0.00076904, 0.00077594,\n",
      "       0.000735  , 0.00078477, 0.00078254, 0.0007444 , 0.00075399,\n",
      "       0.00076381, 0.00077898, 0.00075974, 0.00078609, 0.00077446,\n",
      "       0.00075826, 0.00072221, 0.00075177, 0.00078563, 0.00070871,\n",
      "       0.00076204, 0.00077386, 0.00077847, 0.00075936], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_4\n",
      "index : 289\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([3.0073537e-08, 2.6873906e-08, 3.0193647e-08, 2.8281393e-08,\n",
      "       2.9476581e-08, 3.0637864e-08, 2.8525388e-08, 3.0080916e-08,\n",
      "       3.0030684e-08, 2.8902011e-08, 2.9988566e-08, 2.9434803e-08,\n",
      "       2.9697556e-08, 2.9417352e-08, 2.8406781e-08, 2.9924966e-08,\n",
      "       2.9765310e-08, 2.9168469e-08, 3.0555153e-08, 3.0082994e-08,\n",
      "       2.9136684e-08, 3.0345038e-08, 2.9630012e-08, 3.0031046e-08,\n",
      "       2.9023967e-08, 2.9650577e-08, 2.9483855e-08, 2.9824491e-08,\n",
      "       3.0800010e-08, 2.8131478e-08, 2.9637935e-08, 2.9645589e-08,\n",
      "       3.0623575e-08, 2.8564093e-08, 2.9608808e-08, 2.8577031e-08,\n",
      "       2.9700495e-08, 2.9610373e-08, 2.7196270e-08, 2.9363427e-08,\n",
      "       3.0496029e-08, 2.9724266e-08, 3.0275732e-08, 2.9893247e-08,\n",
      "       3.0161690e-08, 2.8570120e-08, 3.0504889e-08, 3.0418004e-08,\n",
      "       2.8935505e-08, 2.9308303e-08, 2.9690108e-08, 3.0279939e-08,\n",
      "       2.9531730e-08, 3.0556052e-08, 3.0104275e-08, 2.9474307e-08,\n",
      "       2.8073009e-08, 2.9221981e-08, 3.0538391e-08, 2.7548371e-08,\n",
      "       2.9621418e-08, 3.0080617e-08, 3.0259905e-08, 2.9517029e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_41\n",
      "index : 290\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.2199016e-08, 3.7709309e-08, 4.2367553e-08, 3.9684288e-08,\n",
      "       4.1361371e-08, 4.2990877e-08, 4.0026663e-08, 4.2209368e-08,\n",
      "       4.2138886e-08, 4.0555136e-08, 4.2079787e-08, 4.1302748e-08,\n",
      "       4.1671441e-08, 4.1278259e-08, 3.9860232e-08, 4.1990543e-08,\n",
      "       4.1766512e-08, 4.0929027e-08, 4.2874817e-08, 4.2212285e-08,\n",
      "       4.0884427e-08, 4.2579984e-08, 4.1576666e-08, 4.2139391e-08,\n",
      "       4.0726267e-08, 4.1605521e-08, 4.1371578e-08, 4.1849557e-08,\n",
      "       4.3218400e-08, 3.9473928e-08, 4.1587782e-08, 4.1598522e-08,\n",
      "       4.2970825e-08, 4.0080973e-08, 4.1546912e-08, 4.0099128e-08,\n",
      "       4.1675566e-08, 4.1549107e-08, 3.8161652e-08, 4.1202593e-08,\n",
      "       4.2791857e-08, 4.1708919e-08, 4.2482736e-08, 4.1946034e-08,\n",
      "       4.2322711e-08, 4.0089429e-08, 4.2804285e-08, 4.2682366e-08,\n",
      "       4.0602135e-08, 4.1125244e-08, 4.1660989e-08, 4.2488637e-08,\n",
      "       4.1438756e-08, 4.2876078e-08, 4.2242149e-08, 4.1358181e-08,\n",
      "       3.9391885e-08, 4.1004117e-08, 4.2851294e-08, 3.8655717e-08,\n",
      "       4.1564604e-08, 4.2208949e-08, 4.2460528e-08, 4.1418126e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_42\n",
      "index : 291\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([5.2636217e-08, 4.7036057e-08, 5.2846435e-08, 4.9499512e-08,\n",
      "       5.1591392e-08, 5.3623925e-08, 4.9926566e-08, 5.2649124e-08,\n",
      "       5.2561212e-08, 5.0585751e-08, 5.2487493e-08, 5.1518271e-08,\n",
      "       5.1978152e-08, 5.1487724e-08, 4.9718974e-08, 5.2376180e-08,\n",
      "       5.2096738e-08, 5.1052115e-08, 5.3479159e-08, 5.2652766e-08,\n",
      "       5.0996487e-08, 5.3111407e-08, 5.1859935e-08, 5.2561841e-08,\n",
      "       5.0799205e-08, 5.1895928e-08, 5.1604125e-08, 5.2200324e-08,\n",
      "       5.3907723e-08, 4.9237123e-08, 5.1873801e-08, 5.1887195e-08,\n",
      "       5.3598917e-08, 4.9994309e-08, 5.1822820e-08, 5.0016954e-08,\n",
      "       5.1983296e-08, 5.1825563e-08, 4.7600277e-08, 5.1393343e-08,\n",
      "       5.3375683e-08, 5.2024902e-08, 5.2990107e-08, 5.2320662e-08,\n",
      "       5.2790501e-08, 5.0004857e-08, 5.3391187e-08, 5.3239113e-08,\n",
      "       5.0644374e-08, 5.1296862e-08, 5.1965117e-08, 5.2997468e-08,\n",
      "       5.1687916e-08, 5.3480736e-08, 5.2690012e-08, 5.1587413e-08,\n",
      "       4.9134787e-08, 5.1145776e-08, 5.3449824e-08, 4.8216542e-08,\n",
      "       5.1844889e-08, 5.2648602e-08, 5.2962406e-08, 5.1662184e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_43\n",
      "index : 292\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.3334634e-08, 3.8724103e-08, 4.3507704e-08, 4.0752230e-08,\n",
      "       4.2474447e-08, 4.4147800e-08, 4.1103817e-08, 4.3345260e-08,\n",
      "       4.3272884e-08, 4.1646516e-08, 4.3212193e-08, 4.2414243e-08,\n",
      "       4.2792859e-08, 4.2389097e-08, 4.0932910e-08, 4.3120547e-08,\n",
      "       4.2890488e-08, 4.2030468e-08, 4.4028617e-08, 4.3348258e-08,\n",
      "       4.1984666e-08, 4.3725851e-08, 4.2695532e-08, 4.3273403e-08,\n",
      "       4.1822247e-08, 4.2725166e-08, 4.2484928e-08, 4.2975767e-08,\n",
      "       4.4381448e-08, 4.0536211e-08, 4.2706947e-08, 4.2717975e-08,\n",
      "       4.4127212e-08, 4.1159588e-08, 4.2664976e-08, 4.1178232e-08,\n",
      "       4.2797094e-08, 4.2667235e-08, 3.9188617e-08, 4.2311395e-08,\n",
      "       4.3943427e-08, 4.2831346e-08, 4.3625985e-08, 4.3074841e-08,\n",
      "       4.3461654e-08, 4.1168274e-08, 4.3956188e-08, 4.3830990e-08,\n",
      "       4.1694776e-08, 4.2231964e-08, 4.2782126e-08, 4.3632046e-08,\n",
      "       4.2553911e-08, 4.4029914e-08, 4.3378925e-08, 4.2471168e-08,\n",
      "       4.0451958e-08, 4.2107576e-08, 4.4004466e-08, 3.9695980e-08,\n",
      "       4.2683148e-08, 4.3344830e-08, 4.3603180e-08, 4.2532726e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_44\n",
      "index : 293\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([7.2071622e-08, 6.4403658e-08, 7.2359462e-08, 6.7776725e-08,\n",
      "       7.0641008e-08, 7.3424033e-08, 6.8361459e-08, 7.2089300e-08,\n",
      "       7.1968920e-08, 6.9264040e-08, 7.1867987e-08, 7.0540885e-08,\n",
      "       7.1170575e-08, 7.0499063e-08, 6.8077220e-08, 7.1715569e-08,\n",
      "       7.1332948e-08, 6.9902612e-08, 7.3225813e-08, 7.2094281e-08,\n",
      "       6.9826434e-08, 7.2722273e-08, 7.1008706e-08, 7.1969787e-08,\n",
      "       6.9556314e-08, 7.1057990e-08, 7.0658437e-08, 7.1474780e-08,\n",
      "       7.3812622e-08, 6.7417446e-08, 7.1027692e-08, 7.1046031e-08,\n",
      "       7.3389792e-08, 6.8454213e-08, 7.0957888e-08, 6.8485221e-08,\n",
      "       7.1177617e-08, 7.0961640e-08, 6.5176209e-08, 7.0369829e-08,\n",
      "       7.3084131e-08, 7.1234588e-08, 7.2556183e-08, 7.1639555e-08,\n",
      "       7.2282873e-08, 6.8468658e-08, 7.3105355e-08, 7.2897137e-08,\n",
      "       6.9344310e-08, 7.0237725e-08, 7.1152726e-08, 7.2566266e-08,\n",
      "       7.0773169e-08, 7.3227973e-08, 7.2145284e-08, 7.0635558e-08,\n",
      "       6.7277327e-08, 7.0030850e-08, 7.3185646e-08, 6.6020029e-08,\n",
      "       7.0988108e-08, 7.2088582e-08, 7.2518255e-08, 7.0737940e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/Conv2D_4\n",
      "index : 294\n",
      "shape : [64  3  3 64]\n",
      "shape_signature : [64  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00073812, 0.00076184, 0.00074595, 0.00072921, 0.00067961,\n",
      "       0.000692  , 0.00073895, 0.00072303, 0.0007054 , 0.00075773,\n",
      "       0.00071122, 0.00074959, 0.00073778, 0.00065095, 0.00075224,\n",
      "       0.00076004, 0.00073207, 0.00075009, 0.00072868, 0.00073586,\n",
      "       0.00072633, 0.00072242, 0.00075812, 0.00071998, 0.00072495,\n",
      "       0.0007413 , 0.00069858, 0.00074454, 0.00070152, 0.0006825 ,\n",
      "       0.00073795, 0.00075157, 0.00069404, 0.00071265, 0.00073303,\n",
      "       0.00074047, 0.00074679, 0.00072162, 0.00073903, 0.00071855,\n",
      "       0.00071025, 0.0007418 , 0.00065859, 0.00073636, 0.00072805,\n",
      "       0.00076204, 0.00071527, 0.00065339, 0.0007018 , 0.00075339,\n",
      "       0.00074278, 0.00067961, 0.00074831, 0.00074549, 0.00071081,\n",
      "       0.0007358 , 0.00073697, 0.00070014, 0.0007462 , 0.00074049,\n",
      "       0.00074793, 0.00073423, 0.00074398, 0.00075306], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_4\n",
      "index : 295\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.6564547e-07, 6.8703810e-07, 6.7271532e-07, 6.5761134e-07,\n",
      "       6.1288330e-07, 6.2405923e-07, 6.6640189e-07, 6.5203818e-07,\n",
      "       6.3614192e-07, 6.8333003e-07, 6.4139249e-07, 6.7599615e-07,\n",
      "       6.6534244e-07, 5.8703432e-07, 6.7838761e-07, 6.8542192e-07,\n",
      "       6.6019675e-07, 6.7643987e-07, 6.5713942e-07, 6.6361520e-07,\n",
      "       6.5501536e-07, 6.5149408e-07, 6.8368257e-07, 6.4928878e-07,\n",
      "       6.5377230e-07, 6.6851862e-07, 6.2999084e-07, 6.7143890e-07,\n",
      "       6.3264662e-07, 6.1549218e-07, 6.6549194e-07, 6.7777552e-07,\n",
      "       6.2590010e-07, 6.4267829e-07, 6.6105770e-07, 6.6777102e-07,\n",
      "       6.7347207e-07, 6.5077000e-07, 6.6646714e-07, 6.4800008e-07,\n",
      "       6.4051585e-07, 6.6896826e-07, 5.9392562e-07, 6.6406290e-07,\n",
      "       6.5656559e-07, 6.8722244e-07, 6.4504508e-07, 5.8923473e-07,\n",
      "       6.3289133e-07, 6.7942204e-07, 6.6985359e-07, 6.1288011e-07,\n",
      "       6.7483796e-07, 6.7229786e-07, 6.4102312e-07, 6.6355864e-07,\n",
      "       6.6461450e-07, 6.3140033e-07, 6.7293820e-07, 6.6778705e-07,\n",
      "       6.7449383e-07, 6.6213755e-07, 6.7093595e-07, 6.7911873e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_41\n",
      "index : 296\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.6703791e-07, 6.8847527e-07, 6.7412253e-07, 6.5898695e-07,\n",
      "       6.1416534e-07, 6.2536463e-07, 6.6779586e-07, 6.5340214e-07,\n",
      "       6.3747262e-07, 6.8475941e-07, 6.4273416e-07, 6.7741024e-07,\n",
      "       6.6673425e-07, 5.8826231e-07, 6.7980670e-07, 6.8685569e-07,\n",
      "       6.6157776e-07, 6.7785487e-07, 6.5851407e-07, 6.6500337e-07,\n",
      "       6.5638557e-07, 6.5285690e-07, 6.8511270e-07, 6.5064700e-07,\n",
      "       6.5513984e-07, 6.6991709e-07, 6.3130864e-07, 6.7284344e-07,\n",
      "       6.3397005e-07, 6.1677969e-07, 6.6688403e-07, 6.7919331e-07,\n",
      "       6.2720943e-07, 6.4402263e-07, 6.6244053e-07, 6.6916789e-07,\n",
      "       6.7488082e-07, 6.5213129e-07, 6.6786129e-07, 6.4935557e-07,\n",
      "       6.4185565e-07, 6.7036763e-07, 5.9516799e-07, 6.6545198e-07,\n",
      "       6.5793898e-07, 6.8866001e-07, 6.4639443e-07, 5.9046732e-07,\n",
      "       6.3421521e-07, 6.8084330e-07, 6.7125478e-07, 6.1416216e-07,\n",
      "       6.7624961e-07, 6.7370416e-07, 6.4236400e-07, 6.6494670e-07,\n",
      "       6.6600472e-07, 6.3272108e-07, 6.7434587e-07, 6.6918392e-07,\n",
      "       6.7590474e-07, 6.6352266e-07, 6.7233947e-07, 6.8053936e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_42\n",
      "index : 297\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.5899565e-07, 6.8017454e-07, 6.6599483e-07, 6.5104177e-07,\n",
      "       6.0676058e-07, 6.1782481e-07, 6.5974444e-07, 6.4552427e-07,\n",
      "       6.2978683e-07, 6.7650353e-07, 6.3498499e-07, 6.6924292e-07,\n",
      "       6.5869563e-07, 5.8116984e-07, 6.7161051e-07, 6.7857451e-07,\n",
      "       6.5360138e-07, 6.6968221e-07, 6.5057458e-07, 6.5698561e-07,\n",
      "       6.4847171e-07, 6.4498562e-07, 6.7685255e-07, 6.4280232e-07,\n",
      "       6.4724105e-07, 6.6184009e-07, 6.2369719e-07, 6.6473120e-07,\n",
      "       6.2632648e-07, 6.0934337e-07, 6.5884365e-07, 6.7100450e-07,\n",
      "       6.1964732e-07, 6.3625788e-07, 6.5445369e-07, 6.6109993e-07,\n",
      "       6.6674403e-07, 6.4426877e-07, 6.5980913e-07, 6.4152653e-07,\n",
      "       6.3411704e-07, 6.6228523e-07, 5.8799225e-07, 6.5742887e-07,\n",
      "       6.5000643e-07, 6.8035706e-07, 6.3860108e-07, 5.8334825e-07,\n",
      "       6.2656869e-07, 6.7263460e-07, 6.6316170e-07, 6.0675740e-07,\n",
      "       6.6809628e-07, 6.6558152e-07, 6.3461925e-07, 6.5692967e-07,\n",
      "       6.5797497e-07, 6.2509258e-07, 6.6621550e-07, 6.6111579e-07,\n",
      "       6.6775561e-07, 6.5552280e-07, 6.6423326e-07, 6.7233429e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_43\n",
      "index : 298\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.6897354e-07, 6.9047309e-07, 6.7607868e-07, 6.6089922e-07,\n",
      "       6.1594756e-07, 6.2717930e-07, 6.6973365e-07, 6.5529815e-07,\n",
      "       6.3932242e-07, 6.8674649e-07, 6.4459925e-07, 6.7937594e-07,\n",
      "       6.6866897e-07, 5.8996932e-07, 6.8177934e-07, 6.8884879e-07,\n",
      "       6.6349753e-07, 6.7982188e-07, 6.6042492e-07, 6.6693309e-07,\n",
      "       6.5829022e-07, 6.5475137e-07, 6.8710079e-07, 6.5253505e-07,\n",
      "       6.5704097e-07, 6.7186102e-07, 6.3314059e-07, 6.7479590e-07,\n",
      "       6.3580967e-07, 6.1856946e-07, 6.6881921e-07, 6.8116418e-07,\n",
      "       6.2902944e-07, 6.4589148e-07, 6.6436280e-07, 6.7110966e-07,\n",
      "       6.7683919e-07, 6.5402367e-07, 6.6979931e-07, 6.5123987e-07,\n",
      "       6.4371824e-07, 6.7231292e-07, 5.9689506e-07, 6.6738301e-07,\n",
      "       6.5984818e-07, 6.9065834e-07, 6.4827015e-07, 5.9218070e-07,\n",
      "       6.3605557e-07, 6.8281895e-07, 6.7320263e-07, 6.1594432e-07,\n",
      "       6.7821196e-07, 6.7565912e-07, 6.4422807e-07, 6.6687625e-07,\n",
      "       6.6793734e-07, 6.3455713e-07, 6.7630270e-07, 6.7112580e-07,\n",
      "       6.7786607e-07, 6.6544806e-07, 6.7429045e-07, 6.8251416e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_44\n",
      "index : 299\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([6.5539137e-07, 6.7645442e-07, 6.6235231e-07, 6.4748099e-07,\n",
      "       6.0344195e-07, 6.1444570e-07, 6.5613608e-07, 6.4199367e-07,\n",
      "       6.2634228e-07, 6.7280348e-07, 6.3151197e-07, 6.6558260e-07,\n",
      "       6.5509300e-07, 5.7799122e-07, 6.6793723e-07, 6.7486314e-07,\n",
      "       6.5002655e-07, 6.6601945e-07, 6.4701635e-07, 6.5339231e-07,\n",
      "       6.4492497e-07, 6.4145797e-07, 6.7315057e-07, 6.3928661e-07,\n",
      "       6.4370107e-07, 6.5822024e-07, 6.2028596e-07, 6.6109556e-07,\n",
      "       6.2290087e-07, 6.0601064e-07, 6.5524017e-07, 6.6733452e-07,\n",
      "       6.1625826e-07, 6.3277793e-07, 6.5087426e-07, 6.5748418e-07,\n",
      "       6.6309735e-07, 6.4074504e-07, 6.5620037e-07, 6.3801775e-07,\n",
      "       6.3064880e-07, 6.5866294e-07, 5.8477633e-07, 6.5383313e-07,\n",
      "       6.4645133e-07, 6.7663592e-07, 6.3510834e-07, 5.8015769e-07,\n",
      "       6.2314177e-07, 6.6895569e-07, 6.5953463e-07, 6.0343882e-07,\n",
      "       6.6444221e-07, 6.6194121e-07, 6.3114828e-07, 6.5333666e-07,\n",
      "       6.5437627e-07, 6.2167373e-07, 6.6257172e-07, 6.5749992e-07,\n",
      "       6.6410337e-07, 6.5193746e-07, 6.6060034e-07, 6.6865704e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_416\n",
      "index : 300\n",
      "shape : [64  3  3 64]\n",
      "shape_signature : [64  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00073403, 0.00076511, 0.0007579 , 0.00076244, 0.00075704,\n",
      "       0.00070914, 0.00071401, 0.00067893, 0.00075527, 0.00072053,\n",
      "       0.00074974, 0.00075164, 0.00068736, 0.0007574 , 0.00071601,\n",
      "       0.00070674, 0.00075498, 0.00072759, 0.00075078, 0.00075502,\n",
      "       0.0007606 , 0.00071333, 0.00070615, 0.00070718, 0.00073566,\n",
      "       0.00072834, 0.00073007, 0.00073674, 0.00073047, 0.00072686,\n",
      "       0.00072772, 0.0007139 , 0.00077469, 0.00076928, 0.0006819 ,\n",
      "       0.00071308, 0.00075593, 0.00075435, 0.00073566, 0.00075036,\n",
      "       0.00069826, 0.00071263, 0.00073101, 0.00071573, 0.00072954,\n",
      "       0.00073897, 0.00075424, 0.00069593, 0.00074315, 0.00071954,\n",
      "       0.00073769, 0.00074685, 0.00073644, 0.00072523, 0.00072375,\n",
      "       0.00073039, 0.00072806, 0.00074665, 0.00072766, 0.00074277,\n",
      "       0.00074469, 0.00076257, 0.00075208, 0.00073845], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_4\n",
      "index : 301\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.0037694e-06, 1.0462707e-06, 1.0364063e-06, 1.0426213e-06,\n",
      "       1.0352342e-06, 9.6974054e-07, 9.7638747e-07, 9.2842009e-07,\n",
      "       1.0328108e-06, 9.8530450e-07, 1.0252512e-06, 1.0278538e-06,\n",
      "       9.3995538e-07, 1.0357332e-06, 9.7912312e-07, 9.6645226e-07,\n",
      "       1.0324125e-06, 9.9496231e-07, 1.0266800e-06, 1.0324799e-06,\n",
      "       1.0401016e-06, 9.7546047e-07, 9.6564440e-07, 9.6704673e-07,\n",
      "       1.0059933e-06, 9.9598753e-07, 9.9836177e-07, 1.0074799e-06,\n",
      "       9.9890485e-07, 9.9396084e-07, 9.9513829e-07, 9.7624888e-07,\n",
      "       1.0593772e-06, 1.0519710e-06, 9.3248758e-07, 9.7512270e-07,\n",
      "       1.0337135e-06, 1.0315528e-06, 1.0060052e-06, 1.0261053e-06,\n",
      "       9.5485836e-07, 9.7450504e-07, 9.9964325e-07, 9.7875227e-07,\n",
      "       9.9762940e-07, 1.0105294e-06, 1.0314126e-06, 9.5167383e-07,\n",
      "       1.0162355e-06, 9.8396151e-07, 1.0087739e-06, 1.0213002e-06,\n",
      "       1.0070685e-06, 9.9174133e-07, 9.8970759e-07, 9.9878810e-07,\n",
      "       9.9560361e-07, 1.0210263e-06, 9.9505564e-07, 1.0157256e-06,\n",
      "       1.0183430e-06, 1.0427916e-06, 1.0284466e-06, 1.0098137e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_41\n",
      "index : 302\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.9567535e-07, 1.0378340e-06, 1.0280492e-06, 1.0342141e-06,\n",
      "       1.0268865e-06, 9.6192093e-07, 9.6851431e-07, 9.2093370e-07,\n",
      "       1.0244827e-06, 9.7735949e-07, 1.0169840e-06, 1.0195656e-06,\n",
      "       9.3237600e-07, 1.0273816e-06, 9.7122791e-07, 9.5865926e-07,\n",
      "       1.0240875e-06, 9.8693943e-07, 1.0184013e-06, 1.0241544e-06,\n",
      "       1.0317146e-06, 9.6759470e-07, 9.5785788e-07, 9.5924895e-07,\n",
      "       9.9788156e-07, 9.8795624e-07, 9.9031149e-07, 9.9935596e-07,\n",
      "       9.9085014e-07, 9.8594603e-07, 9.8711394e-07, 9.6837675e-07,\n",
      "       1.0508348e-06, 1.0434884e-06, 9.2496845e-07, 9.6725978e-07,\n",
      "       1.0253781e-06, 1.0232347e-06, 9.9789315e-07, 1.0178313e-06,\n",
      "       9.4715881e-07, 9.6664701e-07, 9.9158251e-07, 9.7086001e-07,\n",
      "       9.8958492e-07, 1.0023809e-06, 1.0230957e-06, 9.4399996e-07,\n",
      "       1.0080410e-06, 9.7602731e-07, 1.0006396e-06, 1.0130649e-06,\n",
      "       9.9894794e-07, 9.8374437e-07, 9.8172700e-07, 9.9073429e-07,\n",
      "       9.8757550e-07, 1.0127932e-06, 9.8703197e-07, 1.0075353e-06,\n",
      "       1.0101315e-06, 1.0343830e-06, 1.0201536e-06, 1.0016710e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_42\n",
      "index : 303\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.9712611e-07, 1.0393461e-06, 1.0295470e-06, 1.0357210e-06,\n",
      "       1.0283827e-06, 9.6332246e-07, 9.6992540e-07, 9.2227555e-07,\n",
      "       1.0259754e-06, 9.7878353e-07, 1.0184658e-06, 1.0210512e-06,\n",
      "       9.3373450e-07, 1.0288785e-06, 9.7264297e-07, 9.6005601e-07,\n",
      "       1.0255796e-06, 9.8837745e-07, 1.0198852e-06, 1.0256466e-06,\n",
      "       1.0332179e-06, 9.6900453e-07, 9.5925350e-07, 9.6064662e-07,\n",
      "       9.9933550e-07, 9.8939574e-07, 9.9175440e-07, 1.0008121e-06,\n",
      "       9.9229385e-07, 9.8738258e-07, 9.8855219e-07, 9.6978772e-07,\n",
      "       1.0523660e-06, 1.0450088e-06, 9.2631615e-07, 9.6866904e-07,\n",
      "       1.0268720e-06, 1.0247256e-06, 9.9934709e-07, 1.0193143e-06,\n",
      "       9.4853885e-07, 9.6805547e-07, 9.9302736e-07, 9.7227462e-07,\n",
      "       9.9102670e-07, 1.0038415e-06, 1.0245865e-06, 9.4537540e-07,\n",
      "       1.0095098e-06, 9.7744942e-07, 1.0020975e-06, 1.0145410e-06,\n",
      "       1.0004034e-06, 9.8517773e-07, 9.8315741e-07, 9.9217777e-07,\n",
      "       9.8901444e-07, 1.0142688e-06, 9.8847011e-07, 1.0090033e-06,\n",
      "       1.0116033e-06, 1.0358901e-06, 1.0216401e-06, 1.0031305e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_43\n",
      "index : 304\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.0032419e-06, 1.0457209e-06, 1.0358616e-06, 1.0420734e-06,\n",
      "       1.0346902e-06, 9.6923088e-07, 9.7587429e-07, 9.2793215e-07,\n",
      "       1.0322681e-06, 9.8478677e-07, 1.0247124e-06, 1.0273136e-06,\n",
      "       9.3946142e-07, 1.0351889e-06, 9.7860857e-07, 9.6594442e-07,\n",
      "       1.0318699e-06, 9.9443946e-07, 1.0261405e-06, 1.0319372e-06,\n",
      "       1.0395549e-06, 9.7494785e-07, 9.6513702e-07, 9.6653855e-07,\n",
      "       1.0054647e-06, 9.9546412e-07, 9.9783711e-07, 1.0069505e-06,\n",
      "       9.9837996e-07, 9.9343845e-07, 9.9461533e-07, 9.7573582e-07,\n",
      "       1.0588204e-06, 1.0514182e-06, 9.3199753e-07, 9.7461020e-07,\n",
      "       1.0331702e-06, 1.0310106e-06, 1.0054765e-06, 1.0255661e-06,\n",
      "       9.5435655e-07, 9.7399288e-07, 9.9911790e-07, 9.7823795e-07,\n",
      "       9.9710508e-07, 1.0099984e-06, 1.0308706e-06, 9.5117372e-07,\n",
      "       1.0157014e-06, 9.8344447e-07, 1.0082438e-06, 1.0207635e-06,\n",
      "       1.0065393e-06, 9.9122019e-07, 9.8918747e-07, 9.9826320e-07,\n",
      "       9.9508043e-07, 1.0204898e-06, 9.9453268e-07, 1.0151919e-06,\n",
      "       1.0178079e-06, 1.0422436e-06, 1.0279061e-06, 1.0092830e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_44\n",
      "index : 305\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([9.9655517e-07, 1.0387510e-06, 1.0289575e-06, 1.0351279e-06,\n",
      "       1.0277938e-06, 9.6277086e-07, 9.6937003e-07, 9.2174741e-07,\n",
      "       1.0253879e-06, 9.7822306e-07, 1.0178826e-06, 1.0204665e-06,\n",
      "       9.3319977e-07, 1.0282893e-06, 9.7208601e-07, 9.5950622e-07,\n",
      "       1.0249923e-06, 9.8781140e-07, 1.0193012e-06, 1.0250593e-06,\n",
      "       1.0326262e-06, 9.6844963e-07, 9.5870416e-07, 9.6009649e-07,\n",
      "       9.9876320e-07, 9.8882924e-07, 9.9118643e-07, 1.0002390e-06,\n",
      "       9.9172564e-07, 9.8681710e-07, 9.8798603e-07, 9.6923236e-07,\n",
      "       1.0517633e-06, 1.0444104e-06, 9.2578568e-07, 9.6811436e-07,\n",
      "       1.0262841e-06, 1.0241388e-06, 9.9877491e-07, 1.0187306e-06,\n",
      "       9.4799566e-07, 9.6750114e-07, 9.9245869e-07, 9.7171790e-07,\n",
      "       9.9045928e-07, 1.0032667e-06, 1.0239997e-06, 9.4483403e-07,\n",
      "       1.0089317e-06, 9.7688962e-07, 1.0015237e-06, 1.0139599e-06,\n",
      "       9.9983049e-07, 9.8461362e-07, 9.8259443e-07, 9.9160968e-07,\n",
      "       9.8844805e-07, 1.0136880e-06, 9.8790406e-07, 1.0084254e-06,\n",
      "       1.0110241e-06, 1.0352969e-06, 1.0210550e-06, 1.0025560e-06],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/Conv2D_4\n",
      "index : 306\n",
      "shape : [180   3   3  64]\n",
      "shape_signature : [180   3   3  64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00042083, 0.00042022, 0.00041969, 0.00042208, 0.0004207 ,\n",
      "       0.0004192 , 0.00042015, 0.00041838, 0.00042035, 0.00042083,\n",
      "       0.0004219 , 0.00041948, 0.0004207 , 0.00042083, 0.00042164,\n",
      "       0.00041948, 0.00042104, 0.00042064, 0.00041848, 0.00042088,\n",
      "       0.00042151, 0.00042042, 0.00042091, 0.00042088, 0.00042164,\n",
      "       0.00042017, 0.00042163, 0.00042175, 0.0004206 , 0.0004208 ,\n",
      "       0.00042064, 0.00042071, 0.00042137, 0.00041836, 0.00041932,\n",
      "       0.00042202, 0.00041949, 0.00042038, 0.0004207 , 0.00041802,\n",
      "       0.00041707, 0.00042065, 0.00042144, 0.000418  , 0.00042192,\n",
      "       0.00041434, 0.00042134, 0.00041889, 0.00042082, 0.00042099,\n",
      "       0.00042057, 0.00042132, 0.0004206 , 0.00042161, 0.00042098,\n",
      "       0.00042074, 0.00042102, 0.00042146, 0.00042203, 0.0004206 ,\n",
      "       0.00041928, 0.00042053, 0.00042124, 0.00042129, 0.0004151 ,\n",
      "       0.00042102, 0.00042055, 0.00042112, 0.00042202, 0.00042183,\n",
      "       0.00042205, 0.00042107, 0.00042146, 0.00042118, 0.00041865,\n",
      "       0.00042135, 0.00041917, 0.00041901, 0.00041917, 0.00042156,\n",
      "       0.00042104, 0.00042129, 0.00042059, 0.00042187, 0.00042143,\n",
      "       0.00042072, 0.00041839, 0.00042172, 0.00042164, 0.00042179,\n",
      "       0.00042191, 0.00041718, 0.00041624, 0.0004205 , 0.00041911,\n",
      "       0.00042079, 0.00041539, 0.00042194, 0.0004206 , 0.00042099,\n",
      "       0.00042104, 0.00042072, 0.00041879, 0.00042104, 0.00041949,\n",
      "       0.00042242, 0.00042146, 0.0004205 , 0.00042016, 0.00042138,\n",
      "       0.0004205 , 0.00041257, 0.00042123, 0.00042082, 0.00042098,\n",
      "       0.00042017, 0.00042183, 0.00042068, 0.00041943, 0.00042021,\n",
      "       0.00042115, 0.00042118, 0.00041953, 0.00041761, 0.00041985,\n",
      "       0.0004213 , 0.00042155, 0.00042201, 0.00042141, 0.0004188 ,\n",
      "       0.00042172, 0.00041906, 0.00042113, 0.0004203 , 0.00042172,\n",
      "       0.00042048, 0.00041732, 0.00042133, 0.00042135, 0.00041704,\n",
      "       0.00041853, 0.00042046, 0.0004196 , 0.00042132, 0.0004209 ,\n",
      "       0.00042104, 0.00041835, 0.00042132, 0.00041959, 0.00042122,\n",
      "       0.00042178, 0.00042005, 0.00042134, 0.00041989, 0.00042164,\n",
      "       0.00042193, 0.00041957, 0.00042162, 0.0004221 , 0.00042146,\n",
      "       0.00042032, 0.00042067, 0.00041997, 0.00042099, 0.00041667,\n",
      "       0.00042151, 0.00042175, 0.00042036, 0.00041968, 0.00041726,\n",
      "       0.00042164, 0.00041935, 0.0004212 , 0.00042159, 0.00041898,\n",
      "       0.00042155, 0.00042108, 0.00042028, 0.00041971, 0.00042063],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_4;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource\n",
      "index : 307\n",
      "shape : [180]\n",
      "shape_signature : [180]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.9381919e-07, 4.9310063e-07, 4.9247598e-07, 4.9528165e-07,\n",
      "       4.9366724e-07, 4.9190783e-07, 4.9302105e-07, 4.9094052e-07,\n",
      "       4.9325530e-07, 4.9381379e-07, 4.9507906e-07, 4.9223740e-07,\n",
      "       4.9366201e-07, 4.9381947e-07, 4.9476910e-07, 4.9223081e-07,\n",
      "       4.9406407e-07, 4.9359198e-07, 4.9105751e-07, 4.9388206e-07,\n",
      "       4.9461693e-07, 4.9334000e-07, 4.9391605e-07, 4.9388177e-07,\n",
      "       4.9477495e-07, 4.9304907e-07, 4.9475756e-07, 4.9490143e-07,\n",
      "       4.9354372e-07, 4.9378230e-07, 4.9359244e-07, 4.9368123e-07,\n",
      "       4.9445248e-07, 4.9092324e-07, 4.9205050e-07, 4.9521316e-07,\n",
      "       4.9224622e-07, 4.9328958e-07, 4.9367185e-07, 4.9052403e-07,\n",
      "       4.8940166e-07, 4.9360591e-07, 4.9453274e-07, 4.9049419e-07,\n",
      "       4.9510362e-07, 4.8620137e-07, 4.9441223e-07, 4.9154124e-07,\n",
      "       4.9380691e-07, 4.9400609e-07, 4.9351331e-07, 4.9439041e-07,\n",
      "       4.9354736e-07, 4.9473402e-07, 4.9399898e-07, 4.9371732e-07,\n",
      "       4.9403968e-07, 4.9456094e-07, 4.9522544e-07, 4.9355174e-07,\n",
      "       4.9200162e-07, 4.9347176e-07, 4.9429912e-07, 4.9435448e-07,\n",
      "       4.8708989e-07, 4.9404713e-07, 4.9349546e-07, 4.9416121e-07,\n",
      "       4.9520997e-07, 4.9499607e-07, 4.9525443e-07, 4.9409812e-07,\n",
      "       4.9455485e-07, 4.9422937e-07, 4.9126322e-07, 4.9442485e-07,\n",
      "       4.9187156e-07, 4.9168557e-07, 4.9186980e-07, 4.9467258e-07,\n",
      "       4.9407066e-07, 4.9435596e-07, 4.9353974e-07, 4.9503836e-07,\n",
      "       4.9452478e-07, 4.9368742e-07, 4.9095570e-07, 4.9486158e-07,\n",
      "       4.9477273e-07, 4.9494946e-07, 4.9508276e-07, 4.8953086e-07,\n",
      "       4.8843805e-07, 4.9343470e-07, 4.9179539e-07, 4.9377422e-07,\n",
      "       4.8743311e-07, 4.9512408e-07, 4.9354338e-07, 4.9400757e-07,\n",
      "       4.9407089e-07, 4.9368981e-07, 4.9142602e-07, 4.9406805e-07,\n",
      "       4.9224337e-07, 4.9568297e-07, 4.9456304e-07, 4.9343248e-07,\n",
      "       4.9303799e-07, 4.9446749e-07, 4.9343657e-07, 4.8412505e-07,\n",
      "       4.9429292e-07, 4.9380839e-07, 4.9399421e-07, 4.9304322e-07,\n",
      "       4.9499414e-07, 4.9364451e-07, 4.9217545e-07, 4.9309386e-07,\n",
      "       4.9419157e-07, 4.9422772e-07, 4.9229516e-07, 4.9003484e-07,\n",
      "       4.9266527e-07, 4.9437079e-07, 4.9465854e-07, 4.9520401e-07,\n",
      "       4.9450495e-07, 4.9144012e-07, 4.9486783e-07, 4.9174469e-07,\n",
      "       4.9417031e-07, 4.9320244e-07, 4.9486414e-07, 4.9341168e-07,\n",
      "       4.8969719e-07, 4.9440371e-07, 4.9442804e-07, 4.8937267e-07,\n",
      "       4.9111998e-07, 4.9338638e-07, 4.9237701e-07, 4.9439348e-07,\n",
      "       4.9390428e-07, 4.9406225e-07, 4.9090715e-07, 4.9439478e-07,\n",
      "       4.9236326e-07, 4.9427615e-07, 4.9493474e-07, 4.9290247e-07,\n",
      "       4.9441167e-07, 4.9271870e-07, 4.9476665e-07, 4.9510726e-07,\n",
      "       4.9234001e-07, 4.9474590e-07, 4.9531076e-07, 4.9456150e-07,\n",
      "       4.9322261e-07, 4.9363456e-07, 4.9281476e-07, 4.9400882e-07,\n",
      "       4.8893747e-07, 4.9461511e-07, 4.9489705e-07, 4.9327275e-07,\n",
      "       4.9246660e-07, 4.8962829e-07, 4.9476688e-07, 4.9208495e-07,\n",
      "       4.9425603e-07, 4.9471123e-07, 4.9165328e-07, 4.9465950e-07,\n",
      "       4.9410795e-07, 4.9317117e-07, 4.9250764e-07, 4.9358340e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_4;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource1\n",
      "index : 308\n",
      "shape : [180]\n",
      "shape_signature : [180]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.9284517e-07, 4.9212804e-07, 4.9150458e-07, 4.9430469e-07,\n",
      "       4.9269346e-07, 4.9093757e-07, 4.9204857e-07, 4.8997214e-07,\n",
      "       4.9228237e-07, 4.9283977e-07, 4.9410249e-07, 4.9126646e-07,\n",
      "       4.9268829e-07, 4.9284540e-07, 4.9379315e-07, 4.9125993e-07,\n",
      "       4.9308954e-07, 4.9261837e-07, 4.9008895e-07, 4.9290793e-07,\n",
      "       4.9364127e-07, 4.9236689e-07, 4.9294181e-07, 4.9290765e-07,\n",
      "       4.9379901e-07, 4.9207654e-07, 4.9378167e-07, 4.9392526e-07,\n",
      "       4.9257022e-07, 4.9280834e-07, 4.9261888e-07, 4.9270750e-07,\n",
      "       4.9347722e-07, 4.8995491e-07, 4.9107990e-07, 4.9423636e-07,\n",
      "       4.9127527e-07, 4.9231659e-07, 4.9269806e-07, 4.8955650e-07,\n",
      "       4.8843634e-07, 4.9263230e-07, 4.9355731e-07, 4.8952671e-07,\n",
      "       4.9412705e-07, 4.8524237e-07, 4.9343703e-07, 4.9057172e-07,\n",
      "       4.9283290e-07, 4.9303168e-07, 4.9253987e-07, 4.9341520e-07,\n",
      "       4.9257386e-07, 4.9375819e-07, 4.9302457e-07, 4.9274348e-07,\n",
      "       4.9306522e-07, 4.9358545e-07, 4.9424858e-07, 4.9257824e-07,\n",
      "       4.9103113e-07, 4.9249837e-07, 4.9332414e-07, 4.9337939e-07,\n",
      "       4.8612912e-07, 4.9307260e-07, 4.9252202e-07, 4.9318652e-07,\n",
      "       4.9423318e-07, 4.9401967e-07, 4.9427751e-07, 4.9312354e-07,\n",
      "       4.9357936e-07, 4.9325456e-07, 4.9029421e-07, 4.9344959e-07,\n",
      "       4.9090136e-07, 4.9071576e-07, 4.9089959e-07, 4.9369686e-07,\n",
      "       4.9309614e-07, 4.9338087e-07, 4.9256624e-07, 4.9406191e-07,\n",
      "       4.9354935e-07, 4.9271364e-07, 4.8998731e-07, 4.9388552e-07,\n",
      "       4.9379685e-07, 4.9397323e-07, 4.9410625e-07, 4.8856526e-07,\n",
      "       4.8747461e-07, 4.9246142e-07, 4.9082536e-07, 4.9280032e-07,\n",
      "       4.8647166e-07, 4.9414746e-07, 4.9256988e-07, 4.9303316e-07,\n",
      "       4.9309637e-07, 4.9271603e-07, 4.9045667e-07, 4.9309347e-07,\n",
      "       4.9127243e-07, 4.9470520e-07, 4.9358755e-07, 4.9245921e-07,\n",
      "       4.9206551e-07, 4.9349217e-07, 4.9246330e-07, 4.8317014e-07,\n",
      "       4.9331794e-07, 4.9283437e-07, 4.9301980e-07, 4.9207074e-07,\n",
      "       4.9401780e-07, 4.9267084e-07, 4.9120462e-07, 4.9212122e-07,\n",
      "       4.9321676e-07, 4.9325286e-07, 4.9132410e-07, 4.8906827e-07,\n",
      "       4.9169353e-07, 4.9339565e-07, 4.9368282e-07, 4.9422721e-07,\n",
      "       4.9352957e-07, 4.9047077e-07, 4.9389172e-07, 4.9077477e-07,\n",
      "       4.9319556e-07, 4.9222962e-07, 4.9388802e-07, 4.9243846e-07,\n",
      "       4.8873130e-07, 4.9342856e-07, 4.9345283e-07, 4.8840741e-07,\n",
      "       4.9015125e-07, 4.9241316e-07, 4.9140579e-07, 4.9341833e-07,\n",
      "       4.9293010e-07, 4.9308773e-07, 4.8993888e-07, 4.9341963e-07,\n",
      "       4.9139209e-07, 4.9330123e-07, 4.9395851e-07, 4.9193028e-07,\n",
      "       4.9343646e-07, 4.9174685e-07, 4.9379071e-07, 4.9413069e-07,\n",
      "       4.9136884e-07, 4.9377007e-07, 4.9433373e-07, 4.9358601e-07,\n",
      "       4.9224980e-07, 4.9266089e-07, 4.9184268e-07, 4.9303441e-07,\n",
      "       4.8797307e-07, 4.9363950e-07, 4.9392088e-07, 4.9229982e-07,\n",
      "       4.9149520e-07, 4.8866252e-07, 4.9379094e-07, 4.9111435e-07,\n",
      "       4.9328111e-07, 4.9373546e-07, 4.9068348e-07, 4.9368379e-07,\n",
      "       4.9313337e-07, 4.9219841e-07, 4.9153618e-07, 4.9260979e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_4;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource2\n",
      "index : 309\n",
      "shape : [180]\n",
      "shape_signature : [180]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.9328781e-07, 4.9257000e-07, 4.9194603e-07, 4.9474863e-07,\n",
      "       4.9313599e-07, 4.9137850e-07, 4.9249047e-07, 4.9041222e-07,\n",
      "       4.9272450e-07, 4.9328241e-07, 4.9454627e-07, 4.9170768e-07,\n",
      "       4.9313081e-07, 4.9328804e-07, 4.9423664e-07, 4.9170114e-07,\n",
      "       4.9353241e-07, 4.9306084e-07, 4.9052909e-07, 4.9335057e-07,\n",
      "       4.9408465e-07, 4.9280914e-07, 4.9338456e-07, 4.9335034e-07,\n",
      "       4.9424250e-07, 4.9251850e-07, 4.9422516e-07, 4.9436886e-07,\n",
      "       4.9301264e-07, 4.9325092e-07, 4.9306129e-07, 4.9314997e-07,\n",
      "       4.9392042e-07, 4.9039494e-07, 4.9152095e-07, 4.9468025e-07,\n",
      "       4.9171655e-07, 4.9275877e-07, 4.9314059e-07, 4.8999618e-07,\n",
      "       4.8887500e-07, 4.9307477e-07, 4.9400057e-07, 4.8996634e-07,\n",
      "       4.9457083e-07, 4.8567819e-07, 4.9388018e-07, 4.9101232e-07,\n",
      "       4.9327554e-07, 4.9347449e-07, 4.9298222e-07, 4.9385835e-07,\n",
      "       4.9301627e-07, 4.9420163e-07, 4.9346738e-07, 4.9318601e-07,\n",
      "       4.9350808e-07, 4.9402871e-07, 4.9469247e-07, 4.9302065e-07,\n",
      "       4.9147218e-07, 4.9294073e-07, 4.9376717e-07, 4.9382248e-07,\n",
      "       4.8656574e-07, 4.9351547e-07, 4.9296438e-07, 4.9362944e-07,\n",
      "       4.9467707e-07, 4.9446339e-07, 4.9472146e-07, 4.9356640e-07,\n",
      "       4.9402263e-07, 4.9369754e-07, 4.9073458e-07, 4.9389280e-07,\n",
      "       4.9134223e-07, 4.9115647e-07, 4.9134047e-07, 4.9414024e-07,\n",
      "       4.9353901e-07, 4.9382396e-07, 4.9300860e-07, 4.9450563e-07,\n",
      "       4.9399262e-07, 4.9315616e-07, 4.9042734e-07, 4.9432907e-07,\n",
      "       4.9424028e-07, 4.9441684e-07, 4.9455002e-07, 4.8900404e-07,\n",
      "       4.8791242e-07, 4.9290372e-07, 4.9126618e-07, 4.9324291e-07,\n",
      "       4.8690856e-07, 4.9459129e-07, 4.9301229e-07, 4.9347597e-07,\n",
      "       4.9353923e-07, 4.9315855e-07, 4.9089721e-07, 4.9353633e-07,\n",
      "       4.9171365e-07, 4.9514955e-07, 4.9403081e-07, 4.9290151e-07,\n",
      "       4.9250747e-07, 4.9393537e-07, 4.9290554e-07, 4.8360408e-07,\n",
      "       4.9376098e-07, 4.9327701e-07, 4.9346261e-07, 4.9251264e-07,\n",
      "       4.9446146e-07, 4.9311330e-07, 4.9164578e-07, 4.9256323e-07,\n",
      "       4.9365974e-07, 4.9369589e-07, 4.9176538e-07, 4.8950750e-07,\n",
      "       4.9213509e-07, 4.9383880e-07, 4.9412625e-07, 4.9467110e-07,\n",
      "       4.9397283e-07, 4.9091130e-07, 4.9433527e-07, 4.9121553e-07,\n",
      "       4.9363854e-07, 4.9267169e-07, 4.9433157e-07, 4.9288070e-07,\n",
      "       4.8917025e-07, 4.9387171e-07, 4.9389598e-07, 4.8884601e-07,\n",
      "       4.9059145e-07, 4.9285541e-07, 4.9184717e-07, 4.9386148e-07,\n",
      "       4.9337280e-07, 4.9353059e-07, 4.9037891e-07, 4.9386279e-07,\n",
      "       4.9183342e-07, 4.9374427e-07, 4.9440217e-07, 4.9237207e-07,\n",
      "       4.9387967e-07, 4.9218852e-07, 4.9423420e-07, 4.9457446e-07,\n",
      "       4.9181017e-07, 4.9421351e-07, 4.9477774e-07, 4.9402928e-07,\n",
      "       4.9269187e-07, 4.9310336e-07, 4.9228441e-07, 4.9347722e-07,\n",
      "       4.8841133e-07, 4.9408288e-07, 4.9436449e-07, 4.9274195e-07,\n",
      "       4.9193665e-07, 4.8910141e-07, 4.9423443e-07, 4.9155545e-07,\n",
      "       4.9372414e-07, 4.9417889e-07, 4.9112418e-07, 4.9412716e-07,\n",
      "       4.9357624e-07, 4.9264048e-07, 4.9197763e-07, 4.9305220e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_4;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource3\n",
      "index : 310\n",
      "shape : [180]\n",
      "shape_signature : [180]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.9029228e-07, 4.8957884e-07, 4.8895868e-07, 4.9174429e-07,\n",
      "       4.9014136e-07, 4.8839456e-07, 4.8949983e-07, 4.8743414e-07,\n",
      "       4.8973237e-07, 4.9028694e-07, 4.9154312e-07, 4.8872175e-07,\n",
      "       4.9013624e-07, 4.9029256e-07, 4.9123537e-07, 4.8871527e-07,\n",
      "       4.9053540e-07, 4.9006667e-07, 4.8755032e-07, 4.9035469e-07,\n",
      "       4.9108428e-07, 4.8981650e-07, 4.9038846e-07, 4.9035441e-07,\n",
      "       4.9124117e-07, 4.8952768e-07, 4.9122394e-07, 4.9136679e-07,\n",
      "       4.9001875e-07, 4.9025567e-07, 4.9006718e-07, 4.9015534e-07,\n",
      "       4.9092108e-07, 4.8741703e-07, 4.8853622e-07, 4.9167630e-07,\n",
      "       4.8873056e-07, 4.8976648e-07, 4.9014596e-07, 4.8702066e-07,\n",
      "       4.8590630e-07, 4.9008054e-07, 4.9100072e-07, 4.8699104e-07,\n",
      "       4.9156750e-07, 4.8272886e-07, 4.9088106e-07, 4.8803059e-07,\n",
      "       4.9028012e-07, 4.9047782e-07, 4.8998857e-07, 4.9085941e-07,\n",
      "       4.9002239e-07, 4.9120058e-07, 4.9047077e-07, 4.9019116e-07,\n",
      "       4.9051124e-07, 4.9102874e-07, 4.9168847e-07, 4.9002676e-07,\n",
      "       4.8848767e-07, 4.8994730e-07, 4.9076880e-07, 4.9082377e-07,\n",
      "       4.8361102e-07, 4.9051857e-07, 4.8997083e-07, 4.9063186e-07,\n",
      "       4.9167312e-07, 4.9146075e-07, 4.9171723e-07, 4.9056922e-07,\n",
      "       4.9102266e-07, 4.9069956e-07, 4.8775456e-07, 4.9089357e-07,\n",
      "       4.8835858e-07, 4.8817390e-07, 4.8835682e-07, 4.9113959e-07,\n",
      "       4.9054199e-07, 4.9082519e-07, 4.9001483e-07, 4.9150270e-07,\n",
      "       4.9099282e-07, 4.9016143e-07, 4.8744920e-07, 4.9132723e-07,\n",
      "       4.9123901e-07, 4.9141448e-07, 4.9154681e-07, 4.8603454e-07,\n",
      "       4.8494957e-07, 4.8991052e-07, 4.8828292e-07, 4.9024766e-07,\n",
      "       4.8395179e-07, 4.9158785e-07, 4.9001846e-07, 4.9047929e-07,\n",
      "       4.9054216e-07, 4.9016381e-07, 4.8791617e-07, 4.9053932e-07,\n",
      "       4.8872772e-07, 4.9214270e-07, 4.9103085e-07, 4.8990836e-07,\n",
      "       4.8951665e-07, 4.9093592e-07, 4.8991240e-07, 4.8066738e-07,\n",
      "       4.9076260e-07, 4.9028154e-07, 4.9046599e-07, 4.8952188e-07,\n",
      "       4.9145882e-07, 4.9011885e-07, 4.8866025e-07, 4.8957213e-07,\n",
      "       4.9066199e-07, 4.9069786e-07, 4.8877911e-07, 4.8653499e-07,\n",
      "       4.8914660e-07, 4.9083991e-07, 4.9112560e-07, 4.9166721e-07,\n",
      "       4.9097315e-07, 4.8793021e-07, 4.9133342e-07, 4.8823256e-07,\n",
      "       4.9064090e-07, 4.8967991e-07, 4.9132973e-07, 4.8988767e-07,\n",
      "       4.8619972e-07, 4.9087265e-07, 4.9089681e-07, 4.8587748e-07,\n",
      "       4.8761234e-07, 4.8986254e-07, 4.8886039e-07, 4.9086248e-07,\n",
      "       4.9037675e-07, 4.9053358e-07, 4.8740105e-07, 4.9086378e-07,\n",
      "       4.8884675e-07, 4.9074600e-07, 4.9139987e-07, 4.8938210e-07,\n",
      "       4.9088055e-07, 4.8919969e-07, 4.9123292e-07, 4.9157114e-07,\n",
      "       4.8882362e-07, 4.9121240e-07, 4.9177316e-07, 4.9102931e-07,\n",
      "       4.8969997e-07, 4.9010896e-07, 4.8929502e-07, 4.9048055e-07,\n",
      "       4.8544547e-07, 4.9108252e-07, 4.9136241e-07, 4.8974977e-07,\n",
      "       4.8894935e-07, 4.8613134e-07, 4.9123321e-07, 4.8857044e-07,\n",
      "       4.9072599e-07, 4.9117796e-07, 4.8814184e-07, 4.9112657e-07,\n",
      "       4.9057900e-07, 4.8964887e-07, 4.8899011e-07, 4.9005814e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_4;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource4\n",
      "index : 311\n",
      "shape : [180]\n",
      "shape_signature : [180]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([4.8151327e-07, 4.8081262e-07, 4.8020354e-07, 4.8293924e-07,\n",
      "       4.8136508e-07, 4.7964954e-07, 4.8073503e-07, 4.7870634e-07,\n",
      "       4.8096342e-07, 4.8150798e-07, 4.8274171e-07, 4.7997088e-07,\n",
      "       4.8136002e-07, 4.8151355e-07, 4.8243948e-07, 4.7996451e-07,\n",
      "       4.8175201e-07, 4.8129169e-07, 4.7882043e-07, 4.8157460e-07,\n",
      "       4.8229111e-07, 4.8104602e-07, 4.8160769e-07, 4.8157432e-07,\n",
      "       4.8244516e-07, 4.8076237e-07, 4.8242828e-07, 4.8256851e-07,\n",
      "       4.8124468e-07, 4.8147729e-07, 4.8129220e-07, 4.8137878e-07,\n",
      "       4.8213082e-07, 4.7868946e-07, 4.7978864e-07, 4.8287251e-07,\n",
      "       4.7997952e-07, 4.8099690e-07, 4.8136957e-07, 4.7830025e-07,\n",
      "       4.7720579e-07, 4.8130534e-07, 4.8220903e-07, 4.7827115e-07,\n",
      "       4.8276564e-07, 4.7408528e-07, 4.8209154e-07, 4.7929211e-07,\n",
      "       4.8150133e-07, 4.8169551e-07, 4.8121501e-07, 4.8207022e-07,\n",
      "       4.8124821e-07, 4.8240531e-07, 4.8168857e-07, 4.8141391e-07,\n",
      "       4.8172831e-07, 4.8223654e-07, 4.8288445e-07, 4.8125247e-07,\n",
      "       4.7974100e-07, 4.8117448e-07, 4.8198126e-07, 4.8203520e-07,\n",
      "       4.7495166e-07, 4.8173553e-07, 4.8119756e-07, 4.8184677e-07,\n",
      "       4.8286938e-07, 4.8266082e-07, 4.8291270e-07, 4.8178521e-07,\n",
      "       4.8223058e-07, 4.8191322e-07, 4.7902097e-07, 4.8210381e-07,\n",
      "       4.7961419e-07, 4.7943280e-07, 4.7961242e-07, 4.8234540e-07,\n",
      "       4.8175849e-07, 4.8203663e-07, 4.8124076e-07, 4.8270203e-07,\n",
      "       4.8220130e-07, 4.8138475e-07, 4.7872112e-07, 4.8252969e-07,\n",
      "       4.8244306e-07, 4.8261541e-07, 4.8274535e-07, 4.7733181e-07,\n",
      "       4.7626619e-07, 4.8113839e-07, 4.7953989e-07, 4.8146944e-07,\n",
      "       4.7528633e-07, 4.8278565e-07, 4.8124434e-07, 4.8169693e-07,\n",
      "       4.8175872e-07, 4.8138708e-07, 4.7917973e-07, 4.8175588e-07,\n",
      "       4.7997673e-07, 4.8333055e-07, 4.8223859e-07, 4.8113623e-07,\n",
      "       4.8075157e-07, 4.8214537e-07, 4.8114015e-07, 4.7206072e-07,\n",
      "       4.8197518e-07, 4.8150275e-07, 4.8168391e-07, 4.8075663e-07,\n",
      "       4.8265895e-07, 4.8134291e-07, 4.7991045e-07, 4.8080602e-07,\n",
      "       4.8187633e-07, 4.8191163e-07, 4.8002721e-07, 4.7782322e-07,\n",
      "       4.8038811e-07, 4.8205112e-07, 4.8233170e-07, 4.8286358e-07,\n",
      "       4.8218192e-07, 4.7919349e-07, 4.8253577e-07, 4.7949044e-07,\n",
      "       4.8185564e-07, 4.8091186e-07, 4.8253219e-07, 4.8111593e-07,\n",
      "       4.7749398e-07, 4.8208324e-07, 4.8210694e-07, 4.7717754e-07,\n",
      "       4.7888130e-07, 4.8109121e-07, 4.8010702e-07, 4.8207323e-07,\n",
      "       4.8159626e-07, 4.8175025e-07, 4.7867377e-07, 4.8207454e-07,\n",
      "       4.8009366e-07, 4.8195886e-07, 4.8260102e-07, 4.8061941e-07,\n",
      "       4.8209102e-07, 4.8044024e-07, 4.8243709e-07, 4.8276922e-07,\n",
      "       4.8007092e-07, 4.8241691e-07, 4.8296766e-07, 4.8223711e-07,\n",
      "       4.8093159e-07, 4.8133325e-07, 4.8053386e-07, 4.8169818e-07,\n",
      "       4.7675323e-07, 4.8228935e-07, 4.8256425e-07, 4.8098048e-07,\n",
      "       4.8019439e-07, 4.7742685e-07, 4.8243731e-07, 4.7982229e-07,\n",
      "       4.8193920e-07, 4.8238309e-07, 4.7940131e-07, 4.8233261e-07,\n",
      "       4.8179487e-07, 4.8088140e-07, 4.8023441e-07, 4.8128334e-07],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/strided_slice_1\n",
      "index : 312\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013031605631113052, -128)\n",
      "quantization_parameters : {'scales': array([0.00130316], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/separable_conv2d/depthwise\n",
      "index : 313\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00063867, 0.00056977, 0.00076007, 0.0007566 , 0.00079242,\n",
      "       0.00069502, 0.00080483, 0.00075682, 0.0007294 , 0.00078686,\n",
      "       0.00075828, 0.00077203, 0.00077848, 0.0007626 , 0.00055604,\n",
      "       0.00080285, 0.00057648, 0.00077999, 0.00064221, 0.00059425,\n",
      "       0.00068449, 0.00063411, 0.00075655, 0.00074631, 0.00077197,\n",
      "       0.00066088, 0.00052652, 0.00077047, 0.0005711 , 0.00072331,\n",
      "       0.00071194, 0.00075167, 0.00079593, 0.00075689, 0.00053001,\n",
      "       0.00072663, 0.0006648 , 0.00076484, 0.00077039, 0.00072496,\n",
      "       0.00056518, 0.00067676, 0.00073797, 0.00072759, 0.00077575,\n",
      "       0.00076426, 0.00074954, 0.00077418, 0.00079756, 0.00077001,\n",
      "       0.00077257, 0.00077767, 0.0007329 , 0.0007663 , 0.00061989,\n",
      "       0.00078341, 0.00069962, 0.00067478, 0.00076522, 0.00046305,\n",
      "       0.00078408, 0.00067304, 0.0007062 , 0.00061969], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/separable_conv2d\n",
      "index : 314\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0018244 , 0.00178869, 0.00186752, 0.00185594, 0.00184494,\n",
      "       0.00178904, 0.00173717, 0.00182639, 0.00180274, 0.00184461,\n",
      "       0.00185583, 0.00180908, 0.00183718, 0.00182076, 0.00183434,\n",
      "       0.00185629, 0.00184702, 0.00184775, 0.00178388, 0.00181254,\n",
      "       0.0018364 , 0.0018397 , 0.00180301, 0.00183861, 0.00181101,\n",
      "       0.00185431, 0.00183665, 0.00180948, 0.00182817, 0.00185303,\n",
      "       0.00174054, 0.00185284, 0.00185581, 0.00186319, 0.00184244,\n",
      "       0.00177174, 0.0018203 , 0.00181871, 0.001858  , 0.001849  ,\n",
      "       0.00185047, 0.00185733, 0.00180399, 0.0018598 , 0.00184511,\n",
      "       0.00185858, 0.00180354, 0.00183485, 0.00184582, 0.00180967,\n",
      "       0.00181392, 0.00184864, 0.0018512 , 0.00185684, 0.00184659,\n",
      "       0.00184377, 0.00182743, 0.00184641, 0.00180063, 0.00184915,\n",
      "       0.00181283, 0.00185514, 0.0017852 , 0.00184667], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/batch_normalization_66/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/BiasAdd\n",
      "index : 315\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.41097516e-08, 1.38335885e-08, 1.44432564e-08, 1.43536827e-08,\n",
      "       1.42685970e-08, 1.38362672e-08, 1.34351374e-08, 1.41251677e-08,\n",
      "       1.39422678e-08, 1.42660612e-08, 1.43528505e-08, 1.39913201e-08,\n",
      "       1.42086503e-08, 1.40816203e-08, 1.41866128e-08, 1.43564369e-08,\n",
      "       1.42847272e-08, 1.42903982e-08, 1.37964014e-08, 1.40180143e-08,\n",
      "       1.42026044e-08, 1.42281369e-08, 1.39443452e-08, 1.42197045e-08,\n",
      "       1.40062015e-08, 1.43411265e-08, 1.42045309e-08, 1.39943568e-08,\n",
      "       1.41389167e-08, 1.43312011e-08, 1.34612081e-08, 1.43296885e-08,\n",
      "       1.43527128e-08, 1.44097507e-08, 1.42493217e-08, 1.37025129e-08,\n",
      "       1.40780374e-08, 1.40658010e-08, 1.43696184e-08, 1.43000509e-08,\n",
      "       1.43114152e-08, 1.43644758e-08, 1.39519383e-08, 1.43835734e-08,\n",
      "       1.42699204e-08, 1.43741232e-08, 1.39484762e-08, 1.41906122e-08,\n",
      "       1.42754262e-08, 1.39958800e-08, 1.40287142e-08, 1.42972665e-08,\n",
      "       1.43170080e-08, 1.43606762e-08, 1.42813628e-08, 1.42595882e-08,\n",
      "       1.41332288e-08, 1.42800225e-08, 1.39259271e-08, 1.43011745e-08,\n",
      "       1.40203174e-08, 1.43475418e-08, 1.38066243e-08, 1.42819871e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/strided_slice_2\n",
      "index : 316\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013082351069897413, -128)\n",
      "quantization_parameters : {'scales': array([0.00130824], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/strided_slice_1\n",
      "index : 317\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013108882121741772, -128)\n",
      "quantization_parameters : {'scales': array([0.00131089], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/separable_conv2d/depthwise\n",
      "index : 318\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00079173, 0.00075324, 0.0007816 , 0.00073616, 0.00077185,\n",
      "       0.00075727, 0.00077241, 0.00072626, 0.00076982, 0.00067284,\n",
      "       0.00058788, 0.00074275, 0.0006321 , 0.00065355, 0.00070314,\n",
      "       0.00072838, 0.00076259, 0.00078418, 0.00064324, 0.00066562,\n",
      "       0.00074632, 0.00077611, 0.00069791, 0.00073828, 0.00064046,\n",
      "       0.00076821, 0.00077807, 0.00067013, 0.00077973, 0.00072379,\n",
      "       0.00079151, 0.00078741, 0.0007862 , 0.00070171, 0.00076814,\n",
      "       0.00078223, 0.00078162, 0.0007295 , 0.00074957, 0.00056825,\n",
      "       0.00079189, 0.0005926 , 0.00057796, 0.0006783 , 0.00077708,\n",
      "       0.00068687, 0.00076758, 0.00073586, 0.00078535, 0.00068435,\n",
      "       0.00075823, 0.00046329, 0.00070993, 0.0007854 , 0.00073834,\n",
      "       0.00073523, 0.00069477, 0.00074727, 0.00079543, 0.00058524,\n",
      "       0.00069457, 0.00079549, 0.00063083, 0.00070152], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/separable_conv2d\n",
      "index : 319\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00176671, 0.00181278, 0.00183393, 0.00181128, 0.0018573 ,\n",
      "       0.00183362, 0.00182706, 0.00184102, 0.00183416, 0.00183573,\n",
      "       0.00182971, 0.00185625, 0.00182387, 0.00183833, 0.00181199,\n",
      "       0.00180925, 0.00183876, 0.00184692, 0.00183049, 0.00185237,\n",
      "       0.00182851, 0.00182216, 0.00182509, 0.00186412, 0.00180764,\n",
      "       0.00181366, 0.0018445 , 0.00186389, 0.00184307, 0.00184625,\n",
      "       0.00180801, 0.0018559 , 0.00172683, 0.00183229, 0.00183685,\n",
      "       0.0018097 , 0.00184061, 0.0018381 , 0.00185044, 0.00181694,\n",
      "       0.00184415, 0.00185427, 0.00185328, 0.00185124, 0.0017719 ,\n",
      "       0.00185408, 0.00184794, 0.0018534 , 0.00180557, 0.00184209,\n",
      "       0.00181509, 0.00176224, 0.00182878, 0.00183677, 0.00185446,\n",
      "       0.00183814, 0.00185211, 0.00178649, 0.00182227, 0.00183811,\n",
      "       0.00181944, 0.00184301, 0.00184922, 0.0018303 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/batch_normalization_67/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/BiasAdd\n",
      "index : 320\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.6425135e-08, 1.6853509e-08, 1.7050143e-08, 1.6839552e-08,\n",
      "       1.7267427e-08, 1.7047245e-08, 1.6986204e-08, 1.7116037e-08,\n",
      "       1.7052246e-08, 1.7066849e-08, 1.7010930e-08, 1.7257653e-08,\n",
      "       1.6956584e-08, 1.7091052e-08, 1.6846105e-08, 1.6820668e-08,\n",
      "       1.7095035e-08, 1.7170857e-08, 1.7018172e-08, 1.7221543e-08,\n",
      "       1.6999754e-08, 1.6940733e-08, 1.6967917e-08, 1.7330805e-08,\n",
      "       1.6805716e-08, 1.6861662e-08, 1.7148404e-08, 1.7328627e-08,\n",
      "       1.7135118e-08, 1.7164682e-08, 1.6809107e-08, 1.7254360e-08,\n",
      "       1.6054381e-08, 1.7034834e-08, 1.7077264e-08, 1.6824815e-08,\n",
      "       1.7112265e-08, 1.7088883e-08, 1.7203595e-08, 1.6892121e-08,\n",
      "       1.7145126e-08, 1.7239232e-08, 1.7230020e-08, 1.7211059e-08,\n",
      "       1.6473399e-08, 1.7237495e-08, 1.7180382e-08, 1.7231175e-08,\n",
      "       1.6786466e-08, 1.7125942e-08, 1.6874958e-08, 1.6383630e-08,\n",
      "       1.7002282e-08, 1.7076491e-08, 1.7241000e-08, 1.7089301e-08,\n",
      "       1.7219159e-08, 1.6609059e-08, 1.6941721e-08, 1.7088984e-08,\n",
      "       1.6915436e-08, 1.7134541e-08, 1.7192233e-08, 1.7016374e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/strided_slice_2\n",
      "index : 321\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013054788578301668, -128)\n",
      "quantization_parameters : {'scales': array([0.00130548], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/strided_slice_1\n",
      "index : 322\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013069909764453769, -128)\n",
      "quantization_parameters : {'scales': array([0.00130699], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/separable_conv2d/depthwise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 323\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00067862, 0.00056833, 0.00075738, 0.00076809, 0.00080175,\n",
      "       0.00075692, 0.00075072, 0.00074846, 0.0007545 , 0.0007193 ,\n",
      "       0.00077565, 0.00062945, 0.00069448, 0.00070792, 0.00074395,\n",
      "       0.00074433, 0.00077548, 0.00078158, 0.00078251, 0.00066663,\n",
      "       0.00077913, 0.00075459, 0.00070696, 0.00073392, 0.00069566,\n",
      "       0.00066422, 0.00078764, 0.00078056, 0.00072826, 0.00077765,\n",
      "       0.00075341, 0.00068209, 0.00074374, 0.00071183, 0.00055349,\n",
      "       0.00079546, 0.00078708, 0.00049775, 0.00079748, 0.00072828,\n",
      "       0.00069343, 0.00074735, 0.000773  , 0.00064956, 0.00074853,\n",
      "       0.00065607, 0.00078641, 0.00065718, 0.00072568, 0.00077062,\n",
      "       0.00074473, 0.00078197, 0.00076971, 0.00074289, 0.00070462,\n",
      "       0.0007963 , 0.000726  , 0.00070805, 0.00057589, 0.00078448,\n",
      "       0.00075997, 0.00067657, 0.00061606, 0.00079528], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/separable_conv2d\n",
      "index : 324\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00184742, 0.00182977, 0.00185827, 0.00182051, 0.00178461,\n",
      "       0.00183757, 0.00183673, 0.00185553, 0.0018053 , 0.00183583,\n",
      "       0.00185224, 0.00183824, 0.00184369, 0.00183351, 0.00185054,\n",
      "       0.00175795, 0.001858  , 0.00182874, 0.00183637, 0.00181368,\n",
      "       0.00184273, 0.00185112, 0.00179878, 0.0018464 , 0.00181581,\n",
      "       0.00185913, 0.00181921, 0.0018019 , 0.00182263, 0.00180345,\n",
      "       0.00182716, 0.00181553, 0.00185442, 0.00179452, 0.00180383,\n",
      "       0.00185128, 0.00181397, 0.00182392, 0.0018189 , 0.0018254 ,\n",
      "       0.00181459, 0.00184966, 0.00182597, 0.0018497 , 0.00183742,\n",
      "       0.00179206, 0.0017394 , 0.00184222, 0.00184858, 0.00182989,\n",
      "       0.0017553 , 0.00182824, 0.00180908, 0.00184366, 0.00182303,\n",
      "       0.00185196, 0.0018464 , 0.00182287, 0.00181013, 0.00181095,\n",
      "       0.0018208 , 0.00185081, 0.00185267, 0.00182607], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/batch_normalization_68/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/BiasAdd\n",
      "index : 325\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.5593351e-08, 1.5444437e-08, 1.5684972e-08, 1.5366252e-08,\n",
      "       1.5063211e-08, 1.5510276e-08, 1.5503122e-08, 1.5661794e-08,\n",
      "       1.5237866e-08, 1.5495539e-08, 1.5634027e-08, 1.5515900e-08,\n",
      "       1.5561930e-08, 1.5475978e-08, 1.5619698e-08, 1.4838236e-08,\n",
      "       1.5682703e-08, 1.5435685e-08, 1.5500095e-08, 1.5308606e-08,\n",
      "       1.5553832e-08, 1.5624645e-08, 1.5182801e-08, 1.5584787e-08,\n",
      "       1.5326560e-08, 1.5692219e-08, 1.5355280e-08, 1.5209142e-08,\n",
      "       1.5384146e-08, 1.5222209e-08, 1.5422396e-08, 1.5324218e-08,\n",
      "       1.5652432e-08, 1.5146899e-08, 1.5225437e-08, 1.5625950e-08,\n",
      "       1.5311054e-08, 1.5395022e-08, 1.5352619e-08, 1.5407537e-08,\n",
      "       1.5316294e-08, 1.5612258e-08, 1.5412358e-08, 1.5612658e-08,\n",
      "       1.5509013e-08, 1.5126133e-08, 1.4681583e-08, 1.5549464e-08,\n",
      "       1.5603192e-08, 1.5445435e-08, 1.4815813e-08, 1.5431525e-08,\n",
      "       1.5269753e-08, 1.5561625e-08, 1.5387506e-08, 1.5631674e-08,\n",
      "       1.5584735e-08, 1.5386149e-08, 1.5278653e-08, 1.5285510e-08,\n",
      "       1.5368654e-08, 1.5622017e-08, 1.5637715e-08, 1.5413159e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/strided_slice_1\n",
      "index : 326\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00196146871894598, -128)\n",
      "quantization_parameters : {'scales': array([0.00196147], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/strided_slice\n",
      "index : 327\n",
      "shape : []\n",
      "shape_signature : []\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0019601001404225826, -128)\n",
      "quantization_parameters : {'scales': array([0.0019601], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/separable_conv2d/depthwise\n",
      "index : 328\n",
      "shape : [ 1  3  3 64]\n",
      "shape_signature : [ 1  3  3 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.00077917, 0.00053817, 0.00075624, 0.00077577, 0.00076517,\n",
      "       0.00078384, 0.00078894, 0.000766  , 0.00070955, 0.00079356,\n",
      "       0.00077734, 0.00075874, 0.00062897, 0.00074353, 0.00075357,\n",
      "       0.00056876, 0.00075583, 0.00070324, 0.00074241, 0.00061604,\n",
      "       0.00077848, 0.00072789, 0.00050202, 0.00078465, 0.00077166,\n",
      "       0.00075625, 0.00070812, 0.00071709, 0.00061819, 0.00075228,\n",
      "       0.00064543, 0.00058723, 0.00048536, 0.0007416 , 0.000704  ,\n",
      "       0.00061765, 0.00074154, 0.00069859, 0.00075916, 0.00071909,\n",
      "       0.00079532, 0.00066747, 0.00075609, 0.00079448, 0.00079546,\n",
      "       0.00064138, 0.00079717, 0.00070041, 0.00065194, 0.00075273,\n",
      "       0.00079279, 0.00079834, 0.00068922, 0.00060963, 0.00077318,\n",
      "       0.00079162, 0.00074238, 0.00075971, 0.00079204, 0.00077647,\n",
      "       0.00055357, 0.00079783, 0.00070534, 0.00079183], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/separable_conv2d\n",
      "index : 329\n",
      "shape : [64  1  1 64]\n",
      "shape_signature : [64  1  1 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([0.0017573 , 0.00184371, 0.00180868, 0.00183009, 0.00185228,\n",
      "       0.00180889, 0.00184074, 0.00184629, 0.0018131 , 0.00176442,\n",
      "       0.00182104, 0.00183255, 0.001815  , 0.00181119, 0.00181248,\n",
      "       0.00184356, 0.00183376, 0.00181886, 0.00184698, 0.00183401,\n",
      "       0.00183749, 0.00176831, 0.00182332, 0.00183688, 0.00185169,\n",
      "       0.00184853, 0.00183786, 0.00181769, 0.00180403, 0.00181317,\n",
      "       0.00185315, 0.00184483, 0.00185249, 0.001811  , 0.00185382,\n",
      "       0.00184191, 0.00181053, 0.00182818, 0.00182921, 0.00183905,\n",
      "       0.0018036 , 0.00177128, 0.00182084, 0.00182935, 0.00182686,\n",
      "       0.00180461, 0.00181392, 0.00182144, 0.00183598, 0.00184946,\n",
      "       0.00178715, 0.00177061, 0.00182599, 0.00182715, 0.00183468,\n",
      "       0.00181883, 0.00180439, 0.00182528, 0.0018418 , 0.00184553,\n",
      "       0.00183498, 0.00179276, 0.00182009, 0.00185415], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/batch_normalization_69/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/BiasAdd\n",
      "index : 330\n",
      "shape : [64]\n",
      "shape_signature : [64]\n",
      "dtype : <class 'numpy.int32'>\n",
      "quantization : (0.0, 0)\n",
      "quantization_parameters : {'scales': array([1.9538945e-08, 2.0499737e-08, 2.0110232e-08, 2.0348258e-08,\n",
      "       2.0594994e-08, 2.0112585e-08, 2.0466748e-08, 2.0528409e-08,\n",
      "       2.0159383e-08, 1.9618096e-08, 2.0247612e-08, 2.0375607e-08,\n",
      "       2.0180497e-08, 2.0138163e-08, 2.0152525e-08, 2.0498087e-08,\n",
      "       2.0389082e-08, 2.0223405e-08, 2.0536083e-08, 2.0391896e-08,\n",
      "       2.0430599e-08, 1.9661403e-08, 2.0272996e-08, 2.0423760e-08,\n",
      "       2.0588448e-08, 2.0553307e-08, 2.0434705e-08, 2.0210425e-08,\n",
      "       2.0058513e-08, 2.0160098e-08, 2.0604697e-08, 2.0512227e-08,\n",
      "       2.0597303e-08, 2.0136003e-08, 2.0612164e-08, 2.0479684e-08,\n",
      "       2.0130797e-08, 2.0327093e-08, 2.0338490e-08, 2.0447944e-08,\n",
      "       2.0053784e-08, 1.9694403e-08, 2.0245432e-08, 2.0340021e-08,\n",
      "       2.0312354e-08, 2.0065015e-08, 2.0168487e-08, 2.0252051e-08,\n",
      "       2.0413824e-08, 2.0563684e-08, 1.9870861e-08, 1.9686961e-08,\n",
      "       2.0302693e-08, 2.0315614e-08, 2.0399277e-08, 2.0223128e-08,\n",
      "       2.0062558e-08, 2.0294776e-08, 2.0478428e-08, 2.0519956e-08,\n",
      "       2.0402608e-08, 1.9933227e-08, 2.0237112e-08, 2.0615797e-08],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : tfl.quantize\n",
      "index : 331\n",
      "shape : [  1 512 512   3]\n",
      "shape_signature : [  1 512 512   3]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.0, -128)\n",
      "quantization_parameters : {'scales': array([1.], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/batch_normalization/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D;efficient_det/efficient_net/conv2d/Conv2D1\n",
      "index : 332\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5585179328918457, 0)\n",
      "quantization_parameters : {'scales': array([2.558518], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/Sigmoid\n",
      "index : 333\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/mul\n",
      "index : 334\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.277585744857788, -128)\n",
      "quantization_parameters : {'scales': array([1.2775857], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_1/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D;efficient_det/efficient_net/sequential/mb_conv/conv2d_1/Conv2D1\n",
      "index : 335\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.2964677810668945, 10)\n",
      "quantization_parameters : {'scales': array([1.2964678], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/Sigmoid\n",
      "index : 336\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/mul\n",
      "index : 337\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.5940740704536438, -128)\n",
      "quantization_parameters : {'scales': array([0.5940741], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_2/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/depthwise_conv2d/depthwise;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D1\n",
      "index : 338\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.45293059945106506, 9)\n",
      "quantization_parameters : {'scales': array([0.4529306], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean\n",
      "index : 339\n",
      "shape : [ 1  1  1 32]\n",
      "shape_signature : [ 1  1  1 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.2037072628736496, 37)\n",
      "quantization_parameters : {'scales': array([0.20370726], dtype=float32), 'zero_points': array([37]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/BiasAdd;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/Conv2D;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_2/BiasAdd/ReadVariableOp/resource1\n",
      "index : 340\n",
      "shape : [1 1 1 8]\n",
      "shape_signature : [1 1 1 8]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.15353122353553772, 29)\n",
      "quantization_parameters : {'scales': array([0.15353122], dtype=float32), 'zero_points': array([29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/Sigmoid\n",
      "index : 341\n",
      "shape : [1 1 1 8]\n",
      "shape_signature : [1 1 1 8]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/mul\n",
      "index : 342\n",
      "shape : [1 1 1 8]\n",
      "shape_signature : [1 1 1 8]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.060312818735837936, -124)\n",
      "quantization_parameters : {'scales': array([0.06031282], dtype=float32), 'zero_points': array([-124]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/BiasAdd;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/Conv2D;efficient_det/efficient_net/sequential/mb_conv/se_block/conv2d_3/BiasAdd/ReadVariableOp/resource1\n",
      "index : 343\n",
      "shape : [ 1  1  1 32]\n",
      "shape_signature : [ 1  1  1 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.07725194096565247, -14)\n",
      "quantization_parameters : {'scales': array([0.07725194], dtype=float32), 'zero_points': array([-14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/Sigmoid_1\n",
      "index : 344\n",
      "shape : [ 1  1  1 32]\n",
      "shape_signature : [ 1  1  1 32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/se_block/mul_1\n",
      "index : 345\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.31374549865722656, 65)\n",
      "quantization_parameters : {'scales': array([0.3137455], dtype=float32), 'zero_points': array([65]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/Sigmoid_1\n",
      "index : 346\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/mul_1\n",
      "index : 347\n",
      "shape : [  1 256 256  32]\n",
      "shape_signature : [  1 256 256  32]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.07734312862157822, -124)\n",
      "quantization_parameters : {'scales': array([0.07734313], dtype=float32), 'zero_points': array([-124]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential/mb_conv/batch_normalization_3/FusedBatchNormV3;efficient_det/efficient_net/sequential/mb_conv/conv2d_4/Conv2D1\n",
      "index : 348\n",
      "shape : [  1 256 256  16]\n",
      "shape_signature : [  1 256 256  16]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.05844186618924141, -9)\n",
      "quantization_parameters : {'scales': array([0.05844187], dtype=float32), 'zero_points': array([-9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_4/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/conv2d_5/Conv2D1\n",
      "index : 349\n",
      "shape : [  1 256 256  96]\n",
      "shape_signature : [  1 256 256  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.042651060968637466, -8)\n",
      "quantization_parameters : {'scales': array([0.04265106], dtype=float32), 'zero_points': array([-8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/Sigmoid\n",
      "index : 350\n",
      "shape : [  1 256 256  96]\n",
      "shape_signature : [  1 256 256  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/mul\n",
      "index : 351\n",
      "shape : [  1 256 256  96]\n",
      "shape_signature : [  1 256 256  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.023546738550066948, -116)\n",
      "quantization_parameters : {'scales': array([0.02354674], dtype=float32), 'zero_points': array([-116]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_5/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_1/depthwise_conv2d_1/depthwise;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D1\n",
      "index : 352\n",
      "shape : [  1 128 128  96]\n",
      "shape_signature : [  1 128 128  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.009519143030047417, 22)\n",
      "quantization_parameters : {'scales': array([0.00951914], dtype=float32), 'zero_points': array([22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/global_average_pooling2d_1/Mean\n",
      "index : 353\n",
      "shape : [ 1  1  1 96]\n",
      "shape_signature : [ 1  1  1 96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.004265370313078165, 42)\n",
      "quantization_parameters : {'scales': array([0.00426537], dtype=float32), 'zero_points': array([42]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/BiasAdd;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_6/BiasAdd/ReadVariableOp/resource1\n",
      "index : 354\n",
      "shape : [ 1  1  1 24]\n",
      "shape_signature : [ 1  1  1 24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0028380637522786856, 4)\n",
      "quantization_parameters : {'scales': array([0.00283806], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/Sigmoid\n",
      "index : 355\n",
      "shape : [ 1  1  1 24]\n",
      "shape_signature : [ 1  1  1 24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/mul\n",
      "index : 356\n",
      "shape : [ 1  1  1 24]\n",
      "shape_signature : [ 1  1  1 24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001401963410899043, -19)\n",
      "quantization_parameters : {'scales': array([0.00140196], dtype=float32), 'zero_points': array([-19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/BiasAdd;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/conv2d_7/BiasAdd/ReadVariableOp/resource1\n",
      "index : 357\n",
      "shape : [ 1  1  1 96]\n",
      "shape_signature : [ 1  1  1 96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0010302012087777257, -16)\n",
      "quantization_parameters : {'scales': array([0.0010302], dtype=float32), 'zero_points': array([-16]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/Sigmoid_1\n",
      "index : 358\n",
      "shape : [ 1  1  1 96]\n",
      "shape_signature : [ 1  1  1 96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/se_block_1/mul_1\n",
      "index : 359\n",
      "shape : [  1 128 128  96]\n",
      "shape_signature : [  1 128 128  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.004840878304094076, 20)\n",
      "quantization_parameters : {'scales': array([0.00484088], dtype=float32), 'zero_points': array([20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/Sigmoid_1\n",
      "index : 360\n",
      "shape : [  1 128 128  96]\n",
      "shape_signature : [  1 128 128  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/mul_1\n",
      "index : 361\n",
      "shape : [  1 128 128  96]\n",
      "shape_signature : [  1 128 128  96]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002190123777836561, -20)\n",
      "quantization_parameters : {'scales': array([0.00219012], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_1/batch_normalization_6/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_1/conv2d_8/Conv2D1\n",
      "index : 362\n",
      "shape : [  1 128 128  24]\n",
      "shape_signature : [  1 128 128  24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013721068389713764, 35)\n",
      "quantization_parameters : {'scales': array([0.00137211], dtype=float32), 'zero_points': array([35]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_7/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_9/Conv2D1\n",
      "index : 363\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011066123843193054, 5)\n",
      "quantization_parameters : {'scales': array([0.00110661], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/Sigmoid\n",
      "index : 364\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/mul\n",
      "index : 365\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0005497930687852204, -4)\n",
      "quantization_parameters : {'scales': array([0.00054979], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_8/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_11/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/depthwise_conv2d_3/depthwise;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/depthwise_conv2d_2/depthwise\n",
      "index : 366\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011943700519623235, 36)\n",
      "quantization_parameters : {'scales': array([0.00011944], dtype=float32), 'zero_points': array([36]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/global_average_pooling2d_2/Mean;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/ExpandDims_1\n",
      "index : 367\n",
      "shape : [  1   1   1 144]\n",
      "shape_signature : [  1   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.733766298973933e-05, 31)\n",
      "quantization_parameters : {'scales': array([8.733766e-05], dtype=float32), 'zero_points': array([31]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/BiasAdd;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_10/BiasAdd/ReadVariableOp/resource1\n",
      "index : 368\n",
      "shape : [ 1  1  1 36]\n",
      "shape_signature : [ 1  1  1 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.967473771306686e-05, 44)\n",
      "quantization_parameters : {'scales': array([5.9674738e-05], dtype=float32), 'zero_points': array([44]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/Sigmoid\n",
      "index : 369\n",
      "shape : [ 1  1  1 36]\n",
      "shape_signature : [ 1  1  1 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/mul\n",
      "index : 370\n",
      "shape : [ 1  1  1 36]\n",
      "shape_signature : [ 1  1  1 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.9758612072328106e-05, 43)\n",
      "quantization_parameters : {'scales': array([2.9758612e-05], dtype=float32), 'zero_points': array([43]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/BiasAdd;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/Conv2D;efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/conv2d_11/BiasAdd/ReadVariableOp/resource1\n",
      "index : 371\n",
      "shape : [  1   1   1 144]\n",
      "shape_signature : [  1   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.189933340763673e-05, 14)\n",
      "quantization_parameters : {'scales': array([3.1899333e-05], dtype=float32), 'zero_points': array([14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/Sigmoid_1\n",
      "index : 372\n",
      "shape : [  1   1   1 144]\n",
      "shape_signature : [  1   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/se_block_2/mul_1\n",
      "index : 373\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.97825892327819e-05, 36)\n",
      "quantization_parameters : {'scales': array([5.978259e-05], dtype=float32), 'zero_points': array([36]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/Sigmoid_1\n",
      "index : 374\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/mul_1\n",
      "index : 375\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.982645673910156e-05, 35)\n",
      "quantization_parameters : {'scales': array([2.9826457e-05], dtype=float32), 'zero_points': array([35]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/batch_normalization_9/FusedBatchNormV3;efficient_det/efficient_net/sequential_1/mb_conv_2/conv2d_12/Conv2D1\n",
      "index : 376\n",
      "shape : [  1 128 128  24]\n",
      "shape_signature : [  1 128 128  24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00014312428538687527, -1)\n",
      "quantization_parameters : {'scales': array([0.00014312], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_1/mb_conv_2/add/add\n",
      "index : 377\n",
      "shape : [  1 128 128  24]\n",
      "shape_signature : [  1 128 128  24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0014442413812503219, 32)\n",
      "quantization_parameters : {'scales': array([0.00144424], dtype=float32), 'zero_points': array([32]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_10/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/conv2d_13/Conv2D1\n",
      "index : 378\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0010580207454040647, 3)\n",
      "quantization_parameters : {'scales': array([0.00105802], dtype=float32), 'zero_points': array([3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/Sigmoid\n",
      "index : 379\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/mul\n",
      "index : 380\n",
      "shape : [  1 128 128 144]\n",
      "shape_signature : [  1 128 128 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.000527207856066525, -6)\n",
      "quantization_parameters : {'scales': array([0.00052721], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_11/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_3/depthwise_conv2d_3/depthwise;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D1\n",
      "index : 381\n",
      "shape : [  1  64  64 144]\n",
      "shape_signature : [  1  64  64 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010644748545018956, 5)\n",
      "quantization_parameters : {'scales': array([0.00010645], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/global_average_pooling2d_3/Mean\n",
      "index : 382\n",
      "shape : [  1   1   1 144]\n",
      "shape_signature : [  1   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.741299097891897e-05, -6)\n",
      "quantization_parameters : {'scales': array([8.741299e-05], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/BiasAdd;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_14/BiasAdd/ReadVariableOp/resource1\n",
      "index : 383\n",
      "shape : [ 1  1  1 36]\n",
      "shape_signature : [ 1  1  1 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.595873466925696e-05, -15)\n",
      "quantization_parameters : {'scales': array([7.5958735e-05], dtype=float32), 'zero_points': array([-15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/Sigmoid\n",
      "index : 384\n",
      "shape : [ 1  1  1 36]\n",
      "shape_signature : [ 1  1  1 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/mul\n",
      "index : 385\n",
      "shape : [ 1  1  1 36]\n",
      "shape_signature : [ 1  1  1 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.802126957452856e-05, -16)\n",
      "quantization_parameters : {'scales': array([3.802127e-05], dtype=float32), 'zero_points': array([-16]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/BiasAdd;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/conv2d_15/BiasAdd/ReadVariableOp/resource1\n",
      "index : 386\n",
      "shape : [  1   1   1 144]\n",
      "shape_signature : [  1   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.223105886718258e-05, -2)\n",
      "quantization_parameters : {'scales': array([3.223106e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/Sigmoid_1\n",
      "index : 387\n",
      "shape : [  1   1   1 144]\n",
      "shape_signature : [  1   1   1 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/se_block_3/mul_1\n",
      "index : 388\n",
      "shape : [  1  64  64 144]\n",
      "shape_signature : [  1  64  64 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.323389996192418e-05, 5)\n",
      "quantization_parameters : {'scales': array([5.32339e-05], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/Sigmoid_1\n",
      "index : 389\n",
      "shape : [  1  64  64 144]\n",
      "shape_signature : [  1  64  64 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/mul_1\n",
      "index : 390\n",
      "shape : [  1  64  64 144]\n",
      "shape_signature : [  1  64  64 144]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.660937752807513e-05, 4)\n",
      "quantization_parameters : {'scales': array([2.6609378e-05], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_3/batch_normalization_12/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_20/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_3/conv2d_16/Conv2D1\n",
      "index : 391\n",
      "shape : [ 1 64 64 40]\n",
      "shape_signature : [ 1 64 64 40]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0001580995012773201, -1)\n",
      "quantization_parameters : {'scales': array([0.0001581], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_13/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_17/Conv2D1\n",
      "index : 392\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011281431216048077, 14)\n",
      "quantization_parameters : {'scales': array([0.00011281], dtype=float32), 'zero_points': array([14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/Sigmoid\n",
      "index : 393\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/mul\n",
      "index : 394\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.63170324312523e-05, 13)\n",
      "quantization_parameters : {'scales': array([5.6317032e-05], dtype=float32), 'zero_points': array([13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_14/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_17/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/depthwise_conv2d_5/depthwise;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/depthwise_conv2d_4/depthwise\n",
      "index : 395\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.36090844636783e-05, -23)\n",
      "quantization_parameters : {'scales': array([6.3609084e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/global_average_pooling2d_4/Mean;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/ExpandDims_1\n",
      "index : 396\n",
      "shape : [  1   1   1 240]\n",
      "shape_signature : [  1   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.23530286247842e-05, -24)\n",
      "quantization_parameters : {'scales': array([6.235303e-05], dtype=float32), 'zero_points': array([-24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_18/BiasAdd/ReadVariableOp/resource1\n",
      "index : 397\n",
      "shape : [ 1  1  1 60]\n",
      "shape_signature : [ 1  1  1 60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.2793515351368114e-05, 1)\n",
      "quantization_parameters : {'scales': array([5.2793515e-05], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/Sigmoid\n",
      "index : 398\n",
      "shape : [ 1  1  1 60]\n",
      "shape_signature : [ 1  1  1 60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/mul\n",
      "index : 399\n",
      "shape : [ 1  1  1 60]\n",
      "shape_signature : [ 1  1  1 60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.639425656525418e-05, 1)\n",
      "quantization_parameters : {'scales': array([2.6394257e-05], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/Conv2D;efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/conv2d_19/BiasAdd/ReadVariableOp/resource1\n",
      "index : 400\n",
      "shape : [  1   1   1 240]\n",
      "shape_signature : [  1   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.456060792610515e-05, 7)\n",
      "quantization_parameters : {'scales': array([2.4560608e-05], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/Sigmoid_1\n",
      "index : 401\n",
      "shape : [  1   1   1 240]\n",
      "shape_signature : [  1   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/se_block_4/mul_1\n",
      "index : 402\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.1814844987820834e-05, -23)\n",
      "quantization_parameters : {'scales': array([3.1814845e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/Sigmoid_1\n",
      "index : 403\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/mul_1\n",
      "index : 404\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.591871478012763e-05, -23)\n",
      "quantization_parameters : {'scales': array([1.5918715e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/batch_normalization_15/FusedBatchNormV3;efficient_det/efficient_net/sequential_2/mb_conv_4/conv2d_20/Conv2D1\n",
      "index : 405\n",
      "shape : [ 1 64 64 40]\n",
      "shape_signature : [ 1 64 64 40]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00013184345152694732, 9)\n",
      "quantization_parameters : {'scales': array([0.00013184], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_2/mb_conv_4/add_1/add\n",
      "index : 406\n",
      "shape : [ 1 64 64 40]\n",
      "shape_signature : [ 1 64 64 40]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00022506217646878213, 7)\n",
      "quantization_parameters : {'scales': array([0.00022506], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act/batch_normalization_49/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act/conv2d_65/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act/conv2d_65/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/conv_norm_act/conv2d_65/Conv2D\n",
      "index : 407\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00020102507551200688, -25)\n",
      "quantization_parameters : {'scales': array([0.00020103], dtype=float32), 'zero_points': array([-25]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act/Sigmoid\n",
      "index : 408\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act/mul\n",
      "index : 409\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0001010138148558326, -27)\n",
      "quantization_parameters : {'scales': array([0.00010101], dtype=float32), 'zero_points': array([-27]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/mul\n",
      "index : 410\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.0556402129586786e-05, -27)\n",
      "quantization_parameters : {'scales': array([5.0556402e-05], dtype=float32), 'zero_points': array([-27]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_16/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/conv2d_21/Conv2D1\n",
      "index : 411\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00015312276082113385, 2)\n",
      "quantization_parameters : {'scales': array([0.00015312], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/Sigmoid\n",
      "index : 412\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/mul\n",
      "index : 413\n",
      "shape : [  1  64  64 240]\n",
      "shape_signature : [  1  64  64 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.65378717915155e-05, 0)\n",
      "quantization_parameters : {'scales': array([7.653787e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_17/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_5/depthwise_conv2d_5/depthwise;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D1\n",
      "index : 414\n",
      "shape : [  1  32  32 240]\n",
      "shape_signature : [  1  32  32 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.141403719084337e-05, 6)\n",
      "quantization_parameters : {'scales': array([6.141404e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/global_average_pooling2d_5/Mean\n",
      "index : 415\n",
      "shape : [  1   1   1 240]\n",
      "shape_signature : [  1   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.109495006967336e-05, 6)\n",
      "quantization_parameters : {'scales': array([6.109495e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_22/BiasAdd/ReadVariableOp/resource1\n",
      "index : 416\n",
      "shape : [ 1  1  1 60]\n",
      "shape_signature : [ 1  1  1 60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.455697777913883e-05, -2)\n",
      "quantization_parameters : {'scales': array([7.455698e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/Sigmoid\n",
      "index : 417\n",
      "shape : [ 1  1  1 60]\n",
      "shape_signature : [ 1  1  1 60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/mul\n",
      "index : 418\n",
      "shape : [ 1  1  1 60]\n",
      "shape_signature : [ 1  1  1 60]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.728169031091966e-05, -2)\n",
      "quantization_parameters : {'scales': array([3.728169e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/BiasAdd;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/conv2d_23/BiasAdd/ReadVariableOp/resource1\n",
      "index : 419\n",
      "shape : [  1   1   1 240]\n",
      "shape_signature : [  1   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.973530354211107e-05, 21)\n",
      "quantization_parameters : {'scales': array([2.9735304e-05], dtype=float32), 'zero_points': array([21]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/Sigmoid_1\n",
      "index : 420\n",
      "shape : [  1   1   1 240]\n",
      "shape_signature : [  1   1   1 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/se_block_5/mul_1\n",
      "index : 421\n",
      "shape : [  1  32  32 240]\n",
      "shape_signature : [  1  32  32 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.06997935695108e-05, 6)\n",
      "quantization_parameters : {'scales': array([3.0699794e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/Sigmoid_1\n",
      "index : 422\n",
      "shape : [  1  32  32 240]\n",
      "shape_signature : [  1  32  32 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/mul_1\n",
      "index : 423\n",
      "shape : [  1  32  32 240]\n",
      "shape_signature : [  1  32  32 240]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.5346773579949513e-05, 6)\n",
      "quantization_parameters : {'scales': array([1.5346774e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_5/batch_normalization_18/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_5/conv2d_24/Conv2D1\n",
      "index : 424\n",
      "shape : [ 1 32 32 80]\n",
      "shape_signature : [ 1 32 32 80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00015077073476277292, -9)\n",
      "quantization_parameters : {'scales': array([0.00015077], dtype=float32), 'zero_points': array([-9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_19/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/conv2d_25/Conv2D1\n",
      "index : 425\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010380877210991457, -3)\n",
      "quantization_parameters : {'scales': array([0.00010381], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/Sigmoid\n",
      "index : 426\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/mul\n",
      "index : 427\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.1915681979153305e-05, -3)\n",
      "quantization_parameters : {'scales': array([5.1915682e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_20/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_26/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/depthwise_conv2d_8/depthwise;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/depthwise_conv2d_6/depthwise\n",
      "index : 428\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.515838372753933e-05, 12)\n",
      "quantization_parameters : {'scales': array([4.5158384e-05], dtype=float32), 'zero_points': array([12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/global_average_pooling2d_6/Mean;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/ExpandDims_1\n",
      "index : 429\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.3703679693862796e-05, 16)\n",
      "quantization_parameters : {'scales': array([4.370368e-05], dtype=float32), 'zero_points': array([16]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_26/BiasAdd/ReadVariableOp/resource1\n",
      "index : 430\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.9333248171024024e-05, -12)\n",
      "quantization_parameters : {'scales': array([4.9333248e-05], dtype=float32), 'zero_points': array([-12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/Sigmoid\n",
      "index : 431\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/mul\n",
      "index : 432\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.4680852220626548e-05, -13)\n",
      "quantization_parameters : {'scales': array([2.4680852e-05], dtype=float32), 'zero_points': array([-13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/conv2d_27/BiasAdd/ReadVariableOp/resource1\n",
      "index : 433\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.366964690736495e-05, 10)\n",
      "quantization_parameters : {'scales': array([2.3669647e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/Sigmoid_1\n",
      "index : 434\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/se_block_6/mul_1\n",
      "index : 435\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.258601125504356e-05, 12)\n",
      "quantization_parameters : {'scales': array([2.2586011e-05], dtype=float32), 'zero_points': array([12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/Sigmoid_1\n",
      "index : 436\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/mul_1\n",
      "index : 437\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.1289778740319889e-05, 12)\n",
      "quantization_parameters : {'scales': array([1.1289779e-05], dtype=float32), 'zero_points': array([12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/batch_normalization_21/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_6/conv2d_28/Conv2D1\n",
      "index : 438\n",
      "shape : [ 1 32 32 80]\n",
      "shape_signature : [ 1 32 32 80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012305204290896654, 8)\n",
      "quantization_parameters : {'scales': array([0.00012305], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_6/add_2/add\n",
      "index : 439\n",
      "shape : [ 1 32 32 80]\n",
      "shape_signature : [ 1 32 32 80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0002027558075496927, -19)\n",
      "quantization_parameters : {'scales': array([0.00020276], dtype=float32), 'zero_points': array([-19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_22/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_29/Conv2D1\n",
      "index : 440\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0001191647388623096, -1)\n",
      "quantization_parameters : {'scales': array([0.00011916], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/Sigmoid\n",
      "index : 441\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/mul\n",
      "index : 442\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.9588972362689674e-05, -2)\n",
      "quantization_parameters : {'scales': array([5.9588972e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_23/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_26/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/depthwise_conv2d_8/depthwise;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/depthwise_conv2d_7/depthwise\n",
      "index : 443\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.433406163821928e-05, -3)\n",
      "quantization_parameters : {'scales': array([3.433406e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/global_average_pooling2d_7/Mean;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/ExpandDims_1\n",
      "index : 444\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.375302185304463e-05, -2)\n",
      "quantization_parameters : {'scales': array([3.3753022e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_30/BiasAdd/ReadVariableOp/resource1\n",
      "index : 445\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.5860171667300165e-05, 7)\n",
      "quantization_parameters : {'scales': array([4.586017e-05], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/Sigmoid\n",
      "index : 446\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/mul\n",
      "index : 447\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2922084099263884e-05, 7)\n",
      "quantization_parameters : {'scales': array([2.2922084e-05], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/Conv2D;efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/conv2d_31/BiasAdd/ReadVariableOp/resource1\n",
      "index : 448\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.219325688201934e-05, -3)\n",
      "quantization_parameters : {'scales': array([2.2193257e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/Sigmoid_1\n",
      "index : 449\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/se_block_7/mul_1\n",
      "index : 450\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.716951373964548e-05, -3)\n",
      "quantization_parameters : {'scales': array([1.7169514e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/Sigmoid_1\n",
      "index : 451\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/mul_1\n",
      "index : 452\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.585068826505449e-06, -3)\n",
      "quantization_parameters : {'scales': array([8.585069e-06], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/batch_normalization_24/FusedBatchNormV3;efficient_det/efficient_net/sequential_3/mb_conv_7/conv2d_32/Conv2D1\n",
      "index : 453\n",
      "shape : [ 1 32 32 80]\n",
      "shape_signature : [ 1 32 32 80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012394675286486745, -29)\n",
      "quantization_parameters : {'scales': array([0.00012395], dtype=float32), 'zero_points': array([-29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_3/mb_conv_7/add_3/add\n",
      "index : 454\n",
      "shape : [ 1 32 32 80]\n",
      "shape_signature : [ 1 32 32 80]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00024212861899286509, -8)\n",
      "quantization_parameters : {'scales': array([0.00024213], dtype=float32), 'zero_points': array([-8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_1/batch_normalization_50/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_1/conv2d_66/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_1/conv2d_66/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/conv_norm_act_1/conv2d_66/Conv2D\n",
      "index : 455\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00019421653996687382, -22)\n",
      "quantization_parameters : {'scales': array([0.00019422], dtype=float32), 'zero_points': array([-22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_1/Sigmoid\n",
      "index : 456\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_1/mul\n",
      "index : 457\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.751060861162841e-05, -23)\n",
      "quantization_parameters : {'scales': array([9.751061e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/mul\n",
      "index : 458\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.870137126999907e-05, -23)\n",
      "quantization_parameters : {'scales': array([4.870137e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/mul\n",
      "index : 459\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.255786214140244e-05, -23)\n",
      "quantization_parameters : {'scales': array([3.2557862e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_25/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/conv2d_33/Conv2D1\n",
      "index : 460\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0001395643485011533, -1)\n",
      "quantization_parameters : {'scales': array([0.00013956], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/Sigmoid\n",
      "index : 461\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/mul\n",
      "index : 462\n",
      "shape : [  1  32  32 480]\n",
      "shape_signature : [  1  32  32 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.978767487453297e-05, -2)\n",
      "quantization_parameters : {'scales': array([6.9787675e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_26/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_8/depthwise_conv2d_8/depthwise;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D1\n",
      "index : 463\n",
      "shape : [  1  16  16 480]\n",
      "shape_signature : [  1  16  16 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.0735056245466694e-05, -4)\n",
      "quantization_parameters : {'scales': array([4.0735056e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/global_average_pooling2d_8/Mean\n",
      "index : 464\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.9896800444694236e-05, -3)\n",
      "quantization_parameters : {'scales': array([3.98968e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_34/BiasAdd/ReadVariableOp/resource1\n",
      "index : 465\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.707077459897846e-05, 3)\n",
      "quantization_parameters : {'scales': array([4.7070775e-05], dtype=float32), 'zero_points': array([3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/Sigmoid\n",
      "index : 466\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/mul\n",
      "index : 467\n",
      "shape : [  1   1   1 120]\n",
      "shape_signature : [  1   1   1 120]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.353183663217351e-05, 2)\n",
      "quantization_parameters : {'scales': array([2.3531837e-05], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/BiasAdd;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/conv2d_35/BiasAdd/ReadVariableOp/resource1\n",
      "index : 468\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.3269298253580928e-05, 4)\n",
      "quantization_parameters : {'scales': array([2.3269298e-05], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/Sigmoid_1\n",
      "index : 469\n",
      "shape : [  1   1   1 480]\n",
      "shape_signature : [  1   1   1 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/se_block_8/mul_1\n",
      "index : 470\n",
      "shape : [  1  16  16 480]\n",
      "shape_signature : [  1  16  16 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0376928659970872e-05, -4)\n",
      "quantization_parameters : {'scales': array([2.0376929e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/Sigmoid_1\n",
      "index : 471\n",
      "shape : [  1  16  16 480]\n",
      "shape_signature : [  1  16  16 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/mul_1\n",
      "index : 472\n",
      "shape : [  1  16  16 480]\n",
      "shape_signature : [  1  16  16 480]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.0189127351623029e-05, -4)\n",
      "quantization_parameters : {'scales': array([1.0189127e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_8/batch_normalization_27/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_8/conv2d_36/Conv2D1\n",
      "index : 473\n",
      "shape : [  1  16  16 112]\n",
      "shape_signature : [  1  16  16 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00014319633191917092, -2)\n",
      "quantization_parameters : {'scales': array([0.0001432], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_28/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/conv2d_37/Conv2D1\n",
      "index : 474\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.951746324077249e-05, 1)\n",
      "quantization_parameters : {'scales': array([9.951746e-05], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/Sigmoid\n",
      "index : 475\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/mul\n",
      "index : 476\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.975295814801939e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.9752958e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_29/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_35/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/depthwise_conv2d_11/depthwise;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/depthwise_conv2d_9/depthwise\n",
      "index : 477\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.8059079088270664e-05, 7)\n",
      "quantization_parameters : {'scales': array([3.805908e-05], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/global_average_pooling2d_9/Mean;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/ExpandDims_1\n",
      "index : 478\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.728765659616329e-05, 8)\n",
      "quantization_parameters : {'scales': array([3.7287657e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_38/BiasAdd/ReadVariableOp/resource1\n",
      "index : 479\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.408214954310097e-05, -8)\n",
      "quantization_parameters : {'scales': array([4.408215e-05], dtype=float32), 'zero_points': array([-8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/Sigmoid\n",
      "index : 480\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/mul\n",
      "index : 481\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2048718165024184e-05, -9)\n",
      "quantization_parameters : {'scales': array([2.2048718e-05], dtype=float32), 'zero_points': array([-9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/conv2d_39/BiasAdd/ReadVariableOp/resource1\n",
      "index : 482\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.4511718947906047e-05, 15)\n",
      "quantization_parameters : {'scales': array([2.4511719e-05], dtype=float32), 'zero_points': array([15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/Sigmoid_1\n",
      "index : 483\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/se_block_9/mul_1\n",
      "index : 484\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9023067579837516e-05, 7)\n",
      "quantization_parameters : {'scales': array([1.9023068e-05], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/Sigmoid_1\n",
      "index : 485\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/mul_1\n",
      "index : 486\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.510229574516416e-06, 7)\n",
      "quantization_parameters : {'scales': array([9.51023e-06], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/batch_normalization_30/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_9/conv2d_40/Conv2D1\n",
      "index : 487\n",
      "shape : [  1  16  16 112]\n",
      "shape_signature : [  1  16  16 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011629241635091603, 8)\n",
      "quantization_parameters : {'scales': array([0.00011629], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_9/add_4/add\n",
      "index : 488\n",
      "shape : [  1  16  16 112]\n",
      "shape_signature : [  1  16  16 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00015174728468991816, -15)\n",
      "quantization_parameters : {'scales': array([0.00015175], dtype=float32), 'zero_points': array([-15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_31/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_41/Conv2D1\n",
      "index : 489\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011574230302358046, 5)\n",
      "quantization_parameters : {'scales': array([0.00011574], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/Sigmoid\n",
      "index : 490\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/mul\n",
      "index : 491\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.783137385151349e-05, 4)\n",
      "quantization_parameters : {'scales': array([5.7831374e-05], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_32/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_35/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/depthwise_conv2d_11/depthwise;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/depthwise_conv2d_10/depthwise\n",
      "index : 492\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.650514190667309e-05, -15)\n",
      "quantization_parameters : {'scales': array([3.6505142e-05], dtype=float32), 'zero_points': array([-15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/global_average_pooling2d_10/Mean;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/ExpandDims_1\n",
      "index : 493\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.635958637460135e-05, -14)\n",
      "quantization_parameters : {'scales': array([3.6359586e-05], dtype=float32), 'zero_points': array([-14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_42/BiasAdd/ReadVariableOp/resource1\n",
      "index : 494\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.0536025810288265e-05, 2)\n",
      "quantization_parameters : {'scales': array([5.0536026e-05], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/Sigmoid\n",
      "index : 495\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/mul\n",
      "index : 496\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5264665964641608e-05, 2)\n",
      "quantization_parameters : {'scales': array([2.5264666e-05], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/Conv2D;efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/conv2d_43/BiasAdd/ReadVariableOp/resource1\n",
      "index : 497\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0983417925890535e-05, -9)\n",
      "quantization_parameters : {'scales': array([2.0983418e-05], dtype=float32), 'zero_points': array([-9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/Sigmoid_1\n",
      "index : 498\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/se_block_10/mul_1\n",
      "index : 499\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.8257234842167236e-05, -15)\n",
      "quantization_parameters : {'scales': array([1.8257235e-05], dtype=float32), 'zero_points': array([-15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/Sigmoid_1\n",
      "index : 500\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/mul_1\n",
      "index : 501\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.130958460445981e-06, -15)\n",
      "quantization_parameters : {'scales': array([9.1309585e-06], dtype=float32), 'zero_points': array([-15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/batch_normalization_33/FusedBatchNormV3;efficient_det/efficient_net/sequential_4/mb_conv_10/conv2d_44/Conv2D1\n",
      "index : 502\n",
      "shape : [  1  16  16 112]\n",
      "shape_signature : [  1  16  16 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012642168439924717, -1)\n",
      "quantization_parameters : {'scales': array([0.00012642], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_4/mb_conv_10/add_5/add\n",
      "index : 503\n",
      "shape : [  1  16  16 112]\n",
      "shape_signature : [  1  16  16 112]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00018532043031882495, -17)\n",
      "quantization_parameters : {'scales': array([0.00018532], dtype=float32), 'zero_points': array([-17]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_2/batch_normalization_51/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_2/conv2d_67/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_2/conv2d_67/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/conv_norm_act_2/conv2d_67/Conv2D\n",
      "index : 504\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00021887003094889224, 12)\n",
      "quantization_parameters : {'scales': array([0.00021887], dtype=float32), 'zero_points': array([12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_2/Sigmoid\n",
      "index : 505\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_2/mul\n",
      "index : 506\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010913625010289252, 10)\n",
      "quantization_parameters : {'scales': array([0.00010914], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/mul\n",
      "index : 507\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.4484495194628835e-05, 10)\n",
      "quantization_parameters : {'scales': array([5.4484495e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/mul\n",
      "index : 508\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.637590998550877e-05, 10)\n",
      "quantization_parameters : {'scales': array([3.637591e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_34/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/conv2d_45/Conv2D1\n",
      "index : 509\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00014023412950336933, -13)\n",
      "quantization_parameters : {'scales': array([0.00014023], dtype=float32), 'zero_points': array([-13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/Sigmoid\n",
      "index : 510\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/mul\n",
      "index : 511\n",
      "shape : [  1  16  16 672]\n",
      "shape_signature : [  1  16  16 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.023556827334687e-05, -14)\n",
      "quantization_parameters : {'scales': array([7.023557e-05], dtype=float32), 'zero_points': array([-14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_35/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_11/depthwise_conv2d_11/depthwise;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D1\n",
      "index : 512\n",
      "shape : [  1   8   8 672]\n",
      "shape_signature : [  1   8   8 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.166019425611012e-05, -20)\n",
      "quantization_parameters : {'scales': array([4.1660194e-05], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/global_average_pooling2d_11/Mean\n",
      "index : 513\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.1345832869410515e-05, -21)\n",
      "quantization_parameters : {'scales': array([4.1345833e-05], dtype=float32), 'zero_points': array([-21]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_46/BiasAdd/ReadVariableOp/resource1\n",
      "index : 514\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.384958083392121e-05, 19)\n",
      "quantization_parameters : {'scales': array([4.384958e-05], dtype=float32), 'zero_points': array([19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/Sigmoid\n",
      "index : 515\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/mul\n",
      "index : 516\n",
      "shape : [  1   1   1 168]\n",
      "shape_signature : [  1   1   1 168]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.1905934772803448e-05, 19)\n",
      "quantization_parameters : {'scales': array([2.1905935e-05], dtype=float32), 'zero_points': array([19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/BiasAdd;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/conv2d_47/BiasAdd/ReadVariableOp/resource1\n",
      "index : 517\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5012679543578997e-05, 9)\n",
      "quantization_parameters : {'scales': array([2.501268e-05], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/Sigmoid_1\n",
      "index : 518\n",
      "shape : [  1   1   1 672]\n",
      "shape_signature : [  1   1   1 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/se_block_11/mul_1\n",
      "index : 519\n",
      "shape : [  1   8   8 672]\n",
      "shape_signature : [  1   8   8 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0836569092352875e-05, -20)\n",
      "quantization_parameters : {'scales': array([2.083657e-05], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/Sigmoid_1\n",
      "index : 520\n",
      "shape : [  1   8   8 672]\n",
      "shape_signature : [  1   8   8 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/mul_1\n",
      "index : 521\n",
      "shape : [  1   8   8 672]\n",
      "shape_signature : [  1   8   8 672]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.0422570085211191e-05, -20)\n",
      "quantization_parameters : {'scales': array([1.042257e-05], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_11/batch_normalization_36/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_11/conv2d_48/Conv2D1\n",
      "index : 522\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012924481416121125, -13)\n",
      "quantization_parameters : {'scales': array([0.00012924], dtype=float32), 'zero_points': array([-13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_37/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/conv2d_49/Conv2D1\n",
      "index : 523\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011332686699461192, 13)\n",
      "quantization_parameters : {'scales': array([0.00011333], dtype=float32), 'zero_points': array([13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/Sigmoid\n",
      "index : 524\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/mul\n",
      "index : 525\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.6579265219625086e-05, 12)\n",
      "quantization_parameters : {'scales': array([5.6579265e-05], dtype=float32), 'zero_points': array([12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_38/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_47/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/depthwise_conv2d_15/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/depthwise_conv2d_12/depthwise\n",
      "index : 526\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.9536255169659853e-05, -5)\n",
      "quantization_parameters : {'scales': array([2.9536255e-05], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/global_average_pooling2d_12/Mean;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/ExpandDims_1\n",
      "index : 527\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.9190294299041852e-05, -6)\n",
      "quantization_parameters : {'scales': array([2.9190294e-05], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_50/BiasAdd/ReadVariableOp/resource1\n",
      "index : 528\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.983058923040517e-05, -1)\n",
      "quantization_parameters : {'scales': array([3.983059e-05], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/Sigmoid\n",
      "index : 529\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/mul\n",
      "index : 530\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9915572920581326e-05, -1)\n",
      "quantization_parameters : {'scales': array([1.9915573e-05], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/conv2d_51/BiasAdd/ReadVariableOp/resource1\n",
      "index : 531\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.1040723368059844e-05, 6)\n",
      "quantization_parameters : {'scales': array([2.1040723e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/Sigmoid_1\n",
      "index : 532\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/se_block_12/mul_1\n",
      "index : 533\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.4762295904802158e-05, -5)\n",
      "quantization_parameters : {'scales': array([1.4762296e-05], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/Sigmoid_1\n",
      "index : 534\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/mul_1\n",
      "index : 535\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.381625891866861e-06, -5)\n",
      "quantization_parameters : {'scales': array([7.381626e-06], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/batch_normalization_39/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_12/conv2d_52/Conv2D1\n",
      "index : 536\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.896570216165856e-05, 19)\n",
      "quantization_parameters : {'scales': array([8.89657e-05], dtype=float32), 'zero_points': array([19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_12/add_6/add\n",
      "index : 537\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00016123063687700778, 7)\n",
      "quantization_parameters : {'scales': array([0.00016123], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_40/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/conv2d_53/Conv2D1\n",
      "index : 538\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010586794087430462, -10)\n",
      "quantization_parameters : {'scales': array([0.00010587], dtype=float32), 'zero_points': array([-10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/Sigmoid\n",
      "index : 539\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/mul\n",
      "index : 540\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.2989955293014646e-05, -11)\n",
      "quantization_parameters : {'scales': array([5.2989955e-05], dtype=float32), 'zero_points': array([-11]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_41/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_47/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/depthwise_conv2d_15/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/depthwise_conv2d_13/depthwise\n",
      "index : 541\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.39204998454079e-05, -2)\n",
      "quantization_parameters : {'scales': array([3.39205e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/global_average_pooling2d_13/Mean;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/ExpandDims_1\n",
      "index : 542\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.3542673918418586e-05, -1)\n",
      "quantization_parameters : {'scales': array([3.3542674e-05], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_54/BiasAdd/ReadVariableOp/resource1\n",
      "index : 543\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.638775888248347e-05, 5)\n",
      "quantization_parameters : {'scales': array([3.638776e-05], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/Sigmoid\n",
      "index : 544\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/mul\n",
      "index : 545\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.81901177711552e-05, 5)\n",
      "quantization_parameters : {'scales': array([1.8190118e-05], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/conv2d_55/BiasAdd/ReadVariableOp/resource1\n",
      "index : 546\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0052562831551768e-05, 2)\n",
      "quantization_parameters : {'scales': array([2.0052563e-05], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/Sigmoid_1\n",
      "index : 547\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/se_block_13/mul_1\n",
      "index : 548\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.696208528301213e-05, -2)\n",
      "quantization_parameters : {'scales': array([1.6962085e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/Sigmoid_1\n",
      "index : 549\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/mul_1\n",
      "index : 550\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.481316399411298e-06, -3)\n",
      "quantization_parameters : {'scales': array([8.481316e-06], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/batch_normalization_42/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_13/conv2d_56/Conv2D1\n",
      "index : 551\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.071327076526359e-05, -11)\n",
      "quantization_parameters : {'scales': array([9.071327e-05], dtype=float32), 'zero_points': array([-11]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_13/add_7/add\n",
      "index : 552\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00017134030349552631, 13)\n",
      "quantization_parameters : {'scales': array([0.00017134], dtype=float32), 'zero_points': array([13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_43/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_57/Conv2D1\n",
      "index : 553\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012004751624772325, 9)\n",
      "quantization_parameters : {'scales': array([0.00012005], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/Sigmoid\n",
      "index : 554\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/mul\n",
      "index : 555\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.995400351821445e-05, 8)\n",
      "quantization_parameters : {'scales': array([5.9954004e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_44/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_47/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/depthwise_conv2d_15/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/depthwise_conv2d_14/depthwise\n",
      "index : 556\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.191592259099707e-05, -8)\n",
      "quantization_parameters : {'scales': array([3.1915923e-05], dtype=float32), 'zero_points': array([-8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/global_average_pooling2d_14/Mean;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/ExpandDims_1\n",
      "index : 557\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.073020343435928e-05, -7)\n",
      "quantization_parameters : {'scales': array([3.0730203e-05], dtype=float32), 'zero_points': array([-7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_58/BiasAdd/ReadVariableOp/resource1\n",
      "index : 558\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.122512837057002e-05, 11)\n",
      "quantization_parameters : {'scales': array([4.122513e-05], dtype=float32), 'zero_points': array([11]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/Sigmoid\n",
      "index : 559\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/mul\n",
      "index : 560\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.060315637208987e-05, 10)\n",
      "quantization_parameters : {'scales': array([2.0603156e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/Conv2D;efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/conv2d_59/BiasAdd/ReadVariableOp/resource1\n",
      "index : 561\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9349306967342272e-05, -9)\n",
      "quantization_parameters : {'scales': array([1.9349307e-05], dtype=float32), 'zero_points': array([-9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/Sigmoid_1\n",
      "index : 562\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/se_block_14/mul_1\n",
      "index : 563\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.59557894221507e-05, -8)\n",
      "quantization_parameters : {'scales': array([1.595579e-05], dtype=float32), 'zero_points': array([-8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/Sigmoid_1\n",
      "index : 564\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/mul_1\n",
      "index : 565\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.978814210218843e-06, -8)\n",
      "quantization_parameters : {'scales': array([7.978814e-06], dtype=float32), 'zero_points': array([-8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/batch_normalization_45/FusedBatchNormV3;efficient_det/efficient_net/sequential_5/mb_conv_14/conv2d_60/Conv2D1\n",
      "index : 566\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012756629439536482, 4)\n",
      "quantization_parameters : {'scales': array([0.00012757], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_5/mb_conv_14/add_8/add\n",
      "index : 567\n",
      "shape : [  1   8   8 192]\n",
      "shape_signature : [  1   8   8 192]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0002033696509897709, 9)\n",
      "quantization_parameters : {'scales': array([0.00020337], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_3/batch_normalization_52/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_3/conv2d_68/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_3/conv2d_68/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/conv_norm_act_3/conv2d_68/Conv2D\n",
      "index : 568\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0001769255759427324, -3)\n",
      "quantization_parameters : {'scales': array([0.00017693], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_3/Sigmoid\n",
      "index : 569\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_3/mul\n",
      "index : 570\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.849864389048889e-05, -4)\n",
      "quantization_parameters : {'scales': array([8.8498644e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/mul\n",
      "index : 571\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.42463751824107e-05, -4)\n",
      "quantization_parameters : {'scales': array([4.4246375e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/mul\n",
      "index : 572\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.950749512820039e-05, -4)\n",
      "quantization_parameters : {'scales': array([2.9507495e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_46/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_6/mb_conv_15/conv2d_61/Conv2D1\n",
      "index : 573\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00012877075641881675, 3)\n",
      "quantization_parameters : {'scales': array([0.00012877], dtype=float32), 'zero_points': array([3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/Sigmoid\n",
      "index : 574\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/mul\n",
      "index : 575\n",
      "shape : [   1    8    8 1152]\n",
      "shape_signature : [   1    8    8 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.435828981921077e-05, 2)\n",
      "quantization_parameters : {'scales': array([6.435829e-05], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_47/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/depthwise_conv2d_15/depthwise;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D1\n",
      "index : 576\n",
      "shape : [   1    4    4 1152]\n",
      "shape_signature : [   1    4    4 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.4777302062138915e-05, -1)\n",
      "quantization_parameters : {'scales': array([3.4777302e-05], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/ExpandDims_1;efficient_det/efficient_net/sequential/mb_conv/se_block/global_average_pooling2d/Mean/reduction_indices;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/global_average_pooling2d_15/Mean\n",
      "index : 577\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.410463250475004e-05, -2)\n",
      "quantization_parameters : {'scales': array([3.4104633e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/Conv2D;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_62/BiasAdd/ReadVariableOp/resource1\n",
      "index : 578\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.556806379696354e-05, 14)\n",
      "quantization_parameters : {'scales': array([4.5568064e-05], dtype=float32), 'zero_points': array([14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/Sigmoid\n",
      "index : 579\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/mul\n",
      "index : 580\n",
      "shape : [  1   1   1 288]\n",
      "shape_signature : [  1   1   1 288]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2768512280890718e-05, 14)\n",
      "quantization_parameters : {'scales': array([2.2768512e-05], dtype=float32), 'zero_points': array([14]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/BiasAdd;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/Conv2D;efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/conv2d_63/BiasAdd/ReadVariableOp/resource1\n",
      "index : 581\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.3497264919569716e-05, -2)\n",
      "quantization_parameters : {'scales': array([2.3497265e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/Sigmoid_1\n",
      "index : 582\n",
      "shape : [   1    1    1 1152]\n",
      "shape_signature : [   1    1    1 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/se_block_15/mul_1\n",
      "index : 583\n",
      "shape : [   1    4    4 1152]\n",
      "shape_signature : [   1    4    4 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.7394891983713023e-05, -1)\n",
      "quantization_parameters : {'scales': array([1.7394892e-05], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/Sigmoid_1\n",
      "index : 584\n",
      "shape : [   1    4    4 1152]\n",
      "shape_signature : [   1    4    4 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/mul_1\n",
      "index : 585\n",
      "shape : [   1    4    4 1152]\n",
      "shape_signature : [   1    4    4 1152]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.697473276697565e-06, -1)\n",
      "quantization_parameters : {'scales': array([8.697473e-06], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/efficient_net/sequential_6/mb_conv_15/batch_normalization_48/FusedBatchNormV3;efficient_det/efficient_net/sequential_6/mb_conv_15/conv2d_64/Conv2D1\n",
      "index : 586\n",
      "shape : [  1   4   4 320]\n",
      "shape_signature : [  1   4   4 320]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.9466200734023e-05, -6)\n",
      "quantization_parameters : {'scales': array([8.94662e-05], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_4/batch_normalization_53/FusedBatchNormV3;efficient_det/bi_fpn/conv_norm_act_4/conv2d_69/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/conv_norm_act_4/conv2d_69/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/conv_norm_act_4/conv2d_69/Conv2D\n",
      "index : 587\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010346193448640406, 10)\n",
      "quantization_parameters : {'scales': array([0.00010346], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_4/Sigmoid\n",
      "index : 588\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/conv_norm_act_4/mul\n",
      "index : 589\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.1675648137461394e-05, 9)\n",
      "quantization_parameters : {'scales': array([5.1675648e-05], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d/resize/ResizeNearestNeighbor\n",
      "index : 590\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.1675648137461394e-05, 9)\n",
      "quantization_parameters : {'scales': array([5.1675648e-05], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/mul_1\n",
      "index : 591\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.42463751824107e-05, -4)\n",
      "quantization_parameters : {'scales': array([4.4246375e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/Sum/input\n",
      "index : 592\n",
      "shape : [ 2  1  8  8 64]\n",
      "shape_signature : [ 2  1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.42463751824107e-05, -4)\n",
      "quantization_parameters : {'scales': array([4.4246375e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/Sum\n",
      "index : 593\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.681406426243484e-05, -26)\n",
      "quantization_parameters : {'scales': array([4.6814064e-05], dtype=float32), 'zero_points': array([-26]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/separable_conv2d/depthwise1\n",
      "index : 594\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.0004920113715343e-05, 9)\n",
      "quantization_parameters : {'scales': array([1.000492e-05], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/batch_normalization_54/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/separable_conv2d/separable_conv2d\n",
      "index : 595\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011714926222339272, -5)\n",
      "quantization_parameters : {'scales': array([0.00011715], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/Sigmoid\n",
      "index : 596\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion/separable_conv_norm_act/mul\n",
      "index : 597\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.8602447097655386e-05, -6)\n",
      "quantization_parameters : {'scales': array([5.8602447e-05], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d_1/resize/ResizeNearestNeighbor\n",
      "index : 598\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.8602447097655386e-05, -6)\n",
      "quantization_parameters : {'scales': array([5.8602447e-05], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/mul_1\n",
      "index : 599\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.4484495194628835e-05, 10)\n",
      "quantization_parameters : {'scales': array([5.4484495e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/Sum/input\n",
      "index : 600\n",
      "shape : [ 2  1 16 16 64]\n",
      "shape_signature : [ 2  1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.4484495194628835e-05, 10)\n",
      "quantization_parameters : {'scales': array([5.4484495e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/Sum\n",
      "index : 601\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.142629328882322e-05, -5)\n",
      "quantization_parameters : {'scales': array([7.142629e-05], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/separable_conv2d/depthwise1\n",
      "index : 602\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.06672957574483e-05, -25)\n",
      "quantization_parameters : {'scales': array([2.0667296e-05], dtype=float32), 'zero_points': array([-25]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/batch_normalization_55/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/separable_conv2d_1/separable_conv2d\n",
      "index : 603\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.803660941543058e-05, -3)\n",
      "quantization_parameters : {'scales': array([9.803661e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/Sigmoid\n",
      "index : 604\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_1/separable_conv_norm_act_1/mul\n",
      "index : 605\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.9032256356440485e-05, -4)\n",
      "quantization_parameters : {'scales': array([4.9032256e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d_2/resize/ResizeNearestNeighbor\n",
      "index : 606\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.9032256356440485e-05, -4)\n",
      "quantization_parameters : {'scales': array([4.9032256e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/mul_1\n",
      "index : 607\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.870137126999907e-05, -23)\n",
      "quantization_parameters : {'scales': array([4.870137e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/Sum/input\n",
      "index : 608\n",
      "shape : [ 2  1 32 32 64]\n",
      "shape_signature : [ 2  1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.870137126999907e-05, -23)\n",
      "quantization_parameters : {'scales': array([4.870137e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/Sum\n",
      "index : 609\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.61321760667488e-05, -7)\n",
      "quantization_parameters : {'scales': array([4.6132176e-05], dtype=float32), 'zero_points': array([-7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/separable_conv2d/depthwise1\n",
      "index : 610\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.6411977412644774e-05, 52)\n",
      "quantization_parameters : {'scales': array([1.6411977e-05], dtype=float32), 'zero_points': array([52]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/batch_normalization_56/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/separable_conv2d_2/separable_conv2d\n",
      "index : 611\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010505769023438916, -11)\n",
      "quantization_parameters : {'scales': array([0.00010506], dtype=float32), 'zero_points': array([-11]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/Sigmoid\n",
      "index : 612\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_2/separable_conv_norm_act_2/mul\n",
      "index : 613\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.258521196083166e-05, -12)\n",
      "quantization_parameters : {'scales': array([5.2585212e-05], dtype=float32), 'zero_points': array([-12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/up_sampling2d_3/resize/ResizeNearestNeighbor\n",
      "index : 614\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.258521196083166e-05, -12)\n",
      "quantization_parameters : {'scales': array([5.2585212e-05], dtype=float32), 'zero_points': array([-12]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/mul_1\n",
      "index : 615\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.0556402129586786e-05, -27)\n",
      "quantization_parameters : {'scales': array([5.0556402e-05], dtype=float32), 'zero_points': array([-27]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/Sum/input\n",
      "index : 616\n",
      "shape : [ 2  1 64 64 64]\n",
      "shape_signature : [ 2  1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.0556402129586786e-05, -27)\n",
      "quantization_parameters : {'scales': array([5.0556402e-05], dtype=float32), 'zero_points': array([-27]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/Sum\n",
      "index : 617\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.876798240933567e-05, -20)\n",
      "quantization_parameters : {'scales': array([5.8767982e-05], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/separable_conv2d/depthwise1\n",
      "index : 618\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.154929577751318e-05, -4)\n",
      "quantization_parameters : {'scales': array([1.1549296e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/batch_normalization_57/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/separable_conv2d_3/separable_conv2d\n",
      "index : 619\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.061658445512876e-05, 30)\n",
      "quantization_parameters : {'scales': array([8.0616584e-05], dtype=float32), 'zero_points': array([30]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/Sigmoid\n",
      "index : 620\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_3/separable_conv_norm_act_3/mul\n",
      "index : 621\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.0210667066276073e-05, 29)\n",
      "quantization_parameters : {'scales': array([4.0210667e-05], dtype=float32), 'zero_points': array([29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/max_pooling2d/MaxPool\n",
      "index : 622\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.0210667066276073e-05, 29)\n",
      "quantization_parameters : {'scales': array([4.0210667e-05], dtype=float32), 'zero_points': array([29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/mul_2\n",
      "index : 623\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.255786214140244e-05, -23)\n",
      "quantization_parameters : {'scales': array([3.2557862e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/mul\n",
      "index : 624\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0093657440156676e-05, 29)\n",
      "quantization_parameters : {'scales': array([2.0093657e-05], dtype=float32), 'zero_points': array([29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/mul_1\n",
      "index : 625\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.255786214140244e-05, -23)\n",
      "quantization_parameters : {'scales': array([3.2557862e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/Sum/input\n",
      "index : 626\n",
      "shape : [ 3  1 32 32 64]\n",
      "shape_signature : [ 3  1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.255786214140244e-05, -23)\n",
      "quantization_parameters : {'scales': array([3.2557862e-05], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/Sum\n",
      "index : 627\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.995183215010911e-05, -26)\n",
      "quantization_parameters : {'scales': array([3.9951832e-05], dtype=float32), 'zero_points': array([-26]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/separable_conv2d/depthwise1\n",
      "index : 628\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.553383850085083e-06, 19)\n",
      "quantization_parameters : {'scales': array([8.553384e-06], dtype=float32), 'zero_points': array([19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/batch_normalization_58/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/separable_conv2d_4/separable_conv2d\n",
      "index : 629\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010366133938077837, -1)\n",
      "quantization_parameters : {'scales': array([0.00010366], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/Sigmoid\n",
      "index : 630\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_4/separable_conv_norm_act_4/mul\n",
      "index : 631\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.1834798796335235e-05, -2)\n",
      "quantization_parameters : {'scales': array([5.18348e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/max_pooling2d_1/MaxPool\n",
      "index : 632\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.1834798796335235e-05, -2)\n",
      "quantization_parameters : {'scales': array([5.18348e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/mul_2\n",
      "index : 633\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.637590998550877e-05, 10)\n",
      "quantization_parameters : {'scales': array([3.637591e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/mul\n",
      "index : 634\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5867106160148978e-05, -2)\n",
      "quantization_parameters : {'scales': array([2.5867106e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/mul\n",
      "index : 635\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.7219810615642928e-05, -2)\n",
      "quantization_parameters : {'scales': array([1.721981e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/mul_1\n",
      "index : 636\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.637590998550877e-05, 10)\n",
      "quantization_parameters : {'scales': array([3.637591e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/Sum/input\n",
      "index : 637\n",
      "shape : [ 3  1 16 16 64]\n",
      "shape_signature : [ 3  1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.637590998550877e-05, 10)\n",
      "quantization_parameters : {'scales': array([3.637591e-05], dtype=float32), 'zero_points': array([10]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/Sum\n",
      "index : 638\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.829166234936565e-05, 16)\n",
      "quantization_parameters : {'scales': array([3.8291662e-05], dtype=float32), 'zero_points': array([16]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/separable_conv2d/depthwise1\n",
      "index : 639\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.9356217358727e-06, -5)\n",
      "quantization_parameters : {'scales': array([8.935622e-06], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/batch_normalization_59/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/separable_conv2d_5/separable_conv2d\n",
      "index : 640\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010678604303393513, 38)\n",
      "quantization_parameters : {'scales': array([0.00010679], dtype=float32), 'zero_points': array([38]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/Sigmoid\n",
      "index : 641\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_5/separable_conv_norm_act_5/mul\n",
      "index : 642\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.31752230017446e-05, 37)\n",
      "quantization_parameters : {'scales': array([5.3175223e-05], dtype=float32), 'zero_points': array([37]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/max_pooling2d_2/MaxPool\n",
      "index : 643\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.31752230017446e-05, 37)\n",
      "quantization_parameters : {'scales': array([5.3175223e-05], dtype=float32), 'zero_points': array([37]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/mul_2\n",
      "index : 644\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.950749512820039e-05, -4)\n",
      "quantization_parameters : {'scales': array([2.9507495e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/mul\n",
      "index : 645\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9239076209487393e-05, 24)\n",
      "quantization_parameters : {'scales': array([1.9239076e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/mul\n",
      "index : 646\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.7718540877685882e-05, 30)\n",
      "quantization_parameters : {'scales': array([2.771854e-05], dtype=float32), 'zero_points': array([30]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/mul_1\n",
      "index : 647\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.950749512820039e-05, -4)\n",
      "quantization_parameters : {'scales': array([2.9507495e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/Sum/input\n",
      "index : 648\n",
      "shape : [ 3  1  8  8 64]\n",
      "shape_signature : [ 3  1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.950749512820039e-05, -4)\n",
      "quantization_parameters : {'scales': array([2.9507495e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/Sum\n",
      "index : 649\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.112584065296687e-05, -2)\n",
      "quantization_parameters : {'scales': array([4.112584e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/separable_conv2d/depthwise1\n",
      "index : 650\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.210319169331342e-05, 18)\n",
      "quantization_parameters : {'scales': array([1.2103192e-05], dtype=float32), 'zero_points': array([18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/batch_normalization_60/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/separable_conv2d_6/separable_conv2d\n",
      "index : 651\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010917975305346772, 9)\n",
      "quantization_parameters : {'scales': array([0.00010918], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/Sigmoid\n",
      "index : 652\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_6/separable_conv_norm_act_6/mul\n",
      "index : 653\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.453571429825388e-05, 8)\n",
      "quantization_parameters : {'scales': array([5.4535714e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/max_pooling2d_3/MaxPool\n",
      "index : 654\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.453571429825388e-05, 8)\n",
      "quantization_parameters : {'scales': array([5.4535714e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/mul_1\n",
      "index : 655\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.7264639356872067e-05, 8)\n",
      "quantization_parameters : {'scales': array([2.726464e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/mul\n",
      "index : 656\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2531658032676205e-05, 17)\n",
      "quantization_parameters : {'scales': array([2.2531658e-05], dtype=float32), 'zero_points': array([17]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/mul\n",
      "index : 657\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.1003047954291105e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.1003048e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/mul\n",
      "index : 658\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.7264639356872067e-05, 8)\n",
      "quantization_parameters : {'scales': array([2.726464e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/Sum/input\n",
      "index : 659\n",
      "shape : [ 2  1  4  4 64]\n",
      "shape_signature : [ 2  1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.7264639356872067e-05, 8)\n",
      "quantization_parameters : {'scales': array([2.726464e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/Sum\n",
      "index : 660\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.991826088167727e-05, 27)\n",
      "quantization_parameters : {'scales': array([3.991826e-05], dtype=float32), 'zero_points': array([27]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/separable_conv2d/depthwise1\n",
      "index : 661\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.1152151273563504e-05, 2)\n",
      "quantization_parameters : {'scales': array([1.1152151e-05], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/batch_normalization_61/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/separable_conv2d_7/separable_conv2d\n",
      "index : 662\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00016385929484385997, 1)\n",
      "quantization_parameters : {'scales': array([0.00016386], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/Sigmoid\n",
      "index : 663\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module/weighted_feature_fusion_7/separable_conv_norm_act_7/mul\n",
      "index : 664\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.190924563677981e-05, 0)\n",
      "quantization_parameters : {'scales': array([8.1909246e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/up_sampling2d_4/resize/ResizeNearestNeighbor\n",
      "index : 665\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.190924563677981e-05, 0)\n",
      "quantization_parameters : {'scales': array([8.1909246e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/mul_1\n",
      "index : 666\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.1003047954291105e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.1003048e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/Sum/input\n",
      "index : 667\n",
      "shape : [ 2  1  8  8 64]\n",
      "shape_signature : [ 2  1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.1003047954291105e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.1003048e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/Sum\n",
      "index : 668\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.75159176858142e-05, 35)\n",
      "quantization_parameters : {'scales': array([4.7515918e-05], dtype=float32), 'zero_points': array([35]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/separable_conv2d/depthwise1\n",
      "index : 669\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.2758951015712228e-05, 6)\n",
      "quantization_parameters : {'scales': array([1.2758951e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/batch_normalization_62/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/separable_conv2d_8/separable_conv2d\n",
      "index : 670\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.882611291483045e-05, 7)\n",
      "quantization_parameters : {'scales': array([8.882611e-05], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/Sigmoid\n",
      "index : 671\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_8/separable_conv_norm_act_8/mul\n",
      "index : 672\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.438500036485493e-05, 6)\n",
      "quantization_parameters : {'scales': array([4.4385e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/up_sampling2d_5/resize/ResizeNearestNeighbor\n",
      "index : 673\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.438500036485493e-05, 6)\n",
      "quantization_parameters : {'scales': array([4.4385e-05], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/mul_1\n",
      "index : 674\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.7718540877685882e-05, 30)\n",
      "quantization_parameters : {'scales': array([2.771854e-05], dtype=float32), 'zero_points': array([30]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/Sum/input\n",
      "index : 675\n",
      "shape : [ 2  1 16 16 64]\n",
      "shape_signature : [ 2  1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.7718540877685882e-05, 30)\n",
      "quantization_parameters : {'scales': array([2.771854e-05], dtype=float32), 'zero_points': array([30]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/Sum\n",
      "index : 676\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.2264993680873886e-05, 8)\n",
      "quantization_parameters : {'scales': array([4.2264994e-05], dtype=float32), 'zero_points': array([8]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/separable_conv2d/depthwise1\n",
      "index : 677\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.1361462384229526e-05, 11)\n",
      "quantization_parameters : {'scales': array([1.1361462e-05], dtype=float32), 'zero_points': array([11]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/batch_normalization_63/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/separable_conv2d_9/separable_conv2d\n",
      "index : 678\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.33175256755203e-05, -2)\n",
      "quantization_parameters : {'scales': array([7.3317526e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/Sigmoid\n",
      "index : 679\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_9/separable_conv_norm_act_9/mul\n",
      "index : 680\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.666413977043703e-05, -3)\n",
      "quantization_parameters : {'scales': array([3.666414e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/up_sampling2d_6/resize/ResizeNearestNeighbor\n",
      "index : 681\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.666413977043703e-05, -3)\n",
      "quantization_parameters : {'scales': array([3.666414e-05], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/mul_1\n",
      "index : 682\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5867106160148978e-05, -2)\n",
      "quantization_parameters : {'scales': array([2.5867106e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/Sum/input\n",
      "index : 683\n",
      "shape : [ 2  1 32 32 64]\n",
      "shape_signature : [ 2  1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5867106160148978e-05, -2)\n",
      "quantization_parameters : {'scales': array([2.5867106e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/Sum\n",
      "index : 684\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.2488827855559066e-05, 5)\n",
      "quantization_parameters : {'scales': array([3.2488828e-05], dtype=float32), 'zero_points': array([5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/separable_conv2d/depthwise1\n",
      "index : 685\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.694465916254558e-06, 26)\n",
      "quantization_parameters : {'scales': array([9.694466e-06], dtype=float32), 'zero_points': array([26]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/batch_normalization_64/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/separable_conv2d_10/separable_conv2d\n",
      "index : 686\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.264502346515656e-05, 24)\n",
      "quantization_parameters : {'scales': array([7.264502e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/Sigmoid\n",
      "index : 687\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_10/separable_conv_norm_act_10/mul\n",
      "index : 688\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.625709723564796e-05, 24)\n",
      "quantization_parameters : {'scales': array([3.6257097e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/up_sampling2d_7/resize/ResizeNearestNeighbor\n",
      "index : 689\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.625709723564796e-05, 24)\n",
      "quantization_parameters : {'scales': array([3.6257097e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/mul_1\n",
      "index : 690\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0093657440156676e-05, 29)\n",
      "quantization_parameters : {'scales': array([2.0093657e-05], dtype=float32), 'zero_points': array([29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/Sum/input\n",
      "index : 691\n",
      "shape : [ 2  1 64 64 64]\n",
      "shape_signature : [ 2  1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.0093657440156676e-05, 29)\n",
      "quantization_parameters : {'scales': array([2.0093657e-05], dtype=float32), 'zero_points': array([29]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/Sum\n",
      "index : 692\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.011042281286791e-05, 30)\n",
      "quantization_parameters : {'scales': array([3.0110423e-05], dtype=float32), 'zero_points': array([30]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/separable_conv2d/depthwise1\n",
      "index : 693\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.684051863383502e-06, -21)\n",
      "quantization_parameters : {'scales': array([8.684052e-06], dtype=float32), 'zero_points': array([-21]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/batch_normalization_65/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/separable_conv2d_11/separable_conv2d\n",
      "index : 694\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.764145993860438e-05, -17)\n",
      "quantization_parameters : {'scales': array([7.764146e-05], dtype=float32), 'zero_points': array([-17]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/Sigmoid\n",
      "index : 695\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_11/separable_conv_norm_act_11/mul\n",
      "index : 696\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.887109050992876e-05, -18)\n",
      "quantization_parameters : {'scales': array([3.887109e-05], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/max_pooling2d_4/MaxPool\n",
      "index : 697\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.887109050992876e-05, -18)\n",
      "quantization_parameters : {'scales': array([3.887109e-05], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/mul_2\n",
      "index : 698\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.7219810615642928e-05, -2)\n",
      "quantization_parameters : {'scales': array([1.721981e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3;efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/Conv2D\n",
      "index : 699\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0020343144424259663, -5)\n",
      "quantization_parameters : {'scales': array([0.00203431], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/Sigmoid\n",
      "index : 700\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/mul\n",
      "index : 701\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0010273592779412866, -22)\n",
      "quantization_parameters : {'scales': array([0.00102736], dtype=float32), 'zero_points': array([-22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3;efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/Conv2D\n",
      "index : 702\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0025283743161708117, -2)\n",
      "quantization_parameters : {'scales': array([0.00252837], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/Sigmoid\n",
      "index : 703\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/mul\n",
      "index : 704\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0012694377219304442, -22)\n",
      "quantization_parameters : {'scales': array([0.00126944], dtype=float32), 'zero_points': array([-22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3;efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/Conv2D\n",
      "index : 705\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002187055768445134, -6)\n",
      "quantization_parameters : {'scales': array([0.00218706], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/Sigmoid\n",
      "index : 706\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/mul\n",
      "index : 707\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001107050571590662, -24)\n",
      "quantization_parameters : {'scales': array([0.00110705], dtype=float32), 'zero_points': array([-24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/Conv2D;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource\n",
      "index : 708\n",
      "shape : [ 1 64 64 36]\n",
      "shape_signature : [ 1 64 64 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape\n",
      "index : 709\n",
      "shape : [    1 36864     4]\n",
      "shape_signature : [    1 36864     4]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3;efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/Conv2D\n",
      "index : 710\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0018855134258046746, 23)\n",
      "quantization_parameters : {'scales': array([0.00188551], dtype=float32), 'zero_points': array([23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/Sigmoid\n",
      "index : 711\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/mul\n",
      "index : 712\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0009018175769597292, 7)\n",
      "quantization_parameters : {'scales': array([0.00090182], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3;efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/Conv2D\n",
      "index : 713\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002616085344925523, -18)\n",
      "quantization_parameters : {'scales': array([0.00261609], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/Sigmoid\n",
      "index : 714\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/mul\n",
      "index : 715\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013674786314368248, -38)\n",
      "quantization_parameters : {'scales': array([0.00136748], dtype=float32), 'zero_points': array([-38]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3;efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D\n",
      "index : 716\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002354071009904146, 1)\n",
      "quantization_parameters : {'scales': array([0.00235407], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/Sigmoid\n",
      "index : 717\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/mul\n",
      "index : 718\n",
      "shape : [ 1 64 64 64]\n",
      "shape_signature : [ 1 64 64 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011734403669834137, -18)\n",
      "quantization_parameters : {'scales': array([0.00117344], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/Conv2D;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource\n",
      "index : 719\n",
      "shape : [  1  64  64 180]\n",
      "shape_signature : [  1  64  64 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0012235038448125124, -6)\n",
      "quantization_parameters : {'scales': array([0.0012235], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid\n",
      "index : 720\n",
      "shape : [  1  64  64 180]\n",
      "shape_signature : [  1  64  64 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid1\n",
      "index : 721\n",
      "shape : [  1  64  64 180]\n",
      "shape_signature : [  1  64  64 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_1\n",
      "index : 722\n",
      "shape : [    1 36864    20]\n",
      "shape_signature : [    1 36864    20]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/mul_1\n",
      "index : 723\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.7219810615642928e-05, -2)\n",
      "quantization_parameters : {'scales': array([1.721981e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/Sum/input\n",
      "index : 724\n",
      "shape : [ 3  1 32 32 64]\n",
      "shape_signature : [ 3  1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.7219810615642928e-05, -2)\n",
      "quantization_parameters : {'scales': array([1.721981e-05], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/Sum\n",
      "index : 725\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.5626002752687782e-05, 11)\n",
      "quantization_parameters : {'scales': array([2.5626003e-05], dtype=float32), 'zero_points': array([11]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/separable_conv2d/depthwise1\n",
      "index : 726\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (7.733925485808868e-06, 2)\n",
      "quantization_parameters : {'scales': array([7.7339255e-06], dtype=float32), 'zero_points': array([2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/batch_normalization_66/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/separable_conv2d_12/separable_conv2d\n",
      "index : 727\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00010931567521765828, 19)\n",
      "quantization_parameters : {'scales': array([0.00010932], dtype=float32), 'zero_points': array([19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/Sigmoid\n",
      "index : 728\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_12/separable_conv_norm_act_12/mul\n",
      "index : 729\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.454369238577783e-05, 18)\n",
      "quantization_parameters : {'scales': array([5.4543692e-05], dtype=float32), 'zero_points': array([18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/max_pooling2d_5/MaxPool\n",
      "index : 730\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.454369238577783e-05, 18)\n",
      "quantization_parameters : {'scales': array([5.4543692e-05], dtype=float32), 'zero_points': array([18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/mul_2\n",
      "index : 731\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9239076209487393e-05, 24)\n",
      "quantization_parameters : {'scales': array([1.9239076e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_1;efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_1;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/Conv2D_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 732\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0020153415389358997, -4)\n",
      "quantization_parameters : {'scales': array([0.00201534], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/Sigmoid_1\n",
      "index : 733\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/mul_1\n",
      "index : 734\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0010142209939658642, -20)\n",
      "quantization_parameters : {'scales': array([0.00101422], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_1;efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_1;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/Conv2D_1\n",
      "index : 735\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002524773823097348, -2)\n",
      "quantization_parameters : {'scales': array([0.00252477], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/Sigmoid_1\n",
      "index : 736\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/mul_1\n",
      "index : 737\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0012685396941378713, -23)\n",
      "quantization_parameters : {'scales': array([0.00126854], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_1;efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_1;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/Conv2D_1\n",
      "index : 738\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002186460653319955, -6)\n",
      "quantization_parameters : {'scales': array([0.00218646], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/Sigmoid_1\n",
      "index : 739\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/mul_1\n",
      "index : 740\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011071814224123955, -24)\n",
      "quantization_parameters : {'scales': array([0.00110718], dtype=float32), 'zero_points': array([-24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_1;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/Conv2D_1;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource\n",
      "index : 741\n",
      "shape : [ 1 32 32 36]\n",
      "shape_signature : [ 1 32 32 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_2\n",
      "index : 742\n",
      "shape : [   1 9216    4]\n",
      "shape_signature : [   1 9216    4]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_1;efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_1;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/Conv2D_1\n",
      "index : 743\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0018898887792602181, 23)\n",
      "quantization_parameters : {'scales': array([0.00188989], dtype=float32), 'zero_points': array([23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/Sigmoid_1\n",
      "index : 744\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/mul_1\n",
      "index : 745\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0009037040290422738, 7)\n",
      "quantization_parameters : {'scales': array([0.0009037], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_1;efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_1;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/Conv2D_1\n",
      "index : 746\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002593778306618333, -19)\n",
      "quantization_parameters : {'scales': array([0.00259378], dtype=float32), 'zero_points': array([-19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/Sigmoid_1\n",
      "index : 747\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/mul_1\n",
      "index : 748\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013564518885686994, -38)\n",
      "quantization_parameters : {'scales': array([0.00135645], dtype=float32), 'zero_points': array([-38]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_1;efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_1;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_1\n",
      "index : 749\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0023504416458308697, 1)\n",
      "quantization_parameters : {'scales': array([0.00235044], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/Sigmoid_1\n",
      "index : 750\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/mul_1\n",
      "index : 751\n",
      "shape : [ 1 32 32 64]\n",
      "shape_signature : [ 1 32 32 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011711257975548506, -18)\n",
      "quantization_parameters : {'scales': array([0.00117113], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_1;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/Conv2D_1;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource\n",
      "index : 752\n",
      "shape : [  1  32  32 180]\n",
      "shape_signature : [  1  32  32 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001210729475133121, -6)\n",
      "quantization_parameters : {'scales': array([0.00121073], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_1\n",
      "index : 753\n",
      "shape : [  1  32  32 180]\n",
      "shape_signature : [  1  32  32 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_11\n",
      "index : 754\n",
      "shape : [  1  32  32 180]\n",
      "shape_signature : [  1  32  32 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_3\n",
      "index : 755\n",
      "shape : [   1 9216   20]\n",
      "shape_signature : [   1 9216   20]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/mul_1\n",
      "index : 756\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9239076209487393e-05, 24)\n",
      "quantization_parameters : {'scales': array([1.9239076e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/Sum/input\n",
      "index : 757\n",
      "shape : [ 3  1 16 16 64]\n",
      "shape_signature : [ 3  1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.9239076209487393e-05, 24)\n",
      "quantization_parameters : {'scales': array([1.9239076e-05], dtype=float32), 'zero_points': array([24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/Sum\n",
      "index : 758\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.909000431827735e-05, 4)\n",
      "quantization_parameters : {'scales': array([2.9090004e-05], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/separable_conv2d/depthwise1\n",
      "index : 759\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.297040378442034e-06, -20)\n",
      "quantization_parameters : {'scales': array([9.29704e-06], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/batch_normalization_67/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/separable_conv2d_13/separable_conv2d\n",
      "index : 760\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00013642404519487172, 19)\n",
      "quantization_parameters : {'scales': array([0.00013642], dtype=float32), 'zero_points': array([19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/Sigmoid\n",
      "index : 761\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_13/separable_conv_norm_act_13/mul\n",
      "index : 762\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.803413270972669e-05, 18)\n",
      "quantization_parameters : {'scales': array([6.803413e-05], dtype=float32), 'zero_points': array([18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/max_pooling2d_6/MaxPool\n",
      "index : 763\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (6.803413270972669e-05, 18)\n",
      "quantization_parameters : {'scales': array([6.803413e-05], dtype=float32), 'zero_points': array([18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/mul_2\n",
      "index : 764\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2531658032676205e-05, 17)\n",
      "quantization_parameters : {'scales': array([2.2531658e-05], dtype=float32), 'zero_points': array([17]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_2;efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_2;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/Conv2D_2\n",
      "index : 765\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0020318953320384026, -3)\n",
      "quantization_parameters : {'scales': array([0.0020319], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/Sigmoid_2\n",
      "index : 766\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/mul_2\n",
      "index : 767\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0010211622575297952, -19)\n",
      "quantization_parameters : {'scales': array([0.00102116], dtype=float32), 'zero_points': array([-19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_2;efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_2;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/Conv2D_2\n",
      "index : 768\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0025232823099941015, -2)\n",
      "quantization_parameters : {'scales': array([0.00252328], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/Sigmoid_2\n",
      "index : 769\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/mul_2\n",
      "index : 770\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0012657593470066786, -22)\n",
      "quantization_parameters : {'scales': array([0.00126576], dtype=float32), 'zero_points': array([-22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_2;efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_2;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/Conv2D_2\n",
      "index : 771\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002185498597100377, -7)\n",
      "quantization_parameters : {'scales': array([0.0021855], dtype=float32), 'zero_points': array([-7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/Sigmoid_2\n",
      "index : 772\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/mul_2\n",
      "index : 773\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011069271713495255, -24)\n",
      "quantization_parameters : {'scales': array([0.00110693], dtype=float32), 'zero_points': array([-24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_2;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/Conv2D_2;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource\n",
      "index : 774\n",
      "shape : [ 1 16 16 36]\n",
      "shape_signature : [ 1 16 16 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_4\n",
      "index : 775\n",
      "shape : [   1 2304    4]\n",
      "shape_signature : [   1 2304    4]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_2;efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_2;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/Conv2D_2\n",
      "index : 776\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0018654976738616824, 23)\n",
      "quantization_parameters : {'scales': array([0.0018655], dtype=float32), 'zero_points': array([23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/Sigmoid_2\n",
      "index : 777\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/mul_2\n",
      "index : 778\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0008928083698265254, 7)\n",
      "quantization_parameters : {'scales': array([0.00089281], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_2;efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_2;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/Conv2D_2\n",
      "index : 779\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0025977708864957094, -18)\n",
      "quantization_parameters : {'scales': array([0.00259777], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/Sigmoid_2\n",
      "index : 780\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/mul_2\n",
      "index : 781\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013584282714873552, -38)\n",
      "quantization_parameters : {'scales': array([0.00135843], dtype=float32), 'zero_points': array([-38]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_2;efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_2;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_2\n",
      "index : 782\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00235282676294446, 1)\n",
      "quantization_parameters : {'scales': array([0.00235283], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/Sigmoid_2\n",
      "index : 783\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/mul_2\n",
      "index : 784\n",
      "shape : [ 1 16 16 64]\n",
      "shape_signature : [ 1 16 16 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001172177609987557, -18)\n",
      "quantization_parameters : {'scales': array([0.00117218], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_2;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/Conv2D_2;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource\n",
      "index : 785\n",
      "shape : [  1  16  16 180]\n",
      "shape_signature : [  1  16  16 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0012198078911751509, -6)\n",
      "quantization_parameters : {'scales': array([0.00121981], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_2\n",
      "index : 786\n",
      "shape : [  1  16  16 180]\n",
      "shape_signature : [  1  16  16 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_21\n",
      "index : 787\n",
      "shape : [  1  16  16 180]\n",
      "shape_signature : [  1  16  16 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_5\n",
      "index : 788\n",
      "shape : [   1 2304   20]\n",
      "shape_signature : [   1 2304   20]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/mul_1\n",
      "index : 789\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2531658032676205e-05, 17)\n",
      "quantization_parameters : {'scales': array([2.2531658e-05], dtype=float32), 'zero_points': array([17]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/Sum/input\n",
      "index : 790\n",
      "shape : [ 3  1  8  8 64]\n",
      "shape_signature : [ 3  1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (2.2531658032676205e-05, 17)\n",
      "quantization_parameters : {'scales': array([2.2531658e-05], dtype=float32), 'zero_points': array([17]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/Sum\n",
      "index : 791\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (3.256979107391089e-05, -6)\n",
      "quantization_parameters : {'scales': array([3.256979e-05], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/separable_conv2d/depthwise1\n",
      "index : 792\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (8.440625606453978e-06, 9)\n",
      "quantization_parameters : {'scales': array([8.440626e-06], dtype=float32), 'zero_points': array([9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/batch_normalization_68/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/separable_conv2d_14/separable_conv2d\n",
      "index : 793\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00011198970605619252, -3)\n",
      "quantization_parameters : {'scales': array([0.00011199], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/Sigmoid\n",
      "index : 794\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_14/separable_conv_norm_act_14/mul\n",
      "index : 795\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.601151497103274e-05, -4)\n",
      "quantization_parameters : {'scales': array([5.6011515e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/max_pooling2d_7/MaxPool\n",
      "index : 796\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (5.601151497103274e-05, -4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantization_parameters : {'scales': array([5.6011515e-05], dtype=float32), 'zero_points': array([-4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/mul_1\n",
      "index : 797\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.0940329199656844e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.094033e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_3;efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_3;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/Conv2D_3\n",
      "index : 798\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0020227020140737295, -5)\n",
      "quantization_parameters : {'scales': array([0.0020227], dtype=float32), 'zero_points': array([-5]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/Sigmoid_3\n",
      "index : 799\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/mul_3\n",
      "index : 800\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001021353411488235, -22)\n",
      "quantization_parameters : {'scales': array([0.00102135], dtype=float32), 'zero_points': array([-22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_3;efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_3;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/Conv2D_3\n",
      "index : 801\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002520279958844185, -2)\n",
      "quantization_parameters : {'scales': array([0.00252028], dtype=float32), 'zero_points': array([-2]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/Sigmoid_3\n",
      "index : 802\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/mul_3\n",
      "index : 803\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001264830119907856, -22)\n",
      "quantization_parameters : {'scales': array([0.00126483], dtype=float32), 'zero_points': array([-22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_3;efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_3;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/Conv2D_3\n",
      "index : 804\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002182909520342946, -7)\n",
      "quantization_parameters : {'scales': array([0.00218291], dtype=float32), 'zero_points': array([-7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/Sigmoid_3\n",
      "index : 805\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/mul_3\n",
      "index : 806\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001105575356632471, -24)\n",
      "quantization_parameters : {'scales': array([0.00110558], dtype=float32), 'zero_points': array([-24]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_3;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/Conv2D_3;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource\n",
      "index : 807\n",
      "shape : [ 1  8  8 36]\n",
      "shape_signature : [ 1  8  8 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_6\n",
      "index : 808\n",
      "shape : [  1 576   4]\n",
      "shape_signature : [  1 576   4]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_3;efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_3;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/Conv2D_3\n",
      "index : 809\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0018920610891655087, 22)\n",
      "quantization_parameters : {'scales': array([0.00189206], dtype=float32), 'zero_points': array([22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/Sigmoid_3\n",
      "index : 810\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/mul_3\n",
      "index : 811\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0009063264005817473, 6)\n",
      "quantization_parameters : {'scales': array([0.00090633], dtype=float32), 'zero_points': array([6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_3;efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_3;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/Conv2D_3\n",
      "index : 812\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002609767485409975, -19)\n",
      "quantization_parameters : {'scales': array([0.00260977], dtype=float32), 'zero_points': array([-19]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/Sigmoid_3\n",
      "index : 813\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/mul_3\n",
      "index : 814\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013667599996551871, -39)\n",
      "quantization_parameters : {'scales': array([0.00136676], dtype=float32), 'zero_points': array([-39]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_3;efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_3;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_3\n",
      "index : 815\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0023394322488456964, 1)\n",
      "quantization_parameters : {'scales': array([0.00233943], dtype=float32), 'zero_points': array([1]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/Sigmoid_3\n",
      "index : 816\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/mul_3\n",
      "index : 817\n",
      "shape : [ 1  8  8 64]\n",
      "shape_signature : [ 1  8  8 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011650595115497708, -18)\n",
      "quantization_parameters : {'scales': array([0.00116506], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_3;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/Conv2D_3;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource\n",
      "index : 818\n",
      "shape : [  1   8   8 180]\n",
      "shape_signature : [  1   8   8 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0012208366533741355, -6)\n",
      "quantization_parameters : {'scales': array([0.00122084], dtype=float32), 'zero_points': array([-6]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_3\n",
      "index : 819\n",
      "shape : [  1   8   8 180]\n",
      "shape_signature : [  1   8   8 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_31\n",
      "index : 820\n",
      "shape : [  1   8   8 180]\n",
      "shape_signature : [  1   8   8 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_7\n",
      "index : 821\n",
      "shape : [  1 576  20]\n",
      "shape_signature : [  1 576  20]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/mul\n",
      "index : 822\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.0940329199656844e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.094033e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/Sum/input\n",
      "index : 823\n",
      "shape : [ 2  1  4  4 64]\n",
      "shape_signature : [ 2  1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.0940329199656844e-05, 0)\n",
      "quantization_parameters : {'scales': array([4.094033e-05], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/Sum\n",
      "index : 824\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (4.6639495849376544e-05, 3)\n",
      "quantization_parameters : {'scales': array([4.6639496e-05], dtype=float32), 'zero_points': array([3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/separable_conv2d/depthwise1\n",
      "index : 825\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (1.111873280024156e-05, 4)\n",
      "quantization_parameters : {'scales': array([1.1118733e-05], dtype=float32), 'zero_points': array([4]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/batch_normalization_69/FusedBatchNormV3;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/BiasAdd/ReadVariableOp/resource;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/BiasAdd;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/separable_conv2d_15/separable_conv2d\n",
      "index : 826\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0001858650502981618, -13)\n",
      "quantization_parameters : {'scales': array([0.00018587], dtype=float32), 'zero_points': array([-13]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/Sigmoid\n",
      "index : 827\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/bi_fpn/bi_fpn_module_1/weighted_feature_fusion_15/separable_conv_norm_act_15/mul\n",
      "index : 828\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (9.315506758866832e-05, -15)\n",
      "quantization_parameters : {'scales': array([9.315507e-05], dtype=float32), 'zero_points': array([-15]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/batch_normalization_70/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_5/conv2d_70/Conv2D_4\n",
      "index : 829\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0020559246186167, -3)\n",
      "quantization_parameters : {'scales': array([0.00205592], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/Sigmoid_4\n",
      "index : 830\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_5/mul_4\n",
      "index : 831\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0010332956444472075, -20)\n",
      "quantization_parameters : {'scales': array([0.0010333], dtype=float32), 'zero_points': array([-20]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/batch_normalization_72/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_7/conv2d_72/Conv2D_4\n",
      "index : 832\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002502074232324958, -3)\n",
      "quantization_parameters : {'scales': array([0.00250207], dtype=float32), 'zero_points': array([-3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/Sigmoid_4\n",
      "index : 833\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_7/mul_4\n",
      "index : 834\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001257839147001505, -23)\n",
      "quantization_parameters : {'scales': array([0.00125784], dtype=float32), 'zero_points': array([-23]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/batch_normalization_74/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_9/conv2d_74/Conv2D_4\n",
      "index : 835\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002144893864169717, -9)\n",
      "quantization_parameters : {'scales': array([0.00214489], dtype=float32), 'zero_points': array([-9]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/Sigmoid_4\n",
      "index : 836\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_9/mul_4\n",
      "index : 837\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001091778976842761, -26)\n",
      "quantization_parameters : {'scales': array([0.00109178], dtype=float32), 'zero_points': array([-26]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_76/BiasAdd_4;efficient_det/box_class_predict/conv2d_76/Conv2D_4;efficient_det/box_class_predict/conv2d_76/BiasAdd/ReadVariableOp/resource11\n",
      "index : 838\n",
      "shape : [ 1  4  4 36]\n",
      "shape_signature : [ 1  4  4 36]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_8\n",
      "index : 839\n",
      "shape : [  1 144   4]\n",
      "shape_signature : [  1 144   4]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/concat\n",
      "index : 840\n",
      "shape : [    1 49104     4]\n",
      "shape_signature : [    1 49104     4]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/batch_normalization_71/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_6/conv2d_71/Conv2D_4\n",
      "index : 841\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0018527460051700473, 22)\n",
      "quantization_parameters : {'scales': array([0.00185275], dtype=float32), 'zero_points': array([22]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/Sigmoid_4\n",
      "index : 842\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_6/mul_4\n",
      "index : 843\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0008879252709448338, 7)\n",
      "quantization_parameters : {'scales': array([0.00088793], dtype=float32), 'zero_points': array([7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/batch_normalization_73/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4;efficient_det/box_class_predict/conv_norm_act_8/conv2d_73/Conv2D_4\n",
      "index : 844\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0025991229340434074, -18)\n",
      "quantization_parameters : {'scales': array([0.00259912], dtype=float32), 'zero_points': array([-18]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/Sigmoid_4\n",
      "index : 845\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_8/mul_4\n",
      "index : 846\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0013576503843069077, -38)\n",
      "quantization_parameters : {'scales': array([0.00135765], dtype=float32), 'zero_points': array([-38]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/batch_normalization_75/FusedBatchNormV3_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd/ReadVariableOp/resource;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/BiasAdd_4;efficient_det/box_class_predict/conv_norm_act_10/conv2d_75/Conv2D_4\n",
      "index : 847\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.002304814523085952, 3)\n",
      "quantization_parameters : {'scales': array([0.00230481], dtype=float32), 'zero_points': array([3]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/Sigmoid_4\n",
      "index : 848\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv_norm_act_10/mul_4\n",
      "index : 849\n",
      "shape : [ 1  4  4 64]\n",
      "shape_signature : [ 1  4  4 64]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.0011441983515396714, -16)\n",
      "quantization_parameters : {'scales': array([0.0011442], dtype=float32), 'zero_points': array([-16]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/conv2d_77/BiasAdd_4;efficient_det/box_class_predict/conv2d_77/Conv2D_4;efficient_det/box_class_predict/conv2d_77/BiasAdd/ReadVariableOp/resource11\n",
      "index : 850\n",
      "shape : [  1   4   4 180]\n",
      "shape_signature : [  1   4   4 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.001052012899890542, -7)\n",
      "quantization_parameters : {'scales': array([0.00105201], dtype=float32), 'zero_points': array([-7]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_4\n",
      "index : 851\n",
      "shape : [  1   4   4 180]\n",
      "shape_signature : [  1   4   4 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.00390625, -128)\n",
      "quantization_parameters : {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Sigmoid_41\n",
      "index : 852\n",
      "shape : [  1   4   4 180]\n",
      "shape_signature : [  1   4   4 180]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/Reshape_9\n",
      "index : 853\n",
      "shape : [  1 144  20]\n",
      "shape_signature : [  1 144  20]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : efficient_det/box_class_predict/concat_1\n",
      "index : 854\n",
      "shape : [    1 49104    20]\n",
      "shape_signature : [    1 49104    20]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : Identity1\n",
      "index : 855\n",
      "shape : [    1 49104    24]\n",
      "shape_signature : [    1 49104    24]\n",
      "dtype : <class 'numpy.int8'>\n",
      "quantization : (0.003044168232008815, -51)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([-51]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n",
      "name : Identity\n",
      "index : 856\n",
      "shape : [    1 49104    24]\n",
      "shape_signature : [    1 49104    24]\n",
      "dtype : <class 'numpy.uint8'>\n",
      "quantization : (0.003044168232008815, 77)\n",
      "quantization_parameters : {'scales': array([0.00304417], dtype=float32), 'zero_points': array([77]), 'quantized_dimension': 0}\n",
      "sparsity_parameters : {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "for item in interpreter.get_tensor_details():\n",
    "    for key in item.keys():\n",
    "        print(\"%s : %s\" % (key, item[key]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c71473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tflite_model_quant.tflite', 'wb') as f:\n",
    "  f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138c246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'input_1', 'index': 0, 'shape': array([  1, 512, 512,   3]), 'shape_signature': array([  1, 512, 512,   3]), 'dtype': <class 'numpy.uint8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'Identity', 'index': 856, 'shape': array([    1, 49104,    24]), 'shape_signature': array([    1, 49104,    24]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003044168232008815, 77), 'quantization_parameters': {'scales': array([0.00304417], dtype=float32), 'zero_points': array([77]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1029241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/yutan/Desktop/EfficientDet_TensorFlow2/tflite_model_quant.tflite\"\n",
    "\n",
    "def load_model(path):  \n",
    "    interpreter = tf.lite.Interpreter(model_path = path)\n",
    "    return interpreter\n",
    "\n",
    "def data_pre(data):\n",
    "    \n",
    "    return\n",
    "\n",
    "def prediction(model, data):\n",
    "    interpreter = model\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_data = np.array(data, dtype = np.uint8)\n",
    "\n",
    "    interpreter.set_tensor(input_details['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data_class= interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data_bb= interpreter.get_tensor(output_details[1]['index'])\n",
    "\n",
    "    return output_data_class, output_data_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72b6af86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_list = tf.data.Dataset.list_files('./data/datasets/JPEGImages'+'\\\\*')\n",
    "image = next(iter(dataset_list))\n",
    "image = tf.io.read_file(image)\n",
    "image = tf.io.decode_jpeg(image, channels=3)\n",
    "image = tf.image.resize(image, (512,512))\n",
    "# image = tf.cast(image / 255., tf.float32)\n",
    "image = tf.expand_dims(image, 0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33bbb5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'input_1', 'index': 0, 'shape': array([  1, 512, 512,   3]), 'shape_signature': array([  1, 512, 512,   3]), 'dtype': <class 'numpy.uint8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "[{'name': 'Identity', 'index': 856, 'shape': array([    1, 49104,    24]), 'shape_signature': array([    1, 49104,    24]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.003044168232008815, 77), 'quantization_parameters': {'scales': array([0.00304417], dtype=float32), 'zero_points': array([77]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1912/1281637009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1912/1735716106.py\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0moutput_data_class\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0moutput_data_bb\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput_data_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data_bb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "classification, regression = prediction(model, image)\n",
    "\n",
    "print(classification.shape)\n",
    "print(regression[0][1])\n",
    "\n",
    "classification =  np.array(classification, dtype=np.float32)\n",
    "regression =  np.array(regression, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44345e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
