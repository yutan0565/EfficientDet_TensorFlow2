{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e32e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 25 16:03:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 22%   36C    P0    37W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29e7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Model: \"efficient_det_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficient_net_1 (EfficientNe multiple                  6771296   \n",
      "_________________________________________________________________\n",
      "bi_fpn_1 (BiFPN)             multiple                  129126    \n",
      "_________________________________________________________________\n",
      "box_class_predict_1 (BoxClas multiple                  249069    \n",
      "=================================================================\n",
      "Total params: 7,149,491\n",
      "Trainable params: 7,106,515\n",
      "Non-trainable params: 42,976\n",
      "_________________________________________________________________\n",
      "Epoch: 0/1000 시작 \n",
      "step: 0/516.0, loss: 235.60594177246094\n",
      "step: 100/516.0, loss: 558.5202026367188\n",
      "step: 200/516.0, loss: 390.23101806640625\n",
      "step: 300/516.0, loss: 292.7613220214844\n",
      "step: 400/516.0, loss: 229.98341369628906\n",
      "step: 500/516.0, loss: 189.39724731445312\n",
      "step: 0/516.0, val_loss: 11.075238227844238\n",
      "step: 100/516.0, val_loss: 24.787328720092773\n",
      "Epoch: 1/1000 시작 \n",
      "step: 0/516.0, loss: 6.207335948944092\n",
      "step: 100/516.0, loss: 21.063819885253906\n",
      "step: 200/516.0, loss: 20.188371658325195\n",
      "step: 300/516.0, loss: 18.529003143310547\n",
      "step: 400/516.0, loss: 16.252635955810547\n",
      "step: 500/516.0, loss: 14.50162124633789\n",
      "step: 0/516.0, val_loss: 4.42600154876709\n",
      "step: 100/516.0, val_loss: 9.38411808013916\n",
      "Epoch: 2/1000 시작 \n",
      "step: 0/516.0, loss: 2.7064967155456543\n",
      "step: 100/516.0, loss: 7.0242533683776855\n",
      "step: 200/516.0, loss: 7.114639759063721\n",
      "step: 300/516.0, loss: 6.873844146728516\n",
      "step: 400/516.0, loss: 6.297776699066162\n",
      "step: 500/516.0, loss: 5.82537841796875\n",
      "step: 0/516.0, val_loss: 3.055973529815674\n",
      "step: 100/516.0, val_loss: 5.6017632484436035\n",
      "Epoch: 3/1000 시작 \n",
      "step: 0/516.0, loss: 1.9857072830200195\n",
      "step: 100/516.0, loss: 3.8733818531036377\n",
      "step: 200/516.0, loss: 3.972715139389038\n",
      "step: 300/516.0, loss: 3.9126484394073486\n",
      "step: 400/516.0, loss: 3.676635980606079\n",
      "step: 500/516.0, loss: 3.476365327835083\n",
      "step: 0/516.0, val_loss: 2.5733399391174316\n",
      "step: 100/516.0, val_loss: 4.239902496337891\n",
      "Epoch: 4/1000 시작 \n",
      "step: 0/516.0, loss: 1.695497751235962\n",
      "step: 100/516.0, loss: 2.6669740676879883\n",
      "step: 200/516.0, loss: 2.736193895339966\n",
      "step: 300/516.0, loss: 2.7177324295043945\n",
      "step: 400/516.0, loss: 2.598924398422241\n",
      "step: 500/516.0, loss: 2.4942874908447266\n",
      "step: 0/516.0, val_loss: 2.3539369106292725\n",
      "step: 100/516.0, val_loss: 3.653754711151123\n",
      "Epoch: 5/1000 시작 \n",
      "step: 0/516.0, loss: 1.498817801475525\n",
      "step: 100/516.0, loss: 2.0645928382873535\n",
      "step: 200/516.0, loss: 2.1108672618865967\n",
      "step: 300/516.0, loss: 2.10715389251709\n",
      "step: 400/516.0, loss: 2.036728620529175\n",
      "step: 500/516.0, loss: 1.9725617170333862\n",
      "step: 0/516.0, val_loss: 2.2758030891418457\n",
      "step: 100/516.0, val_loss: 3.315551519393921\n",
      "Epoch: 6/1000 시작 \n",
      "step: 0/516.0, loss: 1.4028538465499878\n",
      "step: 100/516.0, loss: 1.712591290473938\n",
      "step: 200/516.0, loss: 1.7375383377075195\n",
      "step: 300/516.0, loss: 1.7331922054290771\n",
      "step: 400/516.0, loss: 1.683356761932373\n",
      "step: 500/516.0, loss: 1.642918348312378\n",
      "step: 0/516.0, val_loss: 2.4057414531707764\n",
      "step: 100/516.0, val_loss: 3.2850942611694336\n",
      "Epoch: 7/1000 시작 \n",
      "step: 0/516.0, loss: 1.2993862628936768\n",
      "step: 100/516.0, loss: 1.4604897499084473\n",
      "step: 200/516.0, loss: 1.4740599393844604\n",
      "step: 300/516.0, loss: 1.4731217622756958\n",
      "step: 400/516.0, loss: 1.438904881477356\n",
      "step: 500/516.0, loss: 1.4119210243225098\n",
      "step: 0/516.0, val_loss: 2.581235647201538\n",
      "step: 100/516.0, val_loss: 3.144214630126953\n",
      "Epoch: 8/1000 시작 \n",
      "step: 0/516.0, loss: 1.1826984882354736\n",
      "step: 100/516.0, loss: 1.2575843334197998\n",
      "step: 200/516.0, loss: 1.2700146436691284\n",
      "step: 300/516.0, loss: 1.2731132507324219\n",
      "step: 400/516.0, loss: 1.251413345336914\n",
      "step: 500/516.0, loss: 1.2288939952850342\n",
      "step: 0/516.0, val_loss: 2.3873353004455566\n",
      "step: 100/516.0, val_loss: 2.6765975952148438\n",
      "Epoch: 9/1000 시작 \n",
      "step: 0/516.0, loss: 1.2005728483200073\n",
      "step: 100/516.0, loss: 1.1515352725982666\n",
      "step: 200/516.0, loss: 1.1393247842788696\n",
      "step: 300/516.0, loss: 1.1388200521469116\n",
      "step: 400/516.0, loss: 1.1250897645950317\n",
      "step: 500/516.0, loss: 1.1124415397644043\n",
      "step: 0/516.0, val_loss: 2.7595858573913574\n",
      "step: 100/516.0, val_loss: 2.8571066856384277\n",
      "Epoch: 10/1000 시작 \n",
      "step: 0/516.0, loss: 0.8797483444213867\n",
      "step: 100/516.0, loss: 1.0053545236587524\n",
      "step: 200/516.0, loss: 1.0233968496322632\n",
      "step: 300/516.0, loss: 1.0226901769638062\n",
      "step: 400/516.0, loss: 1.0165456533432007\n",
      "step: 500/516.0, loss: 1.00748872756958\n",
      "step: 0/516.0, val_loss: 2.2156624794006348\n",
      "step: 100/516.0, val_loss: 2.1915433406829834\n",
      "Epoch: 11/1000 시작 \n",
      "step: 0/516.0, loss: 0.8444734811782837\n",
      "step: 100/516.0, loss: 0.9327957630157471\n",
      "step: 200/516.0, loss: 0.9359279870986938\n",
      "step: 300/516.0, loss: 0.9372482299804688\n",
      "step: 400/516.0, loss: 0.9412156939506531\n",
      "step: 500/516.0, loss: 0.9382185339927673\n",
      "step: 0/516.0, val_loss: 2.4926815032958984\n",
      "step: 100/516.0, val_loss: 2.5091452598571777\n",
      "Epoch: 12/1000 시작 \n",
      "step: 0/516.0, loss: 0.7851561903953552\n",
      "step: 100/516.0, loss: 0.8965781927108765\n",
      "step: 200/516.0, loss: 0.8983685970306396\n",
      "step: 300/516.0, loss: 0.893592894077301\n",
      "step: 400/516.0, loss: 0.8862299919128418\n",
      "step: 500/516.0, loss: 0.883622407913208\n",
      "step: 0/516.0, val_loss: 1.9359945058822632\n",
      "step: 100/516.0, val_loss: 2.0544352531433105\n",
      "Epoch: 13/1000 시작 \n",
      "step: 0/516.0, loss: 0.8012760877609253\n",
      "step: 100/516.0, loss: 0.8316243886947632\n",
      "step: 200/516.0, loss: 0.8420488834381104\n",
      "step: 300/516.0, loss: 0.8383451700210571\n",
      "step: 400/516.0, loss: 0.8307244181632996\n",
      "step: 500/516.0, loss: 0.8250970840454102\n",
      "step: 0/516.0, val_loss: 2.0885932445526123\n",
      "step: 100/516.0, val_loss: 2.0575315952301025\n",
      "Epoch: 14/1000 시작 \n",
      "step: 0/516.0, loss: 0.7894381284713745\n",
      "step: 100/516.0, loss: 0.7930366396903992\n",
      "step: 200/516.0, loss: 0.7861565947532654\n",
      "step: 300/516.0, loss: 0.7847385406494141\n",
      "step: 400/516.0, loss: 0.7771306037902832\n",
      "step: 500/516.0, loss: 0.7769340872764587\n",
      "step: 0/516.0, val_loss: 2.030932903289795\n",
      "step: 100/516.0, val_loss: 2.0032052993774414\n",
      "Epoch: 15/1000 시작 \n",
      "step: 0/516.0, loss: 0.7078118324279785\n",
      "step: 100/516.0, loss: 0.7417494654655457\n",
      "step: 200/516.0, loss: 0.7533226013183594\n",
      "step: 300/516.0, loss: 0.7505550980567932\n",
      "step: 400/516.0, loss: 0.7517882585525513\n",
      "step: 500/516.0, loss: 0.7499315142631531\n",
      "step: 0/516.0, val_loss: 1.956709623336792\n",
      "step: 100/516.0, val_loss: 1.978925347328186\n",
      "Epoch: 16/1000 시작 \n",
      "step: 0/516.0, loss: 0.7213823199272156\n",
      "step: 100/516.0, loss: 0.7283596396446228\n",
      "step: 200/516.0, loss: 0.7357701659202576\n",
      "step: 300/516.0, loss: 0.7321677207946777\n",
      "step: 400/516.0, loss: 0.7363808155059814\n",
      "step: 500/516.0, loss: 0.7323940992355347\n",
      "step: 0/516.0, val_loss: 2.1688127517700195\n",
      "step: 100/516.0, val_loss: 1.9027646780014038\n",
      "Epoch: 17/1000 시작 \n",
      "step: 0/516.0, loss: 0.6076549887657166\n",
      "step: 100/516.0, loss: 0.6895145177841187\n",
      "step: 200/516.0, loss: 0.6953413486480713\n",
      "step: 300/516.0, loss: 0.6941159963607788\n",
      "step: 400/516.0, loss: 0.6935672760009766\n",
      "step: 500/516.0, loss: 0.6886604428291321\n",
      "step: 0/516.0, val_loss: 1.505516529083252\n",
      "step: 100/516.0, val_loss: 1.9869260787963867\n",
      "Epoch: 18/1000 시작 \n",
      "step: 0/516.0, loss: 0.7539713382720947\n",
      "step: 100/516.0, loss: 0.6665121912956238\n",
      "step: 200/516.0, loss: 0.6771398782730103\n",
      "step: 300/516.0, loss: 0.6812685132026672\n",
      "step: 400/516.0, loss: 0.67384272813797\n",
      "step: 500/516.0, loss: 0.6741570234298706\n",
      "step: 0/516.0, val_loss: 1.5790200233459473\n",
      "step: 100/516.0, val_loss: 1.8018765449523926\n",
      "Epoch: 19/1000 시작 \n",
      "step: 0/516.0, loss: 0.6494370102882385\n",
      "step: 100/516.0, loss: 0.6385517120361328\n",
      "step: 200/516.0, loss: 0.6461176872253418\n",
      "step: 300/516.0, loss: 0.6388583779335022\n",
      "step: 400/516.0, loss: 0.6412908434867859\n",
      "step: 500/516.0, loss: 0.645996630191803\n",
      "step: 0/516.0, val_loss: 1.6740467548370361\n",
      "step: 100/516.0, val_loss: 1.7583248615264893\n",
      "Epoch: 20/1000 시작 \n",
      "step: 0/516.0, loss: 0.48282530903816223\n",
      "step: 100/516.0, loss: 0.619276225566864\n",
      "step: 200/516.0, loss: 0.6385148763656616\n",
      "step: 300/516.0, loss: 0.6373816728591919\n",
      "step: 400/516.0, loss: 0.6331669688224792\n",
      "step: 500/516.0, loss: 0.6303633451461792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0/516.0, val_loss: 1.6840198040008545\n",
      "step: 100/516.0, val_loss: 1.7183399200439453\n",
      "Epoch: 21/1000 시작 \n",
      "step: 0/516.0, loss: 0.6333618760108948\n",
      "step: 100/516.0, loss: 0.5964115262031555\n",
      "step: 200/516.0, loss: 0.6239574551582336\n",
      "step: 300/516.0, loss: 0.6194629073143005\n",
      "step: 400/516.0, loss: 0.6181637048721313\n",
      "step: 500/516.0, loss: 0.6130026578903198\n",
      "step: 0/516.0, val_loss: 1.9419527053833008\n",
      "step: 100/516.0, val_loss: 1.879021167755127\n",
      "Epoch: 22/1000 시작 \n",
      "step: 0/516.0, loss: 0.600379228591919\n",
      "step: 100/516.0, loss: 0.5918190479278564\n",
      "step: 200/516.0, loss: 0.5961025357246399\n",
      "step: 300/516.0, loss: 0.5920231342315674\n",
      "step: 400/516.0, loss: 0.590379536151886\n",
      "step: 500/516.0, loss: 0.5884073376655579\n",
      "step: 0/516.0, val_loss: 2.021570920944214\n",
      "step: 100/516.0, val_loss: 1.7761867046356201\n",
      "Epoch: 23/1000 시작 \n",
      "step: 0/516.0, loss: 0.6106200814247131\n",
      "step: 100/516.0, loss: 0.5792917013168335\n",
      "step: 200/516.0, loss: 0.5934498906135559\n",
      "step: 300/516.0, loss: 0.5865333080291748\n",
      "step: 400/516.0, loss: 0.5815951228141785\n",
      "step: 500/516.0, loss: 0.5761321187019348\n",
      "step: 0/516.0, val_loss: 1.881588101387024\n",
      "step: 100/516.0, val_loss: 1.7571418285369873\n",
      "Epoch: 24/1000 시작 \n",
      "step: 0/516.0, loss: 0.47391101717948914\n",
      "step: 100/516.0, loss: 0.552781343460083\n",
      "step: 200/516.0, loss: 0.5513057708740234\n",
      "step: 300/516.0, loss: 0.5530835390090942\n",
      "step: 400/516.0, loss: 0.5487065315246582\n",
      "step: 500/516.0, loss: 0.5465064644813538\n",
      "step: 0/516.0, val_loss: 1.9436163902282715\n",
      "step: 100/516.0, val_loss: 1.6698176860809326\n",
      "Epoch: 25/1000 시작 \n",
      "step: 0/516.0, loss: 0.47427353262901306\n",
      "step: 100/516.0, loss: 0.514468252658844\n",
      "step: 200/516.0, loss: 0.520912230014801\n",
      "step: 300/516.0, loss: 0.5264955163002014\n",
      "step: 400/516.0, loss: 0.5232418775558472\n",
      "step: 500/516.0, loss: 0.5226871967315674\n",
      "step: 0/516.0, val_loss: 1.8501043319702148\n",
      "step: 100/516.0, val_loss: 1.7013205289840698\n",
      "Epoch: 26/1000 시작 \n",
      "step: 0/516.0, loss: 0.505733072757721\n",
      "step: 100/516.0, loss: 0.504664421081543\n",
      "step: 200/516.0, loss: 0.516331672668457\n",
      "step: 300/516.0, loss: 0.5171788334846497\n",
      "step: 400/516.0, loss: 0.5111374855041504\n",
      "step: 500/516.0, loss: 0.5115702748298645\n",
      "step: 0/516.0, val_loss: 1.705436110496521\n",
      "step: 100/516.0, val_loss: 1.5429415702819824\n",
      "Epoch: 27/1000 시작 \n",
      "step: 0/516.0, loss: 0.37533077597618103\n",
      "step: 100/516.0, loss: 0.4964215159416199\n",
      "step: 200/516.0, loss: 0.5127713680267334\n",
      "step: 300/516.0, loss: 0.5128887891769409\n",
      "step: 400/516.0, loss: 0.5020023584365845\n",
      "step: 500/516.0, loss: 0.498319536447525\n",
      "step: 0/516.0, val_loss: 2.190131902694702\n",
      "step: 100/516.0, val_loss: 1.6548269987106323\n",
      "Epoch: 28/1000 시작 \n",
      "step: 0/516.0, loss: 0.43973058462142944\n",
      "step: 100/516.0, loss: 0.47360143065452576\n",
      "step: 200/516.0, loss: 0.48701050877571106\n",
      "step: 300/516.0, loss: 0.4876490533351898\n",
      "step: 400/516.0, loss: 0.47785401344299316\n",
      "step: 500/516.0, loss: 0.4757489860057831\n",
      "step: 0/516.0, val_loss: 2.5484189987182617\n",
      "step: 100/516.0, val_loss: 1.7555642127990723\n",
      "Epoch: 29/1000 시작 \n",
      "step: 0/516.0, loss: 0.35673215985298157\n",
      "step: 100/516.0, loss: 0.4616297781467438\n",
      "step: 200/516.0, loss: 0.46731701493263245\n",
      "step: 300/516.0, loss: 0.4678609371185303\n",
      "step: 400/516.0, loss: 0.46186721324920654\n",
      "step: 500/516.0, loss: 0.45908865332603455\n",
      "step: 0/516.0, val_loss: 2.048255681991577\n",
      "step: 100/516.0, val_loss: 1.5901250839233398\n",
      "Epoch: 30/1000 시작 \n",
      "step: 0/516.0, loss: 0.3656579554080963\n",
      "step: 100/516.0, loss: 0.44317203760147095\n",
      "step: 200/516.0, loss: 0.4502413868904114\n",
      "step: 300/516.0, loss: 0.46060600876808167\n",
      "step: 400/516.0, loss: 0.4509376287460327\n",
      "step: 500/516.0, loss: 0.4486036002635956\n",
      "step: 0/516.0, val_loss: 2.147184371948242\n",
      "step: 100/516.0, val_loss: 1.7089815139770508\n",
      "Epoch: 31/1000 시작 \n",
      "step: 0/516.0, loss: 0.29218247532844543\n",
      "step: 100/516.0, loss: 0.42117956280708313\n",
      "step: 200/516.0, loss: 0.4301055669784546\n",
      "step: 300/516.0, loss: 0.43220028281211853\n",
      "step: 400/516.0, loss: 0.42940253019332886\n",
      "step: 500/516.0, loss: 0.4269917607307434\n",
      "step: 0/516.0, val_loss: 2.0418052673339844\n",
      "step: 100/516.0, val_loss: 1.5950939655303955\n",
      "Epoch: 32/1000 시작 \n",
      "step: 0/516.0, loss: 0.3376791477203369\n",
      "step: 100/516.0, loss: 0.44243335723876953\n",
      "step: 200/516.0, loss: 0.433307409286499\n",
      "step: 300/516.0, loss: 0.4364299476146698\n",
      "step: 400/516.0, loss: 0.4256012737751007\n",
      "step: 500/516.0, loss: 0.4226211905479431\n",
      "step: 0/516.0, val_loss: 1.9971715211868286\n",
      "step: 100/516.0, val_loss: 1.6775727272033691\n",
      "Epoch: 33/1000 시작 \n",
      "step: 0/516.0, loss: 0.3627271056175232\n",
      "step: 100/516.0, loss: 0.3905181884765625\n",
      "step: 200/516.0, loss: 0.404217004776001\n",
      "step: 300/516.0, loss: 0.42604485154151917\n",
      "step: 400/516.0, loss: 0.4165102243423462\n",
      "step: 500/516.0, loss: 0.4210793673992157\n",
      "step: 0/516.0, val_loss: 1.8108792304992676\n",
      "step: 100/516.0, val_loss: 1.54257071018219\n",
      "Epoch: 34/1000 시작 \n",
      "step: 0/516.0, loss: 0.3280488848686218\n",
      "step: 100/516.0, loss: 0.392691433429718\n",
      "step: 200/516.0, loss: 0.39628368616104126\n",
      "step: 300/516.0, loss: 0.40776342153549194\n",
      "step: 400/516.0, loss: 0.40345266461372375\n",
      "step: 500/516.0, loss: 0.3999864161014557\n",
      "step: 0/516.0, val_loss: 1.7079116106033325\n",
      "step: 100/516.0, val_loss: 1.5524559020996094\n",
      "Epoch: 35/1000 시작 \n",
      "step: 0/516.0, loss: 0.41644835472106934\n",
      "step: 100/516.0, loss: 0.3955349326133728\n",
      "step: 200/516.0, loss: 0.39385128021240234\n",
      "step: 300/516.0, loss: 0.39478039741516113\n",
      "step: 400/516.0, loss: 0.3887125253677368\n",
      "step: 500/516.0, loss: 0.38495221734046936\n",
      "step: 0/516.0, val_loss: 1.9232676029205322\n",
      "step: 100/516.0, val_loss: 1.5616058111190796\n",
      "Epoch: 36/1000 시작 \n",
      "step: 0/516.0, loss: 0.27916181087493896\n",
      "step: 100/516.0, loss: 0.373772531747818\n",
      "step: 200/516.0, loss: 0.3746493458747864\n",
      "step: 300/516.0, loss: 0.38529789447784424\n",
      "step: 400/516.0, loss: 0.3766575753688812\n",
      "step: 500/516.0, loss: 0.3763044774532318\n",
      "step: 0/516.0, val_loss: 2.2050342559814453\n",
      "step: 100/516.0, val_loss: 1.5882511138916016\n",
      "Epoch: 37/1000 시작 \n",
      "step: 0/516.0, loss: 0.29165107011795044\n",
      "step: 100/516.0, loss: 0.3728947639465332\n",
      "step: 200/516.0, loss: 0.3731408715248108\n",
      "step: 300/516.0, loss: 0.375940203666687\n",
      "step: 400/516.0, loss: 0.36711585521698\n",
      "step: 500/516.0, loss: 0.36583206057548523\n",
      "step: 0/516.0, val_loss: 1.9663374423980713\n",
      "step: 100/516.0, val_loss: 1.6025102138519287\n",
      "Epoch: 38/1000 시작 \n",
      "step: 0/516.0, loss: 0.2328617125749588\n",
      "step: 100/516.0, loss: 0.3541161119937897\n",
      "step: 200/516.0, loss: 0.3524132966995239\n",
      "step: 300/516.0, loss: 0.34818679094314575\n",
      "step: 400/516.0, loss: 0.34577736258506775\n",
      "step: 500/516.0, loss: 0.34407705068588257\n",
      "step: 0/516.0, val_loss: 1.5918841361999512\n",
      "step: 100/516.0, val_loss: 1.6140810251235962\n",
      "Epoch: 39/1000 시작 \n",
      "step: 0/516.0, loss: 0.2817206084728241\n",
      "step: 100/516.0, loss: 0.3263355791568756\n",
      "step: 200/516.0, loss: 0.33566632866859436\n",
      "step: 300/516.0, loss: 0.34200000762939453\n",
      "step: 400/516.0, loss: 0.33734214305877686\n",
      "step: 500/516.0, loss: 0.3364747166633606\n",
      "step: 0/516.0, val_loss: 1.2298909425735474\n",
      "step: 100/516.0, val_loss: 1.5755201578140259\n",
      "Epoch: 40/1000 시작 \n",
      "step: 0/516.0, loss: 0.27947795391082764\n",
      "step: 100/516.0, loss: 0.349658727645874\n",
      "step: 200/516.0, loss: 0.3386227488517761\n",
      "step: 300/516.0, loss: 0.335174024105072\n",
      "step: 400/516.0, loss: 0.3331882655620575\n",
      "step: 500/516.0, loss: 0.3341580033302307\n",
      "step: 0/516.0, val_loss: 1.6143453121185303\n",
      "step: 100/516.0, val_loss: 1.6117044687271118\n",
      "Epoch: 41/1000 시작 \n",
      "step: 0/516.0, loss: 0.20567001402378082\n",
      "step: 100/516.0, loss: 0.3265255391597748\n",
      "step: 200/516.0, loss: 0.3304799795150757\n",
      "step: 300/516.0, loss: 0.3277081847190857\n",
      "step: 400/516.0, loss: 0.32392609119415283\n",
      "step: 500/516.0, loss: 0.32933199405670166\n",
      "step: 0/516.0, val_loss: 1.3810930252075195\n",
      "step: 100/516.0, val_loss: 1.6662077903747559\n",
      "Epoch: 42/1000 시작 \n",
      "step: 0/516.0, loss: 0.30887019634246826\n",
      "step: 100/516.0, loss: 0.3240947127342224\n",
      "step: 200/516.0, loss: 0.3240738809108734\n",
      "step: 300/516.0, loss: 0.320939302444458\n",
      "step: 400/516.0, loss: 0.3151704668998718\n",
      "step: 500/516.0, loss: 0.31657665967941284\n",
      "step: 0/516.0, val_loss: 1.3478469848632812\n",
      "step: 100/516.0, val_loss: 1.6113972663879395\n",
      "Epoch: 43/1000 시작 \n",
      "step: 0/516.0, loss: 0.2336294949054718\n",
      "step: 100/516.0, loss: 0.30359986424446106\n",
      "step: 200/516.0, loss: 0.29981327056884766\n",
      "step: 300/516.0, loss: 0.3187721073627472\n",
      "step: 400/516.0, loss: 0.31426599621772766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500/516.0, loss: 0.31733110547065735\n",
      "step: 0/516.0, val_loss: 1.5212504863739014\n",
      "step: 100/516.0, val_loss: 1.565592646598816\n",
      "Epoch: 44/1000 시작 \n",
      "step: 0/516.0, loss: 0.27073654532432556\n",
      "step: 100/516.0, loss: 0.29951581358909607\n",
      "step: 200/516.0, loss: 0.2947394847869873\n",
      "step: 300/516.0, loss: 0.298453688621521\n",
      "step: 400/516.0, loss: 0.29369238018989563\n",
      "step: 500/516.0, loss: 0.29423290491104126\n",
      "step: 0/516.0, val_loss: 1.6144754886627197\n",
      "step: 100/516.0, val_loss: 1.7252339124679565\n",
      "Epoch: 45/1000 시작 \n",
      "step: 0/516.0, loss: 0.21769100427627563\n",
      "step: 100/516.0, loss: 0.2976454496383667\n",
      "step: 200/516.0, loss: 0.29797840118408203\n",
      "step: 300/516.0, loss: 0.29302355647087097\n",
      "step: 400/516.0, loss: 0.28767797350883484\n",
      "step: 500/516.0, loss: 0.2907107472419739\n",
      "step: 0/516.0, val_loss: 1.1022430658340454\n",
      "step: 100/516.0, val_loss: 1.5466742515563965\n",
      "Epoch: 46/1000 시작 \n",
      "step: 0/516.0, loss: 0.16875751316547394\n",
      "step: 100/516.0, loss: 0.2911444306373596\n",
      "step: 200/516.0, loss: 0.2927999794483185\n",
      "step: 300/516.0, loss: 0.2880626320838928\n",
      "step: 400/516.0, loss: 0.2879154682159424\n",
      "step: 500/516.0, loss: 0.29209524393081665\n",
      "step: 0/516.0, val_loss: 1.7615408897399902\n",
      "step: 100/516.0, val_loss: 1.6188315153121948\n",
      "Epoch: 47/1000 시작 \n",
      "step: 0/516.0, loss: 0.5966641902923584\n",
      "step: 100/516.0, loss: 0.2678202688694\n",
      "step: 200/516.0, loss: 0.28146255016326904\n",
      "step: 300/516.0, loss: 0.2835226356983185\n",
      "step: 400/516.0, loss: 0.28599825501441956\n",
      "step: 500/516.0, loss: 0.2834808826446533\n",
      "step: 0/516.0, val_loss: 1.3964476585388184\n",
      "step: 100/516.0, val_loss: 1.5485830307006836\n",
      "Epoch: 48/1000 시작 \n",
      "step: 0/516.0, loss: 0.25810790061950684\n",
      "step: 100/516.0, loss: 0.28076112270355225\n",
      "step: 200/516.0, loss: 0.2849609851837158\n",
      "step: 300/516.0, loss: 0.28561484813690186\n",
      "step: 400/516.0, loss: 0.28131458163261414\n",
      "step: 500/516.0, loss: 0.2812047004699707\n",
      "step: 0/516.0, val_loss: 1.568610668182373\n",
      "step: 100/516.0, val_loss: 1.4853090047836304\n",
      "Epoch: 49/1000 시작 \n",
      "step: 0/516.0, loss: 0.3370211124420166\n",
      "step: 100/516.0, loss: 0.26770108938217163\n",
      "step: 200/516.0, loss: 0.3144747316837311\n",
      "step: 300/516.0, loss: 0.3146544098854065\n",
      "step: 400/516.0, loss: 0.3017383813858032\n",
      "step: 500/516.0, loss: 0.2983166575431824\n",
      "step: 0/516.0, val_loss: 1.4947307109832764\n",
      "step: 100/516.0, val_loss: 1.5209615230560303\n",
      "Epoch: 50/1000 시작 \n",
      "step: 0/516.0, loss: 0.3569546341896057\n",
      "step: 100/516.0, loss: 0.265762597322464\n",
      "step: 200/516.0, loss: 0.25801753997802734\n",
      "step: 300/516.0, loss: 0.25777024030685425\n",
      "step: 400/516.0, loss: 0.25240764021873474\n",
      "step: 500/516.0, loss: 0.254677414894104\n",
      "step: 0/516.0, val_loss: 1.2767882347106934\n",
      "step: 100/516.0, val_loss: 1.5242526531219482\n",
      "Epoch: 51/1000 시작 \n",
      "step: 0/516.0, loss: 0.2448807805776596\n",
      "step: 100/516.0, loss: 0.25813764333724976\n",
      "step: 200/516.0, loss: 0.2603203356266022\n",
      "step: 300/516.0, loss: 0.26469752192497253\n",
      "step: 400/516.0, loss: 0.26233971118927\n",
      "step: 500/516.0, loss: 0.2700669467449188\n",
      "step: 0/516.0, val_loss: 1.281488060951233\n",
      "step: 100/516.0, val_loss: 1.5350475311279297\n",
      "Epoch: 52/1000 시작 \n",
      "step: 0/516.0, loss: 0.19882813096046448\n",
      "step: 100/516.0, loss: 0.26714128255844116\n",
      "step: 200/516.0, loss: 0.2504503130912781\n",
      "step: 300/516.0, loss: 0.2448245882987976\n",
      "step: 400/516.0, loss: 0.24669919908046722\n",
      "step: 500/516.0, loss: 0.24640576541423798\n",
      "step: 0/516.0, val_loss: 0.9604387283325195\n",
      "step: 100/516.0, val_loss: 1.4970132112503052\n",
      "Epoch: 53/1000 시작 \n",
      "step: 0/516.0, loss: 0.23587457835674286\n",
      "step: 100/516.0, loss: 0.23937733471393585\n",
      "step: 200/516.0, loss: 0.24219399690628052\n",
      "step: 300/516.0, loss: 0.24110879004001617\n",
      "step: 400/516.0, loss: 0.2383313775062561\n",
      "step: 500/516.0, loss: 0.23927190899848938\n",
      "step: 0/516.0, val_loss: 1.4476046562194824\n",
      "step: 100/516.0, val_loss: 1.5632119178771973\n",
      "Epoch: 54/1000 시작 \n",
      "step: 0/516.0, loss: 0.3470790386199951\n",
      "step: 100/516.0, loss: 0.24322260916233063\n",
      "step: 200/516.0, loss: 0.2336089313030243\n",
      "step: 300/516.0, loss: 0.23127985000610352\n",
      "step: 400/516.0, loss: 0.23446504771709442\n",
      "step: 500/516.0, loss: 0.232981875538826\n",
      "step: 0/516.0, val_loss: 1.1043299436569214\n",
      "step: 100/516.0, val_loss: 1.420573353767395\n",
      "Epoch: 55/1000 시작 \n",
      "step: 0/516.0, loss: 0.1459973305463791\n",
      "step: 100/516.0, loss: 0.23294182121753693\n",
      "step: 200/516.0, loss: 0.23049086332321167\n",
      "step: 300/516.0, loss: 0.23055177927017212\n",
      "step: 400/516.0, loss: 0.2292938232421875\n",
      "step: 500/516.0, loss: 0.23489008843898773\n",
      "step: 0/516.0, val_loss: 1.2085880041122437\n",
      "step: 100/516.0, val_loss: 1.569063663482666\n",
      "Epoch: 56/1000 시작 \n",
      "step: 0/516.0, loss: 0.2518402934074402\n",
      "step: 100/516.0, loss: 0.23823948204517365\n",
      "step: 200/516.0, loss: 0.2408474236726761\n",
      "step: 300/516.0, loss: 0.2386000156402588\n",
      "step: 400/516.0, loss: 0.23401884734630585\n",
      "step: 500/516.0, loss: 0.23436252772808075\n",
      "step: 0/516.0, val_loss: 1.4539943933486938\n",
      "step: 100/516.0, val_loss: 1.4504810571670532\n",
      "Epoch: 57/1000 시작 \n",
      "step: 0/516.0, loss: 0.11998656392097473\n",
      "step: 100/516.0, loss: 0.22412097454071045\n",
      "step: 200/516.0, loss: 0.22235111892223358\n",
      "step: 300/516.0, loss: 0.21527999639511108\n",
      "step: 400/516.0, loss: 0.2191205620765686\n",
      "step: 500/516.0, loss: 0.22178997099399567\n",
      "step: 0/516.0, val_loss: 1.5274354219436646\n",
      "step: 100/516.0, val_loss: 1.6410611867904663\n",
      "Epoch: 58/1000 시작 \n",
      "step: 0/516.0, loss: 0.14191539585590363\n",
      "step: 100/516.0, loss: 0.21689733862876892\n",
      "step: 200/516.0, loss: 0.21214549243450165\n",
      "step: 300/516.0, loss: 0.21357227861881256\n",
      "step: 400/516.0, loss: 0.21359336376190186\n",
      "step: 500/516.0, loss: 0.21442626416683197\n",
      "step: 0/516.0, val_loss: 0.8414391279220581\n",
      "step: 100/516.0, val_loss: 1.6263141632080078\n",
      "Epoch: 59/1000 시작 \n",
      "step: 0/516.0, loss: 0.18727558851242065\n",
      "step: 100/516.0, loss: 0.2300730049610138\n",
      "step: 200/516.0, loss: 0.21673424541950226\n",
      "step: 300/516.0, loss: 0.2270299196243286\n",
      "step: 400/516.0, loss: 0.22883552312850952\n",
      "step: 500/516.0, loss: 0.22643746435642242\n",
      "step: 0/516.0, val_loss: 1.5833919048309326\n",
      "step: 100/516.0, val_loss: 1.5520150661468506\n",
      "Epoch: 60/1000 시작 \n",
      "step: 0/516.0, loss: 0.15553560853004456\n",
      "step: 100/516.0, loss: 0.23272119462490082\n",
      "step: 200/516.0, loss: 0.23089386522769928\n",
      "step: 300/516.0, loss: 0.2263985127210617\n",
      "step: 400/516.0, loss: 0.22597366571426392\n",
      "step: 500/516.0, loss: 0.22648721933364868\n",
      "step: 0/516.0, val_loss: 1.4567174911499023\n",
      "step: 100/516.0, val_loss: 1.5710902214050293\n",
      "Epoch: 61/1000 시작 \n",
      "step: 0/516.0, loss: 0.1417337954044342\n",
      "step: 100/516.0, loss: 0.19400079548358917\n",
      "step: 200/516.0, loss: 0.19171899557113647\n",
      "step: 300/516.0, loss: 0.1943710744380951\n",
      "step: 400/516.0, loss: 0.19802837073802948\n",
      "step: 500/516.0, loss: 0.19857317209243774\n",
      "step: 0/516.0, val_loss: 1.6696209907531738\n",
      "step: 100/516.0, val_loss: 1.6023802757263184\n",
      "Epoch: 62/1000 시작 \n",
      "step: 0/516.0, loss: 0.2632748782634735\n",
      "step: 100/516.0, loss: 0.34237995743751526\n",
      "step: 200/516.0, loss: 0.277030348777771\n",
      "step: 300/516.0, loss: 0.2582625150680542\n",
      "step: 400/516.0, loss: 0.24318750202655792\n",
      "step: 500/516.0, loss: 0.24108465015888214\n",
      "step: 0/516.0, val_loss: 1.3536561727523804\n",
      "step: 100/516.0, val_loss: 1.5111786127090454\n",
      "Epoch: 63/1000 시작 \n",
      "step: 0/516.0, loss: 0.0903736874461174\n",
      "step: 100/516.0, loss: 0.20572271943092346\n",
      "step: 200/516.0, loss: 0.19765262305736542\n",
      "step: 300/516.0, loss: 0.19973643124103546\n",
      "step: 400/516.0, loss: 0.20210012793540955\n",
      "step: 500/516.0, loss: 0.20118866860866547\n",
      "step: 0/516.0, val_loss: 1.570716381072998\n",
      "step: 100/516.0, val_loss: 1.5374523401260376\n",
      "Epoch: 64/1000 시작 \n",
      "step: 0/516.0, loss: 0.20531684160232544\n",
      "step: 100/516.0, loss: 0.20293568074703217\n",
      "step: 200/516.0, loss: 0.1926056444644928\n",
      "step: 300/516.0, loss: 0.19696439802646637\n",
      "step: 400/516.0, loss: 0.19552825391292572\n",
      "step: 500/516.0, loss: 0.19287273287773132\n",
      "step: 0/516.0, val_loss: 1.1475298404693604\n",
      "step: 100/516.0, val_loss: 1.6835026741027832\n",
      "Epoch: 65/1000 시작 \n",
      "step: 0/516.0, loss: 0.13601796329021454\n",
      "step: 100/516.0, loss: 0.20488421618938446\n",
      "step: 200/516.0, loss: 0.20341935753822327\n",
      "step: 300/516.0, loss: 0.19687753915786743\n",
      "step: 400/516.0, loss: 0.19684985280036926\n",
      "step: 500/516.0, loss: 0.19336143136024475\n",
      "step: 0/516.0, val_loss: 1.9813051223754883\n",
      "step: 100/516.0, val_loss: 1.5519742965698242\n",
      "Epoch: 66/1000 시작 \n",
      "step: 0/516.0, loss: 0.11113884299993515\n",
      "step: 100/516.0, loss: 0.18293273448944092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200/516.0, loss: 0.18412311375141144\n",
      "step: 300/516.0, loss: 0.18241029977798462\n",
      "step: 400/516.0, loss: 0.18830671906471252\n",
      "step: 500/516.0, loss: 0.1879044473171234\n",
      "step: 0/516.0, val_loss: 1.4097020626068115\n",
      "step: 100/516.0, val_loss: 1.6220800876617432\n",
      "Epoch: 67/1000 시작 \n",
      "step: 0/516.0, loss: 0.17660468816757202\n",
      "step: 100/516.0, loss: 0.18930646777153015\n",
      "step: 200/516.0, loss: 0.1883789300918579\n",
      "step: 300/516.0, loss: 0.1904546469449997\n",
      "step: 400/516.0, loss: 0.18865381181240082\n",
      "step: 500/516.0, loss: 0.19045127928256989\n",
      "step: 0/516.0, val_loss: 1.1469402313232422\n",
      "step: 100/516.0, val_loss: 1.889459252357483\n",
      "Epoch: 68/1000 시작 \n",
      "step: 0/516.0, loss: 0.11485113948583603\n",
      "step: 100/516.0, loss: 0.17488627135753632\n",
      "step: 200/516.0, loss: 0.17646169662475586\n",
      "step: 300/516.0, loss: 0.1833031177520752\n",
      "step: 400/516.0, loss: 0.19065918028354645\n",
      "step: 500/516.0, loss: 0.19035857915878296\n",
      "step: 0/516.0, val_loss: 1.9246872663497925\n",
      "step: 100/516.0, val_loss: 1.6409729719161987\n",
      "Epoch: 69/1000 시작 \n",
      "step: 0/516.0, loss: 0.18798163533210754\n",
      "step: 100/516.0, loss: 0.17810297012329102\n",
      "step: 200/516.0, loss: 0.17311838269233704\n",
      "step: 300/516.0, loss: 0.1750437319278717\n",
      "step: 400/516.0, loss: 0.17508162558078766\n",
      "step: 500/516.0, loss: 0.18015897274017334\n",
      "step: 0/516.0, val_loss: 1.4570692777633667\n",
      "step: 100/516.0, val_loss: 1.683447241783142\n",
      "Epoch: 70/1000 시작 \n",
      "step: 0/516.0, loss: 0.19123466312885284\n",
      "step: 100/516.0, loss: 0.17710287868976593\n",
      "step: 200/516.0, loss: 0.18215115368366241\n",
      "step: 300/516.0, loss: 0.18711987137794495\n",
      "step: 400/516.0, loss: 0.1886301189661026\n",
      "step: 500/516.0, loss: 0.18843545019626617\n",
      "step: 0/516.0, val_loss: 1.6731839179992676\n",
      "step: 100/516.0, val_loss: 1.6531486511230469\n",
      "Epoch: 71/1000 시작 \n",
      "step: 0/516.0, loss: 0.15919668972492218\n",
      "step: 100/516.0, loss: 0.1654372215270996\n",
      "step: 200/516.0, loss: 0.17582641541957855\n",
      "step: 300/516.0, loss: 0.17632637917995453\n",
      "step: 400/516.0, loss: 0.17940333485603333\n",
      "step: 500/516.0, loss: 0.1765589714050293\n",
      "step: 0/516.0, val_loss: 2.6204066276550293\n",
      "step: 100/516.0, val_loss: 1.743589997291565\n",
      "Epoch: 72/1000 시작 \n",
      "step: 0/516.0, loss: 0.10319274663925171\n",
      "step: 100/516.0, loss: 0.1653575748205185\n",
      "step: 200/516.0, loss: 0.16561651229858398\n",
      "step: 300/516.0, loss: 0.16575254499912262\n",
      "step: 400/516.0, loss: 0.16948089003562927\n",
      "step: 500/516.0, loss: 0.1699906587600708\n",
      "step: 0/516.0, val_loss: 1.9189565181732178\n",
      "step: 100/516.0, val_loss: 1.62276029586792\n",
      "Epoch: 73/1000 시작 \n",
      "step: 0/516.0, loss: 0.13122479617595673\n",
      "step: 100/516.0, loss: 0.1663130223751068\n",
      "step: 200/516.0, loss: 0.17241188883781433\n",
      "step: 300/516.0, loss: 0.16598458588123322\n",
      "step: 400/516.0, loss: 0.16629332304000854\n",
      "step: 500/516.0, loss: 0.16782215237617493\n",
      "step: 0/516.0, val_loss: 1.3176944255828857\n",
      "step: 100/516.0, val_loss: 1.972916603088379\n",
      "Epoch: 74/1000 시작 \n",
      "step: 0/516.0, loss: 0.16378657519817352\n",
      "step: 100/516.0, loss: 0.17033611238002777\n",
      "step: 200/516.0, loss: 0.16849210858345032\n",
      "step: 300/516.0, loss: 0.1734902411699295\n",
      "step: 400/516.0, loss: 0.17092041671276093\n",
      "step: 500/516.0, loss: 0.16851851344108582\n",
      "step: 0/516.0, val_loss: 1.9851408004760742\n",
      "step: 100/516.0, val_loss: 1.5754287242889404\n",
      "Epoch: 75/1000 시작 \n",
      "step: 0/516.0, loss: 0.132120281457901\n",
      "step: 100/516.0, loss: 0.17287850379943848\n",
      "step: 200/516.0, loss: 0.18284690380096436\n",
      "step: 300/516.0, loss: 0.18000926077365875\n",
      "step: 400/516.0, loss: 0.17959441244602203\n",
      "step: 500/516.0, loss: 0.17589199542999268\n",
      "step: 0/516.0, val_loss: 1.2949731349945068\n",
      "step: 100/516.0, val_loss: 1.7669988870620728\n",
      "Epoch: 76/1000 시작 \n",
      "step: 0/516.0, loss: 0.08587270975112915\n",
      "step: 100/516.0, loss: 0.1606108546257019\n",
      "step: 200/516.0, loss: 0.16375717520713806\n",
      "step: 300/516.0, loss: 0.16342312097549438\n",
      "step: 400/516.0, loss: 0.1624244600534439\n",
      "step: 500/516.0, loss: 0.16087158024311066\n",
      "step: 0/516.0, val_loss: 1.8445775508880615\n",
      "step: 100/516.0, val_loss: 1.757719874382019\n",
      "Epoch: 77/1000 시작 \n",
      "step: 0/516.0, loss: 0.10267885029315948\n",
      "step: 100/516.0, loss: 0.16777433454990387\n",
      "step: 200/516.0, loss: 0.1771518588066101\n",
      "step: 300/516.0, loss: 0.20765537023544312\n",
      "step: 400/516.0, loss: 0.21631711721420288\n",
      "step: 500/516.0, loss: 0.2401811182498932\n",
      "step: 0/516.0, val_loss: 1.969966173171997\n",
      "step: 100/516.0, val_loss: 1.6181390285491943\n",
      "Epoch: 78/1000 시작 \n",
      "step: 0/516.0, loss: 0.33554062247276306\n",
      "step: 100/516.0, loss: 0.20043477416038513\n",
      "step: 200/516.0, loss: 0.19228202104568481\n",
      "step: 300/516.0, loss: 0.19355055689811707\n",
      "step: 400/516.0, loss: 0.19150963425636292\n",
      "step: 500/516.0, loss: 0.18967778980731964\n",
      "step: 0/516.0, val_loss: 1.845107078552246\n",
      "step: 100/516.0, val_loss: 1.5730501413345337\n",
      "Epoch: 79/1000 시작 \n",
      "step: 0/516.0, loss: 0.10336479544639587\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from core.efficientdet import EfficientDet, PostProcessing\n",
    "from data.dataloader import DetectionDataset, DataLoader\n",
    "from configuration import Config\n",
    "from utils.visualize import visualize_training_results\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def print_model_summary(network):\n",
    "    sample_inputs = tf.random.normal(shape=(Config.batch_size, Config.get_image_size()[0], Config.get_image_size()[1], Config.image_channels))\n",
    "    sample_outputs = network(sample_inputs, training=True)\n",
    "    network.summary()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # GPU settings\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    print(gpus)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "        try:\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        except RuntimeError as e:\n",
    "            # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "            print(e)\n",
    "\n",
    "    # dataset\n",
    "    # train에 사용할 데이터셋을 불러오기\n",
    "    train_dataset = DetectionDataset(\"train\")\n",
    "    train_data, train_size = train_dataset.generate_datatset()\n",
    "    data_loader = DataLoader()\n",
    "    train_steps_per_epoch = tf.math.ceil(train_size / Config.batch_size)\n",
    "\n",
    "    # validation loss 계산에 사용할 데이터셋 불러오기\n",
    "    valid_dataset = DetectionDataset(\"valid\")\n",
    "    valid_data, valid_size = valid_dataset.generate_datatset()\n",
    "    valid_steps_per_epoch = tf.math.ceil(train_size / Config.batch_size)\n",
    "\n",
    "    # model\n",
    "    efficientdet = EfficientDet()\n",
    "    print_model_summary(efficientdet)\n",
    "\n",
    "    load_weights_from_epoch = Config.load_weights_from_epoch\n",
    "    if Config.load_weights_before_training:\n",
    "        efficientdet.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "        print(\"Successfully load weights!\")\n",
    "    else:\n",
    "        load_weights_from_epoch = -1\n",
    "\n",
    "    post_process = PostProcessing()\n",
    "\n",
    "    # optimizer\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4,\n",
    "                                                                 decay_steps=train_steps_per_epoch * Config.learning_rate_decay_epochs,\n",
    "                                                                 decay_rate=0.96)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    # metrics\n",
    "    loss_metric_train = tf.metrics.Mean()\n",
    "    loss_metric_valid = tf.metrics.Mean()\n",
    "\n",
    "    temp_loss_1 = []\n",
    "    temp_loss_2 = []\n",
    "\n",
    "    def train_step(batch_images, batch_labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = efficientdet(batch_images, training=True)\n",
    "            loss_value = post_process.training_procedure(pred, batch_labels)\n",
    "        gradients = tape.gradient(target=loss_value, sources=efficientdet.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(gradients, efficientdet.trainable_variables))\n",
    "        loss_metric_train.update_state(values=loss_value)\n",
    "\n",
    "    # validation set에 대한 loss 계산해주는 함수\n",
    "    def valid_step(batch_images, batch_labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = efficientdet(batch_images, training=False)\n",
    "            loss_value = post_process.training_procedure(pred, batch_labels)\n",
    "        loss_metric_valid.update_state(values=loss_value)\n",
    "\n",
    "    # # early stop - loss 가 떨어지지 않는 경우 조정해주는 함수\n",
    "    # def early_stop(val_loss, epoch):\n",
    "    #     if\n",
    "\n",
    "\n",
    "    flag = True\n",
    "    min = 10000000\n",
    "    count = 0\n",
    "    \n",
    "    for epoch in range(load_weights_from_epoch + 1, Config.epochs):\n",
    "        print(\"Epoch: {}/{} 시작 \".format(epoch, Config.epochs))\n",
    "\n",
    "        for step, batch_data  in enumerate(train_data):\n",
    "            images_train, labels_train = data_loader.read_batch_data(batch_data)\n",
    "            train_step(images_train, labels_train)\n",
    "\n",
    "            if step%100==0:\n",
    "                print(\"step: {}/{}, loss: {}\".format(      step,\n",
    "                                                       train_steps_per_epoch,\n",
    "                                                       loss_metric_train.result()))\n",
    "\n",
    "        temp_loss_1.append(loss_metric_train.result())\n",
    "        loss_metric_train.reset_states()\n",
    "\n",
    "        for step, batch_data in enumerate(valid_data):\n",
    "            images, labels = data_loader.read_batch_data(batch_data)\n",
    "            valid_step(images, labels)\n",
    "            if step % 100 == 0:\n",
    "                print(\"step: {}/{}, val_loss: {}\".format(step,\n",
    "                                                 valid_steps_per_epoch,\n",
    "                                                 loss_metric_valid.result()))\n",
    "#         if temp_loss_2[epoch] < min:\n",
    "#             min = temp_loss_2[epoch]\n",
    "#             count = 0\n",
    "#         elif temp_loss_2[epoch] > min:\n",
    "#             count += 1 \n",
    "        \n",
    "#         if count == 3:\n",
    "#             break\n",
    "        \n",
    "#         print(min)\n",
    "        \n",
    "        temp_loss_2.append(loss_metric_valid.result())\n",
    "\n",
    "        loss_metric_valid.reset_states()\n",
    "\n",
    "        if epoch % Config.save_frequency == 0:\n",
    "            efficientdet.save_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(epoch), save_format=\"tf\")\n",
    "\n",
    "        if Config.test_images_during_training:\n",
    "            visualize_training_results(pictures=Config.test_images_dir_list, model=efficientdet, epoch=epoch)\n",
    "        \n",
    "        see = 150\n",
    "        if epoch >= see:\n",
    "            x_len = np.arange(epoch+1)\n",
    "            plt.plot(x_len[see:], temp_loss_1[see:], marker='.', c='red', label=\"Train-set Loss\")\n",
    "            plt.plot(x_len[see:], temp_loss_2[see:], marker='.', c='blue', label=\"Valid-set Loss\")\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.grid()\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('step_loss')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    efficientdet.save_weights(filepath=Config.save_model_dir + \"saved_model_sgd\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85004754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (601,) and (344,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5133/830176691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_loss_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train-set Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_loss_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Valid-set Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/efficient_det/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     return gca().plot(\n\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/efficient_det/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/efficient_det/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/efficient_det/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (601,) and (344,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = np.arange(Config.epochs)\n",
    "\n",
    "plt.plot(x_len, temp_loss_1, marker='.', c='red', label=\"Train-set Loss\")\n",
    "plt.plot(x_len, temp_loss_2, marker='.', c='blue', label=\"Valid-set Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('step_loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b925f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1273292216.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5133/1273292216.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    df = pd.DataFrame({'epoch': x_len, 'train_loss':temp_loss_1., 'valid_loss':temp_loss_2})\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'epoch': x_len, 'train_loss':temp_loss_1., 'valid_loss':temp_loss_2})\n",
    "print(df)\n",
    "df.to_csv(\"loss_log.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5738d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 25 18:48:00 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:3B:00.0 Off |                  N/A |\r\n",
      "| 41%   51C    P2    68W / 280W |  23764MiB / 24220MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      5133      C   .../efficient_det/bin/python    23761MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df63f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
