{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e32e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 29 19:04:59 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:AF:00.0 Off |                  N/A |\r\n",
      "| 21%   36C    P0    31W / 280W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29e7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 21:54:49.833586: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-29 21:54:51.192587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22854 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:af:00.0, compute capability: 7.5\n",
      "2021-10-29 21:54:51.769398: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-29 21:54:53.341248: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2021-10-29 21:54:55.463519: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficient_det\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficient_net (EfficientNet) multiple                  6771296   \n",
      "_________________________________________________________________\n",
      "bi_fpn (BiFPN)               multiple                  129126    \n",
      "_________________________________________________________________\n",
      "box_class_predict (BoxClassP multiple                  249069    \n",
      "=================================================================\n",
      "Total params: 7,149,491\n",
      "Trainable params: 7,106,515\n",
      "Non-trainable params: 42,976\n",
      "_________________________________________________________________\n",
      "Epoch: 0/400 시작 \n",
      "step: 0/1533.0, loss: 351.26806640625\n",
      "step: 100/1533.0, loss: 509.7305603027344\n",
      "step: 200/1533.0, loss: 344.06634521484375\n",
      "step: 300/1533.0, loss: 252.91928100585938\n",
      "step: 400/1533.0, loss: 202.46522521972656\n",
      "step: 500/1533.0, loss: 167.98388671875\n",
      "step: 600/1533.0, loss: 143.72055053710938\n",
      "step: 700/1533.0, loss: 125.17533111572266\n",
      "step: 800/1533.0, loss: 111.24337005615234\n",
      "step: 900/1533.0, loss: 100.29488372802734\n",
      "step: 1000/1533.0, loss: 91.20391845703125\n",
      "step: 1100/1533.0, loss: 83.67036437988281\n",
      "step: 1200/1533.0, loss: 77.29957580566406\n",
      "step: 1300/1533.0, loss: 71.76097869873047\n",
      "step: 1400/1533.0, loss: 67.0470199584961\n",
      "step: 1500/1533.0, loss: 62.803375244140625\n",
      "step: 0/1533.0, val_loss: 2.6930999755859375\n",
      "step: 100/1533.0, val_loss: 4.323965072631836\n",
      "1 epoch에 걸린 시간 :  598.9981594085693\n",
      "Epoch: 1/400 시작 \n",
      "step: 0/1533.0, loss: 1.893223524093628\n",
      "step: 100/1533.0, loss: 3.276177167892456\n",
      "step: 200/1533.0, loss: 3.219677448272705\n",
      "step: 300/1533.0, loss: 3.0625834465026855\n",
      "step: 400/1533.0, loss: 3.0334651470184326\n",
      "step: 500/1533.0, loss: 2.966068983078003\n",
      "step: 600/1533.0, loss: 2.9045825004577637\n",
      "step: 700/1533.0, loss: 2.8105969429016113\n",
      "step: 800/1533.0, loss: 2.761154890060425\n",
      "step: 900/1533.0, loss: 2.726870536804199\n",
      "step: 1000/1533.0, loss: 2.6758363246917725\n",
      "step: 1100/1533.0, loss: 2.632253408432007\n",
      "step: 1200/1533.0, loss: 2.589317560195923\n",
      "step: 1300/1533.0, loss: 2.5369162559509277\n",
      "step: 1400/1533.0, loss: 2.500314474105835\n",
      "step: 1500/1533.0, loss: 2.4437217712402344\n",
      "step: 0/1533.0, val_loss: 2.8336052894592285\n",
      "step: 100/1533.0, val_loss: 3.066267251968384\n",
      "1 epoch에 걸린 시간 :  588.1934912204742\n",
      "Epoch: 2/400 시작 \n",
      "step: 0/1533.0, loss: 1.0508025884628296\n",
      "step: 100/1533.0, loss: 1.6240489482879639\n",
      "step: 200/1533.0, loss: 1.6151833534240723\n",
      "step: 300/1533.0, loss: 1.5802887678146362\n",
      "step: 400/1533.0, loss: 1.5751341581344604\n",
      "step: 500/1533.0, loss: 1.5669182538986206\n",
      "step: 600/1533.0, loss: 1.5476040840148926\n",
      "step: 700/1533.0, loss: 1.5193408727645874\n",
      "step: 800/1533.0, loss: 1.5038907527923584\n",
      "step: 900/1533.0, loss: 1.4883962869644165\n",
      "step: 1000/1533.0, loss: 1.4682469367980957\n",
      "step: 1100/1533.0, loss: 1.4508754014968872\n",
      "step: 1200/1533.0, loss: 1.4320440292358398\n",
      "step: 1300/1533.0, loss: 1.4132888317108154\n",
      "step: 1400/1533.0, loss: 1.3990755081176758\n",
      "step: 1500/1533.0, loss: 1.38232421875\n",
      "step: 0/1533.0, val_loss: 3.0664610862731934\n",
      "step: 100/1533.0, val_loss: 3.403280735015869\n",
      "1 epoch에 걸린 시간 :  593.1260318756104\n",
      "Epoch: 3/400 시작 \n",
      "step: 0/1533.0, loss: 0.7214937806129456\n",
      "step: 100/1533.0, loss: 1.1543759107589722\n",
      "step: 200/1533.0, loss: 1.1407668590545654\n",
      "step: 300/1533.0, loss: 1.1146358251571655\n",
      "step: 400/1533.0, loss: 1.1082137823104858\n",
      "step: 500/1533.0, loss: 1.1048996448516846\n",
      "step: 600/1533.0, loss: 1.0894997119903564\n",
      "step: 700/1533.0, loss: 1.0768141746520996\n",
      "step: 800/1533.0, loss: 1.067440152168274\n",
      "step: 900/1533.0, loss: 1.0555169582366943\n",
      "step: 1000/1533.0, loss: 1.0432171821594238\n",
      "step: 1100/1533.0, loss: 1.033393144607544\n",
      "step: 1200/1533.0, loss: 1.0210305452346802\n",
      "step: 1300/1533.0, loss: 1.0098336935043335\n",
      "step: 1400/1533.0, loss: 1.0015628337860107\n",
      "step: 1500/1533.0, loss: 0.9934658408164978\n",
      "step: 0/1533.0, val_loss: 3.2754807472229004\n",
      "step: 100/1533.0, val_loss: 3.23970103263855\n",
      "1 epoch에 걸린 시간 :  594.7185044288635\n",
      "Epoch: 4/400 시작 \n",
      "step: 0/1533.0, loss: 0.551198422908783\n",
      "step: 100/1533.0, loss: 0.8741194605827332\n",
      "step: 200/1533.0, loss: 0.8796902298927307\n",
      "step: 300/1533.0, loss: 0.8642824292182922\n",
      "step: 400/1533.0, loss: 0.8668151497840881\n",
      "step: 500/1533.0, loss: 0.8671687245368958\n",
      "step: 600/1533.0, loss: 0.8576864004135132\n",
      "step: 700/1533.0, loss: 0.848967432975769\n",
      "step: 800/1533.0, loss: 0.842075765132904\n",
      "step: 900/1533.0, loss: 0.8319791555404663\n",
      "step: 1000/1533.0, loss: 0.8209183812141418\n",
      "step: 1100/1533.0, loss: 0.8133792281150818\n",
      "step: 1200/1533.0, loss: 0.8018260598182678\n",
      "step: 1300/1533.0, loss: 0.7949574589729309\n",
      "step: 1400/1533.0, loss: 0.7875998616218567\n",
      "step: 1500/1533.0, loss: 0.7861014008522034\n",
      "step: 0/1533.0, val_loss: 3.4303340911865234\n",
      "step: 100/1533.0, val_loss: 2.7107856273651123\n",
      "1 epoch에 걸린 시간 :  594.3920390605927\n",
      "Epoch: 5/400 시작 \n",
      "step: 0/1533.0, loss: 0.40635067224502563\n",
      "step: 100/1533.0, loss: 0.7457634806632996\n",
      "step: 200/1533.0, loss: 0.7429350018501282\n",
      "step: 300/1533.0, loss: 0.7254392504692078\n",
      "step: 400/1533.0, loss: 0.7258211970329285\n",
      "step: 500/1533.0, loss: 0.7337530851364136\n",
      "step: 600/1533.0, loss: 0.7231702208518982\n",
      "step: 700/1533.0, loss: 0.7129307389259338\n",
      "step: 800/1533.0, loss: 0.7030738592147827\n",
      "step: 900/1533.0, loss: 0.694430410861969\n",
      "step: 1000/1533.0, loss: 0.6844177842140198\n",
      "step: 1100/1533.0, loss: 0.6770715713500977\n",
      "step: 1200/1533.0, loss: 0.6669605374336243\n",
      "step: 1300/1533.0, loss: 0.6591571569442749\n",
      "step: 1400/1533.0, loss: 0.6516861915588379\n",
      "step: 1500/1533.0, loss: 0.6465464234352112\n",
      "step: 0/1533.0, val_loss: 3.259951114654541\n",
      "step: 100/1533.0, val_loss: 2.47802996635437\n",
      "1 epoch에 걸린 시간 :  595.9307305812836\n",
      "Epoch: 6/400 시작 \n",
      "step: 0/1533.0, loss: 0.390729159116745\n",
      "step: 100/1533.0, loss: 0.6028299331665039\n",
      "step: 200/1533.0, loss: 0.6010600924491882\n",
      "step: 300/1533.0, loss: 0.5842092037200928\n",
      "step: 400/1533.0, loss: 0.5776082277297974\n",
      "step: 500/1533.0, loss: 0.5793284773826599\n",
      "step: 600/1533.0, loss: 0.5701615214347839\n",
      "step: 700/1533.0, loss: 0.5638484954833984\n",
      "step: 800/1533.0, loss: 0.5557395219802856\n",
      "step: 900/1533.0, loss: 0.5508585572242737\n",
      "step: 1000/1533.0, loss: 0.5481876134872437\n",
      "step: 1100/1533.0, loss: 0.5449036955833435\n",
      "step: 1200/1533.0, loss: 0.5381847023963928\n",
      "step: 1300/1533.0, loss: 0.5333285927772522\n",
      "step: 1400/1533.0, loss: 0.5275750756263733\n",
      "step: 1500/1533.0, loss: 0.526954710483551\n",
      "step: 0/1533.0, val_loss: 3.379377603530884\n",
      "step: 100/1533.0, val_loss: 2.1536550521850586\n",
      "1 epoch에 걸린 시간 :  596.4967350959778\n",
      "Epoch: 7/400 시작 \n",
      "step: 0/1533.0, loss: 0.20771920680999756\n",
      "step: 100/1533.0, loss: 0.5088943839073181\n",
      "step: 200/1533.0, loss: 0.5015014410018921\n",
      "step: 300/1533.0, loss: 0.48356151580810547\n",
      "step: 400/1533.0, loss: 0.4758959710597992\n",
      "step: 500/1533.0, loss: 0.4852238595485687\n",
      "step: 600/1533.0, loss: 0.4781520962715149\n",
      "step: 700/1533.0, loss: 0.468685120344162\n",
      "step: 800/1533.0, loss: 0.45985090732574463\n",
      "step: 900/1533.0, loss: 0.45425042510032654\n",
      "step: 1000/1533.0, loss: 0.44810497760772705\n",
      "step: 1100/1533.0, loss: 0.44481420516967773\n",
      "step: 1200/1533.0, loss: 0.4409586191177368\n",
      "step: 1300/1533.0, loss: 0.4372785985469818\n",
      "step: 1400/1533.0, loss: 0.43363896012306213\n",
      "step: 1500/1533.0, loss: 0.4305502772331238\n",
      "step: 0/1533.0, val_loss: 3.3054964542388916\n",
      "step: 100/1533.0, val_loss: 2.0275375843048096\n",
      "1 epoch에 걸린 시간 :  595.8651964664459\n",
      "Epoch: 8/400 시작 \n",
      "step: 0/1533.0, loss: 0.13824239373207092\n",
      "step: 100/1533.0, loss: 0.42598584294319153\n",
      "step: 200/1533.0, loss: 0.42681440711021423\n",
      "step: 300/1533.0, loss: 0.4138698875904083\n",
      "step: 400/1533.0, loss: 0.40530693531036377\n",
      "step: 500/1533.0, loss: 0.4127640724182129\n",
      "step: 600/1533.0, loss: 0.40358126163482666\n",
      "step: 700/1533.0, loss: 0.3962904214859009\n",
      "step: 800/1533.0, loss: 0.38901206851005554\n",
      "step: 900/1533.0, loss: 0.3835149109363556\n",
      "step: 1000/1533.0, loss: 0.3774554133415222\n",
      "step: 1100/1533.0, loss: 0.3784193992614746\n",
      "step: 1200/1533.0, loss: 0.376447856426239\n",
      "step: 1300/1533.0, loss: 0.37472736835479736\n",
      "step: 1400/1533.0, loss: 0.37109071016311646\n",
      "step: 1500/1533.0, loss: 0.36938032507896423\n",
      "step: 0/1533.0, val_loss: 3.1593704223632812\n",
      "step: 100/1533.0, val_loss: 2.2302041053771973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch에 걸린 시간 :  595.722980260849\n",
      "Epoch: 9/400 시작 \n",
      "step: 0/1533.0, loss: 0.11247284710407257\n",
      "step: 100/1533.0, loss: 0.36610525846481323\n",
      "step: 200/1533.0, loss: 0.3786006569862366\n",
      "step: 300/1533.0, loss: 0.363506019115448\n",
      "step: 400/1533.0, loss: 0.3536626100540161\n",
      "step: 500/1533.0, loss: 0.35667362809181213\n",
      "step: 600/1533.0, loss: 0.34996089339256287\n",
      "step: 700/1533.0, loss: 0.34396812319755554\n",
      "step: 800/1533.0, loss: 0.3383542597293854\n",
      "step: 900/1533.0, loss: 0.3348778784275055\n",
      "step: 1000/1533.0, loss: 0.33000072836875916\n",
      "step: 1100/1533.0, loss: 0.32940539717674255\n",
      "step: 1200/1533.0, loss: 0.32644644379615784\n",
      "step: 1300/1533.0, loss: 0.32461708784103394\n",
      "step: 1400/1533.0, loss: 0.32597076892852783\n",
      "step: 1500/1533.0, loss: 0.3265047073364258\n",
      "step: 0/1533.0, val_loss: 2.9725494384765625\n",
      "step: 100/1533.0, val_loss: 2.3651301860809326\n",
      "1 epoch에 걸린 시간 :  595.09579205513\n",
      "Epoch: 10/400 시작 \n",
      "step: 0/1533.0, loss: 0.10609931498765945\n",
      "step: 100/1533.0, loss: 0.33771461248397827\n",
      "step: 200/1533.0, loss: 0.328728586435318\n",
      "step: 300/1533.0, loss: 0.316498726606369\n",
      "step: 400/1533.0, loss: 0.3086005747318268\n",
      "step: 500/1533.0, loss: 0.3161528706550598\n",
      "step: 600/1533.0, loss: 0.3090495765209198\n",
      "step: 700/1533.0, loss: 0.30235302448272705\n",
      "step: 800/1533.0, loss: 0.29850298166275024\n",
      "step: 900/1533.0, loss: 0.2926415205001831\n",
      "step: 1000/1533.0, loss: 0.28647252917289734\n",
      "step: 1100/1533.0, loss: 0.28677091002464294\n",
      "step: 1200/1533.0, loss: 0.2852170467376709\n",
      "step: 1300/1533.0, loss: 0.28567054867744446\n",
      "step: 1400/1533.0, loss: 0.28403690457344055\n",
      "step: 1500/1533.0, loss: 0.28341197967529297\n",
      "step: 0/1533.0, val_loss: 3.147000312805176\n",
      "step: 100/1533.0, val_loss: 2.23907208442688\n",
      "1 epoch에 걸린 시간 :  594.1808466911316\n",
      "Epoch: 11/400 시작 \n",
      "step: 0/1533.0, loss: 0.11088024079799652\n",
      "step: 100/1533.0, loss: 0.2756190299987793\n",
      "step: 200/1533.0, loss: 0.3107769191265106\n",
      "step: 300/1533.0, loss: 0.3072013854980469\n",
      "step: 400/1533.0, loss: 0.2951156795024872\n",
      "step: 500/1533.0, loss: 0.2919715344905853\n",
      "step: 600/1533.0, loss: 0.28434622287750244\n",
      "step: 700/1533.0, loss: 0.27654242515563965\n",
      "step: 800/1533.0, loss: 0.2721434235572815\n",
      "step: 900/1533.0, loss: 0.26715606451034546\n",
      "step: 1000/1533.0, loss: 0.2618564963340759\n",
      "step: 1100/1533.0, loss: 0.260085791349411\n",
      "step: 1200/1533.0, loss: 0.25608029961586\n",
      "step: 1300/1533.0, loss: 0.2555442452430725\n",
      "step: 1400/1533.0, loss: 0.2543986439704895\n",
      "step: 1500/1533.0, loss: 0.2540990114212036\n",
      "step: 0/1533.0, val_loss: 3.3363962173461914\n",
      "step: 100/1533.0, val_loss: 2.5104503631591797\n",
      "1 epoch에 걸린 시간 :  593.3032760620117\n",
      "Epoch: 12/400 시작 \n",
      "step: 0/1533.0, loss: 0.07466495037078857\n",
      "step: 100/1533.0, loss: 0.2613734006881714\n",
      "step: 200/1533.0, loss: 0.2545471787452698\n",
      "step: 300/1533.0, loss: 0.24236232042312622\n",
      "step: 400/1533.0, loss: 0.23730315268039703\n",
      "step: 500/1533.0, loss: 0.24630047380924225\n",
      "step: 600/1533.0, loss: 0.24206006526947021\n",
      "step: 700/1533.0, loss: 0.23796586692333221\n",
      "step: 800/1533.0, loss: 0.23652532696723938\n",
      "step: 900/1533.0, loss: 0.23249070346355438\n",
      "step: 1000/1533.0, loss: 0.22957174479961395\n",
      "step: 1100/1533.0, loss: 0.22950977087020874\n",
      "step: 1200/1533.0, loss: 0.22801357507705688\n",
      "step: 1300/1533.0, loss: 0.2271026223897934\n",
      "step: 1400/1533.0, loss: 0.2254784107208252\n",
      "step: 1500/1533.0, loss: 0.22499796748161316\n",
      "step: 0/1533.0, val_loss: 3.2812862396240234\n",
      "step: 100/1533.0, val_loss: 2.111341953277588\n",
      "1 epoch에 걸린 시간 :  594.1923980712891\n",
      "Epoch: 13/400 시작 \n",
      "step: 0/1533.0, loss: 0.09336057305335999\n",
      "step: 100/1533.0, loss: 0.2391972541809082\n",
      "step: 200/1533.0, loss: 0.25227200984954834\n",
      "step: 300/1533.0, loss: 0.2455558180809021\n",
      "step: 400/1533.0, loss: 0.23532401025295258\n",
      "step: 500/1533.0, loss: 0.23454372584819794\n",
      "step: 600/1533.0, loss: 0.22664237022399902\n",
      "step: 700/1533.0, loss: 0.2206086367368698\n",
      "step: 800/1533.0, loss: 0.2180768847465515\n",
      "step: 900/1533.0, loss: 0.21316979825496674\n",
      "step: 1000/1533.0, loss: 0.20860381424427032\n",
      "step: 1100/1533.0, loss: 0.21051593124866486\n",
      "step: 1200/1533.0, loss: 0.2101978063583374\n",
      "step: 1300/1533.0, loss: 0.20894551277160645\n",
      "step: 1400/1533.0, loss: 0.20842741429805756\n",
      "step: 1500/1533.0, loss: 0.2094240039587021\n",
      "step: 0/1533.0, val_loss: 3.385545253753662\n",
      "step: 100/1533.0, val_loss: 2.321636915206909\n",
      "1 epoch에 걸린 시간 :  601.090569972992\n",
      "Epoch: 14/400 시작 \n",
      "step: 0/1533.0, loss: 0.08463236689567566\n",
      "step: 100/1533.0, loss: 0.22069349884986877\n",
      "step: 200/1533.0, loss: 0.22052410244941711\n",
      "step: 300/1533.0, loss: 0.21151737868785858\n",
      "step: 400/1533.0, loss: 0.20785364508628845\n",
      "step: 500/1533.0, loss: 0.22208112478256226\n",
      "step: 600/1533.0, loss: 0.22373272478580475\n",
      "step: 700/1533.0, loss: 0.21698452532291412\n",
      "step: 800/1533.0, loss: 0.21418116986751556\n",
      "step: 900/1533.0, loss: 0.20991578698158264\n",
      "step: 1000/1533.0, loss: 0.2059166133403778\n",
      "step: 1100/1533.0, loss: 0.20451609790325165\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from core.efficientdet import EfficientDet, PostProcessing\n",
    "from data.dataloader import DetectionDataset, DataLoader\n",
    "from configuration import Config\n",
    "from utils.visualize import visualize_training_results\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def print_model_summary(network):\n",
    "    sample_inputs = tf.random.normal(shape=(Config.batch_size, Config.get_image_size()[0], Config.get_image_size()[1], Config.image_channels))\n",
    "    sample_outputs = network(sample_inputs, training=True)\n",
    "    network.summary()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # GPU settings\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    print(gpus)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "        try:\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        except RuntimeError as e:\n",
    "            # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "            print(e)\n",
    "\n",
    "    # dataset\n",
    "    # train에 사용할 데이터셋을 불러오기\n",
    "    train_dataset = DetectionDataset(\"train\")\n",
    "    train_data, train_size = train_dataset.generate_datatset()\n",
    "    data_loader = DataLoader()\n",
    "    train_steps_per_epoch = tf.math.ceil(train_size / Config.batch_size)\n",
    "\n",
    "    # validation loss 계산에 사용할 데이터셋 불러오기\n",
    "    valid_dataset = DetectionDataset(\"valid\")\n",
    "    valid_data, valid_size = valid_dataset.generate_datatset()\n",
    "    valid_steps_per_epoch = tf.math.ceil(train_size / Config.batch_size)\n",
    "\n",
    "    # model\n",
    "    efficientdet = EfficientDet()\n",
    "    print_model_summary(efficientdet)\n",
    "\n",
    "    load_weights_from_epoch = Config.load_weights_from_epoch\n",
    "    if Config.load_weights_before_training:\n",
    "        efficientdet.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "        print(\"Successfully load weights!\")\n",
    "    else:\n",
    "        load_weights_from_epoch = -1\n",
    "\n",
    "    post_process = PostProcessing()\n",
    "\n",
    "    # optimizer\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4,\n",
    "                                                                 decay_steps=train_steps_per_epoch * Config.learning_rate_decay_epochs,\n",
    "                                                                 decay_rate=0.96)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    # metrics\n",
    "    loss_metric_train = tf.metrics.Mean()\n",
    "    loss_metric_valid = tf.metrics.Mean()\n",
    "\n",
    "    temp_loss_1 = []\n",
    "    temp_loss_2 = []\n",
    "\n",
    "    def train_step(batch_images, batch_labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = efficientdet(batch_images, training=True)\n",
    "            loss_value = post_process.training_procedure(pred, batch_labels)\n",
    "        gradients = tape.gradient(target=loss_value, sources=efficientdet.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(gradients, efficientdet.trainable_variables))\n",
    "        loss_metric_train.update_state(values=loss_value)\n",
    "\n",
    "    # validation set에 대한 loss 계산해주는 함수\n",
    "    def valid_step(batch_images, batch_labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = efficientdet(batch_images, training=False)\n",
    "            loss_value = post_process.training_procedure(pred, batch_labels)\n",
    "        loss_metric_valid.update_state(values=loss_value)\n",
    "\n",
    "    # # early stop - loss 가 떨어지지 않는 경우 조정해주는 함수\n",
    "    # def early_stop(val_loss, epoch):\n",
    "    #     if\n",
    "\n",
    "\n",
    "    for epoch in range(load_weights_from_epoch + 1, Config.epochs):\n",
    "        t1 = time.time()\n",
    "        print(\"Epoch: {}/{} 시작 \".format(epoch, Config.epochs))\n",
    "\n",
    "        for step, batch_data  in enumerate(train_data):\n",
    "            images_train, labels_train = data_loader.read_batch_data(batch_data)\n",
    "            train_step(images_train, labels_train)\n",
    "\n",
    "            if step%100==0:\n",
    "                print(\"step: {}/{}, loss: {}\".format(      step,\n",
    "                                                       train_steps_per_epoch,\n",
    "                                                       loss_metric_train.result()))\n",
    "\n",
    "        temp_loss_1.append(loss_metric_train.result())\n",
    "        loss_metric_train.reset_states()\n",
    "\n",
    "        for step, batch_data in enumerate(valid_data):\n",
    "            images, labels = data_loader.read_batch_data(batch_data)\n",
    "            valid_step(images, labels)\n",
    "            if step % 100 == 0:\n",
    "                print(\"step: {}/{}, val_loss: {}\".format(step,\n",
    "                                                 valid_steps_per_epoch,\n",
    "                                                 loss_metric_valid.result()))\n",
    "#         if temp_loss_2[epoch] < min:\n",
    "#             min = temp_loss_2[epoch]\n",
    "#             count = 0\n",
    "#         elif temp_loss_2[epoch] > min:\n",
    "#             count += 1 \n",
    "        \n",
    "#         if count == 3:\n",
    "#             break\n",
    "        \n",
    "#         print(min)\n",
    "        \n",
    "        temp_loss_2.append(loss_metric_valid.result())\n",
    "\n",
    "        loss_metric_valid.reset_states()\n",
    "\n",
    "        if epoch % Config.save_frequency == 0:\n",
    "            efficientdet.save_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(epoch), save_format=\"tf\")\n",
    "\n",
    "        if Config.test_images_during_training:\n",
    "            visualize_training_results(pictures=Config.test_images_dir_list, model=efficientdet, epoch=epoch)\n",
    "        \n",
    "        see = 150\n",
    "        if epoch >= see:\n",
    "            x_len = np.arange(epoch+1)\n",
    "            plt.plot(x_len[see:], temp_loss_1[see:], marker='.', c='red', label=\"Train-set Loss\")\n",
    "            plt.plot(x_len[see:], temp_loss_2[see:], marker='.', c='blue', label=\"Valid-set Loss\")\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.grid()\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('step_loss')\n",
    "            plt.show()\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print(\"1 epoch에 걸린 시간 : \",t2-t1)\n",
    "\n",
    "\n",
    "    efficientdet.save_weights(filepath=Config.save_model_dir + \"saved_model_sgd\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85004754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_len = np.arange(Config.epochs)\n",
    "\n",
    "plt.plot(x_len, temp_loss_1, marker='.', c='red', label=\"Train-set Loss\")\n",
    "plt.plot(x_len, temp_loss_2, marker='.', c='blue', label=\"Valid-set Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('step_loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b925f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'epoch': x_len, 'train_loss':temp_loss_1, 'valid_loss':temp_loss_2})\n",
    "print(df)\n",
    "df.to_csv(\"./log/aug_32_1000_20.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5738d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df63f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
