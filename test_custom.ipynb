{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689f122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b496f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "from configuration import Config\n",
    "from core.efficientdet import EfficientDet, PostProcessing\n",
    "from data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b707efd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원래 모델\n",
    "\n",
    "def idx2class():\n",
    "    return dict((v, k) for k, v in Config.pascal_voc_classes.items())\n",
    "\n",
    "\n",
    "def draw_boxes_on_image(image, boxes, scores, classes):\n",
    "    num_boxes = boxes.shape[0]\n",
    "    for i in range(num_boxes):\n",
    "        class_and_score = str(idx2class()[classes[i]]) + \": \" + str(scores[i])\n",
    "        cv2.rectangle(img=image, pt1=(boxes[i, 0], boxes[i, 1]), pt2=(boxes[i, 2], boxes[i, 3]), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img=image, text=class_and_score, org=(boxes[i, 0], boxes[i, 1] - 10), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1.5, color=(0, 255, 255), thickness=2)\n",
    "    return image\n",
    "\n",
    "def test_single_picture(picture_dir, model):\n",
    "    image_array = cv2.imread(picture_dir)\n",
    "    print(image_array.shape)\n",
    "    image = DataLoader.image_preprocess(is_training=False, image_dir=picture_dir)\n",
    "    image = tf.expand_dims(input=image, axis=0)\n",
    "\n",
    "    outputs = model(image, training=True)\n",
    "    post_process = PostProcessing()\n",
    "    boxes, scores, classes = post_process.testing_procedure(outputs, [image_array.shape[0], image_array.shape[1]])\n",
    "#     print(\"-\"*50)\n",
    "#     print(\"boxes\")\n",
    "#     print(boxes)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"scores\")\n",
    "    print(scores)\n",
    "#     print(\"-\" * 50)\n",
    "#     print(\"classes\")\n",
    "#     print(classes)\n",
    "#     print(\"-\" * 50)\n",
    "    image_with_boxes = draw_boxes_on_image(image_array, boxes.astype(np.int), scores, classes)\n",
    "    return image_with_boxes\n",
    "\n",
    "def test_batch_picture(image_list, model):\n",
    "    outputs = model(image_list_batch, training=True)\n",
    "    post_process = PostProcessing()\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    classes = []\n",
    "    \n",
    "    for i in range(32):\n",
    "        image_array  = image_list[i]\n",
    "        image  = tf.expand_dims(input=image_array, axis=0)     \n",
    "        print(outputs[i].shape)\n",
    "        print(image_list[i].shape)\n",
    "        print( [ image_array.shape[0], image_array.shape[1]])\n",
    "        boxes[i], scores[i], classes[i] = post_process.testing_procedure(outputs[i], [ image_array.shape[0], image_array.shape[1]])\n",
    "    \n",
    "    print(\"boxes : \", boxes.shape)\n",
    "    print(\"scores : \", scores.shape)\n",
    "    print(\"classes : \", classes.shape)\n",
    "    image_with_boxes = draw_boxes_on_image(image_array, boxes.astype(np.int), scores, classes)\n",
    "    return image_with_boxes\n",
    "\n",
    "def data_load(image_path):\n",
    "    path = image_path\n",
    "    count = 0\n",
    "    image_list = []\n",
    "    for item in os.listdir(path)[:32]:\n",
    "        imgpath = path +'/' + item\n",
    "        img = Image.open(imgpath)\n",
    "        arr = np.array(img)\n",
    "        image_list.append(arr)\n",
    "        #img.save(str(count) +  \"output.png\")\n",
    "        count = count +1\n",
    "    image_batch =  tf.image.resize(image_list, (512,512))\n",
    "#     image_temp = tf.data.Dataset.from_tensor_slices(image_list).batch(32).take(1)\n",
    "#     image_batch =  tf.image.resize(image_temp, (512,512))\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fe60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "tf.Tensor(\n",
      "[[[ 0.7088107   0.7109723  -0.27025694  0.0806222 ]\n",
      "  [ 1.1524887   0.90309393 -0.2866565   0.25125507]\n",
      "  [ 0.8455226   0.8777355  -0.30260748  0.14800467]\n",
      "  ...\n",
      "  [-1.4592397  -0.38103324  0.53015804  0.34384662]\n",
      "  [-1.072972   -0.27228624  0.609822   -0.05261111]\n",
      "  [-0.51025945 -0.351021    0.5311432  -0.643444  ]]], shape=(1, 49104, 4), dtype=float32)\n",
      "--------------------------------------------------\n",
      "scores\n",
      "[0.32910994 0.30569202]\n",
      "(480, 640, 3)\n",
      "tf.Tensor(\n",
      "[[[-4.0809271e-01 -8.8971719e-02 -2.6890066e-01  4.5591199e-01]\n",
      "  [-1.8167628e-01  3.4414700e-01 -1.6716890e-01  3.3359399e-01]\n",
      "  [ 1.0054319e-02  5.2168214e-01 -3.4370458e-01 -9.7476400e-02]\n",
      "  ...\n",
      "  [-1.3519413e+00 -1.2423390e+00  6.7243731e-01  3.6875263e-01]\n",
      "  [-7.5216192e-01 -5.8681273e-01  1.1325007e-02  5.0501954e-03]\n",
      "  [-4.2377129e-01 -3.6537039e-01 -1.0101125e-03 -9.6658194e-01]]], shape=(1, 49104, 4), dtype=float32)\n",
      "--------------------------------------------------\n",
      "scores\n",
      "[0.40829057 0.31488016]\n",
      "(480, 640, 3)\n",
      "tf.Tensor(\n",
      "[[[-0.04081653  0.5561842  -0.54598886 -0.11491933]\n",
      "  [ 0.26396012  0.5738553  -0.09997118 -0.0767349 ]\n",
      "  [ 0.08700636  0.7290679  -0.45408955 -0.05016575]\n",
      "  ...\n",
      "  [-2.0807357  -0.5225799   0.6027514   0.23651749]\n",
      "  [-0.787732   -0.2950503   0.20159984 -0.2986433 ]\n",
      "  [-0.50391984 -0.56720287 -0.1496337  -0.66796887]]], shape=(1, 49104, 4), dtype=float32)\n",
      "--------------------------------------------------\n",
      "scores\n",
      "[0.2832042  0.18703526]\n",
      "(682, 1023, 3)\n",
      "tf.Tensor(\n",
      "[[[ 1.4050871   0.15166534 -0.0513408   0.590167  ]\n",
      "  [ 1.2553864   0.58862793 -0.09008829  0.4680438 ]\n",
      "  [ 1.156559    0.5587679  -0.17032209  0.0945476 ]\n",
      "  ...\n",
      "  [-1.6572212  -0.42650092  0.1823886  -0.34243408]\n",
      "  [-1.0361915  -0.3102095   0.6361716  -0.00285149]\n",
      "  [-0.19324255 -0.42053592  0.52540386 -0.54751915]]], shape=(1, 49104, 4), dtype=float32)\n",
      "--------------------------------------------------\n",
      "scores\n",
      "[0.45545408 0.19196928]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # GPU settings\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "            \n",
    "    #load_weights_from_epoch = Config.load_weights_from_epoch_quan\n",
    "    \n",
    "    efficientdet = EfficientDet()\n",
    "    #efficientdet.load_weights(filepath=Config.save_model_dir + \"saved_model\")\n",
    " \n",
    "\n",
    "    load_weights_from_epoch = 555\n",
    "    efficientdet.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "    \n",
    "    \n",
    "#     image_path = './data/fire_smoke/train/JPEGImages'\n",
    "#     image_list_batch =  data_load(image_path)\n",
    "    \n",
    "#     t1 = time.time()\n",
    "#     outputs = efficientdet(image_list_batch, training=True)\n",
    "#     t2 = time.time()\n",
    "#     print(\"------------------------------------\")\n",
    "#     print(t2-t1)\n",
    "#     print(outputs.shape)\n",
    "    \n",
    "    \n",
    "#     image_output_list = test_batch_picture(image_list_batch, efficientdet)\n",
    "#     print(image_output_list.shape)\n",
    "    \n",
    "    test_image_dir_1 = \"./test_pictures/ck0kepbs9kdym0848hgpcf3y9_jpeg.rf.d0a63becb54a83b6b026f4b38a42933b.jpg\"\n",
    "\n",
    "    test_image_dir_2 = \"./test_pictures/ck0kewsaha6hh07215jgx1bp2_jpeg.rf.1a375d20560d0de016bb524921f7b2a9.jpg\"\n",
    "    \n",
    "    test_image_dir_3 = \"./test_pictures/ck0kfhu4n8q7f0701ixmonyig_jpeg.rf.a3cc5282520b3bac90718bdd5528bd76.jpg\"\n",
    "\n",
    "    test_image_dir_4 = \"./test_pictures/smoking_women.jpg\"\n",
    "    \n",
    "    \n",
    "    image = test_single_picture(picture_dir=test_image_dir_1, model=efficientdet)\n",
    "    cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"detect result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    image = test_single_picture(picture_dir=test_image_dir_2, model=efficientdet)\n",
    "    cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"detect result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    image = test_single_picture(picture_dir=test_image_dir_3, model=efficientdet)\n",
    "    cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"detect result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    image = test_single_picture(picture_dir=test_image_dir_4, model=efficientdet)\n",
    "    cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"detect result\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef51c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb21f5bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_48948/137353603.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[0mefficientdet_lite\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest_single_picture\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpicture_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest_image_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mefficientdet_lite\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnamedWindow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"detect result\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mWINDOW_NORMAL\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_48948/137353603.py\u001B[0m in \u001B[0;36mtest_single_picture\u001B[1;34m(picture_dir, model)\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[0minput_details\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_input_details\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[0moutput_details\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_output_details\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_details\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'index'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minvoke\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_details\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'index'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001B[0m in \u001B[0;36mset_tensor\u001B[1;34m(self, tensor_index, value)\u001B[0m\n\u001B[0;32m    605\u001B[0m       \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIf\u001B[0m \u001B[0mthe\u001B[0m \u001B[0minterpreter\u001B[0m \u001B[0mcould\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mset\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    606\u001B[0m     \"\"\"\n\u001B[1;32m--> 607\u001B[1;33m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_interpreter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSetTensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    608\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mresize_tensor_input\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstrict\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0."
     ]
    }
   ],
   "source": [
    "# tflite 평가 하기\n",
    "\n",
    "def idx2class():\n",
    "    return dict((v, k) for k, v in Config.pascal_voc_classes.items())\n",
    "\n",
    "\n",
    "def draw_boxes_on_image(image, boxes, scores, classes):\n",
    "    num_boxes = boxes.shape[0]\n",
    "    for i in range(num_boxes):\n",
    "        class_and_score = str(idx2class()[classes[i]]) + \": \" + str(scores[i])\n",
    "        cv2.rectangle(img=image, pt1=(boxes[i, 0], boxes[i, 1]), pt2=(boxes[i, 2], boxes[i, 3]), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img=image, text=class_and_score, org=(boxes[i, 0], boxes[i, 1] - 10), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1.5, color=(0, 255, 255), thickness=2)\n",
    "    return image\n",
    "\n",
    "def load_model(path):  \n",
    "    interpreter = tf.lite.Interpreter(model_path = path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "def test_single_picture(picture_dir, model):\n",
    "    image_array = cv2.imread(picture_dir)\n",
    "    image = DataLoader.image_preprocess(is_training=False, image_dir=picture_dir)\n",
    "    image = tf.expand_dims(input=image, axis=0)\n",
    "    \n",
    "    input_data = np.array(image, dtype = np.uint8)\n",
    "    input_details = model.get_input_details()[0]\n",
    "    output_details = model.get_output_details()[0]\n",
    "    model.set_tensor(input_details['index'], input_data)\n",
    "    model.invoke()\n",
    "    outputs= model.get_tensor(output_details['index'])\n",
    "    \n",
    "    print(outputs)\n",
    "    # 원래 outputs =  소수점 형태\n",
    "    # quantizaation model =  숫자 너무큼.. output_tensor shape 해결하기\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs = tf.constant(outputs)\n",
    "    \n",
    "    post_process = PostProcessing()\n",
    "    boxes, scores, classes = post_process.testing_procedure(outputs, [image_array.shape[0], image_array.shape[1]])\n",
    "    print(\"-\"*50)\n",
    "    print(\"boxes\")\n",
    "    print(boxes)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"scores\")\n",
    "    print(scores)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"classes\")\n",
    "    print(classes)\n",
    "    print(\"-\" * 50)\n",
    "    image_with_boxes = draw_boxes_on_image(image_array, boxes.astype(np.int), scores, classes)\n",
    "    return image_with_boxes\n",
    "\n",
    "test_image_dir = \"./data/fire_smoke/test/JPEGImages/ck0kdhymna0b10721v4wntit8_jpeg.rf.a08e34d04fb672ce6cf8e94e810ec81d.jpg\"\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "model_path = \"./tflite_model_quant.tflite\"\n",
    "efficientdet_lite = load_model(model_path)\n",
    "\n",
    "image = test_single_picture(picture_dir=test_image_dir, model=efficientdet_lite)\n",
    "\n",
    "cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc40eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}