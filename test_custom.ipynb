{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689f122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b496f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "from configuration import Config\n",
    "from core.efficientdet import EfficientDet, PostProcessing\n",
    "from data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b707efd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원래 모델\n",
    "\n",
    "def idx2class():\n",
    "    return dict((v, k) for k, v in Config.pascal_voc_classes.items())\n",
    "\n",
    "\n",
    "def draw_boxes_on_image(image, boxes, scores, classes):\n",
    "    num_boxes = boxes.shape[0]\n",
    "    for i in range(num_boxes):\n",
    "        class_and_score = str(idx2class()[classes[i]]) + \": \" + str(scores[i])\n",
    "        cv2.rectangle(img=image, pt1=(boxes[i, 0], boxes[i, 1]), pt2=(boxes[i, 2], boxes[i, 3]), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img=image, text=class_and_score, org=(boxes[i, 0], boxes[i, 1] - 10), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1.5, color=(0, 255, 255), thickness=2)\n",
    "    return image\n",
    "\n",
    "def test_single_picture(picture_dir, model):\n",
    "    image_array = cv2.imread(picture_dir)\n",
    "    print(image_array.shape)\n",
    "    image = DataLoader.image_preprocess(is_training=False, image_dir=picture_dir)\n",
    "    image = tf.expand_dims(input=image, axis=0)\n",
    "\n",
    "    outputs = model(image, training=True)\n",
    "    post_process = PostProcessing()\n",
    "    boxes, scores, classes = post_process.testing_procedure(outputs, [image_array.shape[0], image_array.shape[1]])\n",
    "#     print(\"-\"*50)\n",
    "#     print(\"boxes\")\n",
    "#     print(boxes)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"scores\")\n",
    "    print(scores)\n",
    "#     print(\"-\" * 50)\n",
    "#     print(\"classes\")\n",
    "#     print(classes)\n",
    "#     print(\"-\" * 50)\n",
    "    image_with_boxes = draw_boxes_on_image(image_array, boxes.astype(np.int), scores, classes)\n",
    "    return image_with_boxes\n",
    "\n",
    "# def test_batch_picture(image_list, model):\n",
    "#     outputs = model(image_list_batch, training=True)\n",
    "#     post_process = PostProcessing()\n",
    "#     boxes = []\n",
    "#     scores = []\n",
    "#     classes = []\n",
    "    \n",
    "#     for i in range(32):\n",
    "#         image_array  = image_list[i]\n",
    "#         image  = tf.expand_dims(input=image_array, axis=0)     \n",
    "#         print(outputs[i].shape)\n",
    "#         print(image_list[i].shape)\n",
    "#         print( [ image_array.shape[0], image_array.shape[1]])\n",
    "#         boxes[i], scores[i], classes[i] = post_process.testing_procedure(outputs[i], [ image_array.shape[0], image_array.shape[1]])\n",
    "    \n",
    "#     print(\"boxes : \", boxes.shape)\n",
    "#     print(\"scores : \", scores.shape)\n",
    "#     print(\"classes : \", classes.shape)\n",
    "#     image_with_boxes = draw_boxes_on_image(image_array, boxes.astype(np.int), scores, classes)\n",
    "#     return image_with_boxes\n",
    "\n",
    "# def data_load(image_path):\n",
    "#     path = image_path\n",
    "#     count = 0\n",
    "#     image_list = []\n",
    "#     for item in os.listdir(path)[:32]:\n",
    "#         imgpath = path +'/' + item\n",
    "#         img = Image.open(imgpath)\n",
    "#         arr = np.array(img)\n",
    "#         image_list.append(arr)\n",
    "#         #img.save(str(count) +  \"output.png\")\n",
    "#         count = count +1\n",
    "#     image_batch =  tf.image.resize(image_list, (512,512))\n",
    "# #     image_temp = tf.data.Dataset.from_tensor_slices(image_list).batch(32).take(1)\n",
    "# #     image_batch =  tf.image.resize(image_temp, (512,512))\n",
    "#     return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56fe60b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Config' has no attribute 'best_model_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11476/1815130369.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mload_weights_from_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mefficientdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_model_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"epoch-{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_weights_from_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m#efficientdet.load_weights(filepath=Config.best_model_dir+\"epoch-{}_cus\".format(load_weights_from_epoch))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#efficientdet.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Config' has no attribute 'best_model_dir'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # GPU settings\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "            \n",
    "    #load_weights_from_epoch = Config.load_weights_from_epoch_quan\n",
    "    \n",
    "    efficientdet = EfficientDet()\n",
    "    #efficientdet.load_weights(filepath=Config.save_model_dir + \"saved_model\")\n",
    " \n",
    "\n",
    "    load_weights_from_epoch = 100\n",
    "    efficientdet.load_weights(filepath=Config.best_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "    #efficientdet.load_weights(filepath=Config.best_model_dir+\"epoch-{}_cus\".format(load_weights_from_epoch))\n",
    "    #efficientdet.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "    #efficientdet.load_weights(filepath=Config.save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "    \n",
    "#     image_path = './data/fire_smoke/train/JPEGImages'\n",
    "#     image_list_batch =  data_load(image_path)\n",
    "    \n",
    "#     t1 = time.time()\n",
    "#     outputs = efficientdet(image_list_batch, training=True)\n",
    "#     t2 = time.time()\n",
    "#     print(\"------------------------------------\")\n",
    "#     print(t2-t1)\n",
    "#     print(outputs.shape)\n",
    "    \n",
    "    \n",
    "#     image_output_list = test_batch_picture(image_list_batch, efficientdet)\n",
    "#     print(image_output_list.shape)\n",
    "    \n",
    "    test_image_dir_1 = \"./test_pictures/KakaoTalk_20211103_192433256.png\"\n",
    "\n",
    "#     test_image_dir_2 = \"./test_pictures/ck0kewsaha6hh07215jgx1bp2_jpeg.rf.1a375d20560d0de016bb524921f7b2a9.jpg\"\n",
    "    \n",
    "#     test_image_dir_3 = \"./test_pictures/ck0kfhu4n8q7f0701ixmonyig_jpeg.rf.a3cc5282520b3bac90718bdd5528bd76.jpg\"\n",
    "\n",
    "#     test_image_dir_4 = \"./test_pictures/smoking_women.jpg\"\n",
    "    \n",
    "    \n",
    "    image = test_single_picture(picture_dir=test_image_dir_1, model=efficientdet)\n",
    "    cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"detect result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "#     image = test_single_picture(picture_dir=test_image_dir_2, model=efficientdet)\n",
    "#     cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "#     cv2.imshow(\"detect result\", image)\n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "#     image = test_single_picture(picture_dir=test_image_dir_3, model=efficientdet)\n",
    "#     cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "#     cv2.imshow(\"detect result\", image)\n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "#     image = test_single_picture(picture_dir=test_image_dir_4, model=efficientdet)\n",
    "#     print(image.shape)\n",
    "#     cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "#     cv2.imshow(\"detect result\", image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef51c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-30 17:27:13.074276: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-30 17:27:13.794591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22854 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:18:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# tflite 평가 하기\n",
    "\n",
    "def idx2class():\n",
    "    return dict((v, k) for k, v in Config.pascal_voc_classes.items())\n",
    "\n",
    "\n",
    "def draw_boxes_on_image(image, boxes, scores, classes):\n",
    "    num_boxes = boxes.shape[0]\n",
    "    for i in range(num_boxes):\n",
    "        class_and_score = str(idx2class()[classes[i]]) + \": \" + str(scores[i])\n",
    "        cv2.rectangle(img=image, pt1=(boxes[i, 0], boxes[i, 1]), pt2=(boxes[i, 2], boxes[i, 3]), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img=image, text=class_and_score, org=(boxes[i, 0], boxes[i, 1] - 10), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1.5, color=(0, 255, 255), thickness=2)\n",
    "    return image\n",
    "\n",
    "def load_model(path):  \n",
    "    interpreter = tf.lite.Interpreter(model_path = path)\n",
    "    \n",
    "    interpreter.resize_tensor_input(0, [ 1 , 640, 640,   3])\n",
    "#     interpreter.resize_tensor_input(856, [ 1, 49104,     5])\n",
    "    \n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "def test_single_picture(picture_dir, model):\n",
    "    image_array = cv2.imread(picture_dir)\n",
    "    image = DataLoader.image_preprocess(is_training=False, image_dir=picture_dir)\n",
    "    image = tf.expand_dims(input=image, axis=0)\n",
    "    print(image.shape)\n",
    "    \n",
    "    input_data = np.array(image, dtype = np.uint8)\n",
    "    input_details = model.get_input_details()[0]\n",
    "    output_details = model.get_output_details()[0]\n",
    "    model.set_tensor(input_details['index'], input_data)\n",
    "    model.invoke()\n",
    "    outputs= model.get_tensor(output_details['index'])\n",
    "    \n",
    "    print(outputs)\n",
    "    # 원래 outputs =  소수점 형태\n",
    "    # quantizaation model =  숫자 너무큼.. output_tensor shape 해결하기\n",
    "    \n",
    "    outputs = tf.constant(outputs)\n",
    "    post_process = PostProcessing()\n",
    "    boxes, scores, classes = post_process.testing_procedure(outputs, [image_array.shape[0], image_array.shape[1]])\n",
    "    print(\"-\"*50)\n",
    "    print(\"boxes\")\n",
    "    print(boxes)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"scores\")\n",
    "    print(scores)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"classes\")\n",
    "    print(classes)\n",
    "    print(\"-\" * 50)\n",
    "    image_with_boxes = draw_boxes_on_image(image_array, boxes.astype(np.int), scores, classes)\n",
    "    return image_with_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideo():\n",
    "\n",
    "    video_capture = cv2.VideoCapture('rtsp://----------')\n",
    "    \n",
    "    video_capture.set(3, 800)  # 영상 가로길이 설정\n",
    "    video_capture.set(4, 600)  # 영상 세로길이 설정\n",
    "    fps = 20\n",
    "    # 가로 길이 가져오기\n",
    "    streaming_window_width = int(video_capture.get(3))\n",
    "    # 세로 길이 가져오기\n",
    "    streaming_window_height = int(video_capture.get(4))  \n",
    "\n",
    "    #파일 저장하기 위한 변수 선언\n",
    "    path = f'D:/cctv/cctv/python/{fileName}.avi'\n",
    "    fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True\n",
    "                                                 \n",
    "model_path = \"./tflite_model_quant_D1_SGD.tflite\"\n",
    "efficientdet_lite = load_model(model_path)   \n",
    "                                                 \n",
    "cap = cv2.VideoCapture(args.camera_idx)\n",
    "                                                 \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2_im = frame\n",
    "\n",
    "    cv2_im_rgb = cv2.cvtColor(cv2_im, cv2.COLOR_BGR2RGB)\n",
    "    cv2_im_rgb = cv2.resize(cv2_im_rgb, inference_size)\n",
    "    cv2_im = test_single_picture(interpreter, cv2_im_rgb.tobytes())\n",
    "    cv2.imshow('frame', cv2_im)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()                                        \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "model_path = \"./tflite_model_quant_D1_SGD.tflite\"\n",
    "efficientdet_lite = load_model(model_path)\n",
    "\n",
    "test_image_dir_1 = \"./test_pictures/ck0kepbs9kdym0848hgpcf3y9_jpeg.rf.d0a63becb54a83b6b026f4b38a42933b.jpg\"\n",
    "\n",
    "test_image_dir_2 = \"./test_pictures/ck0kewsaha6hh07215jgx1bp2_jpeg.rf.1a375d20560d0de016bb524921f7b2a9.jpg\"\n",
    "    \n",
    "test_image_dir_3 = \"./test_pictures/ck0kfhu4n8q7f0701ixmonyig_jpeg.rf.a3cc5282520b3bac90718bdd5528bd76.jpg\"\n",
    "\n",
    "test_image_dir_4 = \"./test_pictures/smoking_women.jpg\"\n",
    "    \n",
    "image = test_single_picture(picture_dir=test_image_dir_1, model=efficientdet_lite)\n",
    "cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "image = test_single_picture(picture_dir=test_image_dir_2, model=efficientdet_lite)\n",
    "cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "image = test_single_picture(picture_dir=test_image_dir_3, model=efficientdet_lite)\n",
    "cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    "image = test_single_picture(picture_dir=test_image_dir_4, model=efficientdet_lite)\n",
    "cv2.namedWindow(\"detect result\", flags=cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"detect result\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc40eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  7 21:33:10 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:86:00.0 Off |                  N/A |\r\n",
      "| 41%   42C    P8    21W / 280W |   1116MiB / 24220MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     52894      C   .../efficient_det/bin/python     1113MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
